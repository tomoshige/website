
<!doctype html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Statistics, Tomoshige Nakamura, Machine Learning, Juntendo University">
      
      
        <meta name="author" content="Tomoshige Nakamura">
      
      
        <link rel="canonical" href="https://tomoshige.github.io/website/research/note/lecture-note-automation/result/ocr_result/">
      
      
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.50">
    
    
      
        <title>Robust Statistics - Statistical Learning Laboratory</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#robust-statistics" class="md-skip">
          コンテンツにスキップ
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="ヘッダー">
    <a href="../../../../.." title="Statistical Learning Laboratory" class="md-header__button md-logo" aria-label="Statistical Learning Laboratory" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Statistical Learning Laboratory
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Robust Statistics
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="検索" placeholder="検索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="検索">
        
        <button type="reset" class="md-search__icon md-icon" title="クリア" aria-label="クリア" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            検索を初期化
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://tomoshige.github.io/website" title="リポジトリへ" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    tomoshige/website
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="タブ" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../lectures/" class="md-tabs__link">
          
  
    
  
  Lectures

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../" class="md-tabs__link">
          
  
    
  
  Research

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="ナビゲーション" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Statistical Learning Laboratory" class="md-nav__button md-logo" aria-label="Statistical Learning Laboratory" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Statistical Learning Laboratory
  </label>
  
    <div class="md-nav__source">
      <a href="https://tomoshige.github.io/website" title="リポジトリへ" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    tomoshige/website
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../lectures/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Lectures
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lectures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../lectures/LA/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Linear algebra
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Linear algebra
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/01-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/02-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Vector and Matrix1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/03-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Vector and Matrix2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/04-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Vector and Matrix3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/05-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Vector and Matrix4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/06-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Vector and Matrix5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/07-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Vector and Matrix6
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/08-vector-and-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Vector and Matrix7
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/09-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. Exersice
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/10-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/11-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/12-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    12. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/13-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    13. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/14-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    14. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/15-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    15. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/16-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    16. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/17-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    17. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/18-system-of-linear-equation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    18. System of Linear Equation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/19-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    19. Exercise
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/20-midterm-exam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    20. Midterm Exam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/21-determinant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    21. Determinant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/22-determinant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    22. Determinant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/23-determinant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    23. Determinant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/24-determinant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    24. Determinant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/25-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    25. Exercise
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/26-vector-space-and-inner-product/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    26. Vector space
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/27-vector-space-and-inner-product/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    27. Vector space
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/28-vector-space-and-inner-product/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    28. Vector space
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/29-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    29. Exercise
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/30-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    30. Exercise
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/31-exam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    31. Semester Exam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/32-eigen-value-vector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    32. Eigen value and vector
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/33-eigen-value-vector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    33. Eigen value and vector
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/34-eigen-value-vector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    34. Eigen value and vector
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/35-eigen-value-vector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    35. Eigen value and vector
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/36-eigen-value-vector/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    36. Eigen value and vector
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/37-exercise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    37. Exercise
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/38-midterm-exam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    38. Midterm Exam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/39-singular-value-decomposition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    39. Singular value decomposition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/40-singular-value-decomposition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    40. Singular value decomposition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/41-principal-component-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    41. Principal component analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/42-principal-component-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    42. Principal component analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/43-principal-component-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    43. Principal component analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/44-factor-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    44. Factor analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/45-factor-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    45. Factor analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/46-nonlinear-dimension-reduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    46. Nonlinear dimension reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/47-wrapup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    47. Wrap up
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/LA/48-exam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    48. Semester Exam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../lectures/SIWS/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Data Science without syntax
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Data Science without syntax
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/01-getting-started/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Getting-Started
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/02-visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Data Visualizaion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/03-wrangling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Data Wrangling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/04-data-import-and-tidy-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Data Import and Tidy Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/05-simple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Simple Linear Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/06-multiple-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Multiple Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/07-sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Sampling Method
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/08-Estimation-CI-Bootstrapping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Estimation, Confidence Interval and Bootstrapping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/09-hypothesis-testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. Hypothesis Testing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/10-inference-for-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. Inference for Regression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../lectures/SIWS/11-tell-your-story-with-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. Tell Your Story with Data
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../lectures/SP/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Statistics and Probability
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Statistics and Probability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Research
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Research
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../generalized-random-forests/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generalized random forests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../variable-importance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Variable Importance Measures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../forest-kernel-and-its-asymptotics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random forest kernels
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../consistency-of-soft-decision-trees/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Consistency of SRT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sparseBART/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sparse Causal BART
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../causal-mediation-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Causal mediation analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../causal-data-repository/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Causal data repository
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../causal-brain-analysis.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Causal Brain Analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../factor-analysis/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Factor analysis
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_10" id="__nav_3_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_10">
            <span class="md-nav__icon md-icon"></span>
            Factor analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/01-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. はじめに
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/02-factor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. 因子とは
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/03-factor-loading-matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. 因子負荷行列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/04-latent-factor-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. 潜在因子推定法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/05-rotation-and-interpretation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. 回転基準と結果の解釈
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/06-sensitivity-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. 感度分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/07-analysis-step/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. 因子分析の手順
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/08-simulation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. シミュレーション
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/09-pima-indians-diabetes-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. 糖尿病潜在原因分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/10-ordered-categorical-factor-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. 順序ありカテゴリカル変数の扱い
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/11-airline-passenger-satisfaction-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. 飛行機乗客満足度分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../factor-analysis/12-technical-note-matrix-factorization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    12. 行列分解と因子分析(Technical)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="robust-statistics">Robust Statistics</h1>
<h1 id="robust-statistics_1">Robust Statistics</h1>
<p>PETER J. HUBER<br>Professor of Statistics<br>Harvard University<br>Cambridge, Massachusetts</p>
<h2 id="john-wiley-sons">John Wiley \&amp; Sons</h2>
<p>New York ・ Chichester ・ Brisbane <span class="arithmatex">\(\cdot\)</span> Toronto ・ Singapore</p>
<p>A NOTE TO THE READER
This book has been electronically reproduced from digital information stored at John Wiley \&amp; Sons, Inc. We are pleased that the use of this new technology will enable us to keep works of enduring scholarly value in print as long as there is a reasonable demand for them. The content of this book is identical to previous printings.</p>
<p>Copyright (c) 1981 by John Wiley \&amp; Sons, Inc.
All rights reserved. Published simultaneously in Canada.
Reproduction or translation of any part of this work beyond that permitted by Sections 107 or 108 of the 1976 United States Copyright Act without the permission of the copyright owner is unlawful. Requests for permission or further information should be addressed to the Permissions Department, John Wiley \&amp; Sons, Inc.</p>
<p>Library of Congress Cataloging in Publication Data:
Huber, Peter J
Robust statistics.
(Wiley series in probability and mathematical statistics)
"A Wiley-Interscience publication."
Includes index.</p>
<ol>
<li>Robust statistics. I. Title.</li>
</ol>
<p>QA276.H785 519.5 80-18627
ISBN 0-471-41805-6
Printed in the United States of America</p>
<h1 id="preface">Preface</h1>
<p>The present monograph is the first systematic, book-length exposition of robust statistics. The technical term "robust" was coined only in 1953 (by G. E. P. Box), and the subject matter acquired recognition as a legitimate topic for investigation only in the mid-sixties, but it certainly never was a revolutionary new concept. Among the leading scientists of the late nineteenth and early twentieth century, there were several practicing statisticians (to name but a few: the astronomer S. Newcomb, the astrophysicist A. Eddington, and the geophysicist H. Jeffreys), who had a perfectly clear, operational understanding of the idea; they knew the dangers of long-tailed error distributions, they proposed probability models for gross errors, and they even invented excellent robust alternatives to the standard estimates, which were rediscovered only recently. But for a long time theoretical statisticians tended to shun the subject as being inexact and "dirty." My 1964 paper may have helped to dispel such prejudices. Amusingly (and disturbingly), it seems that lately a kind of bandwagon effect has evolved, that the pendulum has swung to the other extreme, and that "robust" has now become a magic word, which is invoked in order to add respectability.</p>
<p>This book gives a solid foundation in robustness to both the theoretical and the applied statistician. The treatment is theoretical, but the stress is on concepts, rather than on mathematical completeness. The level of presentation is deliberately uneven: in some chapters simple cases are treated with mathematical rigor; in others the results obtained in the simple cases are transferred by analogy to more complicated situations (like multiparameter regression and covariance matrix estimation), where proofs are not always available (or are available only under unrealistically severe assumptions). Also selected numerical algorithms for computing robust estimates are described and, where possible, convergence proofs are given.</p>
<p>Chapter 1 gives a general introduction and overview; it is a must for every reader. Chapter 2 contains an account of the formal mathematical background behind qualitative and quantitative robustness, which can be skipped (or skimmed) if the reader is willing to accept certain results on faith. Chapter 3 introduces and discusses the three basic types of estimates ( <span class="arithmatex">\(M\)</span>-, <span class="arithmatex">\(L\)</span>-, and <span class="arithmatex">\(R\)</span>-estimates), and Chapter 4 treats the asymptotic minimax</p>
<p>theory for location estimates; both chapters again are musts. The remaining chapters branch out in different directions and are fairly independent and self-contained; they can be read or taught in more or less any order.</p>
<p>The book does not contain exercises-I found it hard to invent a sufficient number of problems in this area that were neither trivial nor too hard-so it does not satisfy some of the formal criteria for a textbook. Nevertheless I have successfully used various stages of the manuscript as such in graduate courses.</p>
<p>The book also has no pretensions of being encyclopedic. I wanted to cover only those aspects and tools that I personally considered to be the most important ones. Some omissions and gaps are simply due to the fact that I currently lack time to fill them in, but do not want to procrastinate any longer (the first draft for this book goes back to 1972). Others are intentional. For instance, adaptive estimates were excluded because I would now prefer to classify them with nonparametric rather than with robust statistics, under the heading of nonparametric efficient estimation. The so-called Bayesian approach to robustness confounds the subject with admissible estimation in an ad hoc parametric supermodel, and still lacks reliable guidelines on how to select the supermodel and the prior so that we end up with something robust. The coverage of <span class="arithmatex">\(L\)</span> - and <span class="arithmatex">\(R\)</span>-estimates was cut back from earlier plans because they do not generalize well and get awkward to compute and to handle in multiparameter situations.</p>
<p>A large part of the final draft was written when I was visiting Harvard University in the fall of 1977; my thanks go to the students, in particular to P. Rosenbaum and Y. Yoshizoe, who then sat in my seminar course and provided many helpful comments.</p>
<h1 id="p-j-huber">P. J. Huber</h1>
<h1 id="contents">Contents</h1>
<p>1 GENERALITIES ..... 1
1.1 Why Robust Procedures? ..... 1
1.2 What Should a Robust Procedure Achieve? ..... 5
1.3 Qualitative Robustness, ..... 7
1.4 Quantitative Robustness, ..... 10
1.5 Infinitesimal Aspects, ..... 13
1.6 Optimal Robustness, ..... 16
1.7 Computation of Robust Estimates, ..... 17
2 THE WEAK TOPOLOGY AND ITS METRIZATION ..... 20
2.1 General Remarks, ..... 20
2.2 The Weak Topology, ..... 20
2.3 Lévy and Prohorov Metrics, ..... 25
2.4 The Bounded Lipschitz Metric, ..... 29
2.5 Fréchet and Gâteaux Derivatives, ..... 34
2.6 Hampel's Theorem, ..... 40
3 THE BASIC TYPES OF ESTIMATES ..... 43
3.1 General Remarks, ..... 43
3.2 Maximum Likelihood Type Estimates ( <span class="arithmatex">\(M\)</span>-Estimates), ..... 43
3.3 Linear Combinations of Order Statistics ( <span class="arithmatex">\(L\)</span>-Estimates), ..... 55
3.4 Estimates Derived from Rank Tests ( <span class="arithmatex">\(R\)</span>-Estimates), ..... 61
3.5 Asymptotically Efficient <span class="arithmatex">\(M\)</span>-, <span class="arithmatex">\(L\)</span>-, and <span class="arithmatex">\(R\)</span>-Estimates, ..... 68
4 ASYMPTOTIC MINIMAX THEORY FOR ESTIMATING A LOCATION PARAMETER ..... 73
4.1 General Remarks, ..... 73
4.2 Minimax Bias, ..... 74
4.3 Minimax Variance: Preliminaries, ..... 76
4.4 Distributions Minimizing Fisher Information, ..... 77</p>
<p>4.5 Determination of <span class="arithmatex">\(F_{0}\)</span> by Variational Methods, ..... 82
4.6 Asymptotically Minimax <span class="arithmatex">\(M\)</span>-Estimates, ..... 94
4.7 On the Minimax Property for <span class="arithmatex">\(L\)</span> - and <span class="arithmatex">\(R\)</span>-Estimates, ..... 97
4.8 Descending <span class="arithmatex">\(M\)</span>-Estimates, ..... 100
4.9 Questions of Asymmetric Contamination, ..... 104
5 SCALE ESTIMATES ..... 107
5.1 General Remarks, ..... 107
5.2 <span class="arithmatex">\(M\)</span>-Estimates of Scale, ..... 109
5.3 L-Estimates of Scale, ..... 110
5.4 <span class="arithmatex">\(R\)</span>-Estimates of Scale, ..... 114
5.5 Asymptotically Efficient Scale Estimates, ..... 116
5.6 Distributions Minimizing Fisher Information for Scale, ..... 118
5.7 Minimax Properties, ..... 122
6 MULTIPARAMETER PROBLEMS, IN PARTICULAR JOINT ESTIMATION OF LOCATION AND SCALE ..... 127
6.1 General Remarks, ..... 127
6.2 Consistency of <span class="arithmatex">\(M\)</span>-Estimates, ..... 127
6.3 Asymptotic Normality of <span class="arithmatex">\(M\)</span>-Estimates, ..... 132
6.4 Simultaneous <span class="arithmatex">\(M\)</span>-Estimates of Location and Scale, ..... 135
6.5 M-Estimates with Preliminary Estimates of Scale, ..... 140
6.6 Quantitative Robustness Properties of Simultaneous Estimates for Location and Scale, ..... 141
6.7 The Computation of <span class="arithmatex">\(M\)</span>-Estimates, ..... 146
6.8 Studentizing, ..... 148
7 REGRESSION ..... 153
7.1 General Remarks, ..... 153
7.2 The Classical Linear Least Squares Case, ..... 155
7.3 Robustizing the Least Squares Approach, ..... 162
7.4 Asymptotics of Robust Regression Estimates, ..... 164
7.5 Conjectures and Empirical Results, ..... 170
7.6 Asymptotic Covariances and Their Estimation, ..... 172
7.7 Concomitant Scale Estimates, ..... 175
7.8 Computation of Regression <span class="arithmatex">\(M\)</span>-Estimates, ..... 179
7.9 Moderate Leverage Points, ..... 192
7.10 Analysis of Variance, ..... 195</p>
<p>8 ROBUST COVARIANCE AND CORRELATION MATRICES ..... 199
8.1 General Remarks, ..... 199
8.2 Estimation of Matrix Elements through Robust Variances, ..... 202
8.3 Estimation of Matrix Elements through Robust Correlation, ..... 204
8.4 An Affinely Invariant Approach, ..... 211
8.5 Estimates Determined by Implicit Equations, ..... 213
8.6 Existence and Uniqueness of Solutions, ..... 215
8.7 Influence Functions and Qualitative Robustness, ..... 223
8.8 Consistency and Asymptotic Normality, ..... 226
8.9 Breakdown Point, ..... 227
8.10 Least Informative Distributions, ..... 229
8.11 Some Notes on Computation, ..... 237
9 ROBUSTNESS OF DESIGN ..... 243
9.1 General Remarks, ..... 243
9.2 Minimax Global Fit, ..... 243
9.3 Minimax Slope, ..... 251
10 EXACT FINITE SAMPLE RESULTS ..... 253
10.1 General Remarks, ..... 253
10.2 Lower and Upper Probabilities and Capacities, ..... 254
10.3 Robust Tests, ..... 264
10.4 Sequential Tests, ..... 273
10.5 The Neyman-Pearson Lemma for 2-Alternating Capacities, ..... 275
10.6 Estimates Derived from Tests, ..... 278
10.7 Minimax Interval Estimates, ..... 282
11 MISCELLANEOUS TOPICS ..... 286
11.1 Hampel's Extremal Problem, ..... 286
11.2 Shrinking Neighborhoods, ..... 290
REFERENCES ..... 294
INDEX ..... 301</p>
<p>Robust Statistics</p>
<h1 id="chapter-1">CHAPTER 1</h1>
<h2 id="generalities">Generalities</h2>
<h3 id="11-why-robust-procedures">1.1 WHY ROBUST PROCEDURES?</h3>
<p>Statistical inferences are based only in part upon the observations. An equally important base is formed by prior assumptions about the underlying situation. Even in the simplest cases, there are explicit or implicit assumptions about randomness and independence, about distributional models, perhaps prior distributions for some unknown parameters, and so on.</p>
<p>These assumptions are not supposed to be exactly true-they are mathematically convenient rationalizations of an often fuzzy knowledge or belief. As in every other branch of applied mathematics, such rationalizations or simplifications are vital, and one justifies their use by appealing to a vague continuity or stability principle: a minor error in the mathematical model should cause only a small error in the final conclusions.</p>
<p>Unfortunately, this does not always hold. During the past decades one has become increasingly aware that some of the most common statistical procedures (in particular, those optimized for an underlying normal distribution) are excessively sensitive to seemingly minor deviations from the assumptions, and a plethora of alternative "robust" procedures have been proposed.</p>
<p>The word "robust" is loaded with many-sometimes inconsistentconnotations. We use it in a relatively narrow sense: for our purposes, robustness signifies insensitivity to small deviations from the assumptions.</p>
<p>Primarily, we are concerned with distributional robustness: the shape of the true underlying distribution deviates slightly from the assumed model (usually the Gaussian law). This is both the most important case and the best understood one. Much less is known about what happens when the other standard assumptions of statistics are not quite satisfied and about the appropriate safeguards in these other cases.</p>
<p>The following example, due to Tukey (1960), shows the dramatic lack of distributional robustness of some of the classical procedures.</p>
<p>Example 1.1 Assume that we have a large, randomly mixed batch of <span class="arithmatex">\(n\)</span> "good" and "bad" observations <span class="arithmatex">\(x_{i}\)</span> of the same quantity <span class="arithmatex">\(\mu\)</span>. Each single observation with probability <span class="arithmatex">\(1-\varepsilon\)</span> is a "good" one, with probability <span class="arithmatex">\(\varepsilon\)</span> a "bad" one, where <span class="arithmatex">\(\varepsilon\)</span> is a small number. In the former case <span class="arithmatex">\(x_{i}\)</span> is <span class="arithmatex">\(\mathfrak{R}\left(\mu, \sigma^{2}\right)\)</span>, in the latter <span class="arithmatex">\(\mathfrak{R}\left(\mu, 9 \sigma^{2}\right)\)</span>. In other words all observations have the same mean, but the errors of some are increased by a factor of 3 .</p>
<p>Equivalently, we could say that the <span class="arithmatex">\(x_{i}\)</span> are independent, identically distributed with the common underlying distribution</p>
<div class="arithmatex">\[
F(x)=(1-\varepsilon) \Phi\left(\frac{x-\mu}{\sigma}\right)+\varepsilon \Phi\left(\frac{x-\mu}{3 \sigma}\right)
\]</div>
<p>where</p>
<div class="arithmatex">\[
\Phi(x)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} e^{-y^{2} / 2} d y
\]</div>
<p>is the standard normal cumulative.
Two time-honored measures of scatter are the mean absolute deviation</p>
<div class="arithmatex">\[
d_{n}=\frac{1}{n} \sum\left|x_{i}-\bar{x}\right|
\]</div>
<p>and the mean square deviation</p>
<div class="arithmatex">\[
s_{n}=\left[\frac{1}{n} \sum\left(x_{i}-\bar{x}\right)^{2}\right]^{1 / 2}
\]</div>
<p>There was a dispute between Eddington (1914, p. 147) and Fisher (1920, footnote on p. 762) about the relative merits of <span class="arithmatex">\(d_{n}\)</span> and <span class="arithmatex">\(s_{n}\)</span>. Eddington advocated the use of the former: "This is contrary to the advice of most textbooks; but it can be shown to be true." Fisher seemingly settled the matter by pointing out that for normal observations <span class="arithmatex">\(s_{n}\)</span> is about <span class="arithmatex">\(12 \%\)</span> more efficient than <span class="arithmatex">\(d_{n}\)</span>.</p>
<p>Of course, the two statistics measure different characteristics of the error distribution. For instance, if the errors are exactly normal, <span class="arithmatex">\(s_{n}\)</span> converges to <span class="arithmatex">\(\sigma\)</span>, while <span class="arithmatex">\(d_{n}\)</span> converges to <span class="arithmatex">\(\sqrt{2 / \pi} \sigma \approx 0.80 \sigma\)</span>. So we must be precise about how their performances are to be compared; we use the asymptotic relative</p>
<p>efficiency (ARE) of <span class="arithmatex">\(d_{n}\)</span> relative to <span class="arithmatex">\(s_{n}\)</span>, defined as follows:</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{ARE}(\varepsilon) &amp; =\lim _{n \rightarrow \infty} \frac{\operatorname{var}\left(s_{n}\right) /\left(E s_{n}\right)^{2}}{\operatorname{var}\left(d_{n}\right) /\left(E d_{n}\right)^{2}} \\
&amp; =\frac{\left[\frac{3(1+80 \varepsilon)}{(1+8 \varepsilon)^{2}}-1\right] / 4}{\frac{\pi(1+8 \varepsilon)}{2(1+2 \varepsilon)^{2}}-1}
\end{aligned}
\]</div>
<p>The results are summarized in the Exhibit 1.1.1.
The result is disquieting: just 2 bad observations in 1000 suffice to offset the <span class="arithmatex">\(12 \%\)</span> advantage of the mean square error, and <span class="arithmatex">\(\operatorname{ARE}(\varepsilon)\)</span> reaches a maximum value greater than 2 at about <span class="arithmatex">\(\varepsilon=0.05\)</span>.</p>
<p>This is particularly unfortunate since in the physical sciences typical "good data" samples appear to be well modeled by an error law of the form (1.1) with <span class="arithmatex">\(\varepsilon\)</span> in the range between 0.01 and 0.1 . (This does not imply that these samples contain between <span class="arithmatex">\(1 \%\)</span> and <span class="arithmatex">\(10 \%\)</span> gross errors, although this is very of ten true; the above law (1.1) may just be a convenient description of a slightly longer-tailed than normal distribution.) Thus it becomes painfully clear that the naturally occurring deviations from the idealized model are large enough to render meaningless the traditional asymptotic optimality theory: in practice we should certainly prefer <span class="arithmatex">\(d_{n}\)</span> to <span class="arithmatex">\(s_{n}\)</span>, since it is better for all <span class="arithmatex">\(\varepsilon\)</span> between 0.002 and 0.5 .</p>
<table>
<thead>
<tr>
<th style="text-align: left;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(\operatorname{ARE}(\varepsilon)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: center;">0.876</td>
</tr>
<tr>
<td style="text-align: left;">0.001</td>
<td style="text-align: center;">0.948</td>
</tr>
<tr>
<td style="text-align: left;">0.002</td>
<td style="text-align: center;">1.016</td>
</tr>
<tr>
<td style="text-align: left;">0.005</td>
<td style="text-align: center;">1.198</td>
</tr>
<tr>
<td style="text-align: left;">0.01</td>
<td style="text-align: center;">1.439</td>
</tr>
<tr>
<td style="text-align: left;">0.02</td>
<td style="text-align: center;">1.752</td>
</tr>
<tr>
<td style="text-align: left;">0.05</td>
<td style="text-align: center;">2.035</td>
</tr>
<tr>
<td style="text-align: left;">0.10</td>
<td style="text-align: center;">1.903</td>
</tr>
<tr>
<td style="text-align: left;">0.15</td>
<td style="text-align: center;">1.689</td>
</tr>
<tr>
<td style="text-align: left;">0.25</td>
<td style="text-align: center;">1.371</td>
</tr>
<tr>
<td style="text-align: left;">0.5</td>
<td style="text-align: center;">1.017</td>
</tr>
<tr>
<td style="text-align: left;">1.0</td>
<td style="text-align: center;">0.876</td>
</tr>
</tbody>
</table>
<p>Exhibit 1.1.1 Asymptotic efficiency of mean absolute relative to mean square deviation.
From Huber (1977b), with permission of the publisher.</p>
<p>To avoid misunderstandings, we should hasten to emphasize what is not implied here. First, the above does not imply that we advocate the use of the mean absolute deviation (there are still better estimates of scale). Second, some people have argued that the example is unrealistic insofar as the "bad" observations will stick out as outliers, so any conscientious statistician will do something about them before calculating the mean square error. This is beside the point; outlier rejection followed by the mean square error might very well beat the performance of the mean absolute error, but we are concerned here with the behavior of the unmodified classical estimates.</p>
<p>The example clearly has to do with longtailedness: lengthening the tails of the underlying distribution explodes the variance of <span class="arithmatex">\(s_{n}\)</span> ( <span class="arithmatex">\(d_{n}\)</span> is much less affected). Shortening the tails, on the other hand, produces quite negligible effects on the distributions of the estimates. (It may impair the absolute efficiency by decreasing the asymptotic Cramér-Rao bound, but the latter is so unstable under small changes of the distribution that this effect cannot be taken very seriously.)</p>
<p>The sensitivity of classical procedures to longtailedness is typical and not limited to this example. As a consequence "distributionally robust" and "outlier resistant," although conceptually distinct, are practically synonymous notions. Any reasonable, formal or informal, procedure for rejecting outliers will prevent the worst.</p>
<p>We might therefore ask whether robust procedures are needed at all; perhaps a two-step approach would suffice:
(1) First clean the data by applying some rule for outlier rejection.
(2) Then use classical estimation and testing procedures on the remainder.</p>
<p>Would these steps do the same job in a simpler way?
Unfortunately they will not, for the following reasons:
(1) It is rarely possible to separate the two steps cleanly; for instance, in multiparameter regression problems outliers are difficult to recognize unless we have reliable, robust estimates for the parameters.
(2) Even if the original batch of observations consists of normal observations interspersed with some gross errors, the cleaned data will not be normal (there will be statistical errors of both kinds, false rejections and false retentions), and the situation is even worse when the original batch derives from a genuine nonnormal distribution, instead of from a gross-error framework. Therefore the classical normal theory is not applicable to cleaned samples, and the</p>
<p>actual performance of such a two-step procedure may be more difficult to work out than that of a straight robust procedure.
(3) It is an empirical fact that the best rejection procedures do not quite reach the performance of the best robust procedures. The latter apparently are superior because they can make a smooth transition between full acceptance and full rejection of an observation. See Hampel (1974a, 1976).</p>
<h1 id="12-what-should-a-robust-procedure-achieve">1.2 WHAT SHOULD A ROBUST PROCEDURE ACHIEVE?</h1>
<p>We are adopting what might be called an "applied parametric viewpoint": we have a parametric model, which hopefully is a good approximation to the true underlying situation, but we cannot and do not assume that it is exactly correct. Therefore any statistical procedure should possess the following desirable features:
(1) It should have a reasonably good (optimal or nearly optimal) efficiency at the assumed model.
(2) It should be robust in the sense that small deviations from the model assumptions should impair the performance only slightly, that is, the latter (described, say, in terms of the asymptotic variance of an estimate, or of the level and power of a test) should be close to the nominal value calculated at the model.
(3) Somewhat larger deviations from the model should not cause a catastrophe.</p>
<p>If asymptotic performance criteria are used, some care is needed. In particular, the convergence should be uniform over a neighborhood of the model, or there should be at least a one-sided uniform bound, because otherwise we cannot guarantee robustness for any finite <span class="arithmatex">\(n\)</span>, no matter how large <span class="arithmatex">\(n\)</span> is. This point has often been overlooked in the past.</p>
<p>It should be emphasized once more that the occurrence of gross errors in a small fraction of the observations is to be regarded as a small deviation, and that, in view of the extreme sensitivity of some classical procedures, a primary goal of robust procedures is to safeguard against gross errors.</p>
<p>The literature contains many other explicit and implicit goals for robust procedures, for example, high asymptotic relative efficiency (relative to some classical reference procedures), or high absolute efficiency, and this either for completely arbitrary (sufficiently smooth) underlying distributions, or for a specific parametric family.</p>
<p>However, it seems to me that these goals are secondary in importance, and they should never be allowed to take precedence over the abovementioned three.</p>
<h1 id="robust-nonparametric-and-distribution-free">Robust, Nonparametric, and Distribution-Free</h1>
<p>Traditionally, robust procedures have been classified together with nonparametric and distribution-free ones. In our view the three notions have very little overlap.</p>
<p>A procedure is called nonparametric if it is supposed to be used for a broad, not-parametrized set of underlying distributions. For instance, the sample mean and the sample median are the nonparametric estimates of the population mean and median, respectively. Although nonparametric the sample mean is highly sensitive to outliers and therefore very nonrobust. In the relatively rare cases where one is specifically interested in estimating the true population mean, there is little choice except to pray and use the sample mean.</p>
<p>A test is called distribution-free if the probability of falsely rejecting the null hypothesis is the same for all possible underlying continuous distributions (optimal robustness of validity). The typical examples are the two-sample rank tests for testing equality between distributions. Most distribution-free tests happen to have a reasonably stable power and thus also a good robustness of total performance. But this seems to be a fortunate accident, since distribution-freeness does not imply anything about the behavior of the power function.</p>
<p>Estimates derived from a distribution-free test are sometimes also called distribution-free, but this is a misnomer: the stochastic behavior of point estimates is intimately connected with the power (not the level) of the parent tests and depends on the underlying distribution. The only exceptions are interval estimates derived from rank tests: for example the interval between two specified sample quantiles catches the true median with a fixed probability (but still the distribution of the length of this interval depends on the underlying distribution).</p>
<p>Robust methods, as conceived in this book, are much closer to the classical parametric ideas than to nonparametric or distribution-free ones. They are destined to work with parametric models; the only differences are that the latter are no longer supposed to be literally true, and that one is also trying to take this into account in a formal way.</p>
<p>In accordance with these ideas, we intend to standardize robust estimates such that they are consistent estimates of the unknown parameters at the idealized model. Because of robustness they will not drift too far away if the model is only approximately true. Outside of the model we then may</p>
<p>define the parameter to be estimated in terms of the limiting value of the estimate-for example, if we use the sample median, then the natural estimand is the population median, and so on.</p>
<h1 id="adaptive-procedures">Adaptive Procedures</h1>
<p>Stein (1956) discovered the possibility of devising nonparametric efficient tests and estimates. Later, several authors, in particular Takeuchi (1971), Beran (1974), Sacks (1975), and Stone (1975), described specific location estimates that are asymptotically efficient for all sufficiently smooth symmetric densities. Since we may say that these estimates adapt themselves to the underlying distribution, they have become known under the name of adaptive procedures. See also the review article by Hogg (1974).</p>
<p>At one time, it almost seemed as if the ultimate goal of robust estimation were to construct fully efficient adaptive estimates.</p>
<p>However, the connection between adaptivity and robustness is far from clear. The crucial point is that in robustness the emphasis rests much more on safety than on efficiency. The behavior of adaptive procedures under asymmetry is practically unexplored. For extremely large samples, where at first blush adaptive estimates look particularly attractive, the statistical variability of the estimate falls below its potential bias (caused by asymmetric contamination and the like), and robustness would therefore suggest to move toward a less efficient estimate, namely the sample median, that minimizes bias (see Section 4.2). We therefore prefer to follow Stein's original terminology and to classify adaptive estimates not under robustness, but under the heading of efficient nonparametric procedures.</p>
<h2 id="resistant-procedures">Resistant Procedures</h2>
<p>A statistical procedure is called resistant (see Mosteller and Tukey, 1977, p. 203) if the value of the estimate (or test statistic) is insensitive to small changes in the underlying sample (small changes in all, or large changes in a few of the values). The underlying distribution does not enter at all. This notion is particularly appropriate for (exploratory) data analysis and is of course conceptually distinct from robustness. However, in view of Hampel's theorem (Section 2.6), the two notions are for all practical purposes synonymous.</p>
<h3 id="13-qualitative-robustness">1.3 QUALITATIVE ROBUSTNESS</h3>
<p>In this section we motivate and give a formal definition of qualitative asymptotic robustness. For statistics representable as a functional <span class="arithmatex">\(T\)</span> of the</p>
<p>empirical distribution, qualitative robustness is essentially equivalent to weak(-star) continuity of <span class="arithmatex">\(T\)</span>, and for the sake of clarity we first discuss this particular case.</p>
<p>Many of the most common test statistics and estimators depend on the sample <span class="arithmatex">\(\left(x_{1}, \ldots, x_{n}\right)\)</span> only through the empirical distribution function</p>
<div class="arithmatex">\[
F_{n}(x)=n^{-1} \sum 1_{\left\{x_{i}&lt;x\right\}}
\]</div>
<p>or, for more general sample spaces, through the empirical measure</p>
<div class="arithmatex">\[
F_{n}=n^{-1} \sum \delta_{x_{i}}
\]</div>
<p>where <span class="arithmatex">\(\delta_{x}\)</span> stands for the pointmass 1 at <span class="arithmatex">\(x\)</span>, that is, we can write</p>
<div class="arithmatex">\[
T_{n}\left(x_{1}, \ldots, x_{n}\right)=T\left(F_{n}\right)
\]</div>
<p>for some functional <span class="arithmatex">\(T\)</span> defined (at least) on the space of empirical measures. Often <span class="arithmatex">\(T\)</span> has a natural extension to (a subspace of) the space <span class="arithmatex">\(\mathscr{R}\)</span> of all probability measures on the sample space. For instance, if the limit in probability exists, put</p>
<div class="arithmatex">\[
T(F)=\lim _{n \rightarrow \infty} T\left(F_{n}\right)
\]</div>
<p>where <span class="arithmatex">\(F\)</span> is the true underlying common distribution of the observations. If a functional <span class="arithmatex">\(T\)</span> satisfies (3.4), it is called consistent at <span class="arithmatex">\(F\)</span>.</p>
<p>Example 3.1 The Test Statistic of the Neyman-Pearson Lemma The most powerful tests between two densities <span class="arithmatex">\(p_{0}\)</span> and <span class="arithmatex">\(p_{1}\)</span> are based on a statistic of the form</p>
<div class="arithmatex">\[
\int \psi(x) F_{n}(d x)=\frac{1}{n} \sum \psi\left(x_{i}\right)
\]</div>
<p>with</p>
<div class="arithmatex">\[
\psi(x)=\log \frac{p_{1}(x)}{p_{0}(x)}
\]</div>
<p>Example 3.2 The maximum likelihood estimate of <span class="arithmatex">\(\theta\)</span> for an assumed underlying family of densities <span class="arithmatex">\(f(x, \theta)\)</span> is a solution of</p>
<div class="arithmatex">\[
\int \psi(x, \theta) F_{n}(d x)=0
\]</div>
<p>with</p>
<div class="arithmatex">\[
\psi(x, \theta)=\frac{\partial}{\partial \theta} \log f(x, \theta)
\]</div>
<p>Example 3.3 The <span class="arithmatex">\(\alpha\)</span>-trimmed mean can be written as</p>
<div class="arithmatex">\[
\bar{X}_{\alpha}=\frac{1}{1-2 \alpha} \int_{\alpha}^{1-\alpha} F_{n}^{-1}(t) d t
\]</div>
<p>Example 3.4 The so-called Hodges-Lehmann estimate is one-half of the median of the convolution square</p>
<div class="arithmatex">\[
\frac{1}{2} \operatorname{med}\left(F_{n} * F_{n}\right)
\]</div>
<p>(NOTE: this is the median of all <span class="arithmatex">\(n^{2}\)</span> pairwise means <span class="arithmatex">\(\left(x_{i}+x_{j}\right) / 2\)</span>; the more customary versions use only the pairs <span class="arithmatex">\(i&lt;j\)</span> or <span class="arithmatex">\(i&lt;j\)</span>, but are asymptotically equivalent.)</p>
<p>Assume now that the sample space is Euclidean, or more generally, a complete, separable metrizable space. We claim that, in this case, the natural robustness (more precisely, resistance) requirement for a statistic of the form (3.3) is that <span class="arithmatex">\(T\)</span> should be continuous with respect to the weak(-star) topology. By definition this is the weakest topology in the space <span class="arithmatex">\(\mathscr{M}\)</span> of all probability measures such that the map</p>
<div class="arithmatex">\[
F \rightarrow \int \psi d F
\]</div>
<p>from <span class="arithmatex">\(\mathscr{M}\)</span> into <span class="arithmatex">\(\mathbb{R}\)</span> is continuous whenever <span class="arithmatex">\(\psi\)</span> is bounded and continuous. The converse is also true: if a linear functional of the form (3.11) is weakly continuous, then <span class="arithmatex">\(\psi\)</span> must be bounded and continuous; see Chapter 2 for details.</p>
<p>The motivation behind this claim is the following basic resistance requirement. Take a linear statistic of the form (3.5) and make a small change in the sample, that is, make either small changes in all of the observations <span class="arithmatex">\(x_{i}\)</span> (rounding, grouping) or large changes in a few of them (gross errors, blunders). If <span class="arithmatex">\(\psi\)</span> is bounded and continuous, then this will result in a small change of <span class="arithmatex">\(T\left(F_{n}\right)=\int \psi d F_{n}\)</span>. But if <span class="arithmatex">\(\psi\)</span> is not bounded, then a single, strategically placed gross error can completely upset <span class="arithmatex">\(T\left(F_{n}\right)\)</span>. If <span class="arithmatex">\(\psi\)</span> is not continuous, and if <span class="arithmatex">\(F_{n}\)</span> happens to put mass onto discontinuity points, then small changes in many of the <span class="arithmatex">\(x_{i}\)</span> may produce a large change in <span class="arithmatex">\(T\left(F_{n}\right)\)</span>.</p>
<p>We conclude from this that our vague, intuitive notion of resistance or robustness should be made precise as follows: a linear functional <span class="arithmatex">\(T\)</span> is robust everywhere if and only if (iff) the corresponding <span class="arithmatex">\(\psi\)</span> is bounded and continuous, that is, iff <span class="arithmatex">\(T\)</span> is weakly continuous.</p>
<p>We could take this last property as our definition and call a (not necessarily linear) statistical functional <span class="arithmatex">\(T\)</span> robust if it is weakly continuous.</p>
<p>But, following Hampel (1971), we prefer to adopt a slightly more general definition.</p>
<p>Let the observations <span class="arithmatex">\(x_{i}\)</span> be independent identically distributed, with common distribution <span class="arithmatex">\(F\)</span>, and let <span class="arithmatex">\(\left(T_{n}\right)\)</span> be a sequence of estimates or test statistics <span class="arithmatex">\(T_{n}=T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span>. Then this sequence is called robust at <span class="arithmatex">\(F=F_{0}\)</span> if the sequence of maps of distributions</p>
<div class="arithmatex">\[
F \rightarrow \hat{\mathbb{C}}_{F}\left(T_{n}\right)
\]</div>
<p>is equicontinuous at <span class="arithmatex">\(F_{0}\)</span>, that is, if we take a suitable distance function <span class="arithmatex">\(d_{*}\)</span> in the space <span class="arithmatex">\(\mathscr{M}\)</span> of probability measures, metrizing the weak topology, and assume that, for each <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a <span class="arithmatex">\(\delta&gt;0\)</span> and an <span class="arithmatex">\(n_{0}&gt;0\)</span> such that, for all <span class="arithmatex">\(F\)</span> and all <span class="arithmatex">\(n \geqslant n_{0}\)</span>,</p>
<div class="arithmatex">\[
d_{*}\left(F_{0}, F\right) \leqslant \delta \Rightarrow d_{*}\left(\hat{\mathbb{C}}_{F_{0}}\left(T_{n}\right), \hat{\mathbb{C}}_{F}\left(T_{n}\right)\right) \leqslant \varepsilon
\]</div>
<p>If the sequence <span class="arithmatex">\(\left(T_{n}\right)\)</span> derives from a functional <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span>, then it is shown in Section 2.6 that this definition is essentially equivalent to weak continuity of <span class="arithmatex">\(T\)</span>.</p>
<p>Note the close formal analogy between this definition of robustness and stability of ordinary differential equations; let <span class="arithmatex">\(y_{x}(\cdot)\)</span> be the solution with initial value <span class="arithmatex">\(y(0)=x\)</span> of the differential equation</p>
<div class="arithmatex">\[
\frac{d y}{d t}=f(t, y)
\]</div>
<p>Then we have stability at <span class="arithmatex">\(x=x_{0}\)</span> if, for all <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a <span class="arithmatex">\(\delta&gt;0\)</span> such that, for all <span class="arithmatex">\(x\)</span> and all <span class="arithmatex">\(t \geqslant 0\)</span>,</p>
<div class="arithmatex">\[
d\left(x_{0}, x\right) \leqslant \delta \Rightarrow d\left(y_{x_{0}}(t), y_{x}(t)\right) \leqslant \varepsilon
\]</div>
<h1 id="14-quantitative-robustness">1.4 QUANTITATIVE ROBUSTNESS</h1>
<p>For several reasons it may be useful to describe quantitatively how greatly a small change in the underlying distribution <span class="arithmatex">\(F\)</span> changes the distribution</p>
<p><span class="arithmatex">\(\mathcal{E}_{F}\left(T_{n}\right)\)</span> of an estimate or test statistic <span class="arithmatex">\(T_{n}=T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span>. A few crude and simple numerical quantifiers might be more effective than a very detailed description.</p>
<p>To fix the idea assume that <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> derives from a functional <span class="arithmatex">\(T\)</span>. In most cases of practical, interest, <span class="arithmatex">\(T_{n}\)</span> is then consistent:</p>
<div class="arithmatex">\[
T_{n} \rightarrow T(F), \quad \text { in probability }
\]</div>
<p>and asymptotically normal</p>
<div class="arithmatex">\[
\mathcal{E}_{F}\left\{\sqrt{n}\left[T_{n}-T(F)\right]\right\} \rightarrow \mathscr{R}(0, A(F, T))
\]</div>
<p>Then it is convenient to discuss the quantitative large sample robustness of <span class="arithmatex">\(T\)</span> in terms of the behavior of its asymptotic bias <span class="arithmatex">\(T(F)-T\left(F_{0}\right)\)</span> and asymptotic variance <span class="arithmatex">\(A(F, T)\)</span> in some neighborhood <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\left(F_{0}\right)\)</span> of the model distribution <span class="arithmatex">\(F_{0}\)</span>.</p>
<p>For instance, <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> might be a Lévy neighborhood</p>
<div class="arithmatex">\[
\mathscr{P}_{\varepsilon}\left(F_{0}\right)=\left\{F \mid \forall t, F_{0}(t-\varepsilon)-\varepsilon \leqslant F(t) \leqslant F_{0}(t+\varepsilon)+\varepsilon\right\}
\]</div>
<p>or a contamination "neighborhood"</p>
<div class="arithmatex">\[
\mathscr{P}_{\varepsilon}\left(F_{0}\right)=\left\{F \mid F=(1-\varepsilon) F_{0}+\varepsilon H, H \in \mathscr{R} \mathbb{\}}\right.
\]</div>
<p>(the latter is not a neighborhood in the sense of the weak topology). Equation 4.4 is also called the gross error model.</p>
<p>The two most important characteristics then are the maximum bias</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=\sup _{F \in \mathscr{P}_{\varepsilon}}\left|T(F)-T\left(F_{0}\right)\right|
\]</div>
<p>and the maximum variance</p>
<div class="arithmatex">\[
v_{1}(\varepsilon)=\sup _{F \in \mathscr{P}_{\varepsilon}} A(F, T)
\]</div>
<p>We often consider a restricted supremum of <span class="arithmatex">\(A(F, T)\)</span> also, assuming that <span class="arithmatex">\(F\)</span> varies only over some slice of <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> where <span class="arithmatex">\(T(F)\)</span> stays constant, for example, only over the set of symmetric distributions.</p>
<p>Unfortunately, the above approach to the problem is conceptually inadequate; we should like to establish that, for sufficiently large <span class="arithmatex">\(n\)</span>, our estimate <span class="arithmatex">\(T_{n}\)</span> behaves well for all <span class="arithmatex">\(F \in \mathscr{P}_{\varepsilon}\)</span>. A description in terms of <span class="arithmatex">\(b_{1}\)</span> and <span class="arithmatex">\(v_{1}\)</span> would allow us to show that, for each fixed <span class="arithmatex">\(F \in \mathscr{P}_{\varepsilon}, T_{n}\)</span> behaves well for</p>
<p>sufficiently large <span class="arithmatex">\(n\)</span>. The distinction involves an interchange in the order of quantifiers and is fundamental, but has been largely ignored in the literature.</p>
<p>A better approach is as follows. Let <span class="arithmatex">\(M\left(F, T_{n}\right)\)</span> be the median of <span class="arithmatex">\(\hat{\mathcal{E}}_{F}\left[T_{n}-\right.\)</span> <span class="arithmatex">\(\left.T\left(F_{0}\right)\right]\)</span> and let <span class="arithmatex">\(Q_{t}\left(F, T_{n}\right)\)</span> be a normalized <span class="arithmatex">\(t\)</span>-quantile range of <span class="arithmatex">\(\hat{\mathcal{E}}_{F}\left(\sqrt{n} T_{n}\right)\)</span>, where, for any distribution <span class="arithmatex">\(G\)</span>, the normalized <span class="arithmatex">\(t\)</span>-quantile range is defined as</p>
<div class="arithmatex">\[
Q_{t}=\frac{G^{-1}(1-t)-G^{-1}(t)}{\Phi^{-1}(1-t)-\Phi^{-1}(t)}
\]</div>
<p><span class="arithmatex">\(\Phi\)</span> being the standard normal cumulative. The value of <span class="arithmatex">\(t\)</span> is arbitrary, but fixed, say <span class="arithmatex">\(t=0.25\)</span> (interquartile range) or <span class="arithmatex">\(t=0.025\)</span> ( <span class="arithmatex">\(95 \%\)</span> range, which is convenient in view of the traditional <span class="arithmatex">\(95 \%\)</span> confidence intervals). For a normal distribution, <span class="arithmatex">\(Q_{t}\)</span> coincides with the standard deviation; therefore <span class="arithmatex">\(Q_{t}^{2}\)</span> is sometimes called pseudo-variance.</p>
<p>Then define the maximum asymptotic bias and variance, respectively, as</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; b(\varepsilon)=\lim _{n} \sup _{F \in \mathscr{F}_{e}}\left|M\left(F, T_{n}\right)\right| \\
&amp; v(\varepsilon)=\lim _{n} \sup _{F \in \mathscr{F}_{e}} Q_{t}\left(F, T_{n}\right)^{2}
\end{aligned}
\]</div>
<p>THEOREM 4.1 If <span class="arithmatex">\(b_{1}\)</span> and <span class="arithmatex">\(v_{1}\)</span> are well-defined, we have <span class="arithmatex">\(b(\varepsilon) \geqslant b_{1}(\varepsilon)\)</span> and <span class="arithmatex">\(v(\varepsilon) \geqslant v_{1}(\varepsilon)\)</span>.
Proof Let <span class="arithmatex">\(T\left(F_{0}\right)=0\)</span> for simplicity and assume that <span class="arithmatex">\(T_{n}\)</span> is consistent: <span class="arithmatex">\(T\left(F_{n}\right) \rightarrow T(F)\)</span>. Then <span class="arithmatex">\(\lim _{n} M\left(F, T_{n}\right)=T(F)\)</span>, and we have the following obvious inequality, valid for any <span class="arithmatex">\(F \in \mathscr{F}_{e}\)</span> :</p>
<div class="arithmatex">\[
b(\varepsilon)=\lim _{n} \sup _{F \in \mathscr{F}_{e}}\left|M\left(F, T_{n}\right)\right| \geqslant \lim _{n}\left|M\left(F, T_{n}\right)\right|=|T(F)|
\]</div>
<p>hence</p>
<div class="arithmatex">\[
b(\varepsilon) \geqslant \sup _{F \in \mathscr{F}_{e}}|T(F)|=b_{1}(\varepsilon)
\]</div>
<p>Similarly, if <span class="arithmatex">\(\sqrt{n}\left[T_{n}-T(F)\right]\)</span> has a limiting normal distribution, we have <span class="arithmatex">\(\lim _{n} Q_{t}\left(F, T_{n}\right)^{2}=A(F, T)\)</span>, and <span class="arithmatex">\(v(\varepsilon) \geqslant v_{1}(\varepsilon)\)</span> follows in the same fashion as above.</p>
<p>The quantities <span class="arithmatex">\(b\)</span> and <span class="arithmatex">\(v\)</span> are awkward to handle, so we usually work with <span class="arithmatex">\(b_{1}\)</span> and <span class="arithmatex">\(v_{1}\)</span> instead. We are then, however, obliged to check whether, for the</p>
<p>particular <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> and <span class="arithmatex">\(T\)</span> under consideration, we have <span class="arithmatex">\(b_{1}=b\)</span> and <span class="arithmatex">\(v_{1}=v\)</span>. Fortunately, this is usually true.</p>
<p>THEOREM 4.2 If <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> is the Lévy neighborhood, then <span class="arithmatex">\(b(\varepsilon) \leqslant b_{1}(\varepsilon+0)=\)</span> <span class="arithmatex">\(\lim _{\eta \downarrow \varepsilon} b_{1}(\eta)\)</span>.
Proof According to the Glivenko-Cantelli theorem, we have <span class="arithmatex">\(\sup \left|F_{n}(x)-\right.\)</span> <span class="arithmatex">\(F(x) \mid \rightarrow 0\)</span> in probability, uniformly in <span class="arithmatex">\(F\)</span>. Thus for any <span class="arithmatex">\(\delta&gt;0\)</span>, the probability of <span class="arithmatex">\(F_{n} \in \mathscr{P}_{\delta}(F)\)</span>, and hence of <span class="arithmatex">\(F_{n} \in \mathscr{P}_{\varepsilon+\delta}\left(F_{0}\right)\)</span>, will tend to 1 , uniformly in <span class="arithmatex">\(F\)</span> for <span class="arithmatex">\(F \in \mathscr{P}_{\varepsilon}\left(F_{0}\right)\)</span>. Hence <span class="arithmatex">\(b(\varepsilon) \leqslant b_{1}(\varepsilon+\delta)\)</span> for all <span class="arithmatex">\(\delta&gt;0\)</span>.</p>
<p>Note that, for the above types of neighborhoods, <span class="arithmatex">\(\mathscr{P}_{1}=\mathscr{R}\)</span> is the set of all probability measures on the sample space, so <span class="arithmatex">\(b(1)\)</span> is the worst possible value of <span class="arithmatex">\(b\)</span> (usually <span class="arithmatex">\(\infty\)</span> ). We define the asymptotic breakdown point of <span class="arithmatex">\(T\)</span> at <span class="arithmatex">\(F_{0}\)</span> as</p>
<div class="arithmatex">\[
\varepsilon^{*}=\varepsilon^{*}\left(F_{0}, T\right)=\sup \{\varepsilon \mid b(\varepsilon)&lt;b(1)\}
\]</div>
<p>Roughly speaking, the breakdown point gives the limiting fraction of bad outliers the estimator can cope with. In many cases <span class="arithmatex">\(\varepsilon^{*}\)</span> does not depend on <span class="arithmatex">\(F_{0}\)</span>, and it is often the same for all the usual choices for <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span>.
Example 4.1 The breakdown point of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean is <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span>. (This is intuitively obvious; for a formal derivation see Section 3.3.)</p>
<p>Similarly we may also define an asymptotic variance breakdown point</p>
<div class="arithmatex">\[
\varepsilon^{* *}=\varepsilon^{* *}\left(F_{0}, T\right)=\sup \{\varepsilon \mid v(\varepsilon)&lt;v(1)\}
\]</div>
<p>but this is a much less useful notion.</p>
<h1 id="15-infinitesimal-aspects">1.5 INFINITESIMAL ASPECTS</h1>
<p>What happens if we add one more observation with value <span class="arithmatex">\(x\)</span> to a very large sample? Its suitably normed limiting influence on the value of an estimate or test statistic <span class="arithmatex">\(T\left(F_{n}\right)\)</span> can be expressed as</p>
<div class="arithmatex">\[
I C(x, F, T)=\lim _{s \rightarrow 0} \frac{T\left((1-s) F+s \delta_{x}\right)-T(F)}{s}
\]</div>
<p>where <span class="arithmatex">\(\delta_{x}\)</span> denotes the pointmass 1 at <span class="arithmatex">\(x\)</span>. The above quantity, considered as a function of <span class="arithmatex">\(x\)</span>, has been introduced by Hampel <span class="arithmatex">\((1968,1974)\)</span> under the name influence curve (IC) or influence function, and is perhaps the most</p>
<p>useful heuristic tool of robust statistics. It is treated in more detail in Section 2.5 .</p>
<p>If <span class="arithmatex">\(T\)</span> is sufficiently regular, it can be linearized near <span class="arithmatex">\(F\)</span> in terms of <span class="arithmatex">\(I C(x, F, T)\)</span>; if <span class="arithmatex">\(G\)</span> is near <span class="arithmatex">\(F\)</span>, then the leading terms of a Taylor expansion are</p>
<div class="arithmatex">\[
T(G)=T(F)+\int I C(x, F, T)[G(d x)-F(d x)]+\cdots
\]</div>
<p>We have</p>
<div class="arithmatex">\[
\int I C(x, F, T) F(d x)=0
\]</div>
<p>and, if we substitute the empirical distribution <span class="arithmatex">\(F_{n}\)</span> for <span class="arithmatex">\(G\)</span> in the above expansion, we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
\sqrt{n}\left(T\left(F_{n}\right)-T(F)\right) &amp; =\sqrt{n} \int I C(x, F, T) F_{n}(d x)+\cdots \\
&amp; =\frac{1}{\sqrt{n}} \sum I C\left(x_{i}, F, T\right)+\cdots
\end{aligned}
\]</div>
<p>By the central limit theorem, the leading term on the right-hand side is asymptotically normal with mean 0 , if the <span class="arithmatex">\(x_{i}\)</span> are independent with common distribution <span class="arithmatex">\(F\)</span>. Since it is often true (but not easy to prove) that the remaining terms are asymptotically negligible, <span class="arithmatex">\(\sqrt{n}\left[T\left(F_{n}\right)-T(F)\right]\)</span> is then asymptotically normal with mean 0 and variance</p>
<div class="arithmatex">\[
A(F, T)=\int I C(x, F, T)^{2} F(d x)
\]</div>
<p>Thus the influence function has two main uses. First, it allows us to assess the relative influence of individual observations toward the value of an estimate or test statistic. If it is unbounded, an outlier might cause trouble. Its maximum absolute value,</p>
<div class="arithmatex">\[
\gamma^{*}=\sup _{x}|I C(x, F, T)|
\]</div>
<p>has been called gross error sensitivity by Hampel. It is related to the maximum bias (4.5): take the gross error model (4.4), then, approximately,</p>
<div class="arithmatex">\[
T(F)-T\left(F_{0}\right) \approx \varepsilon \int I C\left(x, F_{0}, T\right) H(d x)
\]</div>
<p>Hence</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=\sup \left|T(F)-T\left(F_{0}\right)\right| \cong \varepsilon \gamma^{*}
\]</div>
<p>However some risky and possibly illegitimate interchanges of suprema and passages to the limit are involved here. We give two examples later (Section 3.5) where
(1) <span class="arithmatex">\(\gamma^{*}&lt;\infty\)</span> but <span class="arithmatex">\(b_{1}(\varepsilon)=\infty\)</span> for all <span class="arithmatex">\(\varepsilon&gt;0\)</span>.
(2) <span class="arithmatex">\(\gamma^{*}=\infty\)</span> but <span class="arithmatex">\(\lim b(\varepsilon)=0\)</span> for <span class="arithmatex">\(\varepsilon \rightarrow 0\)</span>.</p>
<p>Second, the influence curve allows an immediate and simple, heuristic assessment of the asymptotic properties of an estimate, since it allows us to guess an explicit formula (5.5) for the asymptotic variance (which then has to be proved rigorously by other means).</p>
<p>There are several finite sample and/or difference quotient versions of (5.1); the most important ones are the sensitivity curve (Tukey 1970) and the jackknife (Quenouille 1956, Tukey 1958, Miller 1964, 1974). We obtain the sensitivity curve if we replace <span class="arithmatex">\(F\)</span> by <span class="arithmatex">\(F_{n-1}\)</span> and <span class="arithmatex">\(s\)</span> by <span class="arithmatex">\(1 / n\)</span> in (5.1):</p>
<div class="arithmatex">\[
\begin{aligned}
S C_{n-1}(x) &amp; =\frac{T\left(\frac{n-1}{n} F_{n-1}+\frac{1}{n} \delta_{x}\right)-T\left(F_{n-1}\right)}{\frac{1}{n}} \\
&amp; =n\left[T_{n}\left(x_{1}, \ldots, x_{n-1}, x\right)-T_{n-1}\left(x_{1}, \ldots, x_{n-1}\right)\right]
\end{aligned}
\]</div>
<p>The jackknife is defined as follows. Consider an estimate <span class="arithmatex">\(T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span>, which is essentially the "same" across different sample sizes (for instance, assume that it is a functional of the empirical distribution). Then the ith jackknifed pseudo-value is, by definition,</p>
<div class="arithmatex">\[
T_{n i}^{*}=n T_{n}-(n-1) T_{n-1}\left(x_{1}, \ldots, x_{i-1}, x_{i+1}, \ldots, x_{n}\right)
\]</div>
<p>For example, if <span class="arithmatex">\(T_{n}\)</span> is the sample mean, then <span class="arithmatex">\(T_{n i}^{*}=x_{i}\)</span>. This is an approximation to <span class="arithmatex">\(I C\left(x_{i}\right)\)</span>; more precisely, if we substitute <span class="arithmatex">\(F_{n}\)</span> for <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(-1 /(n-1)\)</span> for <span class="arithmatex">\(s\)</span> in (5.1), we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \frac{T\left(\frac{n}{n-1} F_{n}-\frac{1}{n-1} \delta_{x_{i}}\right)-T\left(F_{n}\right)}{-\frac{1}{n-1}} \\
&amp; =(n-1)\left[T_{n}-T_{n-1}\left(x_{1}, \ldots, x_{i-1}, x_{i+1}, \ldots, x_{n}\right)\right] \\
&amp; =T_{n i}^{*}-T_{n}
\end{aligned}
\]</div>
<p>If <span class="arithmatex">\(T_{n}\)</span> is a consistent estimate of <span class="arithmatex">\(\theta\)</span>, whose bias has the asymptotic expansion</p>
<div class="arithmatex">\[
E\left(T_{n}-\theta\right)=\frac{a_{1}}{n}+\frac{a_{2}}{n^{2}}+O\left(\frac{1}{n^{3}}\right)
\]</div>
<p>then</p>
<div class="arithmatex">\[
T_{n}^{*}=\frac{1}{n} \sum_{i} T_{n i}^{*}
\]</div>
<p>has a smaller bias:</p>
<div class="arithmatex">\[
E\left(T_{n}^{*}-\theta\right)=-\frac{a_{2}}{n^{2}}+O\left(\frac{1}{n^{3}}\right)
\]</div>
<p>Example 5.1 If <span class="arithmatex">\(T_{n}=1 / n \sum\left(x_{i}-\bar{x}\right)^{2}\)</span>, then</p>
<div class="arithmatex">\[
T_{n i}^{*}=\frac{n}{n-1}\left(x_{i}-\bar{x}\right)^{2}
\]</div>
<p>and</p>
<div class="arithmatex">\[
T_{n}^{*}=\frac{1}{n-1} \sum\left(x_{i}-\bar{x}\right)^{2}
\]</div>
<p>Tukey (1958) pointed out that</p>
<div class="arithmatex">\[
\frac{1}{n(n-1)} \sum\left(T_{n i}^{*}-T_{n}^{*}\right)^{2}
\]</div>
<p>(a finite sample version of 5.5 ) usually is a good estimator of the variance of <span class="arithmatex">\(T_{n}\)</span>. (It can also be used as an estimate of the variance of <span class="arithmatex">\(T_{n}^{*}\)</span>, but it is better matched to <span class="arithmatex">\(T_{n}\)</span>.)</p>
<p>WARNING In some cases, namely when the influence function <span class="arithmatex">\(I C(x ; F, T)\)</span> does not depend smoothly on <span class="arithmatex">\(F\)</span>, the jackknife is in trouble and may yield a variance that is worse than useless. This happens, in particular, for estimates that are based on a small number of order statistics, like the median.</p>
<h1 id="16-optimal-robustness">1.6 OPTIMAL ROBUSTNESS</h1>
<p>In Section 1.4 we introduced some quantitative measures of robustness. They certainly are not the only ones. But, as we defined robustness to</p>
<p>mean insensitivity with regard to small deviations from the assumptions, any quantitative measure of robustness must somehow be concerned with the maximum degradation of performance possible for an <span class="arithmatex">\(\varepsilon\)</span>-deviation from the assumptions. An optimally robust procedure then minimizes this maximum degradation and hence will be a minimax procedure of some kind. As we have considerable freedom in how we quantize performance and <span class="arithmatex">\(\varepsilon\)</span>-deviations, we also have a host of notions of optimal robustness, of various usefulness, and of various mathematical manageability.</p>
<p>Exact, finite sample minimax results are available for two simple, but important special cases: the first corresponds to a robustification of the Neyman-Pearson lemma, and the second yields interval estimates of location. They are treated in Chapter 10. While the resulting tests and estimates are quite simple, the approach does not generalize well. In particular, it does not seem possible to obtain explicit, finite-sample results when there are nuisance parameters (e.g., when scale is unknown).</p>
<p>If we use asymptotic performance criteria (like asymptotic variances), we obtain asymptotic minimax estimates, treated in Chapters 4 to 6 . These asymptotic theories work well only if there is a high degree of symmetry (left-right symmetry, translation invariance, etc.), but they are able to cope with nuisance parameters. By a fortunate accident some of the asymptotic minimax estimates, although derived under quite different assumptions, coincide with certain finite-sample minimax estimates; this gives a strong heuristic support for using asymptotic optimality criteria.</p>
<p>Multiparameter regression, and the estimation of covariance matrices possess enough symmetries that the above asymptotic optimality results are transferable (Chapters 7 and 8). However the value of this transfer is somewhat questionable because of the fact that in practice the number of observations per parameter tends to be uncomfortably low. Other, designrelated dangers, like leverage points, may become more important than distributional robustness itself.</p>
<p>In problems lacking invariance, for instance in the general one-parameter estimation problem, Hampel (1968) has proposed optimizing robustness by minimizing the asymptotic variance at the model, subject to a bound on the gross-error sensitivity <span class="arithmatex">\(\gamma^{*}\)</span> defined by (5.6). This approach is technically the simplest one, but it has some conceptual drawbacks; reassuringly, it again yields the same estimates as those obtained by the exact, finite-sample minimax approach when the latter is applicable. For details, see Section 11.1.</p>
<h1 id="17-computation-of-robust-estimates">1.7 COMPUTATION OF ROBUST ESTIMATES</h1>
<p>In many practical applications of (say) the method of least squares, the actual setting up and solving of the least squares equations occupies only a</p>
<p>small fraction of the total length of the computer program. We should therefore strive for robust algorithms that can easily be patched into existing programs, rather than for comprehensive robust packages.</p>
<p>This is in fact possible. Technicalities are discussed in Chapter 7; the salient ideas are as follows.</p>
<p>Assume we are doing a least squares fit on observations <span class="arithmatex">\(y_{i}\)</span>, yielding fitted values <span class="arithmatex">\(\hat{y}_{i}\)</span>, and residuals <span class="arithmatex">\(r_{i}=y_{i}-\hat{y}_{i}\)</span>. Let <span class="arithmatex">\(s_{i}\)</span> be some estimate of the standard error of <span class="arithmatex">\(y_{i}\)</span> (or, even better, of the standard error of <span class="arithmatex">\(r_{i}\)</span> ).</p>
<p>We metrically Winsorize the observations <span class="arithmatex">\(y_{i}\)</span> and replace them by pseudoobservations <span class="arithmatex">\(y_{i}^{*}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
y_{i}^{*} &amp; =y_{i}, &amp; &amp; \text { if }\left|r_{i}\right| \leqslant c s_{i} \\
&amp; =\hat{y}_{i}-c s_{i}, &amp; &amp; \text { if } r_{i}&lt;-c s_{i} \\
&amp; =\hat{y}_{i}+c s_{i}, &amp; &amp; \text { if } r_{i}&gt;c s_{i}
\end{aligned}
\]</div>
<p>The constant <span class="arithmatex">\(c\)</span> regulates the amount of robustness; good choices are in the range between 1 and 2 , say <span class="arithmatex">\(c=1.5\)</span>.</p>
<p>Then use the pseudo-observations <span class="arithmatex">\(y_{i}^{*}\)</span> to calculate new fitted values <span class="arithmatex">\(\hat{y}_{i}\)</span> (and new <span class="arithmatex">\(s_{i}\)</span> ), and iterate to convergence.</p>
<p>If all observations are equally accurate, the classical estimate of the variance of a single observation would be</p>
<div class="arithmatex">\[
s^{2}=\frac{1}{n-p} \sum r_{i}^{2}
\]</div>
<p>and we can then estimate the standard error of the residual <span class="arithmatex">\(r_{i}\)</span> by <span class="arithmatex">\(s_{i}=\sqrt{1-h_{i}} s\)</span>, where <span class="arithmatex">\(h_{i}\)</span> is the <span class="arithmatex">\(i\)</span> th diagonal element of <span class="arithmatex">\(H=X\left(X^{T} X\right)^{-1} X^{T}\)</span>.</p>
<p>If we use modified residuals <span class="arithmatex">\(r_{i}^{*}=y_{i}^{*}-\hat{y}_{i}\)</span> instead of the <span class="arithmatex">\(r_{i}\)</span>, we clearly would underestimate scale; we can correct this bias (to a zero order approximation) by putting</p>
<div class="arithmatex">\[
s^{2}=\frac{\frac{1}{n-p} \sum r_{i}^{* 2}}{\left(\frac{m}{n}\right)^{2}}
\]</div>
<p>where <span class="arithmatex">\(n-p\)</span> is the number of observations minus the number of parameters, and <span class="arithmatex">\(m\)</span> is the number of unmodified observations <span class="arithmatex">\(\left(y_{i}^{*}=y_{i}\right)\)</span>.</p>
<p>It is evident that this procedure deflates the influence of outliers. Moreover there are versions of this procedure that are demonstrably convergent; they converge to a reasonably well-understood <span class="arithmatex">\(M\)</span>-estimate.</p>
<p>These ideas yield a completely general recipe to robustize almost any procedure: we first "clean" the data by pulling outliers towards their fitted values in the manner of (7.1), refitting iteratively until convergence is obtained. Then we apply the procedure in question to the pseudoobservations <span class="arithmatex">\(y_{i}^{*}\)</span>. Compare Huber (1979) and Kleiner et al. (1979) for specific examples.</p>
<h1 id="chapter-2">CHAPTER 2</h1>
<h2 id="the-weak-topology-and-its-metrization">The Weak Topology and its Metrization</h2>
<h3 id="21-general-remarks">2.1 GENERAL REMARKS</h3>
<p>This chapter attempts to give a more or less self-contained account of the formal mathematics underlying qualitative and quantitative robustness. It can be skipped by a reader who is willing to accept a number of results on faith: the more important ones are quoted and explained in an informal, heuristic fashion at the appropriate places elsewhere in this book.</p>
<p>The principal background references for this chapter are Prohorov (1956) and Billingsley (1968); some details on Polish spaces are most elegantly treated in Neveu (1964).</p>
<h3 id="22-the-weak-topology">2.2 THE WEAK TOPOLOGY</h3>
<p>Ordinarily, our sample space <span class="arithmatex">\(\Omega\)</span> is a finite dimensional Euclidean space. Somewhat more generally, we assume throughout this chapter that <span class="arithmatex">\(\Omega\)</span> is a Polish space, that is, a topological space whose topology is metrizable by some metric <span class="arithmatex">\(d\)</span>, such that <span class="arithmatex">\(\Omega\)</span> is complete and separable (i.e., contains a countable dense subset). Let <span class="arithmatex">\(\mathscr{M}\)</span> be the space of all probability measures on <span class="arithmatex">\((\Omega, \mathscr{B})\)</span>, where <span class="arithmatex">\(\mathscr{B}\)</span> is the Borel- <span class="arithmatex">\(\sigma\)</span>-algebra (i.e., the smallest <span class="arithmatex">\(\sigma\)</span>-algebra containing the open subsets of <span class="arithmatex">\(\Omega\)</span> ). By <span class="arithmatex">\(\mathscr{M}^{\prime}\)</span> we denote the set of finite signed measures on <span class="arithmatex">\((\Omega, \mathscr{B})\)</span>, that is the linear space generated by <span class="arithmatex">\(\mathscr{M}\)</span>. We use capital latin italic letters for the elements of <span class="arithmatex">\(\Omega\)</span>; if <span class="arithmatex">\(\Omega=\mathbb{R}\)</span> is the real line, we use the same letter <span class="arithmatex">\(F\)</span> for both the measure and the associated distribution function, with the convention that <span class="arithmatex">\(F(\cdot)\)</span> denotes the distribution function, <span class="arithmatex">\(F\{\cdot\}\)</span> the set function: <span class="arithmatex">\(F(x)=F[(-\infty, x)\}\)</span>.</p>
<p>It is well known that every measure <span class="arithmatex">\(F \in \mathscr{M}\)</span> is regular in the sense that any Borel set <span class="arithmatex">\(B \in \mathscr{B}\)</span> ca. 1 be approximated in <span class="arithmatex">\(F\)</span>-measure by compact sets <span class="arithmatex">\(C\)</span></p>
<p>from below and by open sets <span class="arithmatex">\(G\)</span> from above:</p>
<div class="arithmatex">\[
\sup _{C \subset B} F\{C\}=F\{B\}=\inf _{G \supset B} F\{G\}
\]</div>
<p>Compare, for example, Neveu (1964).
The weak(-star) topology in <span class="arithmatex">\(\mathscr{M}\)</span> is the weakest topology such that, for every bounded continuous function <span class="arithmatex">\(\psi\)</span>, the map</p>
<div class="arithmatex">\[
F \rightarrow \int \psi d F
\]</div>
<p>from <span class="arithmatex">\(\mathscr{M}\)</span> into <span class="arithmatex">\(\mathbb{R}\)</span> is continuous.
Let <span class="arithmatex">\(L\)</span> be a linear functional on <span class="arithmatex">\(\mathscr{M}\)</span> (or, more precisely, the restriction to <span class="arithmatex">\(\mathscr{M}\)</span> of a linear functional on <span class="arithmatex">\(\left.\mathscr{M}^{\prime}\right)\)</span>.</p>
<p>LEMMA 2.1 A linear functional <span class="arithmatex">\(L\)</span> is weakly continuous on <span class="arithmatex">\(\mathscr{M}\)</span> iff it can be represented in the form</p>
<div class="arithmatex">\[
L(F)=\int \psi d F
\]</div>
<p>for some bounded continuous function <span class="arithmatex">\(\psi\)</span>.
Proof Evidently, every functional representable in this way is linear and weakly continuous on <span class="arithmatex">\(\mathscr{M}\)</span>. Conversely, assume that <span class="arithmatex">\(L\)</span> is weakly continuous and linear. Put</p>
<div class="arithmatex">\[
\psi(x)=L\left(\delta_{x}\right)
\]</div>
<p>where <span class="arithmatex">\(\delta_{x}\)</span> denotes the measure putting a pointmass 1 at <span class="arithmatex">\(x\)</span>. Then, because of linearity, (2.3) holds for all <span class="arithmatex">\(F\)</span> with finite support. Clearly, whenever <span class="arithmatex">\(x_{n}\)</span> is a sequence of points converging to <span class="arithmatex">\(x\)</span>, then <span class="arithmatex">\(\delta_{x_{n}} \rightarrow \delta_{x}\)</span> weakly; hence</p>
<div class="arithmatex">\[
\psi\left(x_{n}\right)=L\left(\delta_{x_{n}}\right) \rightarrow L\left(\delta_{x}\right)=\psi(x)
\]</div>
<p>and <span class="arithmatex">\(\psi\)</span> must be continuous. If <span class="arithmatex">\(\psi\)</span> should be unbounded, say <span class="arithmatex">\(\sup \psi(x)=\infty\)</span>, then choose a sequence of points such that <span class="arithmatex">\(\psi\left(x_{n}\right) \geqslant n^{2}\)</span>, and let (with an arbitrary <span class="arithmatex">\(x_{0}\)</span> )</p>
<div class="arithmatex">\[
F_{n}=\left(1-\frac{1}{n}\right) \delta_{x_{0}}+\frac{1}{n} \delta_{x_{n}}
\]</div>
<p>Clearly, <span class="arithmatex">\(F_{n} \rightarrow \delta_{x_{0}}\)</span> weakly, but <span class="arithmatex">\(L\left(F_{n}\right)=\psi\left(x_{0}\right)+(1 / n)\left[\psi\left(x_{n}\right)-\psi\left(x_{0}\right)\right]\)</span> diverges.</p>
<p>This contradicts the assumed continuity of <span class="arithmatex">\(L\)</span>; hence <span class="arithmatex">\(\psi\)</span> must be bounded. Furthermore the measures with finite support are dense in <span class="arithmatex">\(\mathscr{M}\)</span> (for every <span class="arithmatex">\(F \in \mathscr{M}\)</span> and every finite set <span class="arithmatex">\(\left\{\psi_{1}, \ldots, \psi_{n}\right\}\)</span> of bounded continuous functions, we can easily find a measure <span class="arithmatex">\(F^{*}\)</span> with finite support such that <span class="arithmatex">\(\int \psi_{i} d F^{*}-\)</span> <span class="arithmatex">\(\int \psi_{i} d F\)</span> is arbitrarily small simultaneously for all <span class="arithmatex">\(i\)</span> ); hence the representation (2.3) holds for all <span class="arithmatex">\(F \in \mathscr{M}\)</span>.</p>
<p>LEMMA 2.2 The following statements are equivalent:
(1) <span class="arithmatex">\(F_{n} \rightarrow F\)</span> weakly.
(2) <span class="arithmatex">\(\liminf F_{n}\{G\} \geqslant F\{G\}\)</span> for all open sets <span class="arithmatex">\(G\)</span>.
(3) <span class="arithmatex">\(\limsup F_{n}\{A\} \leqslant F\{A\}\)</span> for all closed sets <span class="arithmatex">\(A\)</span>.
(4) <span class="arithmatex">\(\lim F_{n}\{B\}=F\{B\}\)</span> for all Borel sets with <span class="arithmatex">\(F\)</span>-null boundary (i.e., <span class="arithmatex">\(F\{\dot{B}\}=F\{B\}=F\{\widetilde{B}\}\)</span>, where <span class="arithmatex">\(\dot{B}\)</span> denotes the interior and <span class="arithmatex">\(\widetilde{B}\)</span> the closure of <span class="arithmatex">\(B\)</span>.</p>
<p>Proof We show <span class="arithmatex">\((1) \Rightarrow(2) \Leftrightarrow(3) \Rightarrow(4) \Rightarrow(1)\)</span>.
Equivalence of (2) and (3) is obvious, and we now show that they imply (4).</p>
<p>If <span class="arithmatex">\(B\)</span> has <span class="arithmatex">\(F\)</span>-null boundary, then it follows from (2) and (3) that</p>
<div class="arithmatex">\[
\liminf F_{n}\{\dot{B}\} \geqslant F\{\dot{B}\}=F\{B\}=F\{\widetilde{B}\} \geqslant \lim \sup F_{n}\{\widetilde{B}\}
\]</div>
<p>As</p>
<div class="arithmatex">\[
F_{n}\{\dot{B}\} \leqslant F_{n}\{B\} \leqslant F_{n}\{\widetilde{B}\}
\]</div>
<p>(4) follows.</p>
<p>We now show (1) <span class="arithmatex">\(\Rightarrow\)</span> (2). Let <span class="arithmatex">\(\varepsilon&gt;0\)</span>, let <span class="arithmatex">\(G\)</span> be open, and let <span class="arithmatex">\(A \subset G\)</span> be a closed set such that <span class="arithmatex">\(F\{A\} \geqslant F\{G\}-\varepsilon\)</span> (remember that <span class="arithmatex">\(F\)</span> is regular). By Urysohn's lemma [cf. Kelley (1955)] there is a continuous function <span class="arithmatex">\(\psi\)</span> satisfying <span class="arithmatex">\(1_{A} \leqslant \psi \leqslant 1_{G}\)</span>. Hence (1) implies</p>
<div class="arithmatex">\[
\liminf F_{n}\{G\} \geqslant \lim \int \psi d F_{n}=\int \psi d F \geqslant F\{A\} \geqslant F\{G\}-\varepsilon
\]</div>
<p>Since <span class="arithmatex">\(\varepsilon\)</span> was arbitrary, (2) follows.
It remains to show (4) <span class="arithmatex">\(\Rightarrow(1)\)</span>. It suffices to verify <span class="arithmatex">\(\int \psi d F_{n} \rightarrow \int \psi d F\)</span> for positive <span class="arithmatex">\(\psi\)</span>, say <span class="arithmatex">\(0 \leqslant \psi \leqslant M\)</span>; thus we can write</p>
<div class="arithmatex">\[
\int \psi d F_{n}=\int_{0}^{M} F_{n}\{\psi&gt;t\} d t
\]</div>
<p>For almost all <span class="arithmatex">\(t,\{\psi&gt;t\}\)</span> is an open set with <span class="arithmatex">\(F\)</span>-null boundary. Hence the</p>
<p>integrand in (2.4) converges to <span class="arithmatex">\(F\{\psi&gt;t\}\)</span> for almost all <span class="arithmatex">\(t\)</span>, and (1) now follows from the dominated convergence theorem.</p>
<p>COROLLARY 2.3 On the real line, weak convergence <span class="arithmatex">\(F_{n} \rightarrow F\)</span> holds iff the sequence of distribution functions converges at every continuity point of <span class="arithmatex">\(F\)</span>.</p>
<p>Proof If <span class="arithmatex">\(F_{n}\)</span> converges weakly, then (4) implies at once convergence at the continuity points of <span class="arithmatex">\(F\)</span>. Conversely, if <span class="arithmatex">\(F_{n}\)</span> converges at the continuity points of <span class="arithmatex">\(F\)</span>, then a straightforward monotonicity argument shows that</p>
<div class="arithmatex">\[
F(x)=F(x-0) \leqslant \liminf F_{n}(x) \leqslant \limsup F_{n}(x+0) \leqslant F(x+0)
\]</div>
<p>where <span class="arithmatex">\(F(x+0)\)</span> and <span class="arithmatex">\(F(x-0)\)</span> denote the left and right limits of <span class="arithmatex">\(F\)</span> at <span class="arithmatex">\(x\)</span>, respectively. We now verify (2). Every open set <span class="arithmatex">\(G\)</span> is a disjoint union of open intervals <span class="arithmatex">\(\left(a_{i}, b_{i}\right)\)</span>; thus</p>
<div class="arithmatex">\[
F_{n}(G)=\sum\left[F_{n}\left(b_{i}\right)-F_{n}\left(a_{i}+0\right)\right]
\]</div>
<p>Fatou's lemma now yields, in view of (2.5),</p>
<div class="arithmatex">\[
\begin{aligned}
\liminf F_{n}(G) &amp; \geqslant \sum \liminf \left[F_{n}\left(b_{i}\right)-F_{n}\left(a_{i}+0\right)\right] \\
&amp; \geqslant \sum\left[F\left(b_{i}\right)-F\left(a_{i}+0\right)\right]=F(G)
\end{aligned}
\]</div>
<p>DEFINITION 2.4 A subset <span class="arithmatex">\(\mathbb{S} \subset \mathscr{M}\)</span> is called tight if, for every <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a compact set <span class="arithmatex">\(K \subset \Omega\)</span> such that, for all <span class="arithmatex">\(F \in \mathbb{S}, F\{K\} \geqslant 1-\varepsilon\)</span>.</p>
<p>In particular, every finite subset is tight [this follows from regularity (2.1)].</p>
<p>LEMMA 2.5 A subset <span class="arithmatex">\(\mathbb{S} \subset \mathscr{M}\)</span> is tight iff, for every <span class="arithmatex">\(\varepsilon&gt;0, \delta&gt;0\)</span>, there is a finite union</p>
<div class="arithmatex">\[
B=\bigcup_{i} B_{i}
\]</div>
<p>of <span class="arithmatex">\(\delta\)</span>-balls, <span class="arithmatex">\(B_{i}=\{y \mid d\left(x_{i}, y\right) \leqslant \delta\}\)</span>, such that, for all <span class="arithmatex">\(F \in \mathbb{S}, F(B) \geqslant 1-\varepsilon\)</span>.
Proof If <span class="arithmatex">\(\mathbb{S}\)</span> is tight, then the existence of such a finite union of <span class="arithmatex">\(\delta\)</span>-balls follows easily from the fact that every compact set <span class="arithmatex">\(K \subset \Omega\)</span> can be covered by a finite union of open <span class="arithmatex">\(\delta\)</span>-balls.</p>
<p>Conversely, given <span class="arithmatex">\(\varepsilon&gt;0\)</span>, choose, for every natural number <span class="arithmatex">\(k\)</span>, a finite union <span class="arithmatex">\(B_{k}=\cup_{i=1}^{n_{k}} B_{k i}\)</span> of <span class="arithmatex">\(1 / k\)</span>-balls <span class="arithmatex">\(B_{k i}\)</span>, such that, for all <span class="arithmatex">\(F \in \mathbb{S}, F\left(B_{k}\right) \geqslant 1-\)</span> <span class="arithmatex">\(\varepsilon 2^{-k}\)</span>.</p>
<p>Let <span class="arithmatex">\(K=\cap B_{k}\)</span>, then evidently <span class="arithmatex">\(F(K) \geqslant 1-\Sigma \varepsilon 2^{-k}=1-\varepsilon\)</span>. We claim that <span class="arithmatex">\(K\)</span> is compact. As <span class="arithmatex">\(K\)</span> is closed it suffices to show that every sequence ( <span class="arithmatex">\(x_{n}\)</span> ) with <span class="arithmatex">\(x_{n} \in K\)</span> has an accumulation point (for Polish spaces, sequential compactness implies compactness). For each <span class="arithmatex">\(k, B_{k 1}, \ldots, B_{k n_{k}}\)</span> form a finite cover of <span class="arithmatex">\(K\)</span>; hence it is possible to inductively choose sets <span class="arithmatex">\(B_{k i_{k}}\)</span> such that, for all <span class="arithmatex">\(m, A_{m}=\cap_{k&lt;m} B_{k i_{k}}\)</span> contains infinitely many members of the sequence <span class="arithmatex">\(\left(x_{n}\right)\)</span>. Thus if we pick a subsequence <span class="arithmatex">\(x_{n_{m}} \in A_{m}\)</span>, it will be a Cauchy sequence, <span class="arithmatex">\(d\left(x_{n_{m}}, x_{n_{l}}\right) \leqslant 2 / \min (m, l)\)</span>, and, since <span class="arithmatex">\(\Omega\)</span> is complete, it converges.</p>
<p>THEOREM 2.6 (Prohorov) A set <span class="arithmatex">\(\mathfrak{S} \subset \mathscr{M}\)</span> is tight iff its weak closure is weakly compact.</p>
<p>Proof In view of Lemma 2.2(3) a set is tight iff its weak closure is, so it suffices to prove the theorem for weakly closed sets <span class="arithmatex">\(\mathscr{S} \subset \mathscr{M}\)</span>.</p>
<p>Let <span class="arithmatex">\(\mathcal{C}\)</span> be the space of bounded continuous functions on <span class="arithmatex">\(\Omega\)</span>. We rely on Daniell's theorem [see Neveu (1964), Proposition II.7.1], according to which a positive, linear functional <span class="arithmatex">\(L\)</span> on <span class="arithmatex">\(\mathcal{C}\)</span>, satisfying <span class="arithmatex">\(L(1)=1\)</span>, is induced by a probability measure <span class="arithmatex">\(F: L(\psi)=\int \psi d F\)</span> for some <span class="arithmatex">\(F \in \mathscr{M}\)</span> iff <span class="arithmatex">\(\psi_{n} \downarrow 0\)</span> (pointwise) implies <span class="arithmatex">\(L\left(\psi_{n}\right) \downarrow 0\)</span>.</p>
<p>Let <span class="arithmatex">\(\mathcal{E}\)</span> be the space of positive linear functionals on <span class="arithmatex">\(\mathcal{C}\)</span>, satisfying <span class="arithmatex">\(L(1) \leqslant 1\)</span>, topologized by the topology of pointwise convergence on <span class="arithmatex">\(\mathcal{C}\)</span>. Then <span class="arithmatex">\(\mathcal{E}\)</span> is compact, and <span class="arithmatex">\(\mathfrak{S}\)</span> can be identified with a subspace <span class="arithmatex">\(\mathfrak{S} \subset \mathcal{E}\)</span> in a natural way. Evidently, <span class="arithmatex">\(\mathfrak{S}\)</span> is compact iff it is closed as a subspace of <span class="arithmatex">\(\mathcal{E}\)</span>.</p>
<p>Now assume that <span class="arithmatex">\(\mathfrak{S}\)</span> is tight. Let <span class="arithmatex">\(L \in \mathcal{E}\)</span> be in the closure of <span class="arithmatex">\(\mathfrak{S}\)</span>; we want to show that <span class="arithmatex">\(L\left(\psi_{n}\right) \downarrow 0\)</span> for every monotone decreasing sequence <span class="arithmatex">\(\psi_{n} \downarrow 0\)</span> of bounded continuous functions. Without loss of generality we can assume <span class="arithmatex">\(0 \leqslant \psi_{n} \leqslant 1\)</span>. Let <span class="arithmatex">\(\varepsilon&gt;0\)</span> and let <span class="arithmatex">\(K\)</span> be such that, for all <span class="arithmatex">\(F \in \mathcal{S}, F(K) \geqslant 1-\varepsilon\)</span>. The restriction of <span class="arithmatex">\(\psi_{n}\)</span> to the compact set <span class="arithmatex">\(K\)</span> converges not only pointwise but uniformly, say <span class="arithmatex">\(\psi_{n} \leqslant \varepsilon\)</span> on <span class="arithmatex">\(K\)</span> for <span class="arithmatex">\(n \geqslant n_{0}\)</span>. Thus for all <span class="arithmatex">\(F \in \mathcal{S}\)</span> and all <span class="arithmatex">\(n \geqslant n_{0}\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
0 \leqslant \int \psi_{n} d F &amp; =\int_{K} \psi_{n} d F+\int_{K^{\tau}} \psi_{n} d F \\
&amp; \leqslant \int_{K} \varepsilon d F+\int_{K^{\tau}} 1 d F \leqslant 2 \varepsilon
\end{aligned}
\]</div>
<p>It follows that <span class="arithmatex">\(0 \leqslant L\left(\psi_{n}\right) \leqslant 2 \varepsilon\)</span>; hence <span class="arithmatex">\(\lim L\left(\psi_{n}\right)=0\)</span>, since <span class="arithmatex">\(\varepsilon\)</span> was arbitrary. Thus <span class="arithmatex">\(L\)</span> is induced by a probability measure; hence it lies in <span class="arithmatex">\(\mathfrak{S}\)</span> (which by assumption is a weakly closed subset of <span class="arithmatex">\(\mathscr{M}\)</span> ), and thus <span class="arithmatex">\(\mathfrak{S}\)</span> is compact ( <span class="arithmatex">\(\mathfrak{S}\)</span> being closed in <span class="arithmatex">\(\mathcal{E}\)</span> ).</p>
<p>Conversely, assume that <span class="arithmatex">\(\mathfrak{S}\)</span> is compact, and let <span class="arithmatex">\(\psi_{n} \in \mathcal{C}\)</span> and <span class="arithmatex">\(\psi_{n} \downarrow 0\)</span>. Then <span class="arithmatex">\(\int \psi_{n} d F \downarrow 0\)</span> pointwise on the compact set <span class="arithmatex">\(\mathfrak{S}\)</span>; thus, also uniformly, <span class="arithmatex">\(\sup _{F \in \mathcal{S}} \int \psi_{n} d F \downarrow 0\)</span>. We now choose <span class="arithmatex">\(\psi_{n}\)</span> as follows. Let <span class="arithmatex">\(\delta&gt;0\)</span> be given. Let <span class="arithmatex">\(\left(x_{n}\right)\)</span> be a dense sequence in <span class="arithmatex">\(\Omega\)</span>, and by Urysohn's lemma, let <span class="arithmatex">\(\varphi_{i}\)</span> be a continuous</p>
<p>function with values between 0 and 1 , such that <span class="arithmatex">\(\varphi_{i}(x)=0\)</span> for <span class="arithmatex">\(d\left(x_{i}, x\right) \leqslant \delta / 2\)</span> and <span class="arithmatex">\(\varphi_{i}(x)=1\)</span> for <span class="arithmatex">\(d\left(x_{i}, x\right) \geqslant \delta\)</span>. Put <span class="arithmatex">\(\psi_{n}(x)=\inf \left\{\varphi_{i}(x) \mid i \leqslant n\right\}\)</span>. Then <span class="arithmatex">\(\psi_{n} \downarrow 0\)</span> and <span class="arithmatex">\(\psi_{n} \geqslant 1_{A_{n}^{c}}\)</span>, where <span class="arithmatex">\(A_{n}\)</span> is the union of the <span class="arithmatex">\(\delta\)</span>-balls around <span class="arithmatex">\(x_{i}, i=1, \ldots, n\)</span>. Hence <span class="arithmatex">\(\sup _{F \in \mathbb{R}} F\left(A_{n}^{c}\right) \leqslant \sup _{F \in \mathbb{R}} \int \psi_{n} d F \downarrow 0\)</span>, and the conclusion follows from Lemma 2.5.</p>
<h1 id="23-levy-and-prohorov-metrics">2.3 LÉVY AND PROHOROV METRICS</h1>
<p>We now show that the space <span class="arithmatex">\(\mathscr{M}\)</span> of probability measures on a Polish space <span class="arithmatex">\(\Omega\)</span>, topologized by the weak topology, is itself a Polish space, that is complete separable metrizable.</p>
<p>For the real line <span class="arithmatex">\(\Omega=\mathbb{R}\)</span>, the most manageable metric metrizing <span class="arithmatex">\(\mathscr{M}\)</span> is the so-called Lévy distance.</p>
<p>DEFINITION 3.1 The Lévy distance between two distribution functions <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> is</p>
<div class="arithmatex">\[
d_{L}(F, G)=\inf \{\varepsilon \mid \forall x F(x-\varepsilon)-\varepsilon \leqslant G(x) \leqslant F(x+\varepsilon)+\varepsilon\}
\]</div>
<p>LEMMA 3.2 <span class="arithmatex">\(d_{L}\)</span> is a metric.
Proof We have to verify (1) <span class="arithmatex">\(d_{L}(F, G) \geqslant 0, d_{L}(F, G)=0\)</span> iff <span class="arithmatex">\(F=G\)</span>; (2) <span class="arithmatex">\(d_{L}(F, G)=d_{L}(G, F)\)</span>; (3) <span class="arithmatex">\(d_{L}(F, H) \leqslant d_{L}(F, G)+d_{L}(G, H)\)</span>. All of this is immediate.</p>
<p>NOTE <span class="arithmatex">\(\sqrt{2} d_{L}(F, G)\)</span> is the maximum distance between the graphs of <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>, measured along a <span class="arithmatex">\(45^{\circ}\)</span>-direction (see Exhibit 2.3.1).</p>
<p>THEOREM 3.3 The Lévy distance metrizes the weak topology.
<img alt="img-0.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhlbl 2.3.1</p>
<p>Proof In view of Lemma 2.3 it suffices to show that convergence of <span class="arithmatex">\(F_{n} \rightarrow F\)</span> at the continuity points of <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(d_{L}\left(F, F_{n}\right) \rightarrow 0\)</span> are equivalent. (1) Assume <span class="arithmatex">\(d_{L}\left(F, F_{n}\right) \rightarrow 0\)</span>. If <span class="arithmatex">\(x\)</span> is a continuity point of <span class="arithmatex">\(F\)</span>, then <span class="arithmatex">\(F(x \pm \varepsilon) \pm \varepsilon \rightarrow F(x)\)</span> as <span class="arithmatex">\(\varepsilon \rightarrow 0\)</span>; hence <span class="arithmatex">\(F_{n}\)</span> converges at <span class="arithmatex">\(x\)</span>. (2) Assume that <span class="arithmatex">\(F_{n} \rightarrow F\)</span> at the continuity points of <span class="arithmatex">\(F\)</span>. Let <span class="arithmatex">\(x_{0}&lt;x_{1}&lt;\cdots&lt;\cdots&lt;x_{N}\)</span> be continuity points of <span class="arithmatex">\(F\)</span> such that <span class="arithmatex">\(F\left(x_{0}\right)&lt;\varepsilon / 2, F\left(x_{N}\right)&gt;1-\varepsilon / 2\)</span>, and that <span class="arithmatex">\(x_{i+1}-x_{i}&lt;\varepsilon\)</span>. Let <span class="arithmatex">\(n_{0}\)</span> be so large that, for all <span class="arithmatex">\(i\)</span> and all <span class="arithmatex">\(n \geqslant n_{0},\left|F_{n}\left(x_{i}\right)-F\left(x_{i}\right)\right|&lt;\varepsilon / 2\)</span>. Then for <span class="arithmatex">\(x_{i-1} \leqslant x \leqslant x_{i}\)</span>,</p>
<div class="arithmatex">\[
F_{n}(x) \leqslant F_{n}\left(x_{i}\right)&lt;F\left(x_{i}\right)+\frac{\varepsilon}{2} \leqslant F(x+\varepsilon)+\varepsilon
\]</div>
<p>This bound obviously also holds for <span class="arithmatex">\(x&lt;x_{0}\)</span> and for <span class="arithmatex">\(x&gt;x_{N}\)</span>. In the same way we establish <span class="arithmatex">\(F_{n}(x) \geqslant F(x-\varepsilon)-\varepsilon\)</span>.</p>
<p>For general Polish sample spaces <span class="arithmatex">\(\Omega\)</span>, the weak topology in <span class="arithmatex">\(\mathscr{M}\)</span> can be metrized by the so-called Prohorov distance. Conceptually, this is the most attractive metric; however, it is not very manageable for actual calculations. We need a few preparatory definitions.</p>
<p>For any subset <span class="arithmatex">\(A \subset \Omega\)</span>, we define the closed <span class="arithmatex">\(\delta\)</span>-neighborhood of <span class="arithmatex">\(A\)</span> as</p>
<div class="arithmatex">\[
A^{\delta}=\{x \in \Omega \mid \inf _{y \in A} d(x, y) \leqslant \delta\}
\]</div>
<p>LEMMA 3.4 For any arbitrary set <span class="arithmatex">\(A\)</span>, we have</p>
<div class="arithmatex">\[
A^{\delta}=\overline{A^{\delta}}=\overline{A^{\delta}}=\overline{\overline{A^{\delta}}}
\]</div>
<p>(where an overbar denotes closure). In particular, <span class="arithmatex">\(A^{\delta}\)</span> is closed.
Proof It suffices to show</p>
<div class="arithmatex">\[
\overline{\overline{A^{\delta}}} \subset A^{\delta}
\]</div>
<p>Let</p>
<div class="arithmatex">\[
\eta&gt;0 \quad \text { and } \quad x \in \overline{\overline{A^{\delta}}}
\]</div>
<p>Then we can successively find <span class="arithmatex">\(y \in \overline{A^{\delta}}, z \in \bar{A}\)</span>, and <span class="arithmatex">\(t \in A\)</span>, such that <span class="arithmatex">\(d(x, y)&lt;\eta\)</span>, <span class="arithmatex">\(d(y, z)&lt;\delta+\eta\)</span>, and <span class="arithmatex">\(d(z, t)&lt;\eta\)</span>. Thus <span class="arithmatex">\(d(x, t)&lt;\delta+3 \eta\)</span>, and, since <span class="arithmatex">\(\eta\)</span> was arbitrary, <span class="arithmatex">\(x \in A^{\delta}\)</span>.</p>
<p>Let <span class="arithmatex">\(G \in \mathscr{M}\)</span> be a fixed probability measure, and let <span class="arithmatex">\(\varepsilon, \delta&gt;0\)</span>. Then the set</p>
<div class="arithmatex">\[
\mathscr{P}_{\varepsilon, \delta}=\left\{F \in \mathscr{M} \mid F\{A\} \leqslant G\left\{A^{\delta}\right\}+\varepsilon \text { for all } A \in \mathscr{B}\right\}
\]</div>
<p>is called a Prohorov neighborhood of <span class="arithmatex">\(G\)</span>. Often we assume <span class="arithmatex">\(\varepsilon=\delta\)</span>.</p>
<p>DEFINITION 3.5 The Prohorov distance between two members <span class="arithmatex">\(F, G \in \mathscr{D}\)</span> is</p>
<div class="arithmatex">\[
d_{p}(F, G)=\inf \{\varepsilon&gt;0 \mid F\{A\} \leqslant G\left\{A^{\varepsilon}\right\}+\varepsilon \text { for all } A \in \mathscr{S}\}
\]</div>
<p>We have to show that this is a metric. First, we show that it is symmetric in <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>; this follows immediately from the following lemma.</p>
<p>LEMMA 3.6 If <span class="arithmatex">\(F\{A\} \leqslant G\left\{A^{\delta}\right\}+\varepsilon\)</span> for all <span class="arithmatex">\(A \in \mathscr{S}\)</span>, then <span class="arithmatex">\(G\{A\} \leqslant F\left\{A^{\delta}\right\}+\varepsilon\)</span> for all <span class="arithmatex">\(A \in \mathscr{S}\)</span>.</p>
<p>Proof Let <span class="arithmatex">\(\delta^{\prime}&gt;\delta\)</span> and insert <span class="arithmatex">\(A=B^{\delta^{\prime} c}\)</span> into the premiss (here superscript <span class="arithmatex">\(c\)</span> denotes complementation). This yields <span class="arithmatex">\(G\left(B^{\delta^{\prime} c \delta c}\right) \leqslant F\left(B^{\delta^{\prime}}\right)+\varepsilon\)</span>. We now show that <span class="arithmatex">\(B \subset B^{\delta^{\prime} c \delta c}\)</span>, or, which is the same, <span class="arithmatex">\(B^{\delta^{\prime} c \delta} \subset B^{c}\)</span>. Assume <span class="arithmatex">\(x \in B^{\delta^{\prime} c \delta}\)</span>, then <span class="arithmatex">\(\exists y \notin B^{\delta^{\prime}}\)</span> with <span class="arithmatex">\(d(x, y) \leqslant \delta^{\prime}\)</span>; thus <span class="arithmatex">\(x \notin B\)</span>, because otherwise <span class="arithmatex">\(d(x, y)&gt;\delta^{\prime}\)</span>. It follows that <span class="arithmatex">\(G(B) \leqslant F\left(B^{\delta^{\prime}}\right)+\varepsilon\)</span>. Since <span class="arithmatex">\(B^{\delta}=\cap_{\delta^{\prime}&gt;\delta} B^{\delta^{\prime}}\)</span>, the assertion of the lemma follows.</p>
<p>We now show that <span class="arithmatex">\(d_{p}(F, G)=0\)</span> implies <span class="arithmatex">\(F=G\)</span>. Since <span class="arithmatex">\(\cap_{\varepsilon&gt;0} A^{\varepsilon}=\bar{A}\)</span>, it follows from <span class="arithmatex">\(d_{p}(F, G)=0\)</span> that <span class="arithmatex">\(F\{A\} \leqslant G\{A\}\)</span> and <span class="arithmatex">\(G\{A\} \leqslant F\{A\}\)</span> for all closed sets <span class="arithmatex">\(A\)</span>; this implies <span class="arithmatex">\(F=G\)</span> (remember that all our measures are regular). To prove the triangle inequality, assume <span class="arithmatex">\(d_{p}(F, G) \leqslant \varepsilon\)</span> and <span class="arithmatex">\(d_{p}(G, H) \leqslant \delta\)</span>, then <span class="arithmatex">\(F\{A\} \leqslant G\left\{A^{\varepsilon}\right\}+\varepsilon \leqslant H\left\{\left(A^{\varepsilon}\right)^{\delta}\right\}+\varepsilon+\delta\)</span>. Thus it suffices to verify <span class="arithmatex">\(\left(A^{\varepsilon}\right)^{\delta} \subset A^{\varepsilon+\delta}\)</span>, which is a simple consequence of the triangle inequality for <span class="arithmatex">\(d\)</span>.</p>
<p>THEOREM 3.7 (Strassen) The following two statements are equivalent:
(1) <span class="arithmatex">\(F\{A\} \leqslant G\left\{A^{\delta}\right\}+\varepsilon\)</span> for all <span class="arithmatex">\(A \in \mathscr{S}\)</span>.
(2) There are (dependent) random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> with values in <span class="arithmatex">\(\Omega\)</span>, such that <span class="arithmatex">\(\mathcal{L}(X)=F, \mathcal{L}(Y)=G\)</span>, and <span class="arithmatex">\(P\{d(X, Y) \leqslant \delta\} \geqslant 1-\varepsilon\)</span>.</p>
<p>Proof As <span class="arithmatex">\(\{X \in A\} \subset\left\{Y \in A^{\delta}\right\} \cup\{d(X, Y)&gt;\delta\}\)</span>, (1) is an immediate consequence of (2). The proof of the converse is contained in a famous paper of Strassen [(1965), p. 436 ff<span class="arithmatex">\(]\)</span>.</p>
<p>NOTE 1 In the above theorem we may put <span class="arithmatex">\(\delta=0\)</span>. Then, since <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> are regular, (1) is equivalent to the assumption that the difference in total variation between <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> satisfies <span class="arithmatex">\(d_{T V}(F, G)=\sup _{A \in \mathscr{B}}|F(A)-G(A)|&lt;\varepsilon\)</span>. In this case Strassen's theorem implies that there are two random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> with marginal distributions <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>, respectively, such that <span class="arithmatex">\(P(X \neq Y)\)</span> <span class="arithmatex">\(\leqslant \varepsilon\)</span>. However, the total variation distance does not metrize the weak topology.</p>
<p>NOTE 2 If <span class="arithmatex">\(G\)</span> is the idealized model and <span class="arithmatex">\(F\)</span> is the true underlying distribution, such that <span class="arithmatex">\(d_{p}(F, G)&lt;\varepsilon\)</span>, then Strassen's theorem shows that we can always assume that there is an ideal (but unobservable) random variable <span class="arithmatex">\(Y\)</span> with <span class="arithmatex">\(\mathcal{E}(Y)=G\)</span>, and an observable <span class="arithmatex">\(X\)</span> with <span class="arithmatex">\(\mathcal{E}(X)=F\)</span>, such that <span class="arithmatex">\(P\{d(X, Y)&lt;\varepsilon\}\)</span> <span class="arithmatex">\(&gt;1-\varepsilon\)</span>, that is, the Prohorov distance provides both for small errors occurring with large probability, and for large errors occurring with low probability, in a very explicit, quantitative fashion.</p>
<p>THEOREM 3.8 The Prohorov metric metrizes the weak topology in <span class="arithmatex">\(\mathfrak{R}\)</span>.
Proof Let <span class="arithmatex">\(P \in \mathfrak{R}\)</span> be fixed. Then a basis for the neighborhood system of <span class="arithmatex">\(P\)</span> in the weak topology is furnished by the sets of the form</p>
<div class="arithmatex">\[
\left\{Q \in \mathfrak{R} \mid\left|\int \varphi_{i} d Q-\int \varphi_{i} d P\right|&lt;\varepsilon, i=1, \ldots, k\right\}
\]</div>
<p>where the <span class="arithmatex">\(\varphi_{i}\)</span> are bounded continuous functions. In view of Lemma 2.2 there are three other bases for this neighborhood system, namely: those furnished by the sets</p>
<div class="arithmatex">\[
\left\{Q \in \mathfrak{R} \mid Q\left(G_{i}\right)&gt;P\left(G_{i}\right)-\varepsilon, i=1, \ldots, k\right\}
\]</div>
<p>where the <span class="arithmatex">\(G_{i}\)</span> are open; those furnished by the sets</p>
<div class="arithmatex">\[
\left\{Q \in \mathfrak{R} \mid Q\left(A_{i}\right)&lt;P\left(A_{i}\right)+\varepsilon, i=1, \ldots, k\right\}
\]</div>
<p>where the <span class="arithmatex">\(A_{i}\)</span> are closed; and those furnished by the sets</p>
<div class="arithmatex">\[
\left\{Q \in \mathfrak{R} \mid\left|Q\left(B_{i}\right)-P\left(B_{i}\right)\right|&lt;\varepsilon, i=1, \ldots, k\right\}
\]</div>
<p>where the <span class="arithmatex">\(B_{i}\)</span> have <span class="arithmatex">\(P\)</span>-null boundary.
We first show that each neighborhood of the form (3.5) contains a Prohorov neighborhood. Assume that <span class="arithmatex">\(P, \varepsilon\)</span>, and a closed set <span class="arithmatex">\(A\)</span> are given. Clearly, we can find a <span class="arithmatex">\(\delta, 0&lt;\delta&lt;\varepsilon\)</span>, such that <span class="arithmatex">\(P\left(A^{\delta}\right)&lt;P(A)+\frac{1}{2} \varepsilon\)</span>. If <span class="arithmatex">\(d_{p}(P, Q)\)</span> <span class="arithmatex">\(&lt;\frac{1}{2} \delta\)</span>, then</p>
<div class="arithmatex">\[
Q(A)&lt;P\left(A^{\delta}\right)+\frac{1}{2} \delta&lt;P(A)+\varepsilon
\]</div>
<p>It follows that (3.5) contains a Prohorov neighborhood. In order to show the converse, let <span class="arithmatex">\(\varepsilon&gt;0\)</span> be given. Choose <span class="arithmatex">\(\delta&lt;\frac{1}{2} \varepsilon\)</span>. In view of Lemma 2.5 there is a finite union of sets <span class="arithmatex">\(A_{i}\)</span> with diameter <span class="arithmatex">\(&lt;\delta\)</span> such that</p>
<div class="arithmatex">\[
P\left(\bigcup_{i=1}^{k} A_{i}\right)&gt;1-\delta
\]</div>
<p>We can choose the <span class="arithmatex">\(A_{i}\)</span> to be disjoint and to have <span class="arithmatex">\(P\)</span>-null boundaries. If <span class="arithmatex">\(\mathscr{Q}\)</span> is the (finite) class of unions of <span class="arithmatex">\(A_{i}\)</span>, then every element of <span class="arithmatex">\(\mathscr{Q}\)</span> has a <span class="arithmatex">\(P\)</span>-null boundary. By (3.6) there is a weak neighborhood <span class="arithmatex">\(\mathscr{R}\)</span> of <span class="arithmatex">\(P\)</span> such that</p>
<div class="arithmatex">\[
\mathscr{R}=\{Q \| Q(B)-P(B) \mid&lt;\delta \text { for } B \in \mathscr{Q}\}
\]</div>
<p>We now show that <span class="arithmatex">\(d_{P}(P, Q)&lt;\varepsilon\)</span> if <span class="arithmatex">\(Q \in \mathscr{R}\)</span>. Let <span class="arithmatex">\(B \in \mathscr{B}\)</span> be an arbitrary set, and let <span class="arithmatex">\(A\)</span> be the union of the sets <span class="arithmatex">\(A_{i}\)</span> that ints rsect <span class="arithmatex">\(B\)</span>. Then</p>
<div class="arithmatex">\[
B \subset A \cup\left[\bigcup_{1}^{k} A_{i}\right]^{c} \quad \text { and } \quad A \subset B^{\delta}
\]</div>
<p>and hence</p>
<div class="arithmatex">\[
P(B)&lt;P(A)+\delta&lt;Q(A)+2 \delta&lt;Q\left(B^{\delta}\right)+2 \delta
\]</div>
<p>The assertion follows.
THEOREM 3.9 <span class="arithmatex">\(\mathscr{R}\)</span> is a Polish space.
Proof It remains to show that <span class="arithmatex">\(\mathscr{R}\)</span> is separable and complete. We already noted (proof of Lemma 2.1) that the measures with finite support are dense in <span class="arithmatex">\(\mathscr{R}\)</span>. Now let <span class="arithmatex">\(\Omega_{0} \subset \Omega\)</span> be a countable dense subset; then it is easy to see that already the countable set <span class="arithmatex">\(\mathscr{R}_{0}\)</span> is dense in <span class="arithmatex">\(\mathscr{R}\)</span>, where <span class="arithmatex">\(\mathscr{R}_{0}\)</span> consists of the measures whose finite support is contained in <span class="arithmatex">\(\Omega_{0}\)</span> and that have rational masses. This establishes separability. Now let <span class="arithmatex">\(\left\{P_{n}\right\}\)</span> be a Cauchy sequence in <span class="arithmatex">\(\mathscr{R}\)</span>. Let <span class="arithmatex">\(\varepsilon&gt;0\)</span> be given, and chose <span class="arithmatex">\(n_{0}\)</span> such that <span class="arithmatex">\(d_{P}\left(P_{n}, P_{m}\right)&lt;\varepsilon / 2\)</span> for <span class="arithmatex">\(m, n \geqslant n_{0}\)</span>, that is <span class="arithmatex">\(P_{m}(A) \leqslant P_{n}\left(A^{\varepsilon / 2}\right)+\varepsilon / 2\)</span>. The finite sequence <span class="arithmatex">\(\left\{P_{m}\right\}_{m&lt;n_{0}}\)</span> is tight, so by Lemma 2.5 there is a finite union <span class="arithmatex">\(B\)</span> of <span class="arithmatex">\(\varepsilon / 2\)</span>-balls such that <span class="arithmatex">\(P_{m}(B) \geqslant 1-\varepsilon / 2\)</span> for <span class="arithmatex">\(m \leqslant n_{0}\)</span>. But then <span class="arithmatex">\(P_{n}\left(B^{\varepsilon / 2}\right) \geqslant P_{n}(B)-\varepsilon / 2 \geqslant 1-\varepsilon\)</span>, and, since <span class="arithmatex">\(B^{\varepsilon / 2}\)</span> is contained in a finite union of <span class="arithmatex">\(\varepsilon\)</span>-balls (with the same centers as the balls forming <span class="arithmatex">\(B\)</span> ), we conclude from Lemma 2.5 that the sequence <span class="arithmatex">\(\left\{P_{n}\right\}\)</span> is tight. Hence it has an accumulation point in <span class="arithmatex">\(\mathscr{R}\)</span> (which by necessity is unique).</p>
<h1 id="24-the-bounded-lipschitz-metric">2.4 THE BOUNDED LIPSCHITZ METRIC</h1>
<p>The weak topology can also be metrized by other metrics. An interesting one is the so-called bounded Lipschitz metric <span class="arithmatex">\(d_{B L}\)</span>. Assume that the distance function <span class="arithmatex">\(d\)</span> in <span class="arithmatex">\(\Omega\)</span> is bounded by 1 {if necessary, replace it by <span class="arithmatex">\(d(x, y) /[1+\)</span> <span class="arithmatex">\(d(x, y)]\}\)</span>. Then define</p>
<div class="arithmatex">\[
d_{B L}(F, G)=\sup \left|\int \psi d F-\int \psi d G\right|
\]</div>
<p>where the supremum is taken over all functions <span class="arithmatex">\(\psi\)</span> satisfying the Lipschitz condition</p>
<div class="arithmatex">\[
|\psi(x)-\psi(y)| \leqslant d(x, y)
\]</div>
<p>LEMMA 4.1 <span class="arithmatex">\(d_{B L}\)</span> is a metric.
Proof The only nontrivial part is to show that <span class="arithmatex">\(d_{B L}(F, G)=0\)</span> implies <span class="arithmatex">\(F=G\)</span>. Clearly, it implies <span class="arithmatex">\(\int \psi d F=\int \psi d G\)</span> for all functions satisfying the Lipschitz condition <span class="arithmatex">\(|\psi(x)-\psi(y)| \leqslant c d(x, y)\)</span> for some <span class="arithmatex">\(c\)</span>. In particular, let <span class="arithmatex">\(\psi(x)=(1-c d(x, A))^{+}\)</span>, with <span class="arithmatex">\(d(x, A)=\inf \{d(x, y) \mid y \in A\}\)</span>; then <span class="arithmatex">\(|\psi(x)-\)</span> <span class="arithmatex">\(\psi(y)|&lt;c d(x, y)\)</span> and <span class="arithmatex">\(1_{A} \leqslant \psi \leqslant 1_{A^{1 / 2}}\)</span>. Let <span class="arithmatex">\(c \rightarrow \infty\)</span>, then it follows that <span class="arithmatex">\(F(A)=\)</span> <span class="arithmatex">\(G(A)\)</span> for all closed sets <span class="arithmatex">\(A\)</span>; hence <span class="arithmatex">\(F=G\)</span>.</p>
<p>Also for this metric an analogue of Strassen's theorem holds [first proved by Kantorovič and Rubinstein (1958) in a special case].</p>
<p>THEOREM 4.2 The following two statements are equivalent:
(1) <span class="arithmatex">\(d_{B L}(F, G) \leqslant \varepsilon\)</span>.
(2) There are random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> with <span class="arithmatex">\(\bar{E}(X)=F\)</span>, and <span class="arithmatex">\(\bar{E}(Y)=G\)</span>, such that</p>
<div class="arithmatex">\[
E d(X, Y) \leqslant \varepsilon
\]</div>
<p>Proof <span class="arithmatex">\((2) \Rightarrow(1)\)</span> is trivial:</p>
<div class="arithmatex">\[
\left|\int \psi d F-\int \psi d G\right|=|E \psi(X)-E \psi(Y)| \leqslant E|\psi(X)-\psi(Y)| \leqslant E d(X, Y)
\]</div>
<p>To prove the reverse implication, we first assume that <span class="arithmatex">\(\Omega\)</span> is a finite set. Then the assertion is, essentially, a particular case of the Kuhn-Tucker (1951) theorem, but a proof from scratch may be more instructive. Assume that the elements of <span class="arithmatex">\(\Omega\)</span> are numbered from 1 to <span class="arithmatex">\(n\)</span>; then the probability measures <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> are represented by <span class="arithmatex">\(n\)</span>-tuples <span class="arithmatex">\(\left(f_{1}, \ldots, f_{n}\right)\)</span> and <span class="arithmatex">\(\left(g_{1}, \ldots, g_{n}\right)\)</span> of real numbers, and we are looking for a probability on <span class="arithmatex">\(\Omega \times \Omega\)</span>, represented by a matrix <span class="arithmatex">\(u_{i j}\)</span>. Thus we attempt to minimize</p>
<div class="arithmatex">\[
E d(X, Y)=\sum d_{i j} u_{i j}
\]</div>
<p>under the side conditions</p>
<div class="arithmatex">\[
\begin{gathered}
u_{i j} \geqslant 0 \\
\sum_{i} u_{i j}=g_{j} \\
\sum_{j} u_{i j}=f_{i}
\end{gathered}
\]</div>
<p>where <span class="arithmatex">\(d_{i j}\)</span> satisfies</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; d_{i j} \geqslant 0, \quad d_{i i}=0 \\
&amp; d_{i j}=d_{j i} \\
&amp; d_{i k} \leqslant d_{i j}+d_{j k}
\end{aligned}
\]</div>
<p>There exist matrices <span class="arithmatex">\(u_{i j}\)</span> satisfying the side conditions, for example <span class="arithmatex">\(u_{i j}=f_{i} g_{j}\)</span>, and it follows from a simple compactness argument that there is a solution to our minimum problem. With the aid of Lagrange multipliers <span class="arithmatex">\(\lambda_{i}\)</span> and <span class="arithmatex">\(\mu_{j}\)</span>, it can be turned into an unconstrained minimum problem: minimize</p>
<div class="arithmatex">\[
\sum\left(d_{i j}-\lambda_{i}-\mu_{j}\right) u_{i j}
\]</div>
<p>on the orthant</p>
<div class="arithmatex">\[
u_{i j} \geqslant 0
\]</div>
<p>At the minimum (which we know to exist) we must have the following implications:</p>
<div class="arithmatex">\[
\begin{array}{lll}
u_{i j}&gt;0 &amp; \Rightarrow &amp; d_{i j}=\lambda_{i}+\mu_{j} \\
u_{i j}=0 &amp; \Rightarrow &amp; d_{i j} \geqslant \lambda_{i}+\mu_{j}
\end{array}
\]</div>
<p>because otherwise (4.6) could be decreased through a suitable small change in some of the <span class="arithmatex">\(u_{i j}\)</span>. We note that (4.4), (4.7), and (4.8) imply that the minimum value <span class="arithmatex">\(\eta\)</span> of (4.3) satisfies</p>
<div class="arithmatex">\[
\eta=\sum d_{i j} u_{i j}=\sum\left(\lambda_{i}+\mu_{j}\right) u_{i j}=\sum \lambda_{i} f_{i}+\sum \mu_{i} g_{i}
\]</div>
<p>Assume for the moment that <span class="arithmatex">\(\mu_{i}=-\lambda_{i}\)</span> for all <span class="arithmatex">\(i\)</span> [this would follow from (4.7) if <span class="arithmatex">\(u_{i i}&gt;0\)</span> for all <span class="arithmatex">\(i\)</span> ]. Then (4.7) and (4.8) show that <span class="arithmatex">\(\lambda\)</span> satisfies the Lipschitz condition <span class="arithmatex">\(\left|\lambda_{i}-\lambda_{j}\right| \leqslant d_{i j}\)</span>, and (4.9) now gives <span class="arithmatex">\(\eta \leqslant \varepsilon\)</span>; thus assertion (2) of the theorem holds.</p>
<p>In order to establish <span class="arithmatex">\(\mu_{i}=-\lambda_{i}\)</span>, for a fixed <span class="arithmatex">\(i\)</span>, assume first that both <span class="arithmatex">\(f_{i}&gt;0\)</span> and <span class="arithmatex">\(g_{i}&gt;0\)</span>. Then both the <span class="arithmatex">\(i\)</span> th row and the <span class="arithmatex">\(i\)</span> th column of the matrix <span class="arithmatex">\(\left\{u_{i j}\right\}\)</span> must contain a strictly positive element. If <span class="arithmatex">\(u_{i i}&gt;0\)</span>, then (4.7) implies <span class="arithmatex">\(\lambda_{i}+\mu_{i}=\)</span> <span class="arithmatex">\(d_{i i}=0\)</span>, and we are finished. If <span class="arithmatex">\(u_{i i}=0\)</span>, then there must be a <span class="arithmatex">\(u_{i i}&gt;0\)</span> and a <span class="arithmatex">\(u_{k i}&gt;\)</span> 0 . Therefore</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \lambda_{i}+\mu_{j}=d_{i j} \\
&amp; \lambda_{k}+\mu_{i}=d_{k i}
\end{aligned}
\]</div>
<p>and the triangle inequality gives</p>
<div class="arithmatex">\[
\lambda_{k}+\mu_{j} \leqslant d_{k j} \leqslant d_{k i}+d_{i j}=\lambda_{k}+\mu_{i}+\lambda_{i}+\mu_{j}
\]</div>
<p>hence</p>
<div class="arithmatex">\[
0 \leqslant \mu_{i}+\lambda_{i} \leqslant d_{i i}=0
\]</div>
<p>and thus <span class="arithmatex">\(\lambda_{i}+\mu_{i}=0\)</span>.
In the case <span class="arithmatex">\(f_{i}=g_{i}=0\)</span> there is nothing to prove (we may drop the <span class="arithmatex">\(i\)</span> th point from consideration).</p>
<p>The most troublesome case is when just one of <span class="arithmatex">\(f_{i}\)</span> and <span class="arithmatex">\(g_{i}\)</span> is 0 , say <span class="arithmatex">\(f_{i}&gt;0\)</span> and <span class="arithmatex">\(g_{i}=0\)</span>. Then <span class="arithmatex">\(u_{k i}=0\)</span> for all <span class="arithmatex">\(k\)</span>, and <span class="arithmatex">\(\lambda_{k}+\mu_{i} \leqslant d_{k i}\)</span>, but <span class="arithmatex">\(\mu_{i}\)</span> is not uniquely determined in general; in particular, note that its coefficient in (4.9) then is 0 . So we increase <span class="arithmatex">\(\mu_{i}\)</span> until, for the first time, <span class="arithmatex">\(\lambda_{k}+\mu_{i}=d_{k i}\)</span> for some <span class="arithmatex">\(k\)</span>. If <span class="arithmatex">\(k=i\)</span>, we are finished. If not, there must be some <span class="arithmatex">\(j\)</span> for which <span class="arithmatex">\(u_{i j}&gt;0\)</span> since <span class="arithmatex">\(f_{i}&gt;0\)</span>; thus <span class="arithmatex">\(\lambda_{i}+\mu_{j}=d_{i j}\)</span>, and we can repeat the argument with the triangle inequality from before.</p>
<p>This proves the theorem for finite sets <span class="arithmatex">\(\Omega\)</span>.
We now show that it holds whenever the support of <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> is finite, say <span class="arithmatex">\(\left\{x_{1}, \ldots, x_{n}\right\}\)</span>. In order to do this, it suffices to show that any function <span class="arithmatex">\(\psi\)</span> defined on the set <span class="arithmatex">\(\left\{x_{1}, \ldots, x_{n}\right\}\)</span> and satisfying the Lipschitz condition <span class="arithmatex">\(\left|\psi\left(x_{i}\right)-\psi\left(x_{j}\right)\right| \leqslant d\left(x_{i}, x_{j}\right)\)</span> can be extended to a function satisfying the Lipschitz condition everywhere in <span class="arithmatex">\(\Omega\)</span>.</p>
<p>Let <span class="arithmatex">\(x_{1}, x_{2}, \ldots\)</span> be a dense sequence in <span class="arithmatex">\(\Omega\)</span>, and assume inductively that <span class="arithmatex">\(\psi\)</span> is defined and satisfies the Lipschitz condition on <span class="arithmatex">\(\left\{x_{1}, \ldots, x_{n}\right\}\)</span>. Then <span class="arithmatex">\(\psi\)</span> will satisfy it on <span class="arithmatex">\(\left\{x_{1}, \ldots, x_{n+1}\right\}\)</span> iff <span class="arithmatex">\(\psi\left(x_{n+1}\right)\)</span> can be defined such that</p>
<div class="arithmatex">\[
\psi\left(x_{n+1}\right) \in\left\{\max _{1 \leqslant i \leqslant n}\left[\psi\left(x_{i}\right)-d\left(x_{i}, x_{n+1}\right)\right], \min _{1 \leqslant i \leqslant n}\left[\psi\left(x_{i}\right)+d\left(x_{i}, x_{n+1}\right)\right]\right\}
\]</div>
<p>It suffices to show that the interval in question is not empty, that is, for all <span class="arithmatex">\(i, j \leqslant n\)</span>,</p>
<div class="arithmatex">\[
\psi\left(x_{i}\right)-d\left(x_{i}, x_{n+1}\right) \leqslant \psi\left(x_{j}\right)+d\left(x_{j}, x_{n+1}\right)
\]</div>
<p>or equivalently,</p>
<div class="arithmatex">\[
\psi\left(x_{i}\right)-\psi\left(x_{j}\right) \leqslant d\left(x_{i}, x_{n+1}\right)+d\left(x_{j}, x_{n+1}\right)
\]</div>
<p>and this is obviously true in view of the triangle inequality.</p>
<p>Thus it is possible to extend the definition of <span class="arithmatex">\(\psi\)</span> to a dense set, and from there, by uniform continuity, to the whole of <span class="arithmatex">\(\Omega\)</span>.</p>
<p>For general measures <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>, the theorem now follows from a straightforward passage to the limit, as follows.</p>
<p>First, we show that, for every <span class="arithmatex">\(\delta&gt;0\)</span> and every <span class="arithmatex">\(F\)</span>, there is a measure <span class="arithmatex">\(F^{*}\)</span> with finite support such that <span class="arithmatex">\(d_{B L}\left(F, F^{*}\right)&lt;\delta\)</span>. In order to see this, find first a compact <span class="arithmatex">\(K \subset \Omega\)</span> such that <span class="arithmatex">\(F(K)&gt;1-\delta / 2\)</span>, cover <span class="arithmatex">\(K\)</span> by a finite number of disjoint sets <span class="arithmatex">\(U_{1}, \ldots, U_{n}\)</span> with diameter <span class="arithmatex">\(&lt;\delta / 2\)</span>, put <span class="arithmatex">\(U_{0}=K^{c}\)</span>, and select points <span class="arithmatex">\(x_{i} \in U_{i}, i=0, \ldots, n\)</span>. Define <span class="arithmatex">\(F^{*}\)</span> with support <span class="arithmatex">\(\left\{x_{0}, \ldots, x_{n}\right\}\)</span> by <span class="arithmatex">\(F^{*}\left\{x_{i}\right\}=F\left\{U_{i}\right\}\)</span>. Then, for any <span class="arithmatex">\(\psi\)</span> satisfying the Lipschitz condition, we have</p>
<div class="arithmatex">\[
\begin{aligned}
\left|\int \psi d F^{*}-\int \psi d F\right| &amp; \leqslant \sum\left[\max _{U_{i}} \psi(x)-\min _{U_{i}} \psi(x)\right] F^{*}\left\{x_{i}\right\} \\
&amp; \leqslant F^{*}\left\{x_{0}\right\}+\sum_{i&gt;0} \frac{\delta}{2} F^{*}\left\{x_{i}\right\}&lt;\delta
\end{aligned}
\]</div>
<p>Thus we can approximate <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span> by <span class="arithmatex">\(F^{*}\)</span> and <span class="arithmatex">\(G^{*}\)</span>, respectively, such that the starred measures have finite support, and</p>
<div class="arithmatex">\[
d_{B L}\left(F^{*}, G^{*}\right)&lt;\varepsilon+2 \delta
\]</div>
<p>Then find a measure <span class="arithmatex">\(P^{*}\)</span> on <span class="arithmatex">\(\Omega \times \Omega\)</span> with marginals <span class="arithmatex">\(F^{*}\)</span> and <span class="arithmatex">\(G^{*}\)</span> such that</p>
<div class="arithmatex">\[
\int d(X, Y) d P^{*}&lt;\varepsilon+2 \delta
\]</div>
<p>If we take a sequence of <span class="arithmatex">\(\delta\)</span> values converging to 0 , then the corresponding sequence <span class="arithmatex">\(P^{*}\)</span> clearly is tight in the space of probability measures on <span class="arithmatex">\(\Omega \times \Omega\)</span>, and the marginals converge weakly to <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>, respectively. Hence there is a weakly convergent subsequence of the <span class="arithmatex">\(P^{*}\)</span>, whose limit <span class="arithmatex">\(P\)</span> then satisfies (2). This terminates the proof of the theorem.</p>
<p>COROLLARY 4.3 For all <span class="arithmatex">\(F, G \in \mathscr{R}\)</span>, we have</p>
<div class="arithmatex">\[
d_{P}(F, G)^{2} \leqslant d_{B L}(F, G) \leqslant 2 d_{P}(F, G)
\]</div>
<p>In particular, <span class="arithmatex">\(d_{P}\)</span> and <span class="arithmatex">\(d_{B L}\)</span> define the same topology.
Proof For any probability measure <span class="arithmatex">\(P\)</span> on <span class="arithmatex">\(\Omega \times \Omega\)</span>, we have</p>
<div class="arithmatex">\[
\begin{aligned}
\int d(X, Y) d P &amp; \leqslant \varepsilon P\{d(X, Y) \leqslant \varepsilon\}+P\{d(X, Y)&gt;\varepsilon\} \\
&amp; =\varepsilon+(1-\varepsilon) P\{d(X, Y)&gt;\varepsilon\}
\end{aligned}
\]</div>
<p>If <span class="arithmatex">\(d_{P}(F, G)&lt;\varepsilon\)</span>, we can (by Theorem 3.8) choose <span class="arithmatex">\(P\)</span> so that this is bounded by <span class="arithmatex">\(\leqslant \varepsilon+(1-\varepsilon) \varepsilon \leqslant 2 \varepsilon\)</span>, which establishes <span class="arithmatex">\(d_{B L} \leqslant 2 d_{P}\)</span>. On the other hand Markov's inequality gives</p>
<div class="arithmatex">\[
P\{(d(X, Y)&gt;\varepsilon\} \leqslant \frac{\int d(X, Y) d P}{\varepsilon}&lt;\varepsilon
\]</div>
<p>if <span class="arithmatex">\(d_{B L}(F, G) \leqslant \varepsilon^{2}\)</span>; thus <span class="arithmatex">\(d_{P}^{2}&lt;d_{B L}\)</span>.</p>
<h1 id="some-further-inequalities">Some Further Inequalities</h1>
<p>The total variation distance</p>
<div class="arithmatex">\[
d_{T V}(F, G)=\sup _{A \in \mathscr{B}}|F\{A\}-G\{A\}|
\]</div>
<p>and, on the real line, the Kolmogorov distance</p>
<div class="arithmatex">\[
d_{K}(F, G)=\sup |F(x)-G(x)|
\]</div>
<p>do not generate the weak topology, but they possess other convenient properties. In particular, we have the inequalities</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; d_{L} \leqslant d_{P} \leqslant d_{T V} \\
&amp; d_{L} \leqslant d_{K} \leqslant d_{T V}
\end{aligned}
\]</div>
<p>Proof <span class="arithmatex">\((4.13,4.14)\)</span> The defining equation for the Prohorov distance</p>
<div class="arithmatex">\[
d_{P}(F, G)=\inf \{\varepsilon \mid \forall A \in \mathscr{B}, F\{A\} \leqslant G\left\{A^{\varepsilon}\right\}+\varepsilon\}
\]</div>
<p>is turned into a definition of the Lévy distance if we decrease the range of conditions to sets <span class="arithmatex">\(A\)</span> of the form <span class="arithmatex">\((-\infty, x]\)</span> and <span class="arithmatex">\([x, \infty)\)</span>. It is turned into a definition of the total variation distance if we replace <span class="arithmatex">\(A^{\varepsilon}\)</span> by <span class="arithmatex">\(A\)</span> and thus make the condition harder to fulfill. This again can be converted into a definition of Kolmogorov distance if we restrict the range of <span class="arithmatex">\(A\)</span> to sets <span class="arithmatex">\((-\infty, x]\)</span> and <span class="arithmatex">\([x, \infty)\)</span>. Finally, if we increase <span class="arithmatex">\(A\)</span> on the right-hand side of the inequality in (4.15) and replace it by <span class="arithmatex">\(A^{\varepsilon}\)</span>, we decrease the infimum and obtain the Levy distance.</p>
<h3 id="25-frechet-and-gateaux-derivatives">2.5 FRÉCHET AND GÂTEAUX DERIVATIVES</h3>
<p>Assume that <span class="arithmatex">\(d_{*}\)</span> is a metric [or pseudo-metric-we shall not actually need <span class="arithmatex">\(\left.d_{*}(F, G)=0 \Rightarrow F=G\right]\)</span>, in the space <span class="arithmatex">\(\mathscr{M}\)</span> of probability measures, that:
(1) Is compatible with the weak topology in the sense that <span class="arithmatex">\(\left\{F \mid d_{*}(G, F)&lt;\varepsilon\right\}\)</span> is open for all <span class="arithmatex">\(\varepsilon&gt;0\)</span>.</p>
<p>(2) Is compatible with the affine structure of <span class="arithmatex">\(\mathscr{R}\)</span> : let <span class="arithmatex">\(F_{t}=(1-t) F_{0}+t F_{1}\)</span>, then <span class="arithmatex">\(d_{*}\left(F_{t}, F_{s}\right)=O(|t-s|)\)</span>.
The "usual" distance functions metrizing the weak topology of course satisfy the first condition; they also satisfy the second, but this has to be checked in each case.</p>
<p>In the case of the Lévy metric we note that</p>
<div class="arithmatex">\[
\left|F_{t}(x)-F_{s}(x)\right|=|t-s|\left|F_{1}(x)-F_{0}(x)\right| \leqslant|t-s|
\]</div>
<p>hence <span class="arithmatex">\(d_{K}\left(F_{t}, F_{s}\right) \leqslant|t-s|\)</span> and, a fortiori,</p>
<div class="arithmatex">\[
d_{L}\left(F_{t}, F_{s}\right) \leqslant|t-s|
\]</div>
<p>In the case of the Prohorov metric, we have, similarly,</p>
<div class="arithmatex">\[
\left|F_{t}(A)-F_{s}(A)\right|=|t-s| \cdot\left|F_{1}(A)-F_{0}(A)\right| \leqslant|t-s|
\]</div>
<p>hence</p>
<div class="arithmatex">\[
d_{P}\left(F_{t}, F_{s}\right) \leqslant|t-s|
\]</div>
<p>In the case of the bounded Lipschitz metric, we have, for any <span class="arithmatex">\(\psi\)</span> satisfying the Lipschitz condition,</p>
<div class="arithmatex">\[
\left|\int \psi d F_{t}-\int \psi d F_{s}\right|=|t-s| \cdot\left|\int \psi d F_{1}-\int \psi d F_{0}\right|
\]</div>
<p>Let <span class="arithmatex">\(\bar{\psi}=\sup \psi(x)\)</span>, and <span class="arithmatex">\(\psi=\inf \psi(x)\)</span>, then <span class="arithmatex">\(\bar{\psi}-\psi \leqslant \sup d(x, y) \leqslant 1\)</span>; thus <span class="arithmatex">\(\int \psi d F_{1}\)</span> <span class="arithmatex">\(-\int \psi d F_{0} \leqslant \int \bar{\psi} d F_{1}-\int \bar{\psi} d F_{0} \leqslant 1\)</span>. It follows that <span class="arithmatex">\(d_{B L}\left(F_{t}, F_{s}\right) \leqslant|t-s|\)</span>.
We say that a statistical functional <span class="arithmatex">\(T\)</span> is Fréchet differentiable at <span class="arithmatex">\(F\)</span> if it can be approximated by a linear functional <span class="arithmatex">\(L\)</span> (defined on the space of finite signed measures) such that, for all <span class="arithmatex">\(G\)</span>,</p>
<div class="arithmatex">\[
|T(G)-T(F)-L(G-F)|=o\left[d_{*}(F, G)\right]
\]</div>
<p>Of course <span class="arithmatex">\(L=L_{F}\)</span> depends on the base point <span class="arithmatex">\(F\)</span>.
It is easy to see that <span class="arithmatex">\(L\)</span> is (essentially) unique: if <span class="arithmatex">\(L_{1}\)</span> and <span class="arithmatex">\(L_{2}\)</span> are two such linear functionals, then their difference satisfies</p>
<div class="arithmatex">\[
\left|\left(L_{1}-L_{2}\right)(G-F)\right|=o\left[d_{*}(F, G)\right]
\]</div>
<p>and, in particular, with <span class="arithmatex">\(F_{t}=(1-t) F+t G\)</span>, we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
\left|\left(L_{1}-L_{2}\right)\left(F_{t}-F\right)\right| &amp; =t\left|\left(L_{1}-L_{2}\right)(G-F)\right| \\
&amp; =o\left(d_{*}\left(F, F_{t}\right)\right)=o(t)
\end{aligned}
\]</div>
<p>hence <span class="arithmatex">\(L_{1}(G-F)=L_{2}(G-F)\)</span> for all <span class="arithmatex">\(G\)</span>.
It follows that <span class="arithmatex">\(L\)</span> is uniquely determined on the space of finite signed measures of total mass 0 , and we may arbitrarily standardize it by putting <span class="arithmatex">\(L(F)=0\)</span>.</p>
<p>If <span class="arithmatex">\(T\)</span> were defined not just on some convex set, but in a full, open neighborhood of <span class="arithmatex">\(F\)</span> in some linear space, weak continuity of <span class="arithmatex">\(T\)</span> at <span class="arithmatex">\(F\)</span> together with (5.1) would imply that <span class="arithmatex">\(L\)</span> is continuous in <span class="arithmatex">\(G\)</span> at <span class="arithmatex">\(G=F\)</span>, and, since <span class="arithmatex">\(L\)</span> is linear, it then would follow that <span class="arithmatex">\(L\)</span> is continuous everywhere.</p>
<p>Unfortunately, this is not so, and thus a somewhat more roundabout approach appears necessary.</p>
<p>We note first that, if we define</p>
<div class="arithmatex">\[
\psi(x)=L\left(\delta_{x}-F\right)
\]</div>
<p>then, by linearity of <span class="arithmatex">\(L\)</span>,</p>
<div class="arithmatex">\[
L(G-F)=\int \psi d G
\]</div>
<p>for all <span class="arithmatex">\(G\)</span> with finite support.
In particular, with <span class="arithmatex">\(F_{t}=(1-t) F+t G\)</span>, we then obtain</p>
<div class="arithmatex">\[
\begin{aligned}
\left|T\left(F_{t}\right)-T(F)-L\left(F_{t}-F\right)\right| &amp; =\left|T\left(F_{t}\right)-T(F)-t L(G-F)\right| \\
&amp; =\left|T\left(F_{t}\right)-T(F)-t \int \psi d G\right| \\
&amp; =o\left(d_{*}\left(F, F_{t}\right)\right)=o(t)
\end{aligned}
\]</div>
<p>Assume that <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F\)</span>; then <span class="arithmatex">\(d_{*}\left(F, F_{t}\right)=O(t)\)</span> implies that <span class="arithmatex">\(\left|T\left(F_{t}\right)-T(F)\right|=o(1)\)</span> uniformly in <span class="arithmatex">\(G\)</span>. A comparison with the preceding formula (5.4) yields that <span class="arithmatex">\(\psi\)</span> must be bounded.</p>
<p>We may rewrite (5.4) as</p>
<div class="arithmatex">\[
\left|\int \psi d G-\frac{T\left(F_{t}\right)-T(F)}{t}\right|=o(1)
\]</div>
<p>holding uniformly in <span class="arithmatex">\(G\)</span>. Now, if <span class="arithmatex">\(T\)</span> is continuous in a neighborhood of <span class="arithmatex">\(F\)</span>, and if <span class="arithmatex">\(G_{n} \rightarrow G\)</span> weakly, then</p>
<div class="arithmatex">\[
F_{n, t}=(1-t) F+t G_{n} \rightarrow F_{t} \quad \text { weakly }
\]</div>
<p>Since <span class="arithmatex">\(t\)</span> can be chosen arbitrarily small, we must have <span class="arithmatex">\(\int \psi d G_{n} \rightarrow \int \psi d G\)</span>. In particular, by letting <span class="arithmatex">\(G_{n}=\delta_{x_{n}}\)</span>, with <span class="arithmatex">\(x_{n} \rightarrow x\)</span>, we obtain that <span class="arithmatex">\(\psi\)</span> must be continuous. If <span class="arithmatex">\(G\)</span> is an arbitrary probability measure, and the <span class="arithmatex">\(G_{n}\)</span> are approximations to <span class="arithmatex">\(G\)</span> with finite support, then the same argument shows that <span class="arithmatex">\(\int \psi d G_{n}\)</span> converges simultaneously to <span class="arithmatex">\(\int \psi d G\)</span> (since <span class="arithmatex">\(\psi\)</span> is bounded and continuous) and to <span class="arithmatex">\(L(G-F)\)</span>; hence <span class="arithmatex">\(L(G-F)=\int \psi d G_{n}\)</span> holds for all <span class="arithmatex">\(G \in \mathscr{M}\)</span>. Thus we have proved the following proposition.</p>
<p>PROPOSITION 5.1 If <span class="arithmatex">\(T\)</span> is weakly continuous in a neighborhood of <span class="arithmatex">\(F\)</span> and Fréchet differentiable at <span class="arithmatex">\(F\)</span>, then its Fréchet derivative at <span class="arithmatex">\(F\)</span> is a weakly continuous linear functional, and it is representable as</p>
<div class="arithmatex">\[
L(G-F)=\int \psi_{F} d G
\]</div>
<p>with <span class="arithmatex">\(\psi_{F}\)</span> bounded and continuous, and <span class="arithmatex">\(\int \psi_{F} d F=0\)</span>.
Unfortunately the concept of Fréchet differentiability appears to be too strong: in too many cases, the Fréchet derivative does not exist, and even if it does, the fact is difficult to establish.</p>
<p>About the weakest concept of differentiability is the Gâteaux derivative [in the statistical literature it has usually been called the Volterra derivative, but this happens to be a misnomer, cf. Reeds (1976)]. We say that a functional <span class="arithmatex">\(T\)</span> is Gâteaux differentiable at <span class="arithmatex">\(F\)</span> if there is a linear functional <span class="arithmatex">\(L=L_{F}\)</span> such that, for all <span class="arithmatex">\(G \in \mathscr{M}\)</span>,</p>
<div class="arithmatex">\[
\lim _{t \rightarrow 0} \frac{T\left(F_{t}\right)-T(F)}{t}=L_{F}(G-F)
\]</div>
<p>with</p>
<div class="arithmatex">\[
F_{t}=(1-t) F+t G
\]</div>
<p>Clearly, if <span class="arithmatex">\(T\)</span> is Fréchet differentiable, it is also Gâteaux differentiable, and the two derivatives <span class="arithmatex">\(L_{F}\)</span> agree. We usually assume in addition that the Gâteaux derivative <span class="arithmatex">\(L_{F}\)</span> is representable by a measurable function <span class="arithmatex">\(\psi_{F}\)</span>, conveniently standardized such that <span class="arithmatex">\(\int \psi_{F} d F=0\)</span> :</p>
<div class="arithmatex">\[
L_{F}(G-F)=\int \psi_{F} d G
\]</div>
<p>[Note that there are discontinuous linear functionals that cannot be represented as integrals with respect to measurable function <span class="arithmatex">\(\psi\)</span>, e.g., <span class="arithmatex">\(L(F)\)</span> <span class="arithmatex">\(=\)</span> sum of the jumps <span class="arithmatex">\(F(x+0)-F(x-0)\)</span> of the distribution function <span class="arithmatex">\(F\)</span>.]</p>
<p>If we put <span class="arithmatex">\(G=\delta_{x}\)</span>, (5.6) gives the value of <span class="arithmatex">\(\psi_{F}(x)\)</span>; following Hampel (1968, 1974b) we write</p>
<div class="arithmatex">\[
I C(x ; F, T)=\lim _{t \rightarrow 0} \frac{T\left(F_{t}\right)-T(F)}{t}
\]</div>
<p>where <span class="arithmatex">\(F_{t}=(1-t) F+t \delta_{x}\)</span> and <span class="arithmatex">\(I C\)</span> stands for influence curve.
The Gâteaux derivative is, after all, nothing but the ordinary derivative of the real valued function <span class="arithmatex">\(T\left(F_{t}\right)\)</span> with respect to the real parameter <span class="arithmatex">\(t\)</span>. If we integrate the derivative of an absolutely continuous function, we get back the function; in this particular case we obtain the useful identity</p>
<div class="arithmatex">\[
T\left(F_{1}\right)-T\left(F_{0}\right)=\int_{0}^{1} \int I C\left(x ; F_{t}, T\right) d\left(F_{1}-F_{0}\right) d t
\]</div>
<p>Proof We have</p>
<div class="arithmatex">\[
T\left(F_{1}\right)-T\left(F_{0}\right)=\int_{0}^{1} \frac{d}{d t} T\left(F_{t}\right) d t
\]</div>
<p>Now</p>
<div class="arithmatex">\[
\frac{d}{d t} T\left(F_{t}\right)=\lim _{h \rightarrow 0} \frac{T\left(F_{t+h}\right)-T\left(F_{t}\right)}{h}
\]</div>
<p>and, since</p>
<div class="arithmatex">\[
F_{t+h}=\left(1-\frac{h}{1-t}\right) F_{t}+\frac{h}{1-t} F_{1}
\]</div>
<p>we obtain, provided the Gâteaux derivative exists at <span class="arithmatex">\(F_{t}\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
\frac{d}{d t} T\left(F_{t}\right) &amp; =\frac{1}{1-t} \int I C\left(x ; F_{t}, T\right) d\left(F_{1}-F_{t}\right) \\
&amp; =\int I C\left(x ; F_{t}, T\right) d\left(F_{1}-F_{0}\right)
\end{aligned}
\]</div>
<p>If the empirical distribution <span class="arithmatex">\(F_{n}\)</span> converges to the true one at the rate <span class="arithmatex">\(n^{-1 / 2}\)</span>,</p>
<div class="arithmatex">\[
d_{*}\left(F, F_{n}\right)=O_{p}\left(n^{-1 / 2}\right)
\]</div>
<p>and if <span class="arithmatex">\(T\)</span> has a Fréchet derivative at <span class="arithmatex">\(F\)</span>, (5.1) and (5.5) allow a one-line asymptotic normality proof</p>
<div class="arithmatex">\[
\begin{aligned}
\sqrt{n}\left[T\left(F_{n}\right)-T(F)\right] &amp; =\sqrt{n} \int \psi_{F} d F_{n}+\sqrt{n} o\left[d_{*}\left(F, F_{n}\right)\right] \\
&amp; =\frac{1}{\sqrt{n}} \sum \psi_{F}\left(x_{i}\right)+o_{F}(1)
\end{aligned}
\]</div>
<p>hence the left-hand side is asymptotically normal with mean 0 and variance <span class="arithmatex">\(\int \psi_{F}^{2} d F\)</span>.</p>
<p>For the Lévy distance, (5.9) is true; this follows at once from (4.14) and the well-known properties of the Kolmogorov-Smirnov test statistic. Unfortunately (5.9) is false for both the Prohorov and the bounded Lipschitz distance, as soon as <span class="arithmatex">\(F\)</span> has sufficiently long tails [rational tails <span class="arithmatex">\(F(|X|&gt;t) \sim\)</span> <span class="arithmatex">\(t^{-k}\)</span> for some <span class="arithmatex">\(k\)</span>, suffice for (5.9) to fail].</p>
<p>Proof The idea behind the proof is that, for long-tailed distributions <span class="arithmatex">\(F\)</span>, the extreme order statistics are widely scattered, so, if we surrounded them by <span class="arithmatex">\(\varepsilon\)</span>-neighborhoods, we catch very little of the mass of <span class="arithmatex">\(F\)</span>. To be specific assume that <span class="arithmatex">\(F(x)=|x|^{-k}\)</span> for large negative <span class="arithmatex">\(x\)</span>, let <span class="arithmatex">\(\delta\)</span> be a small positive number to be fixed later, let <span class="arithmatex">\(m=n^{1 / 2+\delta}\)</span>, and let <span class="arithmatex">\(A=\left\{x_{(1)}, \ldots, x_{(m)}\right\}\)</span> be the set of the <span class="arithmatex">\(m\)</span> leftmost order statistics. Put <span class="arithmatex">\(\varepsilon=\frac{1}{2} n^{-1 / 2+\delta}\)</span>. We intend to show that, for large <span class="arithmatex">\(n\)</span>,</p>
<div class="arithmatex">\[
F_{n}(A)-\varepsilon \geqslant F\left\{A^{\varepsilon}\right\}
\]</div>
<p>hence <span class="arithmatex">\(d_{F}\left(F, F_{n}\right) \geqslant \varepsilon\)</span>. We have <span class="arithmatex">\(F_{n}(A)=m / n=2 \varepsilon\)</span>, so it suffices to show <span class="arithmatex">\(F\left(A^{\varepsilon}\right) \leqslant \varepsilon\)</span>. We only sketch the calculations.</p>
<p>We have, approximately,</p>
<div class="arithmatex">\[
F\left(A^{\varepsilon}\right) \lesssim \sum_{1}^{m} 2 \varepsilon f\left(x_{(i)}\right)
\]</div>
<p>where <span class="arithmatex">\(f\)</span> is the density of <span class="arithmatex">\(F\)</span>. Now <span class="arithmatex">\(x_{(i)}\)</span> can be represented as <span class="arithmatex">\(F^{-1}\left(u_{(i)}\right)\)</span>, where <span class="arithmatex">\(u_{(i)}\)</span> is the <span class="arithmatex">\(i\)</span> th order statistic from the uniform distribution on <span class="arithmatex">\((0,1)\)</span>, and <span class="arithmatex">\(f\left(F^{-1}(t)\right)=k t^{(k+1) / k}\)</span>. Thus</p>
<div class="arithmatex">\[
F\left(A^{\varepsilon}\right) \lesssim 2 \varepsilon k \sum_{1}^{m}\left(u_{(i)}\right)^{(k+1) / k}
\]</div>
<p>Since <span class="arithmatex">\(u_{(i)} \approx i /(n+1)\)</span>, we can approximate the right-hand side</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \approx 2 \varepsilon k \sum_{1}^{m}\left(\frac{i}{n+1}\right)^{(k+1) / k} \\
&amp; \approx 2 \varepsilon k n \int_{0}^{m / n} t^{(k+1) / k} d t \\
&amp; =\frac{2 \varepsilon k n}{2+1 / k}\left(\frac{m}{n}\right)^{2+1 / k} \\
&amp; =\frac{2 k}{2+1 / k} \frac{1}{2} n^{-1 / 2+\delta} n\left(n^{-1 / 2+\delta}\right)^{2+1 / k} \\
&amp; =\frac{k}{2+1 / k} n^{-(1 / 2)-(1 / 2 k)+[3+(1 / k)] \delta}
\end{aligned}
\]</div>
<p>If we choose <span class="arithmatex">\(\delta\)</span> sufficiently small, this is of a smaller order of magnitude than <span class="arithmatex">\(\varepsilon\)</span>.</p>
<p>Compare also Kersting (1978).
On the other hand (5.9) is true for <span class="arithmatex">\(d_{P}\)</span> and <span class="arithmatex">\(d_{B L}\)</span> if <span class="arithmatex">\(F\)</span> is the uniform distribution on a finite interval, but it fails again for the uniform distribution on the unit cube in three or more dimensions [see Dudley (1969) for details].</p>
<p>It seems we are in trouble here because of a phenomenon that has been colorfully called the "curse of dimensionality"; the higher the dimension, the more empty space there is, and it becomes progressively more difficult to relate the coarse and sparse empirical measure to the true one.</p>
<p>Mere Gâteaux differentiability does not suffice to establish asymptotic normality [unless we also have higher order derivatives, cf. von Mises (1937, 1947), who introduced the concept of differentiable statistical functionals, and Filippova (1962)]. The most promising intermediate approach seems to be the one by Reeds (1976), which is based on the notion of compact differentiability (Averbukh and Smolyanov 1967, 1968).</p>
<h1 id="26-hampels-theorem">2.6 HAMPEL'S THEOREM</h1>
<p>We recall Hampel's definition of qualitative asymptotic robustness (cf. Section 1.3).</p>
<p>Let the observations <span class="arithmatex">\(x_{i}\)</span> be independent, with common distribution <span class="arithmatex">\(F\)</span>, and let <span class="arithmatex">\(T_{n}=T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span> be a sequence of estimates or test statistics with</p>
<p>values in <span class="arithmatex">\(\mathbb{R}^{k}\)</span>. This sequence is called robust at <span class="arithmatex">\(F=F_{0}\)</span> if the sequence of maps of distributions</p>
<div class="arithmatex">\[
F \rightarrow \hat{\mathcal{C}}_{F}\left(T_{n}\right)
\]</div>
<p>is equicontinuous at <span class="arithmatex">\(F_{0}\)</span>, that is, if, for every <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a <span class="arithmatex">\(\delta&gt;0\)</span> and an <span class="arithmatex">\(n_{0}\)</span> such that, for all <span class="arithmatex">\(F\)</span> and all <span class="arithmatex">\(n \geqslant n_{0}\)</span>,</p>
<div class="arithmatex">\[
d_{*}\left(F_{0}, F\right)&lt;\delta \Rightarrow d_{*}\left(\hat{\mathcal{C}}_{F_{0}}\left(T_{n}\right), \hat{\mathcal{C}}_{F}\left(T_{n}\right)\right)&lt;\varepsilon
\]</div>
<p>Here, <span class="arithmatex">\(d_{*}\)</span> is any metric generating the weak topology. It is by no means clear whether different metrics give rise to equivalent robustness notions; to be specific we work the Lévy metric for <span class="arithmatex">\(F\)</span> and the Prohorov metric for <span class="arithmatex">\(\mathcal{E}\left(T_{n}\right)\)</span>.</p>
<p>Assume that <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> derives from a functional <span class="arithmatex">\(T\)</span>, which is defined on some weakly open subset of <span class="arithmatex">\(\mathfrak{M}\)</span>.</p>
<p>PROPOSITION 6.1 If <span class="arithmatex">\(T\)</span> is weakly continuous at <span class="arithmatex">\(F\)</span>, then <span class="arithmatex">\(\left\{T_{n}\right\}\)</span> is consistent at <span class="arithmatex">\(F\)</span>, in the sense that <span class="arithmatex">\(T_{n} \rightarrow T(F)\)</span> in probability and almost surely.
Proof It follows from the Glivenko-Cantelli theorem and (4.14) that, in probability and almost surely,</p>
<div class="arithmatex">\[
d_{L}\left(F, F_{n}\right) \leqslant d_{K}\left(F, F_{n}\right) \rightarrow 0
\]</div>
<p>hence <span class="arithmatex">\(F_{n} \rightarrow F\)</span> weakly, and thus <span class="arithmatex">\(T\left(F_{n}\right) \rightarrow T(F)\)</span>.
The following is a variant of somewhat more general results first proved by Hampel (1971).</p>
<p>THEOREM 6.2 Assume that <span class="arithmatex">\(\left\{T_{n}\right\}\)</span> is consistent in a neighborhood of <span class="arithmatex">\(F_{0}\)</span>. Then <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span> iff <span class="arithmatex">\(\left\{T_{n}\right\}\)</span> is robust at <span class="arithmatex">\(F_{0}\)</span>.</p>
<p>Proof Assume first that <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span>. We can write</p>
<div class="arithmatex">\[
d_{P}\left(\hat{\mathcal{C}}_{F_{0}}\left(T_{n}\right), \hat{\mathcal{C}}_{F}\left(T_{n}\right)\right) \leqslant d_{P}\left(\delta_{T\left(F_{0}\right)}, \hat{\mathcal{C}}_{F_{0}}\left(T_{n}\right)\right)+d_{P}\left(\delta_{T\left(F_{0}\right)}, \hat{\mathcal{C}}_{F}\left(T_{n}\right)\right)
\]</div>
<p>where <span class="arithmatex">\(\delta_{T\left(F_{0}\right)}\)</span> denotes the degenerate law concentrated at <span class="arithmatex">\(T\left(F_{0}\right)\)</span>. Thus robustness at <span class="arithmatex">\(F_{0}\)</span> is proved if we can show that, for each <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a <span class="arithmatex">\(\delta&gt;0\)</span> and an <span class="arithmatex">\(n_{0}\)</span>, such that <span class="arithmatex">\(d_{L}\left(F_{0}, F\right) \leqslant \delta\)</span> implies</p>
<div class="arithmatex">\[
d_{P}\left(\delta_{T\left(F_{0}\right)}, \hat{\mathcal{C}}_{F}\left(T\left(F_{n}\right)\right)\right) \leqslant \frac{1}{2} \varepsilon, \quad \text { for } n \geqslant n_{0}
\]</div>
<p>It follows from the easy part of Strassen's theorem (Theorem 3.7) that this</p>
<p>last inequality holds if we can show</p>
<div class="arithmatex">\[
P_{F}\left\{d\left(T\left(F_{0}\right), T\left(F_{n}\right)\right)&lt;\frac{1}{2} \varepsilon\right\} \geqslant 1-\frac{1}{2} \varepsilon
\]</div>
<p>But, since <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span>, there is a <span class="arithmatex">\(\delta&gt;0\)</span> such that <span class="arithmatex">\(d_{L}\left(F_{0}, F\right) \leqslant 2 \delta\)</span> implies <span class="arithmatex">\(d\left(T\left(F_{0}\right), T(F)\right) \leqslant \frac{1}{2} \varepsilon\)</span>, so it suffices to show</p>
<div class="arithmatex">\[
P_{F}\left\{d_{L}\left(F_{0}, F_{n}\right) \leqslant 2 \delta\right\} \geqslant 1-\frac{1}{2} \varepsilon
\]</div>
<p>We note that Glivenko-Cantelli convergence is uniform in <span class="arithmatex">\(F\)</span> : for each <span class="arithmatex">\(\delta&gt;0\)</span> and <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is an <span class="arithmatex">\(n_{0}\)</span> such that, for all <span class="arithmatex">\(F\)</span> and all <span class="arithmatex">\(n \geqslant n_{0}\)</span>,</p>
<div class="arithmatex">\[
P_{F}\left\{d_{L}\left(F, F_{n}\right) \leqslant \delta\right\} \geqslant 1-\frac{1}{2} \varepsilon
\]</div>
<p>But, since <span class="arithmatex">\(d_{*}\left(F_{0}, F_{n}\right) \leqslant d_{*}\left(F_{0}, F\right)+d_{*}\left(F, F_{n}\right)\)</span>, we have established robustness at <span class="arithmatex">\(F_{0}\)</span>.</p>
<p>Conversely, assume that <span class="arithmatex">\(\left\{T_{n}\right\}\)</span> is robust at <span class="arithmatex">\(F_{0}\)</span>. We note that, for degenerate laws <span class="arithmatex">\(\delta_{x}\)</span>, which put all mass on a single point <span class="arithmatex">\(x\)</span>, Prohorov distance degenerates to the ordinary distance: <span class="arithmatex">\(d_{P}\left(\delta_{x}, \delta_{y}\right)=d(x, y)\)</span>.</p>
<p>Since <span class="arithmatex">\(T_{n}\)</span> is consistent for each <span class="arithmatex">\(F\)</span> in some neighborhood of <span class="arithmatex">\(F_{0}\)</span>, we have <span class="arithmatex">\(d_{P}\left(\delta_{T(F)}, \hat{\mathrm{E}}_{F}\left(T_{n}\right)\right) \rightarrow 0\)</span>. Hence (6.1) implies, in particular,</p>
<div class="arithmatex">\[
d_{L}\left(F_{0}, F\right) \leqslant \delta \Rightarrow d_{P}\left(\delta_{T\left(F_{0}\right)}, \delta_{T(F)}\right)=d\left(T\left(F_{0}\right), T(F)\right) \leqslant \varepsilon
\]</div>
<p>It follows that <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span>.</p>
<h1 id="chapter-3">CHAPTER 3</h1>
<h2 id="the-basic-types-of-estimates">The Basic Types of Estimates</h2>
<h3 id="31-general-remarks">3.1 GENERAL REMARKS</h3>
<p>This chapter introduces three basic types of estimates ( <span class="arithmatex">\(M, L\)</span>, and <span class="arithmatex">\(R\)</span> ) and discusses their qualitative and quantitative robustness properties. They correspond, respectively, to maximum likelihood type estimates, linear combinations of order statistics, and estimates derived from rank tests.</p>
<p>For reasons discussed in more detail near the end of Section 3.5, the emphasis is on the first type, the <span class="arithmatex">\(M\)</span>-estimates: they are the most flexible ones, and they generalize straightforwardly to multiparameter problems, even though (or, perhaps, because) they are not automatically scale invariant and have to be supplemented for practical applications by an auxiliary estimate of scale (see Chapters 6 ff ).</p>
<h3 id="32-maximum-likelihood-type-estimates-m-estimates">3.2 MAXIMUM LIKELIHOOD TYPE ESTIMATES (M-ESTIMATES)</h3>
<p>Any estimate <span class="arithmatex">\(T_{n}\)</span>, defined by a minimum problem of the form</p>
<div class="arithmatex">\[
\sum \rho\left(x_{i} ; T_{n}\right)=\min !
\]</div>
<p>or by an implicit equation</p>
<div class="arithmatex">\[
\sum \psi\left(x_{i} ; T_{n}\right)=0
\]</div>
<p>where <span class="arithmatex">\(\rho\)</span> is an arbitrary function, <span class="arithmatex">\(\psi(x ; \theta)=(\partial / \partial \theta) \rho(x ; \theta)\)</span>, is called an <span class="arithmatex">\(M\)</span>-estimate [or maximum likelihood type estimate; note that the choice <span class="arithmatex">\(\rho(x ; \theta)=-\log f(x ; \theta)\)</span> gives the ordinary ML estimate].</p>
<p>We are particularly interested in location estimates</p>
<div class="arithmatex">\[
\sum \rho\left(x_{i}-T_{n}\right)=\min !
\]</div>
<p>or</p>
<div class="arithmatex">\[
\sum \psi\left(x_{i}-T_{n}\right)=0
\]</div>
<p>This last equation can be written equivalently as</p>
<div class="arithmatex">\[
\sum w_{i} \cdot\left(x_{i}-T_{n}\right)=0
\]</div>
<p>with</p>
<div class="arithmatex">\[
w_{i}=\frac{\psi\left(x_{i}-T_{n}\right)}{x_{i}-T_{n}}
\]</div>
<p>this gives a formal representation of <span class="arithmatex">\(T_{n}\)</span> as a weighted mean</p>
<div class="arithmatex">\[
T_{n}=\frac{\sum w_{i} x_{i}}{\sum w_{i}}
\]</div>
<p>with weights depending on the sample.
Remark The functional version of (2.1) may cause trouble: we cannot in general define <span class="arithmatex">\(T(F)\)</span> to be a value of <span class="arithmatex">\(t\)</span> that minimizes</p>
<div class="arithmatex">\[
\int \rho(x ; t) F(d x)
\]</div>
<p>Note, for instance, that the median corresponds to <span class="arithmatex">\(\rho(x ; t)=|x-t|\)</span>, but that</p>
<div class="arithmatex">\[
\int|x-t| F(d x) \equiv \infty
\]</div>
<p>identically in <span class="arithmatex">\(t\)</span> unless <span class="arithmatex">\(F\)</span> has a finite first absolute moment. There is a simple remedy: replace <span class="arithmatex">\(\rho(x ; t)\)</span> by <span class="arithmatex">\(\rho(x ; t)-\rho\left(x ; t_{0}\right)\)</span> for some fixed <span class="arithmatex">\(t_{0}\)</span>, that is, in the case of the median, minimize</p>
<div class="arithmatex">\[
\int(|x-t|-|x|) F(d x)
\]</div>
<p>instead of (2.9).
The functional derived from (2.2), defining <span class="arithmatex">\(T(F)\)</span> by</p>
<div class="arithmatex">\[
\int \psi(x ; T(F)) F(d x)=0
\]</div>
<p>does not suffer from this difficulty, but it may have more solutions [corresponding to local minima of (2.8)].</p>
<h1 id="influence-function-of-boldsymbolm-estimates">Influence Function of <span class="arithmatex">\(\boldsymbol{M}\)</span>-Estimates</h1>
<p>To calculate the influence function of an <span class="arithmatex">\(M\)</span>-estimate, we insert <span class="arithmatex">\(F_{t}=(1-t) F\)</span> <span class="arithmatex">\(+t G\)</span> for <span class="arithmatex">\(F\)</span> into (2.11) and take the derivative with respect to <span class="arithmatex">\(t\)</span> at <span class="arithmatex">\(t=0\)</span>. In detail, if we put for short</p>
<div class="arithmatex">\[
\dot{T}=\lim _{t \rightarrow 0} \frac{T\left(F_{t}\right)-T(F)}{t}
\]</div>
<p>we obtain, by differentiation of the defining equation (2.11),</p>
<div class="arithmatex">\[
\dot{T} \int \frac{\partial}{\partial \theta} \psi(x ; T(F)) F(d x)+\int \psi(x ; T(F))(d G-d F)=0
\]</div>
<p>For the moment we do not worry about regularity conditions. We recall from (2.5.7) that, for <span class="arithmatex">\(G=\delta_{x}, \dot{T}\)</span> gives the value of the influence function at <span class="arithmatex">\(x\)</span>, so, by solving (2.12) for <span class="arithmatex">\(\dot{T}\)</span>, we obtain</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\psi(x ; T(F))}{-\int(\partial / \partial \theta) \psi(x ; T(F)) F(d x)}
\]</div>
<p>In other words the influence function of an <span class="arithmatex">\(M\)</span>-estimate is proportional to <span class="arithmatex">\(\psi\)</span>.</p>
<p>In the special case of a location problem, <span class="arithmatex">\(\psi(x ; \theta)=\psi(x-\theta)\)</span>, we obtain</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\psi[x-T(F)]}{\int \psi^{\prime}[x-T(F)] F(d x)}
\]</div>
<p>We conclude from this in a heuristic way that <span class="arithmatex">\(\sqrt{n}\left[T_{n}-T(F)\right]\)</span> is asymptotically normal with mean 0 and variance</p>
<div class="arithmatex">\[
A(F, T)=\int I C(x ; F, T)^{2} F(d x)
\]</div>
<p>However, this must be checked by a rigorous proof.</p>
<h2 id="asymptotic-properties-of-boldsymbolm-estimates">Asymptotic Properties of <span class="arithmatex">\(\boldsymbol{M}\)</span>-Estimates</h2>
<p>A fairly simple and straightforward theory is possible if <span class="arithmatex">\(\psi(x ; \theta)\)</span> is monotone in <span class="arithmatex">\(\theta\)</span>; more general cases are treated in Chapter 6.</p>
<p><img alt="img-1.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 3.2.1</p>
<p>Assume that <span class="arithmatex">\(\psi(x ; \theta)\)</span> is measurable in <span class="arithmatex">\(x\)</span> and decreasing (i.e., nonincreasing) in <span class="arithmatex">\(\theta\)</span>, from strictly positive to strictly negative values. Put</p>
<div class="arithmatex">\[
\begin{aligned}
T_{n}^{*} &amp; =\sup \left\{t \mid \sum_{1}^{n} \psi\left(x_{i} ; t\right)&gt;0\right\} \\
T_{n}^{* *} &amp; =\inf \left\{t \mid \sum_{1}^{n} \psi\left(x_{i} ; t\right)&lt;0\right\}
\end{aligned}
\]</div>
<p>Clearly, <span class="arithmatex">\(-\infty&lt;T_{n}^{*} \leqslant T_{n}^{* *}&lt;\infty\)</span>, and any value <span class="arithmatex">\(T_{n}\)</span> satisfying <span class="arithmatex">\(T_{n}^{*} \leqslant T_{n} \leqslant T_{n}^{* *}\)</span> can serve as our estimate. Exhibit 3.2.1 may help with the interpretation of <span class="arithmatex">\(T_{n}^{*}\)</span> and <span class="arithmatex">\(T_{n}^{* *}\)</span>.</p>
<p>Note that</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \left\{T_{n}^{*}&lt;t\right\} \subset\left\{\sum \psi\left(x_{i} ; t\right) \leqslant 0\right\} \subset\left\{T_{n}^{*} \leqslant t\right\} \\
&amp; \left\{T_{n}^{* *}&lt;t\right\} \subset\left\{\sum \psi\left(x_{i} ; t\right)&lt;0\right\} \subset\left\{T_{n}^{* *} \leqslant t\right\}
\end{aligned}
\]</div>
<p>Hence</p>
<div class="arithmatex">\[
\begin{aligned}
P\left\{T_{n}^{*}&lt;t\right\} &amp; =P\left\{\sum \psi\left(x_{i} ; t\right) \leqslant 0\right\} \\
P\left\{T_{n}^{* *}&lt;t\right\} &amp; =P\left\{\sum \psi\left(x_{i} ; t\right)&lt;0\right\}
\end{aligned}
\]</div>
<p>at the continuity points <span class="arithmatex">\(t\)</span> of the left-hand side.</p>
<p>The distribution of the customary midpoint estimate <span class="arithmatex">\(\frac{1}{2}\left(T_{n}^{*}+T_{n}^{* *}\right)\)</span> is somewhat difficult to work out, but the randomized estimate <span class="arithmatex">\(T_{n}\)</span>, which selects one of <span class="arithmatex">\(T_{n}^{*}\)</span> or <span class="arithmatex">\(T_{n}^{* *}\)</span> at random with equal probability, has an explicitly expressible distribution function</p>
<div class="arithmatex">\[
P\left\{T_{n}&lt;t\right\}=\frac{1}{2} P\left\{\sum \psi\left(x_{i} ; t\right) \leqslant 0\right\}+\frac{1}{2} P\left\{\sum \psi\left(x_{i} ; t\right)&lt;0\right\}
\]</div>
<p>It follows that the exact distributions of <span class="arithmatex">\(T_{n}^{*}, T_{n}^{* *}\)</span>, and <span class="arithmatex">\(T_{n}\)</span> can be calculated from the convolution powers of <span class="arithmatex">\(\mathcal{E}(\psi(x ; t))\)</span>.</p>
<p>Asymptotic approximations can be found by expanding <span class="arithmatex">\(G_{n}=\mathcal{E}\left(\sum_{1}^{n} \psi\left(x_{i} ; t\right)\right)\)</span> into an asymptotic series.</p>
<p>We may take the traditional Edgeworth expansion</p>
<div class="arithmatex">\[
G_{n}(x) \sim \Phi(x)+\varphi(x)\left[\frac{1}{\sqrt{n}} R_{3}(x)+\frac{1}{n} R_{4}(x)+\cdots\right]
\]</div>
<p>However, this gives a somewhat poor approximation in the tails, that is, precisely in the region where we are most interested. Therefore it is preferable to use so-called saddlepoint techniques and recenter the distributions at the point of interest. Thus if we have independent random variables <span class="arithmatex">\(Y_{t}\)</span> with density <span class="arithmatex">\(f(x)\)</span> and would like to determine the distribution <span class="arithmatex">\(G_{n}\)</span> of <span class="arithmatex">\(Y_{1}+\cdots+Y_{n}\)</span> at the point <span class="arithmatex">\(t\)</span>, we replace the original density <span class="arithmatex">\(f\)</span> by a conjugate density <span class="arithmatex">\(f_{t}\)</span> :</p>
<div class="arithmatex">\[
f_{t}(z)=c_{t} e^{a_{t} z} f(t+z)
\]</div>
<p>where <span class="arithmatex">\(c_{t}\)</span> and <span class="arithmatex">\(a_{t}\)</span> are chosen such that this is a probability density with expectation 0 . See Daniels (1954).</p>
<p>Later Hampel (1973b) noticed that the principal error term of the saddlepoint method seems to reside in the normalizing constant (standardizing the total mass of <span class="arithmatex">\(G_{n}\)</span> to 1 ), so it would be advantageous not to expand <span class="arithmatex">\(G_{n}\)</span> or its density <span class="arithmatex">\(g_{n}\)</span>, but <span class="arithmatex">\(g_{n}^{\prime} / g_{n^{\prime}}\)</span> and then to determine the normalizing constant by numerical integration. Thus his procedure can be summarized as follows. Determine the second and the normalized third moment of <span class="arithmatex">\(f_{t}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
\sigma_{t}^{2} &amp; =\int z^{2} f_{t}(z) d z \\
\lambda_{3, t} &amp; =\frac{\int z^{3} f_{t}(z) d z}{\sigma_{t}^{3}}
\end{aligned}
\]</div>
<p>Then we get from the first two terms of the Edgeworth expansion, calculated at <span class="arithmatex">\(x=0\)</span>, that</p>
<div class="arithmatex">\[
\frac{g_{n}^{\prime}}{g_{n}} \sim-n a_{t}-\frac{\lambda_{3, t}}{2 \sigma_{t}}
\]</div>
<p>From this we obtain <span class="arithmatex">\(g_{n}\)</span> and <span class="arithmatex">\(G_{n}\)</span> by two numerical integrations and one exponentiation; the integration constant must be determined such that <span class="arithmatex">\(G_{n}\)</span> has total mass 1. It turns out that the first integration can be done explicitly:</p>
<div class="arithmatex">\[
\log g_{n}(t) \sim-n c_{t}-\log \sigma_{t}+\text { const. }
\]</div>
<p>This method appears to give fantastically accurate approximations down to very small sample sizes ( <span class="arithmatex">\(n=3\)</span> or 4). See Field and Hampel (1980) for details.</p>
<p>We now turn to the limiting distribution of <span class="arithmatex">\(T_{n}\)</span>. Put</p>
<div class="arithmatex">\[
\lambda(t)=\lambda(t, F)=E_{F} \psi(X, t)
\]</div>
<p>If <span class="arithmatex">\(\lambda\)</span> exists and is finite for at least one value of <span class="arithmatex">\(t\)</span>, then it exists and is monotone (although not necessarily finite) for all <span class="arithmatex">\(t\)</span>. This follows at once from the remark that <span class="arithmatex">\(\psi(X ; t)-\psi(X ; s)\)</span> is positive for <span class="arithmatex">\(t \leqslant s\)</span> and hence has a well defined expectation (possibly <span class="arithmatex">\(+\infty\)</span> ).</p>
<p>PROPOSITION 2.1 Assume that there is a <span class="arithmatex">\(t_{0}\)</span> such that <span class="arithmatex">\(\lambda(t)&gt;0\)</span> for <span class="arithmatex">\(t&lt;t_{0}\)</span> and <span class="arithmatex">\(\lambda(t)&lt;0\)</span> for <span class="arithmatex">\(t&gt;t_{0}\)</span>. Then both <span class="arithmatex">\(T_{n}^{*}\)</span> and <span class="arithmatex">\(T_{n}^{* *}\)</span> converge in probability and almost surely to <span class="arithmatex">\(t_{0}\)</span>.</p>
<p>Proof This follows easily from (2.18) and the weak (strong) law of large numbers applied to <span class="arithmatex">\((1 / n) \Sigma \psi\left(x_{t} ; t_{0} \pm \varepsilon\right)\)</span>.</p>
<p>COROLLARY 2.2 If <span class="arithmatex">\(T(F)\)</span> is uniquely defined, then <span class="arithmatex">\(T_{n}\)</span> is consistent at <span class="arithmatex">\(F\)</span> : <span class="arithmatex">\(T_{n} \rightarrow T(F)\)</span> in probability and almost surely.</p>
<p>Note that <span class="arithmatex">\(\lambda(s ; F)=\lambda(t ; F)\)</span> implies <span class="arithmatex">\(\psi(x ; s)=\psi(x ; t)\)</span> a.e. <span class="arithmatex">\([F]\)</span>, so for many purposes <span class="arithmatex">\(\lambda(t)\)</span> furnishes a more convenient parameterization than <span class="arithmatex">\(t\)</span> itself. If <span class="arithmatex">\(\lambda\)</span> is continuous, then Proposition 2.1 can be restated by saying that <span class="arithmatex">\(\lambda\left(T_{n}\right)\)</span> is a consistent estimate of 0 ; this holds also if <span class="arithmatex">\(\lambda\)</span> vanishes on a nondegenerate interval. Also other aspects of the asymptotic behavior of <span class="arithmatex">\(T_{n}\)</span> are best studied through that of <span class="arithmatex">\(\lambda\left(T_{n}\right)\)</span>. Since <span class="arithmatex">\(\lambda\)</span> is monotone decreasing, we have, in particular,</p>
<div class="arithmatex">\[
\left\{-\lambda\left(T_{n}\right)&lt;-\lambda(t)\right\} \subset\left\{T_{n}&lt;t\right\} \subset\left\{T_{n}&lt;t\right\} \subset\left\{-\lambda\left(T_{n}\right) \leqslant-\lambda(t)\right\}
\]</div>
<p>We now plan to show that <span class="arithmatex">\(\sqrt{n} \lambda\left(T_{n}\right)\)</span> is asymptotically normal under the following.</p>
<h1 id="assumptions">ASSUMPTIONS</h1>
<p>(A-1) <span class="arithmatex">\(\psi(x, t)\)</span> is measurable in <span class="arithmatex">\(x\)</span> and monotone decreasing in <span class="arithmatex">\(t\)</span>.
(A-2) There is at least one <span class="arithmatex">\(t_{0}\)</span> for which <span class="arithmatex">\(\lambda\left(t_{0}\right)=0\)</span>.
Let <span class="arithmatex">\(\Gamma_{0}\)</span> be the set of <span class="arithmatex">\(t\)</span>-values for which <span class="arithmatex">\(\lambda(t)=0\)</span>.
(A-3) <span class="arithmatex">\(\lambda\)</span> is continuous in a neighborhood of <span class="arithmatex">\(\Gamma_{0}\)</span>.
(A-4) <span class="arithmatex">\(\sigma(t)^{2}=E_{F}\left[\psi(X ; t)^{2}\right]-\lambda(t, F)^{2}\)</span> is finite, nonzero, and continuous in a neighborhood of <span class="arithmatex">\(\Gamma_{0}\)</span>. Put <span class="arithmatex">\(\sigma_{0}=\sigma\left(t_{0}\right)\)</span>.</p>
<p>Asymptotically, all <span class="arithmatex">\(T_{n}, T_{n}^{*} \leqslant T_{n} \leqslant T_{n}^{* *}\)</span>, show the same behavior; formally, we work with <span class="arithmatex">\(T_{n}^{*}\)</span>.</p>
<p>Let <span class="arithmatex">\(y\)</span> be an arbitrary real number. With the aid of (A-3) define a sequence <span class="arithmatex">\(t_{n}\)</span>, for sufficiently large <span class="arithmatex">\(n\)</span>, such that <span class="arithmatex">\(y=-\sqrt{n} \lambda\left(t_{n}\right)\)</span>. Put</p>
<div class="arithmatex">\[
Y_{n i}=\frac{\psi\left(x_{i} ; t_{n}\right)-\lambda\left(t_{n}\right)}{\sigma\left(t_{n}\right)}
\]</div>
<p>The <span class="arithmatex">\(Y_{n i}, 1 \leqslant i \leqslant n\)</span>, are independent, identically distributed random variables with expectation 0 and variance 1 . We have, in view of (2.18) and (2.26),</p>
<div class="arithmatex">\[
\begin{aligned}
P\left\{-\sqrt{n} \lambda\left(T_{n}^{*}\right)&lt;y\right\} &amp; =P\left\{T_{n}^{*}&lt;t_{n}\right\} \\
&amp; =P\left\{\frac{1}{\sqrt{n}} \sum Y_{n i} \leqslant \frac{y}{\sigma\left(t_{n}\right)}\right\}
\end{aligned}
\]</div>
<p>if <span class="arithmatex">\(y / \sqrt{n}\)</span> is a continuity point of the distribution of <span class="arithmatex">\(\lambda\left(T_{n}^{*}\right)\)</span>, that is, for almost all <span class="arithmatex">\(y\)</span>.</p>
<p>LEMMA 2.3 When <span class="arithmatex">\(n \rightarrow \infty\)</span>, then</p>
<div class="arithmatex">\[
P\left\{\frac{1}{\sqrt{n}} \sum Y_{n i}&lt;z\right\} \rightarrow \Phi(z)
\]</div>
<p>uniformly in <span class="arithmatex">\(z\)</span>.
Proof We have to verify Lindeberg's condition, which in our case reads: for every <span class="arithmatex">\(\varepsilon&gt;0\)</span>,</p>
<div class="arithmatex">\[
E\left\{Y_{n i}^{2} ;\left|Y_{n i}\right|&gt;\sqrt{n} \varepsilon\right\} \rightarrow 0
\]</div>
<p>as <span class="arithmatex">\(n \rightarrow \infty\)</span>. Since <span class="arithmatex">\(\lambda\)</span> and <span class="arithmatex">\(\sigma\)</span> are continuous, this is equivalent to: for every <span class="arithmatex">\(\varepsilon&gt;0\)</span>, as <span class="arithmatex">\(n \rightarrow \infty\)</span>,</p>
<div class="arithmatex">\[
E\left\{\psi\left(x ; t_{n}\right)^{2} ;\left|\psi\left(x ; t_{n}\right)\right|&gt;\sqrt{n} \varepsilon\right\} \rightarrow 0
\]</div>
<p>Thus it suffices to show that the family of random variables <span class="arithmatex">\(\left(\psi\left(x ; t_{n}\right)\right)_{n \geqslant n_{0}}\)</span> is uniformly integrable [cf. Neveu (1964), p. 48]. But, since <span class="arithmatex">\(\psi\)</span> is monotone,</p>
<div class="arithmatex">\[
\psi(X ; s)^{2} \leqslant \psi\left(X ; s_{0}\right)^{2}+\psi\left(X ; s_{1}\right)^{2}
\]</div>
<p>for <span class="arithmatex">\(s_{0} \leqslant s \leqslant s_{1}\)</span>; hence the family in view of (A-4) is majorized by an integrable random variable, and thus is uniformly integrable.</p>
<p>In view of (2.28) we thus have the following theorem.
THEOREM 2.4 Under assumptions (A-1) to (A-4)</p>
<div class="arithmatex">\[
P\left\{-\sqrt{n} \lambda\left(T_{n}\right)&lt;y\right\}-\Phi\left(\frac{y}{\sigma_{0}}\right) \rightarrow 0
\]</div>
<p>uniformly in <span class="arithmatex">\(y\)</span>. In other words <span class="arithmatex">\(\sqrt{n} \lambda\left(T_{n}\right)\)</span> is asymptotically normal <span class="arithmatex">\(N\left(0, \sigma_{0}^{2}\right)\)</span>.
Proof It only remains to show that the convergence is uniform. This is clearly true for any bounded <span class="arithmatex">\(y\)</span>-interval <span class="arithmatex">\(\left[-y_{0}, y_{0}\right]\)</span>, so, if <span class="arithmatex">\(\varepsilon&gt;0\)</span> is given and if we choose <span class="arithmatex">\(y_{0}\)</span> so large that <span class="arithmatex">\(\Phi\left(-y_{0} / \sigma_{0}\right)&lt;\varepsilon / 2\)</span> and <span class="arithmatex">\(n_{0}\)</span> so large that (2.29) is <span class="arithmatex">\(&lt;\varepsilon / 2\)</span> for all <span class="arithmatex">\(n \geqslant n_{0}\)</span> and all <span class="arithmatex">\(y \in\left[-y_{0}, y_{0}\right]\)</span>, it follows that (2.29) must be <span class="arithmatex">\(&lt;\varepsilon\)</span> for all <span class="arithmatex">\(y\)</span>.</p>
<p>COROLLARY 2.5 If <span class="arithmatex">\(\lambda\)</span> has a derivative <span class="arithmatex">\(\lambda^{\prime}\left(t_{0}\right)&lt;0\)</span>, then <span class="arithmatex">\(\sqrt{n}\left(T_{n}-t_{0}\right)\)</span> is asymptotically normal with mean 0 and variance <span class="arithmatex">\(\sigma_{0}^{2} /\left(\lambda^{\prime}\left(t_{0}\right)\right)^{2}\)</span>.</p>
<p>Proof In this case</p>
<div class="arithmatex">\[
t_{n}=t_{0}-\frac{y}{\sqrt{n} \lambda^{\prime}\left(t_{0}\right)}+o\left(\frac{1}{\sqrt{n}}\right)
\]</div>
<p>so the corollary follows from a comparison between (2.28) and (2.29).
If we compare this with the heuristically derived expression (2.15), we notice that the latter is correct only if we can interchange the order of integration and differentiation in the denominator of (2.13), that is, if</p>
<div class="arithmatex">\[
\lambda^{\prime}(t ; F)=\frac{\partial}{\partial t} \int \psi(x ; t) F(d x)=\int \frac{\partial}{\partial t} \psi(x ; t) F(d x)
\]</div>
<p>at <span class="arithmatex">\(t=T(F)\)</span>.</p>
<p>To illustrate some of the issues, we take the location case, <span class="arithmatex">\(\psi(x ; t)=\)</span> <span class="arithmatex">\(\psi(x-t)\)</span>. If <span class="arithmatex">\(F\)</span> has a smooth density, we can write</p>
<div class="arithmatex">\[
\lambda(t ; F)=\int_{x} \psi(x-t) f(x) d x=\int \psi(x) f(x+t) d x
\]</div>
<p>thus</p>
<div class="arithmatex">\[
\lambda^{\prime}(t ; F)=\int \psi(x) f^{\prime}(x+t) d x
\]</div>
<p>may be well behaved even if <span class="arithmatex">\(\psi\)</span> is not differentiable.
If <span class="arithmatex">\(F=(1-\varepsilon) G+\varepsilon \delta_{x_{0}}\)</span> is a mixture of a smooth distribution and a pointmass, we have</p>
<div class="arithmatex">\[
\lambda(t ; F)=(1-\varepsilon) \int \psi(x-t) g(x) d x+\varepsilon \psi\left(x_{0}-t\right)
\]</div>
<p>and</p>
<div class="arithmatex">\[
\lambda^{\prime}(t, F)=(1-\varepsilon) \int \psi(x) g^{\prime}(x+t) d x-\varepsilon \psi^{\prime}\left(x_{0}-t\right)
\]</div>
<p>Hence if <span class="arithmatex">\(\psi^{\prime}\)</span> is discontinuous and happens to have a jump at the point <span class="arithmatex">\(x_{0}-T(F)\)</span>, then the left-hand side and the right-hand side derivatives of <span class="arithmatex">\(\lambda\)</span> at <span class="arithmatex">\(t=T(F)\)</span> exist but are different. As a consequence <span class="arithmatex">\(\sqrt{n}\left[T_{n}-T(F)\right]\)</span> has a nonnormal limiting distribution: it is pieced together from the left half and the right half of two normal distributions with different standard deviations.</p>
<p>Hitherto we have been concerned with a fixed underlying distribution <span class="arithmatex">\(F\)</span>. From the point of view of robustness, such a result is of limited use; we would really like to have the convergence in Theorem 2.4 be uniform with respect to <span class="arithmatex">\(F\)</span> in some neighborhood of the model distribution <span class="arithmatex">\(F_{0}\)</span>. For this we need more stringent regularity conditions.</p>
<p>For instance, let us assume that <span class="arithmatex">\(\psi(x ; t)\)</span> is bounded and continuous as a function of <span class="arithmatex">\(x\)</span> and that the map <span class="arithmatex">\(t \rightarrow \psi(\cdot ; t)\)</span> is continuous for the topology of uniform convergence. Then <span class="arithmatex">\(\lambda(t ; F)\)</span> and <span class="arithmatex">\(\sigma(t ; F)\)</span> depend continuously on both <span class="arithmatex">\(t\)</span> and <span class="arithmatex">\(F\)</span>. With the aid of the Berry-Esseen theorem, it is then possible to put a bound on (2.29) that is uniform in <span class="arithmatex">\(F\)</span> [cf. Feller (1966), p. 515 ff ].</p>
<p>Of course, this does not yet suffice to make the asymptotic variance of <span class="arithmatex">\(\sqrt{n}\left[T_{n}-T(F)\right]\)</span></p>
<div class="arithmatex">\[
A(F, T)=\frac{\sigma(T(F) ; F)^{2}}{\left(\lambda^{\prime}(T(F) ; F)\right)^{2}}
\]</div>
<p>continuous as a function of <span class="arithmatex">\(F\)</span>.</p>
<h1 id="quantitative-and-qualitative-robustness-of-boldsymbolm-estimates">Quantitative and Qualitative Robustness of <span class="arithmatex">\(\boldsymbol{M}\)</span>-Estimates</h1>
<p>We now calculate the maximum bias <span class="arithmatex">\(b_{1}\)</span> (see Section 1.4) for <span class="arithmatex">\(M\)</span>-estimates. Specifically, we consider the location case, <span class="arithmatex">\(\psi(x ; t)=\psi(x-t)\)</span>, with a monotone increasing <span class="arithmatex">\(\psi\)</span>, and for <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> we take a Lévy neighborhood (the results for Prohorov neighborhoods happen to be the same). For simplicity we assume that the target value is <span class="arithmatex">\(T\left(F_{0}\right)=0\)</span>.</p>
<p>Put</p>
<div class="arithmatex">\[
b_{+}(\varepsilon)=\sup \left\{T(F) \mid d_{L}\left(F_{0}, F\right)&lt;\varepsilon\right\}
\]</div>
<p>and</p>
<div class="arithmatex">\[
b_{-}(\varepsilon)=\inf \left\{T(F) \mid d_{L}\left(F_{0}, F\right)&lt;\varepsilon\right\}
\]</div>
<p>then</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=\max \left\{b_{+}(\varepsilon),-b_{-}(\varepsilon)\right\}
\]</div>
<p>In view of Theorems 1.4.1 and 1.4.2, we have <span class="arithmatex">\(b_{1}(\varepsilon)=b(\varepsilon)\)</span> at the continuity points of <span class="arithmatex">\(b_{1}\)</span>.</p>
<p>As before we let</p>
<div class="arithmatex">\[
\lambda(t ; F)=\int \psi(x-t) F(d x)
\]</div>
<p>We note that <span class="arithmatex">\(\lambda\)</span> is decreasing in <span class="arithmatex">\(t\)</span>, and that it increases if <span class="arithmatex">\(F\)</span> is made stochastically larger [see, e.g., Lehmann (1959), p. 74, Lemma 2(i)]. The solution <span class="arithmatex">\(t=T(F)\)</span> of <span class="arithmatex">\(\lambda(t ; F)=0\)</span> is not necessarily unique; we have <span class="arithmatex">\(T^{*}(F) \leqslant\)</span> <span class="arithmatex">\(T(F) \leqslant T^{* *}(F)\)</span> with</p>
<div class="arithmatex">\[
\begin{aligned}
T^{*}(F) &amp; =\sup \{t \mid \lambda(t ; F)&gt;0\} \\
T^{* *}(F) &amp; =\inf \{t \mid \lambda(t ; F)&lt;0\}
\end{aligned}
\]</div>
<p>and we are concerned with the worst possible choice of <span class="arithmatex">\(T(F)\)</span> when we determine <span class="arithmatex">\(b_{+}\)</span>and <span class="arithmatex">\(b_{-}\)</span>.</p>
<p>The stochastically largest member of the set <span class="arithmatex">\(d_{L}\left(F_{0}, F\right)&lt;\varepsilon\)</span> is the (improper) distribution <span class="arithmatex">\(F_{1}\)</span> (it puts mass <span class="arithmatex">\(\varepsilon\)</span> at <span class="arithmatex">\(+\infty\)</span> ):</p>
<div class="arithmatex">\[
F_{1}(x)=\left(F_{0}(x-\varepsilon)-\varepsilon\right)^{+} ;
\]</div>
<p>that is,</p>
<div class="arithmatex">\[
\begin{aligned}
F_{1}(x) &amp; =0, &amp; &amp; \text { for } x \leqslant x_{0}+\varepsilon \\
&amp; =F_{0}(x-\varepsilon)-\varepsilon, &amp; &amp; \text { for } x&gt;x_{0}+\varepsilon
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(x_{0}\)</span> satisfying</p>
<div class="arithmatex">\[
F_{0}\left(x_{0}\right)=\varepsilon
\]</div>
<p>We gloss over some (inessential) complications that arise in the discontinuous case, when <span class="arithmatex">\(\varepsilon\)</span> does not belong to the set of values of <span class="arithmatex">\(F_{0}\)</span>.</p>
<p>Thus</p>
<div class="arithmatex">\[
\lambda(t ; F) \leqslant \lambda\left(t ; F_{1}\right)=\int_{x_{0}}^{\infty} \psi(x-t+\varepsilon) F_{0}(d x)+\varepsilon \psi(\infty)
\]</div>
<p>and</p>
<div class="arithmatex">\[
b_{+}(\varepsilon)=\inf \left\{t \mid \lambda\left(t ; F_{1}\right)&lt;0\right\}
\]</div>
<p>The other quantity <span class="arithmatex">\(b_{-}(\varepsilon)\)</span> is calculated analogously; in the important special case where <span class="arithmatex">\(F_{0}\)</span> is symmetric and <span class="arithmatex">\(\psi\)</span> is an odd function, we have, of course,</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=b_{+}(\varepsilon)=-b_{-}(\varepsilon)
\]</div>
<p>We conclude that <span class="arithmatex">\(b_{+}(\varepsilon)&lt;b_{+}(1)=\infty\)</span>, provided <span class="arithmatex">\(\psi(+\infty)&lt;\infty\)</span> and</p>
<div class="arithmatex">\[
\lim _{t \rightarrow \infty} \lambda\left(t ; F_{1}\right)=(1-\varepsilon) \psi(-\infty)+\varepsilon \psi(+\infty)&lt;0
\]</div>
<p>Thus in order to avoid breakdown on the right-hand side, we should have <span class="arithmatex">\(\varepsilon /(1-\varepsilon)&lt;-\psi(-\infty) / \psi(+\infty)\)</span>. If we also take the left-hand side into account, we obtain that the breakdown point is</p>
<div class="arithmatex">\[
\varepsilon^{*}=\frac{\eta}{1+\eta}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\eta=\min \left\{-\frac{\psi(-\infty)}{\psi(+\infty)},-\frac{\psi(+\infty)}{\psi(-\infty)}\right\}
\]</div>
<p>and that it reaches its best possible value <span class="arithmatex">\(\varepsilon^{*}=\frac{1}{2}\)</span> if <span class="arithmatex">\(\psi(-\infty)=-\psi(+\infty)\)</span>. If <span class="arithmatex">\(\psi\)</span> is unbounded, we have <span class="arithmatex">\(\varepsilon^{*}=0\)</span>.</p>
<p>The continuity properties of <span class="arithmatex">\(T\)</span> are also easy to establish. Put</p>
<div class="arithmatex">\[
\|\psi\|=\psi(+\infty)-\psi(-\infty)
\]</div>
<p>then (2.36) implies</p>
<div class="arithmatex">\[
\lambda\left(t+\varepsilon ; F_{0}\right)-\|\psi\| \varepsilon \leqslant \lambda(t ; F) \leqslant \lambda\left(t-\varepsilon ; F_{0}\right)+\|\psi\| \varepsilon
\]</div>
<p>Hence if <span class="arithmatex">\(\psi\)</span> is bounded and <span class="arithmatex">\(\lambda\left(t ; F_{0}\right)\)</span> has a unique zero at <span class="arithmatex">\(t=T\left(F_{0}\right)\)</span>, then <span class="arithmatex">\(T(F) \rightarrow T\left(F_{0}\right)\)</span> as <span class="arithmatex">\(\varepsilon \rightarrow 0\)</span>, and <span class="arithmatex">\(T\)</span> thus is continuous at <span class="arithmatex">\(F_{0}\)</span>. On the other hand if <span class="arithmatex">\(\psi\)</span> is unbounded, or if the zero of <span class="arithmatex">\(\lambda\left(t ; F_{0}\right)\)</span> is not unique, then <span class="arithmatex">\(T\)</span> cannot be continuous at <span class="arithmatex">\(F_{0}\)</span>, as we can easily verify.</p>
<p>We summarize these results in a theorem.
THEOREM 2.6 Let <span class="arithmatex">\(\psi\)</span> be a monotone increasing, but not necessarily continuous, function that takes values of both signs. Then the <span class="arithmatex">\(M\)</span>-estimator <span class="arithmatex">\(T\)</span> of location, defined by <span class="arithmatex">\(\int \psi(x-T(F)) F(d x)=0\)</span>, is weakly continuous at <span class="arithmatex">\(F_{0}\)</span> iff <span class="arithmatex">\(\psi\)</span> is bounded and <span class="arithmatex">\(T\left(F_{0}\right)\)</span> is unique. The breakdown point <span class="arithmatex">\(\varepsilon^{*}\)</span> is given by (2.39) and (2.40) and reaches its maximal value <span class="arithmatex">\(\varepsilon^{*}=\frac{1}{2}\)</span> whenever <span class="arithmatex">\(\psi(-\infty)\)</span> <span class="arithmatex">\(=-\psi(+\infty)\)</span>.
Example 2.1 The median, corresponding to <span class="arithmatex">\(\psi(x)=\operatorname{sign}(x)\)</span>, is a continuous functional at every <span class="arithmatex">\(F_{0}\)</span> whose median is uniquely defined.
Example 2.2 If <span class="arithmatex">\(\psi\)</span> is bounded and strictly monotone, then the corresponding <span class="arithmatex">\(M\)</span>-estimate is everywhere continuous.</p>
<p>If <span class="arithmatex">\(\psi\)</span> is not monotone, the situation is much more complicated. To be specific take</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x) &amp; =\sin (x), &amp; &amp; \text { for }-\pi \leqslant x \leqslant \pi \\
&amp; =0, &amp; &amp; \text { elsewhere }
\end{aligned}
\]</div>
<p>(an estimate proposed by D. F. Andrews). Then <span class="arithmatex">\(\Sigma \psi\left(x_{i}-T_{n}\right)\)</span> has many distinct zeros in general, and even vanishes identically for large absolute values of <span class="arithmatex">\(T_{n}\)</span>. Two possibilities for narrowing down the choice of solutions are:
(1) Take the absolute minimum of <span class="arithmatex">\(\Sigma \rho\left(x_{i}-T_{n}\right)\)</span>, with</p>
<div class="arithmatex">\[
\begin{aligned}
\rho(x) &amp; =1-\cos (x), &amp; &amp; \text { for }-\pi \leqslant x \leqslant \pi \\
&amp; =2, &amp; &amp; \text { elsewhere. }
\end{aligned}
\]</div>
<p>(2) Take the solution nearest to the sample median.</p>
<p>For computational reasons we prefer (2) or a variant thereof; start an iterative root-finding procedure at the sample median and accept whatever root it converges to.</p>
<p>In case (2), the procedure inherits the high breakdown point <span class="arithmatex">\(\varepsilon^{*}=\frac{1}{2}\)</span> from the median.</p>
<p>Consistency and asymptotic normality of <span class="arithmatex">\(M\)</span>-estimates are treated again in Sections 6.2 and 6.3.</p>
<h1 id="33-linear-combinations-of-order-statistics-l-estimates">3.3 LINEAR COMBINATIONS OF ORDER STATISTICS ( <span class="arithmatex">\(L\)</span>-ESTIMATES)</h1>
<p>Consider a statistic that is a linear combination of order statistics, or more generally, of some function <span class="arithmatex">\(h\)</span> of them:</p>
<div class="arithmatex">\[
T_{n}=\sum_{i=1}^{n} a_{n i} h\left(x_{(i)}\right)
\]</div>
<p>We assume that the weights are generated by a (signed) measure <span class="arithmatex">\(M\)</span> on <span class="arithmatex">\((0,1)\)</span> :</p>
<div class="arithmatex">\[
a_{n i}=\frac{1}{2} M\left\{\left(\frac{i-1}{n}, \frac{i}{n}\right)\right\}+\frac{1}{2} M\left\{\left[\frac{i-1}{n}, \frac{i}{n}\right]\right\}
\]</div>
<p>(This choice preserves the total mass, <span class="arithmatex">\(\Sigma_{i} a_{n i}=M\{(0,1)\}\)</span>, and symmetry of the coefficients, if <span class="arithmatex">\(M\)</span> is symmetric about <span class="arithmatex">\(t=\frac{1}{2}\)</span>.)</p>
<p>Then <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> derives from the functional</p>
<div class="arithmatex">\[
T(F)=\int h\left(F^{-1}(s)\right) M(d s)
\]</div>
<p>We have exact equality <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> if we regularize the integrand at its discontinuity points and replace it by</p>
<div class="arithmatex">\[
\frac{1}{2} h\left(F_{n}^{-1}(s-0)\right)+\frac{1}{2} h\left(F_{n}^{-1}(s+0)\right)
\]</div>
<p>but only asymptotic equivalence if we do not care. Here, the inverse of any distribution function <span class="arithmatex">\(F\)</span> is defined in the usual way as</p>
<div class="arithmatex">\[
F^{-1}(s)=\inf \{x \mid F(x) \geqslant s\} \quad 0&lt;s&lt;1
\]</div>
<h1 id="influence-function-of-l-estimates">Influence Function of <span class="arithmatex">\(L\)</span>-Estimates</h1>
<p>It is now a matter of plain calculus to find the influence function <span class="arithmatex">\(I C(x ; F, T)\)</span> of <span class="arithmatex">\(T\)</span> : insert <span class="arithmatex">\(F_{t}=(1-t) F+t G\)</span> into (3.3), and take the derivative with respect to <span class="arithmatex">\(t\)</span> at <span class="arithmatex">\(t=0\)</span>, for <span class="arithmatex">\(G=\delta_{x}\)</span>.</p>
<p>We begin with the derivative of <span class="arithmatex">\(T_{s}=F_{t}^{-1}(s)\)</span>, that is, of the <span class="arithmatex">\(s\)</span>-quantile. If we differentiate the identity</p>
<div class="arithmatex">\[
F_{t}\left(F_{t}^{-1}(s)\right)=s
\]</div>
<p>with respect to <span class="arithmatex">\(t\)</span> at <span class="arithmatex">\(t=0\)</span>, we obtain</p>
<div class="arithmatex">\[
G\left(F^{-1}(s)\right)-F\left(F^{-1}(s)\right)+f\left(F^{-1}(s)\right) \dot{T}_{s}=0
\]</div>
<p>or</p>
<div class="arithmatex">\[
\dot{T}_{s}=\frac{s-G\left(F^{-1}(s)\right)}{f\left(F^{-1}(s)\right)}
\]</div>
<p>If <span class="arithmatex">\(G=\delta_{x}\)</span> is the pointmass 1 at <span class="arithmatex">\(x\)</span>, this gives the value of the influence function of <span class="arithmatex">\(T_{s}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
I C\left(x ; F, T_{s}\right) &amp; =\frac{s-1}{f\left(F^{-1}(s)\right)}, &amp; &amp; \text { for } \quad x&lt;F^{-1}(s) \\
&amp; =\frac{s}{f\left(F^{-1}(s)\right)}, &amp; &amp; \text { for } \quad x&gt;F^{-1}(s)
\end{aligned}
\]</div>
<p>Quite clearly, these calculations make sense only if <span class="arithmatex">\(F\)</span> has a nonzero finite derivative <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(F^{-1}(s)\)</span>, but then they are legitimate.</p>
<p>By the chain rule for differentiation, the influence function of <span class="arithmatex">\(h\left(T_{s}\right)\)</span> is</p>
<div class="arithmatex">\[
I C\left(x ; F, h\left(T_{s}\right)\right)=I C\left(x ; F, T_{s}\right) h^{\prime}\left(T_{s}\right)
\]</div>
<p>and that of <span class="arithmatex">\(T\)</span> itself then is</p>
<div class="arithmatex">\[
\begin{aligned}
I C(x ; F, T) &amp; =\int I C\left(x ; F, h\left(T_{s}\right)\right) M(d s) \\
&amp; =\int \frac{s h^{\prime}\left(F^{-1}(s)\right)}{f\left(F^{-1}(s)\right)} M(d s)-\int_{F(x)}^{1} \frac{h^{\prime}\left(F^{-1}(s)\right)}{f\left(F^{-1}(s)\right)} M(d s)
\end{aligned}
\]</div>
<p>Of course, the legitimacy of taking the derivative under the integral sign in (3.3) must be checked in each particular case.</p>
<p>If <span class="arithmatex">\(M\)</span> has a density <span class="arithmatex">\(m\)</span>, it may be more convenient to write (3.11) as</p>
<div class="arithmatex">\[
I C(x ; F, T)=\int_{-\infty}^{x} h^{\prime}(y) m(F(y)) d y-\int_{-\infty}^{\infty}(1-F(y)) h^{\prime}(y) m(F(y)) d y
\]</div>
<p>This can be easily remembered through its derivative:</p>
<div class="arithmatex">\[
\frac{d}{d x} I C(x ; F, T)=h^{\prime}(x) m(F(x))
\]</div>
<p>The last two formulas also hold if <span class="arithmatex">\(F\)</span> does not have a density. This can easily be seen by starting from an alternative version of (3.3):</p>
<div class="arithmatex">\[
\begin{aligned}
T(F) &amp; =\int h\left(F^{-1}(s)\right) m(s) d s=\int h(y) m(F(y)) F(d y) \\
&amp; =-\int h^{\prime}(y) M(F(y)) d y
\end{aligned}
\]</div>
<p>If we now insert <span class="arithmatex">\(F_{s}\)</span> and differentiate, we obtain (3.12). Of course, here also the legitimacy of the integration by parts and of the differentiation under the integral sign must be checked but, for the "usual" <span class="arithmatex">\(h\)</span> and <span class="arithmatex">\(m\)</span>, this does not present a problem.</p>
<p>Example 3.1 For the median <span class="arithmatex">\(\left(s=\frac{1}{2}\right)\)</span> we have</p>
<div class="arithmatex">\[
\begin{aligned}
I C\left(x ; F, T_{1 / 2}\right) &amp; =\frac{-1}{2 f\left(F^{-1}\left(\frac{1}{2}\right)\right)} &amp; &amp; \text { for } x&lt;F^{-1}\left(\frac{1}{2}\right) \\
&amp; =\frac{1}{2 f\left(F^{-1}\left(\frac{1}{2}\right)\right)} &amp; &amp; \text { for } x&gt;F^{-1}\left(\frac{1}{2}\right)
\end{aligned}
\]</div>
<p>Example 3.2 If <span class="arithmatex">\(T(F)=\sum \beta_{i} F^{-1}\left(s_{i}\right)\)</span>, then <span class="arithmatex">\(I C(x ; F, T)\)</span> has jumps of size <span class="arithmatex">\(\beta_{i} / f\left(F^{-1}\left(s_{i}\right)\right)\)</span> at the points <span class="arithmatex">\(x=F^{-1}\left(s_{i}\right)\)</span>.
Example 3.3 The <span class="arithmatex">\(\alpha\)</span>-trimmed mean corresponds to <span class="arithmatex">\(h(x)=x\)</span> and</p>
<div class="arithmatex">\[
\begin{aligned}
m(s) &amp; =\frac{1}{1-2 \alpha}, &amp; &amp; \text { for } \alpha&lt;s&lt;1-\alpha \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>thus</p>
<div class="arithmatex">\[
T(F)=\frac{1}{1-2 \alpha} \int_{\alpha}^{1-\alpha} F^{-1}(s) d s
\]</div>
<p>Note that the <span class="arithmatex">\(\alpha\)</span>-trimmed mean <span class="arithmatex">\(T\left(F_{n}\right)\)</span>, as defined by (3.17), has the following property: if <span class="arithmatex">\(\alpha n\)</span> is an integer, then <span class="arithmatex">\(\alpha n\)</span> observations are removed from each end of the sample and the mean of the rest is taken. If it is not an integer, say <span class="arithmatex">\(\alpha n=|\alpha n|+p\)</span>, then <span class="arithmatex">\(|\alpha n|\)</span> observations are removed from each end, and the next observations <span class="arithmatex">\(x_{(s[\alpha n]+1)}\)</span> and <span class="arithmatex">\(x_{(n-[\alpha n])}\)</span> are given the reduced weight <span class="arithmatex">\(1-p\)</span>.</p>
<p>The influence function of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean is, according to (3.12),</p>
<div class="arithmatex">\[
\begin{aligned}
I C(x) &amp; =\frac{1}{1-2 \alpha}\left[F^{-1}(\alpha)-W(F)\right], &amp; &amp; \text { for } x&lt;F^{-1}(\alpha) \\
&amp; =\frac{1}{1-2 \alpha}[x-W(F)], &amp; &amp; \text { for } F^{-1}(\alpha) \leqslant x \leqslant F^{-1}(1-\alpha) \\
&amp; =\frac{1}{1-2 \alpha}\left[F^{-1}(1-\alpha)-W(F)\right], &amp; &amp; \text { for } x&gt;F^{-1}(1-\alpha)
\end{aligned}
\]</div>
<p>Here <span class="arithmatex">\(W\)</span> is the functional corresponding to the so-called <span class="arithmatex">\(\alpha\)</span>-Winsorized mean:</p>
<div class="arithmatex">\[
\begin{aligned}
W(F) &amp; =\int_{\alpha}^{1-\alpha} F^{-1}(s) d s+\alpha F^{-1}(\alpha)+\alpha F^{-1}(1-\alpha) \\
&amp; =(1-2 \alpha) T(F)+\alpha F^{-1}(\alpha)+\alpha F^{-1}(1-\alpha)
\end{aligned}
\]</div>
<p>Clearly, there will be trouble if the corner points <span class="arithmatex">\(F^{-1}(\alpha)\)</span> and <span class="arithmatex">\(F^{-1}(1-\alpha)\)</span> are not uniquely determined (i.e. if <span class="arithmatex">\(F^{-1}\)</span> has jumps there).</p>
<p>Example 3.4 The <span class="arithmatex">\(\alpha\)</span>-Winsorized mean (3.19) has the influence curve</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
I C(x ; F, W) &amp; &amp; &amp; \\
&amp; =F^{-1}(\alpha)-\frac{\alpha}{f\left(F^{-1}(\alpha)\right)}-C(F), &amp; &amp; \text { for } x&lt;F^{-1}(\alpha) \\
&amp; =x-C(F), &amp; &amp; \text { for } F^{-1}(\alpha)&lt;x&lt;F^{-1}(1-\alpha) \\
&amp; =F^{-1}(1-\alpha)+\frac{\alpha}{f\left(F^{-1}(1-\alpha)\right)}-C(F), &amp; &amp; \text { for } x&gt;F^{-1}(1-\alpha)
\end{array}
\]</div>
<p>with</p>
<div class="arithmatex">\[
C(F)=W(F)-\frac{\alpha^{2}}{f\left(F^{-1}\left(f\left(F^{-1}(\alpha)\right)\right.\right.}-\frac{\alpha^{2}}{f\left(F^{-1}(1-\alpha)\right)}
\]</div>
<p>Thus the influence curve has jumps at <span class="arithmatex">\(F^{-1}(\alpha)\)</span> and <span class="arithmatex">\(F^{-1}(1-\alpha)\)</span>.
The <span class="arithmatex">\(\alpha\)</span>-Winsorized mean corresponds to: replace the values of the <span class="arithmatex">\(\alpha n\)</span> leftmost observations by that of <span class="arithmatex">\(x_{(\alpha n+1)}\)</span>, the values of the <span class="arithmatex">\(\alpha n\)</span> rightmost observations by that of <span class="arithmatex">\(x_{(n-\alpha n)}\)</span>, and take the mean of this modified sample. The heuristic idea behind this proposal is that we did not want to "throw away" the <span class="arithmatex">\(\alpha n\)</span> leftmost and rightmost observations as in the trimmed mean, but wanted only to reduce their influences to those of a more moderate order statistic. This exemplifies how unreliable our intuition can be; we know now from looking at the influence functions that the trimmed mean does not throw away all of the information sitting in the discarded observations, but that it does exactly what the Winsorized mean was supposed to do!</p>
<h1 id="quantitative-and-qualitative-robustness-of-l-estimates">Quantitative and Qualitative Robustness of <span class="arithmatex">\(L\)</span>-Estimates</h1>
<p>We now calculate the maximum bias <span class="arithmatex">\(b_{1}\)</span> (see Section 1.4) for <span class="arithmatex">\(L\)</span>-estimates. To fix the idea assume that <span class="arithmatex">\(h(x)=x\)</span> and that <span class="arithmatex">\(M\)</span> is a positive measure with total mass 1. Clearly, the resulting functional then corresponds to a location estimate; if <span class="arithmatex">\(F_{a X+b}\)</span> denotes the distribution of the random variable <span class="arithmatex">\(a X+b\)</span>, we have</p>
<div class="arithmatex">\[
T\left(F_{a X+b}\right)=a T\left(F_{X}\right)+b, \quad \text { for } \quad a \geqslant 0
\]</div>
<p>It is rather evident that <span class="arithmatex">\(T\)</span> cannot be continuous if the support of <span class="arithmatex">\(M\)</span> (i.e., the smallest closed set with total mass 1) contains 0 or 1 . Let <span class="arithmatex">\(\alpha\)</span> be the largest real number such that <span class="arithmatex">\([\alpha, 1-\alpha]\)</span> contains the support of <span class="arithmatex">\(M\)</span>; then, also evidently, the breakdown point satisfies <span class="arithmatex">\(\varepsilon^{*} \leqslant \alpha\)</span>. We now show that <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span>.</p>
<p>Assume that the target value is <span class="arithmatex">\(T\left(F_{0}\right)=0\)</span>, let <span class="arithmatex">\(0&lt;\varepsilon&lt;\alpha\)</span>, and define <span class="arithmatex">\(b_{+}, b_{-}\)</span> as in (2.31) and (2.32). Then with <span class="arithmatex">\(F_{1}\)</span> as in (2.35), we have</p>
<div class="arithmatex">\[
b_{+}(\varepsilon)=\int F_{1}^{-1}(s) M(d s)=\varepsilon+\int_{\alpha}^{1-\alpha} F_{0}^{-1}(s+\varepsilon) M(d s)
\]</div>
<p>and symmetrically,</p>
<div class="arithmatex">\[
b_{-}(\varepsilon)=-\varepsilon+\int_{\alpha}^{1-\alpha} F_{0}^{-1}(s-\varepsilon) M(d s)
\]</div>
<p>and <span class="arithmatex">\(b_{1}(\varepsilon)\)</span> is again given by (2.33).</p>
<p>As <span class="arithmatex">\(F_{0}{ }^{-1}(s+\varepsilon)-F_{0}{ }^{-1}(s-\varepsilon) \downarrow 0\)</span> for <span class="arithmatex">\(\varepsilon \downarrow 0\)</span>, except at the discontinuity points of <span class="arithmatex">\(F_{0}{ }^{-1}\)</span>, we conclude that <span class="arithmatex">\(b_{1}(\varepsilon) \leqslant b_{+}(\varepsilon)-b_{-}(\varepsilon) \downarrow 0\)</span> iff the distribution function of <span class="arithmatex">\(M\)</span> and <span class="arithmatex">\(F_{0}{ }^{-1}\)</span> do not have common discontinuity points, and then <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span>. Since <span class="arithmatex">\(b_{1}(\varepsilon)\)</span> is finite for <span class="arithmatex">\(\varepsilon&lt;\alpha\)</span>, we must have <span class="arithmatex">\(\varepsilon^{*} \geqslant \alpha\)</span>.</p>
<p>In particular, the <span class="arithmatex">\(\alpha\)</span>-trimmed mean with <span class="arithmatex">\(0&lt;\alpha&lt;\frac{1}{2}\)</span> is everywhere continuous. The <span class="arithmatex">\(\alpha\)</span>-Winsorized mean is continuous at <span class="arithmatex">\(F_{0}\)</span> if <span class="arithmatex">\(F_{0}^{-1}(\alpha)\)</span> and <span class="arithmatex">\(F_{0}^{-1}(1-\alpha)\)</span> are uniquely determined (i.e. if <span class="arithmatex">\(F_{0}{ }^{-1}\)</span> does not have jumps there).</p>
<p>The generalization to signed measures is immediate, as far as sufficiency is concerned: if <span class="arithmatex">\(M=M^{+}-M^{-}\)</span>, then continuity of <span class="arithmatex">\(T^{+}(F)=\)</span> <span class="arithmatex">\(\int F^{-1}(s) M^{+}(d s)\)</span> and <span class="arithmatex">\(T^{-}(F)=\int F^{-1}(s) M^{-}(d s)\)</span> implies continuity of <span class="arithmatex">\(T(F)=\int F^{-1}(s) M(d s)\)</span>; if both <span class="arithmatex">\(T^{+}\)</span>and <span class="arithmatex">\(T^{-}\)</span>have breakdown points <span class="arithmatex">\(\geqslant \alpha\)</span>, then <span class="arithmatex">\(T\)</span> also has.</p>
<p>The necessity part is trickier, but the arguments given above carry through if there are neighborhoods of the endpoints <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(1-\alpha\)</span> of the support, respectively, where the measure <span class="arithmatex">\(M\)</span> is of one sign only. We conjecture that <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span> holds generally, but it has not even been proved that <span class="arithmatex">\(\alpha=0\)</span> implies discontinuity of <span class="arithmatex">\(T\)</span> in the signed case.</p>
<p>We summarize the results in a theorem.</p>
<p>THEOREM 3.1 Let <span class="arithmatex">\(M=M^{+}-M^{-}\)</span>be a finite signed measure on <span class="arithmatex">\((0,1)\)</span> and let <span class="arithmatex">\(T(F)=\int F^{-1}(s) M(d s)\)</span>. Let <span class="arithmatex">\(\alpha\)</span> be the largest real number such that <span class="arithmatex">\([\alpha, 1-\alpha]\)</span> contains the support of <span class="arithmatex">\(M^{+}\)</span>and <span class="arithmatex">\(M^{-}\)</span>. If <span class="arithmatex">\(\alpha&gt;0\)</span>, then <span class="arithmatex">\(T\)</span> is weakly continuous at <span class="arithmatex">\(F_{0}\)</span>, provided <span class="arithmatex">\(M\)</span> does not put any pointmass on a discontinuity point of <span class="arithmatex">\(F_{0}{ }^{-1}\)</span>. The breakdown point satisfies <span class="arithmatex">\(\varepsilon^{*} \geqslant \alpha\)</span>. If <span class="arithmatex">\(M\)</span> is positive, we have <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span>, and <span class="arithmatex">\(\alpha=0\)</span> implies that <span class="arithmatex">\(T\)</span> is discontinuous.</p>
<p>Since weak continuity of <span class="arithmatex">\(T\)</span> at <span class="arithmatex">\(F\)</span> implies consistency, <span class="arithmatex">\(T\left(F_{\alpha}\right) \rightarrow T(F)\)</span>, the above theorem also gives a simple sufficient condition for consistency. Of course, it does not cover the case <span class="arithmatex">\(\alpha=0\)</span>.</p>
<p>The asymptotic properties of <span class="arithmatex">\(L\)</span>-estimates are in fact rather tricky to establish. In the case <span class="arithmatex">\(\alpha=0\)</span> (which is only of limited interest to us, because of its lack of robustness) some awkward smoothness conditions on the tails of <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(M\)</span> seem to be needed [cf. Chernoff et al. (1967)]. Even if <span class="arithmatex">\(\alpha&gt;0\)</span>, there is no blanket theorem covering all the more interesting cases simultaneously. But if <span class="arithmatex">\(\sqrt{n}\left(T\left(F_{\alpha}\right)-T(F)\right)\)</span> is asymptotically normal, then <span class="arithmatex">\(\int I C(x ; F, T)^{2} F(d x)\)</span> always seems to give the correct asymptotic variance. For our purposes the most useful version is the following.</p>
<p>THEOREM 3.2 Let <span class="arithmatex">\(M\)</span> be an absolutely continuous signed measure with density <span class="arithmatex">\(m\)</span>, whose support is contained in <span class="arithmatex">\([\alpha, 1-\alpha], \alpha&gt;0\)</span>. Let <span class="arithmatex">\(T(F)=\)</span> <span class="arithmatex">\(\int F^{-1}(s) m(s) d s\)</span>. Then <span class="arithmatex">\(\sqrt{n}\left(T\left(F_{\alpha}\right)-T(F)\right)\)</span> is asymptotically normal with</p>
<p>mean 0 and variance <span class="arithmatex">\(\left\{I C(x ; F, T)^{2} F(d x)\right.\)</span>, provided both (1) and (2) hold:
(1) <span class="arithmatex">\(m\)</span> is of bounded total variation (so all its discontinuities are jumps).
(2) No discontinuity of <span class="arithmatex">\(m\)</span> coincides with a discontinuity of <span class="arithmatex">\(F^{-1}\)</span>.</p>
<p>Proof See, for instance, Huber (1969). Condition (2) is necessary; without it not even the influence function would be well defined [see the remark at the end of Example 3.3, and Stigler (1969)].</p>
<h1 id="34-estimates-derived-from-rank-tests-r-estimates">3.4 ESTIMATES DERIVED FROM RANK TESTS ( <span class="arithmatex">\(R\)</span>-ESTIMATES)</h1>
<p>Consider a two-sample rank test for shift: let <span class="arithmatex">\(x_{1}, \ldots, x_{m}\)</span> and <span class="arithmatex">\(y_{1}, \ldots, y_{n}\)</span> be two independent samples from the distributions <span class="arithmatex">\(F(x)\)</span> and <span class="arithmatex">\(G(x)=F(x-\Delta)\)</span>, respectively. Merge the two samples into one of size <span class="arithmatex">\(m+n\)</span> and let <span class="arithmatex">\(R_{i}\)</span> be the rank of <span class="arithmatex">\(x_{i}\)</span> in the combined sample. Let <span class="arithmatex">\(a_{i}=a(i), 1 \leqslant i \leqslant m+n\)</span>, be some given scores; then base a test of <span class="arithmatex">\(\Delta=0\)</span> against <span class="arithmatex">\(\Delta&gt;0\)</span> on the test statistic</p>
<div class="arithmatex">\[
S_{m, n}=\frac{1}{m} \sum_{i=1}^{m} a\left(R_{i}\right)
\]</div>
<p>Usually, we assume that the scores <span class="arithmatex">\(a_{i}\)</span> are generated by some function <span class="arithmatex">\(J\)</span> as follows:</p>
<div class="arithmatex">\[
a_{i}=J\left(\frac{i}{m+n+1}\right)
\]</div>
<p>There are several other possibilities for deriving scores <span class="arithmatex">\(a_{i}\)</span> from <span class="arithmatex">\(J\)</span>, for example,</p>
<div class="arithmatex">\[
a_{i}=J\left(\frac{i-\frac{1}{2}}{m+n}\right)
\]</div>
<p>or</p>
<div class="arithmatex">\[
a_{i}=(m+n) \int_{(i-1) /(m+n)}^{i /(m+n)} J(s) d s
\]</div>
<p>and in fact we prefer to work with this last version. Of course, for "nice" <span class="arithmatex">\(J\)</span> and <span class="arithmatex">\(F\)</span>, all these scores lead to asymptotically equivalent tests. In the case of the Wilcoxon test, <span class="arithmatex">\(J(t)=t-\frac{1}{2}\)</span>, the above three variants even create exactly the same tests.</p>
<p>To simplify the presentation, from now on we assume that <span class="arithmatex">\(m=n\)</span>. In terms of functionals (4.1) can then be written as</p>
<div class="arithmatex">\[
S(F, G)=\int J\left[\frac{1}{2} F(x)+\frac{1}{2} G(x)\right] F(d x)
\]</div>
<p>or, if we substitute <span class="arithmatex">\(F(x)=s\)</span>,</p>
<div class="arithmatex">\[
S(F, G)=\int J\left[\frac{1}{2} s+\frac{1}{2} G\left(F^{-1}(s)\right)\right] d s
\]</div>
<p>If <span class="arithmatex">\(F\)</span> is continuous and strictly monotone, the two formulas (4.5) and (4.6) are equivalent. For discontinuous distributions, for instance if we insert the empirical distributions <span class="arithmatex">\(F_{n}\)</span> and <span class="arithmatex">\(G_{n}\)</span> corresponding to the <span class="arithmatex">\(x\)</span> - and <span class="arithmatex">\(y\)</span>-samples, the exact equivalence is destroyed. Moreover, (4.5) is no longer well defined (its value depends on the arbitrary convention about the value of <span class="arithmatex">\(H=\frac{1}{2} F+\frac{1}{2} G\)</span> at its jump points).</p>
<p>If we standardize <span class="arithmatex">\(H(x)=\frac{1}{2} H(x-0)+\frac{1}{2} H(x+0)\)</span>, then (4.5) combined with the scores (4.3) gives (4.1). In any case (4.6) with (4.4) gives (4.1); we assume that there are no ties between <span class="arithmatex">\(x\)</span> - and <span class="arithmatex">\(y\)</span>-values. To fix the ideas from now on we work with (4.6) and (4.4). We also assume once and for all that</p>
<div class="arithmatex">\[
\int J(s) d s=0
\]</div>
<p>corresponding to</p>
<div class="arithmatex">\[
\sum a_{i}=0
\]</div>
<p>Then the expected value of (4.1) under the null hypothesis is 0 .
We can derive estimates of shift <span class="arithmatex">\(\Delta_{n}\)</span> and of location <span class="arithmatex">\(T_{n}\)</span> from such rank tests:
(1) In the two sample case, adjust <span class="arithmatex">\(\Delta_{n}\)</span> such that <span class="arithmatex">\(S_{n, n} \approx 0\)</span> when computed from <span class="arithmatex">\(\left(x_{1}, \ldots, x_{n}\right)\)</span> and <span class="arithmatex">\(\left(y_{1}-\Delta_{n}, \ldots, y_{n}-\Delta_{n}\right)\)</span>.
(2) In the one-sample case, adjust <span class="arithmatex">\(T_{n}\)</span> such that <span class="arithmatex">\(S_{n, n} \approx 0\)</span> when computed from <span class="arithmatex">\(\left(x_{1}, \ldots, x_{n}\right)\)</span> and <span class="arithmatex">\(\left(2 T_{n}-x_{1}, \ldots, 2 T_{n}-x_{n}\right)\)</span>. In this case a mirror image of the first sample serves as a stand-in for the missing second sample.</p>
<p>In other words we shift the second sample until the test is least able to detect a difference in location. Note that it may not be possible to achieve an exact zero, <span class="arithmatex">\(S_{n, n}\)</span> being a discontinuous function.</p>
<p>Example 4.1 The Wilcoxon test, <span class="arithmatex">\(J(t)=t-\frac{1}{2}\)</span>, leads to the Hodges-Lehmann estimates <span class="arithmatex">\(\Delta_{n}=\operatorname{med}\left\{y_{i}-x_{j}\right\}\)</span> and <span class="arithmatex">\(T_{n}=\operatorname{med}\left\{\frac{1}{2}\left(x_{i}+x_{j}\right)\right\}\)</span>. Note that our recipe in the second case leads to the median of the set of all <span class="arithmatex">\(n^{2}\)</span> pairs; the more customary versions use only the pairs <span class="arithmatex">\(i&lt;j\)</span> or <span class="arithmatex">\(i&lt;j\)</span>, but asymptotically all three versions are equivalent.</p>
<p>Thus our location estimate <span class="arithmatex">\(T_{n}\)</span> derives from a functional <span class="arithmatex">\(T(F)\)</span>, defined by the implicit equation</p>
<div class="arithmatex">\[
\int J\left\{\frac{1}{2}\left[s+1-F\left(2 T(F)-F^{-1}(s)\right)\right]\right\} d s=0
\]</div>
<h1 id="influence-function-of-boldsymbolr-estimates">Influence Function of <span class="arithmatex">\(\boldsymbol{R}\)</span>-Estimates</h1>
<p>We now derive the influence function of <span class="arithmatex">\(T(F)\)</span>. To shorten the notation we introduce the distribution function of the pooled population:</p>
<div class="arithmatex">\[
K(x)=\frac{1}{2}[F(x)+1-F(2 T(F)-x)]
\]</div>
<p>Assume that <span class="arithmatex">\(F\)</span> has a strictly positive density <span class="arithmatex">\(f\)</span>.
We insert <span class="arithmatex">\(F_{t}=(1-t) F+t G\)</span> for <span class="arithmatex">\(F\)</span> in (4.9) and take the derivative <span class="arithmatex">\(\partial / \partial t\)</span> (denoted by a dot <span class="arithmatex">\(\left.{ }^{-}\right)\)</span>at <span class="arithmatex">\(t=0\)</span>. This gives</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \int J^{\prime}\left(K\left(F^{-1}(s)\right)\right)\left[\dot{F}\left(2 T-F^{-1}(s)\right)+\frac{f\left(2 T-F^{-1}(s)\right)}{f\left(F^{-1}(s)\right)} \dot{F}\left(F^{-1}(s)\right)\right. \\
&amp; \left.\quad+2 f\left(2 T-F^{-1}(s)\right) \dot{T}\right] d s=0
\end{aligned}
\]</div>
<p>We separate this expression in a sum of three integrals and substitute <span class="arithmatex">\(x=2 T-F^{-1}(s)\)</span> in the first [thus <span class="arithmatex">\(s=F(2 T-x)\)</span> ], but <span class="arithmatex">\(x=F^{-1}(s)\)</span> in the second and third integrals. This gives</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \dot{T} \int J^{\prime}(K(x)) f(2 T-x) f(x) d x \\
&amp; \quad+\int \frac{1}{2}\left[J^{\prime}(K(x))+J^{\prime}(1-K(x))\right] f(2 T-x) \dot{F}(x) d x=0
\end{aligned}
\]</div>
<p>Let us now assume that the scores-generating function is symmetric in the</p>
<p>sense that</p>
<div class="arithmatex">\[
J(1-t)=-J(t), \quad 0&lt;t&lt;1
\]</div>
<p>(asymmetric functions do not make much sense in the one-sample problem); then we can simplify (4.12) by introducing the function <span class="arithmatex">\(U(x)\)</span>, being an indefinite integral of</p>
<div class="arithmatex">\[
U^{\prime}(x)=J^{\prime}\left\{\frac{1}{2}[F(x)+1-F(2 T(F)-x)]\right\} f(2 T(F)-x)
\]</div>
<p>Then (4.12) turns into</p>
<div class="arithmatex">\[
\dot{T} \int U^{\prime}(x) f(x) d x+\int U^{\prime}(x) \dot{F}(x) d x=0
\]</div>
<p>Integration by parts of the second integral yields</p>
<div class="arithmatex">\[
\int U^{\prime}(x) \dot{F}(x) d x=-\int U(x) \dot{F}(d x)
\]</div>
<p>As <span class="arithmatex">\(\dot{F}=G-F\)</span> any additive constant in <span class="arithmatex">\(U\)</span> cancels out on the right-hand side. With <span class="arithmatex">\(G=\delta_{x}\)</span> we now obtain the influence function from (4.15) by solving for <span class="arithmatex">\(\dot{T}\)</span> :</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{U(x)-\int U(x) f(x) d x}{\int U^{\prime}(x) f(x) d x}
\]</div>
<p>For symmetric <span class="arithmatex">\(F\)</span> this can be simplified considerably, since then <span class="arithmatex">\(U(x)=\)</span> <span class="arithmatex">\(J(F(x)):\)</span></p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{J(F(x))}{\int J^{\prime}(F(x)) f(x)^{2} d x}
\]</div>
<p>Example 4.2 The influence function of the Hodges-Lehmann estimate <span class="arithmatex">\(\left(J(t)=t-\frac{1}{2}\right)\)</span> is</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\frac{1}{2}-F(2 T(F)-x)}{\int f(2 T(F)-x) f(x) d x}
\]</div>
<p>with <span class="arithmatex">\(T(F)\)</span> defined by</p>
<div class="arithmatex">\[
\int F(2 T(F)-x) F(d x)=\frac{1}{2}
\]</div>
<p>For symmetric <span class="arithmatex">\(F\)</span> this simplifies to</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{F(x)-\frac{1}{2}}{\int f(x)^{2} d x}
\]</div>
<p>and the asymptotic variance of <span class="arithmatex">\(\sqrt{n}\left[T\left(F_{n}\right)-T(F)\right]\)</span> is indeed known to be</p>
<div class="arithmatex">\[
A(F, T)=\int I C^{2} d F=\frac{1}{12\left[\int f(x)^{2} d x\right]^{2}}
\]</div>
<p>[Formula (4.18) suggests that the Hodges-Lehmann estimate will be quite poor for certain asymmetric densities, since the denominator of the influence function might become very small.]
Example 4.3 The normal scores estimate is defined by <span class="arithmatex">\(J(t)=\Phi^{-1}(t)\)</span>. For symmetric <span class="arithmatex">\(F\)</span> its influence function is</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\Phi^{-1}(F(x))}{\int \frac{f(x)^{2}}{\varphi\left\{\Phi^{-1}[F(x)]\right\}} d x}
\]</div>
<p>where <span class="arithmatex">\(\varphi=\Phi^{\prime}\)</span> is the standard normal density. In particular, for <span class="arithmatex">\(F=\Phi\)</span>, we obtain</p>
<div class="arithmatex">\[
I C(x ; \Phi, T)=x
\]</div>
<h1 id="quantitative-and-qualitative-robustness-of-boldsymbolr-estimates">Quantitative and Qualitative Robustness of <span class="arithmatex">\(\boldsymbol{R}\)</span>-Estimates</h1>
<p>We now calculate the maximum bias (see Section 1.4) for <span class="arithmatex">\(R\)</span>-estimates. We assume that the scores function <span class="arithmatex">\(J\)</span> is monotone increasing and symmetric, <span class="arithmatex">\(J(1-t)=-J(t)\)</span>. In order that (4.6) be well defined, we must require</p>
<div class="arithmatex">\[
\int|J(s)| d s&lt;\infty
\]</div>
<p>The function</p>
<div class="arithmatex">\[
\lambda(t ; F)=\int J\left\{\frac{1}{2}\left[s+1-F\left(2 t-F^{-1}(s)\right)\right]\right\} d s
\]</div>
<p>then is monotone decreasing in <span class="arithmatex">\(t\)</span>, and it increases if <span class="arithmatex">\(F\)</span> is made stochastically larger. Thus among all <span class="arithmatex">\(F\)</span> satisfying <span class="arithmatex">\(d_{L}\left(F_{0}, F\right)&lt;\varepsilon\)</span> [or also <span class="arithmatex">\(d_{P}\left(F_{0}, F\right)&lt;\varepsilon\)</span> ], <span class="arithmatex">\(\lambda(t, F)\)</span> is largest at the (improper) distribution <span class="arithmatex">\(F_{1}\)</span> of (2.35). Thus we have to calculate <span class="arithmatex">\(\lambda\left(t ; F_{1}\right)\)</span>.</p>
<p>We note first that</p>
<div class="arithmatex">\[
\begin{aligned}
F_{1}^{-1}(s) &amp; =F_{0}^{-1}(s+\varepsilon)+\varepsilon, &amp; &amp; \text { for } 0 \leqslant s \leqslant 1-\varepsilon \\
&amp; =\infty, &amp; &amp; \text { for } s&gt;1-\varepsilon .
\end{aligned}
\]</div>
<p>Thus provided the two side conditions</p>
<div class="arithmatex">\[
0 \leqslant s \leqslant 1-\varepsilon
\]</div>
<p>and</p>
<div class="arithmatex">\[
2 t-F_{1}^{-1}(s) \geqslant x_{0}+\varepsilon
\]</div>
<p>where</p>
<div class="arithmatex">\[
F_{0}\left(x_{0}\right)=\varepsilon
\]</div>
<p>are satisfied, we have</p>
<div class="arithmatex">\[
F_{1}\left[2 t-F_{1}^{-1}(s)\right]=F_{0}\left[2 t-2 \varepsilon-F_{0}^{-1}(s+\varepsilon)\right]-\varepsilon
\]</div>
<p>The second side condition can be written as</p>
<div class="arithmatex">\[
s \leqslant F_{0}\left(2 t-2 \varepsilon-x_{0}\right)-\varepsilon
\]</div>
<p>Putting things together we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
\lambda\left(t ; F_{1}\right)= &amp; \int_{0}^{s_{0}} J\left(\frac{1}{2}\left[s+\varepsilon+1-F_{0}\left(2(t-\varepsilon)-F_{0}^{-1}(s+\varepsilon)\right)\right]\right) d s \\
&amp; +\int_{s_{0}}^{1} J\left[\frac{1}{2}(s+1)\right] d s
\end{aligned}
\]</div>
<p>with</p>
<div class="arithmatex">\[
s_{0}=\left[F_{0}\left(2(t-\varepsilon)-x_{0}\right)-\varepsilon\right]^{+}
\]</div>
<p>We then have</p>
<div class="arithmatex">\[
b_{+}(\varepsilon)=\inf \left\{t \mid \lambda\left(t ; F_{1}\right)&lt;0\right\}
\]</div>
<p>and symmetrically, we also calculate <span class="arithmatex">\(b_{-}(\varepsilon)\)</span>; if <span class="arithmatex">\(F_{0}\)</span> is symmetric, we have of course</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=b_{+}(\varepsilon)=-b_{-}(\varepsilon)
\]</div>
<p>With regard to breakdown we note that <span class="arithmatex">\(b_{+}(\varepsilon)&lt;\infty\)</span> iff</p>
<div class="arithmatex">\[
\lim _{t \rightarrow \infty} \lambda\left(t ; F_{1}\right)&lt;0
\]</div>
<p>Since</p>
<div class="arithmatex">\[
\begin{aligned}
\lim _{t \rightarrow \infty} \lambda\left(t ; F_{1}\right) &amp; =\int_{0}^{1-\varepsilon} J\left[\frac{1}{2}(s+\varepsilon)\right] d s+\int_{1-\varepsilon}^{1} J\left[\frac{1}{2}(s+1)\right] d s \\
&amp; =2\left[\int_{\varepsilon / 2}^{1 / 2} J(s) d s+\int_{1-\varepsilon / 2}^{1} J(s) d s\right]
\end{aligned}
\]</div>
<p>(using symmetry of <span class="arithmatex">\(J\)</span> ):</p>
<div class="arithmatex">\[
=2\left[\int_{1-\varepsilon / 2}^{1} J(s) d s-\int_{1 / 2}^{1-\varepsilon / 2} J(s) d s\right]
\]</div>
<p>the breakdown point <span class="arithmatex">\(\varepsilon^{*}\)</span> is that value <span class="arithmatex">\(\varepsilon\)</span> for which</p>
<div class="arithmatex">\[
\int_{1 / 2}^{1-\varepsilon / 2} J(s) d s=\int_{1-\varepsilon / 2}^{1} J(s) d s
\]</div>
<p>Example 4.4 For the Hodges-Lehmann estimates, <span class="arithmatex">\(J(t)=t-\frac{1}{2}\)</span>, we obtain as breakdown point</p>
<div class="arithmatex">\[
\varepsilon^{*}=1-\frac{1}{\sqrt{2}} \approx 0.293
\]</div>
<p>Example 4.5 For the normal scores estimate, <span class="arithmatex">\(J(t)=\Phi^{-1}(t)\)</span>, we obtain as breakdown point</p>
<div class="arithmatex">\[
\varepsilon^{*}=2 \Phi(-\sqrt{\ln 4}) \approx 0.239
\]</div>
<p>When <span class="arithmatex">\(\varepsilon \downarrow 0\)</span> the integrand in (4.26) decreases and converges to the integrand corresponding to <span class="arithmatex">\(F_{0}\)</span> for almost all <span class="arithmatex">\(s\)</span> and <span class="arithmatex">\(t\)</span>. It follows from the monotone convergence theorem that <span class="arithmatex">\(\lambda\left(t ; F_{1}\right) \downarrow \lambda\left(t ; F_{0}\right)\)</span> at the continuity points of <span class="arithmatex">\(\lambda\left(\cdot ; F_{0}\right)\)</span>. Hence if <span class="arithmatex">\(\lambda\left(t ; F_{0}\right)\)</span> has a unique zero, that is, if <span class="arithmatex">\(T\left(F_{0}\right)\)</span> is uniquely defined, <span class="arithmatex">\(T\)</span> is continuous at <span class="arithmatex">\(F_{0}\)</span>. If <span class="arithmatex">\(T\left(F_{0}\right)\)</span> is not unique, then <span class="arithmatex">\(T\)</span> of course cannot be continuous at <span class="arithmatex">\(F_{0}\)</span>. A sufficient condition for uniqueness is, for instance, that the derivative of <span class="arithmatex">\(\lambda\left(t ; F_{0}\right)\)</span> with regard to <span class="arithmatex">\(t\)</span> exists and is not equal to 0 at <span class="arithmatex">\(T=T\left(F_{0}\right)\)</span>; this derivative occurred already (with the opposite sign) as the denominator of (4.16) and (4.17).</p>
<p>We summarize the results in a theorem.
THEOREM 4.1 Assume that the scores generating function <span class="arithmatex">\(J\)</span> is monotone increasing, integrable, and symmetric: <span class="arithmatex">\(J(1-t)=-J(t)\)</span>. If the <span class="arithmatex">\(R\)</span> estimate <span class="arithmatex">\(T\left(F_{0}\right)\)</span> is uniquely defined by (4.9), then <span class="arithmatex">\(T\)</span> is weakly continuous at <span class="arithmatex">\(F_{0}\)</span>. The breakdown point of <span class="arithmatex">\(T\)</span> is given by (4.27).</p>
<h1 id="35-asymptotically-efficient-m-l-and-r-estimates">3.5 ASYMPTOTICALLY EFFICIENT <span class="arithmatex">\(M\)</span>-, <span class="arithmatex">\(L\)</span>-, AND <span class="arithmatex">\(R\)</span>-ESTIMATES</h1>
<p>The main purpose of this section is to develop some heuristic guidelines for the selection of the functions <span class="arithmatex">\(\psi, m\)</span>, and <span class="arithmatex">\(J\)</span> characterizing <span class="arithmatex">\(M\)</span>-, <span class="arithmatex">\(L\)</span>-, and <span class="arithmatex">\(R\)</span>-estimates, respectively. The arguments, as they stand, are rigorous for Fréchet differentiable functionals only.</p>
<p>Let <span class="arithmatex">\(\left(F_{\theta}\right)_{\theta \in \Theta}\)</span> be a parametric family of distributions, and let the functional <span class="arithmatex">\(T\)</span> be a Fisher consistent estimate of <span class="arithmatex">\(\theta\)</span>, that is,</p>
<div class="arithmatex">\[
T\left(F_{\theta}\right)=\theta, \quad \text { for all } \theta
\]</div>
<p>Assume that <span class="arithmatex">\(T\)</span> is Fréchet differentiable at <span class="arithmatex">\(F\)</span>. We intend to show that the corresponding estimate is asymptotically efficient at <span class="arithmatex">\(F_{\theta}\)</span> iff its influence function satisfies</p>
<div class="arithmatex">\[
I C\left(x ; F_{\theta}, T\right)=\frac{1}{I\left(F_{\theta}\right)} \frac{\partial}{\partial \theta}\left(\log f_{\theta}\right)
\]</div>
<p>Here, <span class="arithmatex">\(f_{\theta}\)</span> is the density of <span class="arithmatex">\(F_{\theta}\)</span>, and</p>
<div class="arithmatex">\[
I\left(F_{\theta}\right)=\int\left(\frac{\partial}{\partial \theta} \log f_{\theta}\right)^{2} d F_{\theta}
\]</div>
<p>is the Fisher information.</p>
<p>Assume that <span class="arithmatex">\(d_{L}\left(F_{\theta}, F_{\theta+\delta}\right)=O(\delta)\)</span>, that</p>
<div class="arithmatex">\[
\frac{f_{\theta+\delta}-f_{\theta}}{\delta f_{\theta}} \rightarrow \frac{\partial}{\partial \theta} \log f_{\theta}
\]</div>
<p>converges in the <span class="arithmatex">\(L_{2}\left(F_{\theta}\right)\)</span>-sense, and that</p>
<div class="arithmatex">\[
0&lt;I\left(F_{\theta}\right)&lt;\infty
\]</div>
<p>Then by definition of the Fréchet derivative,</p>
<div class="arithmatex">\[
T\left(F_{\theta+\delta}\right)-T\left(F_{\theta}\right)-\int I C\left(x ; F_{\theta}, T\right)\left(f_{\theta+\delta}-f_{\theta}\right) d x=o\left(d_{L}\left(F_{\theta}, F_{\theta+\delta}\right)\right)=o(\delta)
\]</div>
<p>We divide this by <span class="arithmatex">\(\delta\)</span> and let <span class="arithmatex">\(\delta \rightarrow 0\)</span>. In view of (5.1) and (5.4) we obtain</p>
<div class="arithmatex">\[
\int I C\left(x ; F_{\theta}, T\right) \frac{\partial}{\partial \theta}\left(\log f_{\theta}\right) f_{\theta} d x=1
\]</div>
<p>The Schwarz inequality applied to (5.7) gives: first, that the asymptotic variance <span class="arithmatex">\(A\left(F_{\theta}, T\right)\)</span> of <span class="arithmatex">\(\sqrt{n}\left[T\left(F_{n}\right)-T\left(F_{\theta}\right)\right]\)</span> satisfies</p>
<div class="arithmatex">\[
A\left(F_{\theta}, T\right)=\int I C\left(x ; F_{\theta}, T\right)^{2} d F_{\theta} \geqslant \frac{1}{I\left(F_{\theta}\right)}
\]</div>
<p>and second, that we can have equality in (5.8) (i.e., asymptotic efficiency) only if <span class="arithmatex">\(I C\left(x ; F_{\theta}, T\right)\)</span> is proportional to <span class="arithmatex">\((\partial / \partial \theta) \log f_{\theta}\)</span>. The factor of proportionality is easy to determine, and this gives the result announced in (5.2).</p>
<p>Remark It is possible to establish a variant of (5.2), not even assuming Gâteaux differentiability of <span class="arithmatex">\(T\)</span>. Assume (5.4), and that the sequence <span class="arithmatex">\(T_{n}\)</span> is efficient at <span class="arithmatex">\(F_{\theta}\)</span>, or, more precisely, that the limit of an expression similar to (1.4.9) satisfies</p>
<div class="arithmatex">\[
\lim _{\varepsilon \rightarrow 0} \lim _{n} \sup _{|\delta|&lt;\varepsilon} Q_{t}\left(F_{\theta+\delta}, T_{n}\right)^{2} \leqslant \frac{1}{I\left(F_{\theta}\right)}
\]</div>
<p>Then it follows that <span class="arithmatex">\(\sqrt{n}\left(T_{n}-\theta\right)\)</span> is asymptotically normal with mean 0 and variance <span class="arithmatex">\(1 / I\left(F_{\theta}\right)\)</span>, and that, in fact, we must have asymptotic equivalence</p>
<div class="arithmatex">\[
\sqrt{n}\left(T_{n}-\theta\right) \sim \frac{1}{I\left(F_{\theta}\right)} \sum \frac{\partial}{\partial \theta} \log f_{\theta}\left(x_{i}\right)
\]</div>
<p>This is, for all practical purposes, the same as (5.2). For details see Hajek (1972), and earlier work by LeCam (1953) and Huber (1966).</p>
<p>Let us now check whether it is possible to achieve (5.2) with <span class="arithmatex">\(M\)</span>-, <span class="arithmatex">\(L\)</span>-, and <span class="arithmatex">\(R\)</span>-estimates, at least in the case of a location parameter, <span class="arithmatex">\(f_{\theta}(x)=f_{0}(x-\theta)\)</span>.
(1) For <span class="arithmatex">\(M\)</span>-estimates it suffices to choose</p>
<div class="arithmatex">\[
\psi(x)=-c \frac{f_{0}^{\prime}(x)}{f_{0}(x)}, \quad c \neq 0
\]</div>
<p>compare (2.14).
(2) For <span class="arithmatex">\(L\)</span>-estimates we must take <span class="arithmatex">\(h(x)=x\)</span> (otherwise we do not have translation invariance and thus lose consistency). Then the proper choice, suggested by (3.13), is</p>
<div class="arithmatex">\[
m\left(F_{0}(x)\right)=\frac{-1}{l\left(F_{0}\right)}\left(\log f_{0}(x)\right)^{\prime \prime}
\]</div>
<p>and it is easy to check that <span class="arithmatex">\(\int m(s) d s=1\)</span> (translation invariance). If <span class="arithmatex">\(f_{0}\)</span> is not twice differentiable, we have to replace (5.12) by a somewhat more complicated integrated version for <span class="arithmatex">\(M\)</span> itself.
(3) For <span class="arithmatex">\(R\)</span>-estimates we assume that <span class="arithmatex">\(F_{0}\)</span> is symmetric. Then (4.17) suggests the choice</p>
<div class="arithmatex">\[
J\left(F_{0}(x)\right)=-c \frac{f_{0}^{\prime}(x)}{f_{0}(x)}, \quad c \neq 0
\]</div>
<p>and this indeed gives (5.2). For asymmetric <span class="arithmatex">\(F_{0}\)</span> we cannot achieve full efficiency with <span class="arithmatex">\(R\)</span>-estimates.</p>
<p>Of course, we must check in each individual case whether these estimates are indeed efficient (the stringent regularity conditions-Fréchet differentiability-that we used to derive efficiency will rarely be satisfied).</p>
<p>Example 5.1 Normal Distribution <span class="arithmatex">\(f_{0}(x)=(1 / \sqrt{2 \pi}) e^{-x^{2} / 2}\)</span></p>
<table>
<thead>
<tr>
<th style="text-align: left;"><span class="arithmatex">\(M:\)</span></th>
<th style="text-align: left;"><span class="arithmatex">\(\psi(x)=x\)</span></th>
<th style="text-align: left;">sample mean, nonrobust,</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(L:\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(m(t)=1\)</span></td>
<td style="text-align: left;">sample mean, nonrobust,</td>
</tr>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(R:\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(J(t)=\Phi^{-1}(t)\)</span></td>
<td style="text-align: left;">normal scores estimate, robust.</td>
</tr>
</tbody>
</table>
<p>Example 5.2 Logistic Distribution <span class="arithmatex">\(F_{0}(x)=1 /\left(1+e^{-x}\right)\)</span>
<span class="arithmatex">\(M: \quad \psi(x)=\tanh (x / 2) \quad\)</span> robust,
<span class="arithmatex">\(L: \quad m(t)=6 t(1-t) \quad\)</span> nonrobust,
<span class="arithmatex">\(R: \quad J(t)=t-\frac{1}{2} \quad\)</span> Hodges-Lehmann, robust.</p>
<p>Example 5.3 Cauchy Distribution <span class="arithmatex">\(f_{0}(x)=1 /\left[\pi\left(1+x^{2}\right)\right]\)</span></p>
<table>
<thead>
<tr>
<th style="text-align: left;"><span class="arithmatex">\(M: \quad \psi(x)=2 x /\left(1+x^{2}\right)\)</span></th>
<th style="text-align: left;">robust,</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(L: \quad m(t)=2 \cos (2 \pi t)[\cos (2 \pi t)-1]\)</span></td>
<td style="text-align: left;">nonrobust,</td>
</tr>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(R: \quad J(t)=-\sin (2 \pi t)\)</span></td>
<td style="text-align: left;">robust(?).</td>
</tr>
</tbody>
</table>
<p>Example 5.4 "Least Informative" Distribution (see Example 4.5.2)</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =C e^{-x^{2} / 2}, &amp; &amp; |x|&lt;c \\
&amp; =C e^{-c|x|+c^{2} / 2}, &amp; &amp; |x|&gt;c
\end{aligned}
\]</div>
<p><span class="arithmatex">\(M: \quad \psi(x)=\max [-c, \min (c, x)], \quad\)</span> Huber-estimate, robust.
<span class="arithmatex">\(L: \quad m(t)=\frac{1}{1-2 \alpha}, \quad\)</span> for <span class="arithmatex">\(\alpha&lt;t&lt;1-\alpha, \alpha=F_{0}(-c)\)</span>,
<span class="arithmatex">\(=0, \quad\)</span> otherwise,
<span class="arithmatex">\(\alpha\)</span>-trimmed mean, robust,
<span class="arithmatex">\(R\)</span> : the corresponding estimate has occasionally been mentioned in the literature, but does not have a simple description; robust.
Some of these estimates deserve a closer look:
(1) The efficient <span class="arithmatex">\(R\)</span>-estimate for the normal distribution, the normal scores estimate, has an unbounded influence curve and hence infinite gross error sensitivity <span class="arithmatex">\(\gamma^{*}=\infty\)</span> (Section 1.5). Nevertheless it is robust! I would hesitate, though, to recommend it for practical use; its quantitative robustness indicators <span class="arithmatex">\(b(\varepsilon)\)</span> and <span class="arithmatex">\(v(\varepsilon)\)</span> increase steeply when we depart from the normal model, and the estimate very soon falls behind, for example, the Hodges-Lehmann estimate, (see Exhibit 6.6.2).
(2) The efficient <span class="arithmatex">\(L\)</span>-estimate for the logistic is not robust, and <span class="arithmatex">\(b_{1}(\varepsilon)=\infty\)</span> for all <span class="arithmatex">\(\varepsilon&gt;0\)</span>, even though its "gross error sensitivity" <span class="arithmatex">\(\gamma^{*}\)</span> at <span class="arithmatex">\(F_{0}\)</span></p>
<p>(Section 1.5) is finite. But note that its influence function for general (not necessarily logistic) <span class="arithmatex">\(F\)</span> satisfies</p>
<div class="arithmatex">\[
\frac{d}{d x} I C(x ; F, T)=6 F(x)[1-F(x)]
\]</div>
<p>Thus if <span class="arithmatex">\(F\)</span> has Cauchy-like tails, the influence function becomes unbounded.</p>
<p>The lesson to be learned from these two examples is that it is not enough to look at the influence function at the model distribution only; we must also take into account its behavior in a neighborhood of the model. In the case of the normal scores estimate, a longer tailed <span class="arithmatex">\(F\)</span> deflates the tails of the influence curve; in the case of the logistic <span class="arithmatex">\(L\)</span>-estimate, the opposite happens. <span class="arithmatex">\(M\)</span>-estimates are more straightforward to handle, since for them the shape of the influence function is fixed by <span class="arithmatex">\(\psi\)</span>.</p>
<p>It is somewhat tricky to construct <span class="arithmatex">\(L\)</span> - and <span class="arithmatex">\(R\)</span>-estimates with prescribed robustness properties. For <span class="arithmatex">\(M\)</span>-estimates the task is more straightforward. If we want to make a robust estimate that has good efficiency at the model <span class="arithmatex">\(F_{0}\)</span>, we should choose a <span class="arithmatex">\(\psi\)</span> that is bounded, but otherwise closely proportional to <span class="arithmatex">\(-\left(\log f_{0}\right)^{\prime}\)</span>. If we feel that very far-out outliers should be totally discarded, we should choose a <span class="arithmatex">\(\psi\)</span> that goes to zero (or is zero) for large absolute 0 . This finds its theoretical justification also in the remark that, for heavier-than-exponential tails, the influence curve of the efficient estimate decreases to zero (compare Examples 5.3 and 5.4). For <span class="arithmatex">\(L\)</span>-estimates such an effect would be impossible to achieve over an entire range of distributions. With <span class="arithmatex">\(R\)</span>-estimates we could do it, but not particularly well, because a change of the influence function in the extreme <span class="arithmatex">\(x\)</span>-range selectively affects long-tailed distributions, while changes in the extreme <span class="arithmatex">\(t\)</span>-range <span class="arithmatex">\([t=F(x)]\)</span> affect all distributions equally.</p>
<p>In one-parameter location problems, <span class="arithmatex">\(L\)</span>-estimates, in particular trimmed means, are very attractive because they are simple to calculate. However, unless we use relatively inefficient high trimming rates (i.e., essentially the sample median), the <span class="arithmatex">\(\alpha\)</span>-trimmed mean has very poor breakdown properties. The situation is particularly bad for small sample sizes. For instance, for sample sizes below 20 the <span class="arithmatex">\(10 \%\)</span> trimmed mean cannot cope with more than one outlier!</p>
<h1 id="chapter-4">CHAPTER 4</h1>
<h2 id="asymptotic-minimax-theory-for-estimating-a-location-parameter">Asymptotic Minimax Theory for Estimating a Location Parameter</h2>
<h3 id="41-general-remarks">4.1 GENERAL REMARKS</h3>
<p>Qualitative robustness is of little help in the actual selection of a robust procedure suited for a particular application. In order to make a rational choice, we must introduce quantitative aspects as well.</p>
<p>Anscombe's (1960) comparison of the situation with an insurance problem is very helpful. Typically a so-called classical procedure is the optimal procedure for some ideal (usually normal) model. If it happens to be nonrobust and we want to insure against accidents caused by deviations from the model, we clearly will have to pay for it by sacrificing some efficiency at the model. The questions are, of course, how much efficiency we are willing to sacrifice, and against how bad a deviation we would like to insure.</p>
<p>One possible approach is to fix a certain neighborhood of the model and to safeguard within that neighborhood (Huber 1964). In the simple location case, this leads to quite manageable minimax problems (even though the space of pure strategies for Nature is not dominated), both for asymptotic performance criteria (asymptotic bias or variance, treated in this chapter) and for finite sample ones (Chapter 10). If we take asymptotic variance as our performance criterion, then the least favorable situation <span class="arithmatex">\(F_{0}\)</span> (the minimax strategy for Nature) can be characterized intrinsically; it minimizes Fisher information in the chosen neighborhood, and the minimax strategy for the Statistician is efficient for <span class="arithmatex">\(F_{0}\)</span>. Typically, if the neighborhood of the model is chosen not too large, the least favorable <span class="arithmatex">\(F_{0}\)</span> is a quite realistic distribution (which is closer to the error distributions observed in actual samples than the normal distribution), and so we even escape the perennial criticism directed against minimax methods, namely, that they safeguard against unlikely contingencies.</p>
<p>Unfortunately, this approach does not carry beyond problems possessing a high degree of symmetry (e.g., translation or scale invariance). Still it</p>
<p>suffices to deal successfully with a very large part of traditional statistics; in particular, the results carry over straightforwardly to regression.</p>
<p>Another approach [proposed by Hampel (1968)] remains even closer to Anscombe's idea; it minimizes the asymptotic variance at the model (i.e., it minimizes the efficiency loss), subject to a bound on the gross error sensitivity (also at the model). This approach has the conceptual flaw that it allows only infinitesimal deviations from the model, but, precisely because of this, it works for arbitrary one-parameter families of distributions; it is discussed in Chapter 11.</p>
<h1 id="42-minimax-bias">4.2 MINIMAX BIAS</h1>
<p>Assume that the true underlying shape <span class="arithmatex">\(F\)</span> lies in some neighborhood <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> of the assumed model distribution <span class="arithmatex">\(F_{0}\)</span>, that the observations are independent with common distribution <span class="arithmatex">\(F(x-\theta)\)</span>, and that the location parameter <span class="arithmatex">\(\theta\)</span> is to be estimated. In this section we plan to optimize the robustness properties of such a location estimate by minimizing its maximum asymptotic bias <span class="arithmatex">\(b(\varepsilon)\)</span> for distributions <span class="arithmatex">\(F \in \mathscr{P}_{\varepsilon}\)</span>. For the reasons mentioned in Section 1.4, we begin with minimizing the maximum bias <span class="arithmatex">\(b_{1}(\varepsilon)\)</span> of the functional <span class="arithmatex">\(T\)</span> underlying the estimate; it is then a trivial matter to verify that <span class="arithmatex">\(b(\varepsilon)=b_{1}(\varepsilon)\)</span>; compare Theorems 1.4.1 and 1.4.2.</p>
<p>To fix the idea, consider the case of <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions</p>
<div class="arithmatex">\[
\mathscr{P}_{\varepsilon}=\{F \mid F=(1-\varepsilon) \Phi+\varepsilon H, H \in \mathscr{N}
\]</div>
<p>We show that the median minimizes <span class="arithmatex">\(b_{1}(\varepsilon)\)</span>.
Clearly the maximum absolute bias <span class="arithmatex">\(b_{1}(\varepsilon)\)</span> of the median is attained whenever the total contaminating mass sits on one side, say on the right, and then its value is given by the solution <span class="arithmatex">\(x_{0}\)</span> of</p>
<div class="arithmatex">\[
(1-\varepsilon) \Phi\left(x_{0}\right)=\frac{1}{2}
\]</div>
<p>or</p>
<div class="arithmatex">\[
b_{1}(\varepsilon)=x_{0}=\Phi^{-1}\left(\frac{1}{2(1-\varepsilon)}\right)
\]</div>
<p>We now construct two <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions <span class="arithmatex">\(F_{+}\)</span>and <span class="arithmatex">\(F_{-}\)</span>, which are symmetric about <span class="arithmatex">\(x_{0}\)</span> and <span class="arithmatex">\(-x_{0}\)</span>, respectively, and which are translates of each other. <span class="arithmatex">\(F_{+}\)</span>is given by its density (cf. Exhibit 4.2.1)</p>
<div class="arithmatex">\[
\begin{aligned}
f_{+}(x) &amp; =(1-\varepsilon) \varphi(x), \quad \text { for } x&lt;x_{0} \\
&amp; =\left(1-\varepsilon\right) \varphi\left(x-2 x_{0}\right), \quad \text { for } x&gt;x_{0}
\end{aligned}
\]</div>
<p><img alt="img-2.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhlbit 4.2.1
where <span class="arithmatex">\(\varphi=\Phi^{\prime}\)</span> is the standard normal density, and</p>
<div class="arithmatex">\[
F_{-}(x)=F_{+}\left(x+2 x_{0}\right)
\]</div>
<p>Thus</p>
<div class="arithmatex">\[
T\left(F_{+}\right)-T\left(F_{-}\right)=2 x_{0}
\]</div>
<p>for any translation invariant functional, and it is evident that none can have an absolute bias smaller than <span class="arithmatex">\(x_{0}\)</span> at <span class="arithmatex">\(F_{+}\)</span>and <span class="arithmatex">\(F_{-}\)</span>simultaneously.</p>
<p>This shows that the median achieves the smallest maximum bias among all translation invariant functionals. It is trivial to verify that, for the median, <span class="arithmatex">\(b(\varepsilon)=b_{1}(\varepsilon)\)</span>, so we have proved that the sample median solves the minimax problem of minimizing the maximum asymptotic bias.</p>
<p>Evidently, we have not used any particular property of the normal distribution, except symmetry and unimodality, and the same kind of argument also carries through for other neighborhoods. For example, with a Lévy neighborhood</p>
<div class="arithmatex">\[
\mathscr{P}_{\varepsilon, \delta}=\{F \mid \forall x \Phi(x-\varepsilon)-\delta \leqslant F(x) \leqslant \Phi(x+\varepsilon)+\delta\}
\]</div>
<p>the expression (2.2) for <span class="arithmatex">\(b_{1}\)</span> is replaced by</p>
<div class="arithmatex">\[
b_{1}(\varepsilon, \delta)=\Phi^{-1}\left(\frac{1}{2}+\delta\right)+\varepsilon
\]</div>
<p>but everything else goes through without change.
Thus minimizing the maximum bias leads to a rather uneventful theory; for symmetric unimodal distributions, the solution invariably is the sample median.</p>
<p>The sample median thus is the estimate of choice for extremely large samples, where the standard deviation of the estimate (which is of the order <span class="arithmatex">\(1 / \sqrt{n}\)</span> ) is comparable to or smaller than the bias <span class="arithmatex">\(b(\varepsilon)\)</span>. Exhibit 4.2.2 evaluates (2.2) and gives the values of <span class="arithmatex">\(n\)</span> for which <span class="arithmatex">\(b(\varepsilon)=1 / \sqrt{n}\)</span>. It appears</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(b(\varepsilon)\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(n=b(\varepsilon)^{-2}\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.4307</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.1396</td>
<td style="text-align: center;">50</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.0660</td>
<td style="text-align: center;">230</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.0126</td>
<td style="text-align: center;">6300</td>
</tr>
</tbody>
</table>
<p>Exhibit 4.2.2
from this table that, for the customary sample sizes and not too large <span class="arithmatex">\(\varepsilon\)</span> (i.e., <span class="arithmatex">\(\varepsilon \leqslant 0.1\)</span> ), the statistical variability of the estimate will be more important than its bias.</p>
<h1 id="43-minimax-variance-preliminaries">4.3 MINIMAX VARIANCE: PRELIMINARIES</h1>
<p>Minimizing the maximal variance <span class="arithmatex">\(v(\varepsilon)\)</span> leads to a deeper theory. We begin by minimizing the more tractable</p>
<div class="arithmatex">\[
v_{1}(\varepsilon)=\sup _{F \in \mathscr{F}_{e}} A(F, T)
\]</div>
<p>(cf. Section 1.4), and, since <span class="arithmatex">\(\varepsilon\)</span> will be kept fixed, we suppress it in the notation.</p>
<p>We assume that the observations are independent with common distribution function <span class="arithmatex">\(F(x-\theta)\)</span>. The location parameter <span class="arithmatex">\(\theta\)</span> is to be estimated, while the shape <span class="arithmatex">\(F\)</span> may lie anywhere in some given set <span class="arithmatex">\(\mathscr{F}=\mathscr{F}_{e}\)</span> of distribution functions. There are some difficulties of a topological nature; for certain existence proofs we would like <span class="arithmatex">\(\mathscr{F}\)</span> to be compact, but the more interesting neighborhoods <span class="arithmatex">\(\mathscr{F}_{e}\)</span> are not tight, and thus their closure is not compact in the weak topology. As a way out we propose to take an even weaker topology, the vague topology (see below); then we can enforce compactness, but at the cost of including substochastic measures in <span class="arithmatex">\(\mathscr{F}\)</span> (or, equivalently, probability measures that put nonzero mass at <span class="arithmatex">\(\pm \infty\)</span> ). These measures may be thought to formalize the possibility of infinitely bad outliers. From now on we assume that <span class="arithmatex">\(\mathscr{F}\)</span> is vaguely closed and hence compact.</p>
<p>The vague topology in the space <span class="arithmatex">\(\mathscr{M}_{+}+\)</span>of substochastic measures on <span class="arithmatex">\(\Omega\)</span> is the weakest topology making the maps</p>
<div class="arithmatex">\[
F \rightarrow \int \psi d F
\]</div>
<p>continuous for all continuous <span class="arithmatex">\(\psi\)</span> having a compact support. Note that we</p>
<p>are now working on the real line; thus <span class="arithmatex">\(\Omega=\mathbb{R}\)</span> is not only Polish, but also locally compact. Then <span class="arithmatex">\(\mathscr{M}_{+}\)</span>is compact [see, e.g., Bourbaki (1952), Ch. III].</p>
<p>Let <span class="arithmatex">\(F_{0}\)</span> be the distribution having the smallest Fisher information</p>
<div class="arithmatex">\[
I(f)=\int\left(\frac{f^{\prime}}{f}\right)^{2} f d x
\]</div>
<p>among the members of <span class="arithmatex">\(\mathscr{P}\)</span>. Under quite general conditions there is one and only one such <span class="arithmatex">\(F_{0}\)</span>, as we see below.</p>
<p>For any sequence <span class="arithmatex">\(\left(T_{n}\right)\)</span> of estimates, the asymptotic variance of <span class="arithmatex">\(\sqrt{n} T_{n}\)</span> at <span class="arithmatex">\(F_{0}\)</span> is at best <span class="arithmatex">\(1 / I\left(F_{0}\right)\)</span>; see Section 3.5. If we can find a sequence <span class="arithmatex">\(\left(T_{n}\right)\)</span> such that its asymptotic variance does not exceed <span class="arithmatex">\(1 / I\left(F_{0}\right)\)</span> for any <span class="arithmatex">\(F \in \mathscr{P}\)</span>, we have clearly solved the minimax problem.</p>
<p>In particular, this sequence <span class="arithmatex">\(\left(T_{n}\right)\)</span> must be asymptotically efficient for <span class="arithmatex">\(F_{0}\)</span>, which gives a hint where to look for asymptotic minimax estimates.</p>
<h1 id="44-distributions-minimizing-fisher-information">4.4 DISTRIBUTIONS MINIMIZING FISHER INFORMATION</h1>
<p>First of all, we extend the definition of Fisher information so that it is infinite whenever the classical expression (3.2) does not make sense. More precisely, we define it as follows.</p>
<p>DEFINITION 4.1 The Fisher information for location of a distribution <span class="arithmatex">\(F\)</span> on the real line is</p>
<div class="arithmatex">\[
I(F)=\sup _{\psi} \frac{\left(\int \psi^{\prime} d F\right)^{2}}{\int \psi^{2} d F}
\]</div>
<p>where the supremum is taken over the set <span class="arithmatex">\(\mathcal{C}_{K}^{1}\)</span> of all continuously differentiable functions with compact support, satisfying <span class="arithmatex">\(\int \psi^{2} d F&gt;0\)</span>.</p>
<p>THEOREM 4.2 The following two assertions are equivalent:
(1) <span class="arithmatex">\(I(F)&lt;\infty\)</span>.
(2) <span class="arithmatex">\(F\)</span> has an absolutely continuous density <span class="arithmatex">\(f\)</span>, and <span class="arithmatex">\(\int\left(f^{\prime} / f\right)^{2} f d x&lt;\infty\)</span>.</p>
<p>In either case, we have <span class="arithmatex">\(I(F)=f\left(f^{\prime} / f\right)^{2} f d x\)</span>.</p>
<p>Proof If <span class="arithmatex">\(\int\left(f^{\prime} / f\right)^{2} f d x&lt;\infty\)</span>, then integration by parts and the Schwarz inequality give</p>
<div class="arithmatex">\[
\left(\int \psi^{\prime} f d x\right)^{2}=\left(\int \psi \frac{f^{\prime}}{f} f d x\right)^{2}&lt;\int \psi^{2} f d x \int\left(\frac{f^{\prime}}{f}\right)^{2} f d x
\]</div>
<p>hence</p>
<div class="arithmatex">\[
I(F)&lt;\int\left(\frac{f^{\prime}}{f}\right)^{2} f d x&lt;\infty
\]</div>
<p>Conversely, assume that <span class="arithmatex">\(I(F)&lt;\infty\)</span>, or, which is the same, the linear functional <span class="arithmatex">\(A\)</span>, defined by</p>
<div class="arithmatex">\[
A \psi=-\int \psi^{\prime} d F
\]</div>
<p>on the dense subset <span class="arithmatex">\(\mathcal{C}_{K}^{1}\)</span> of the Hilbert space <span class="arithmatex">\(L_{2}(F)\)</span> of square <span class="arithmatex">\(F\)</span>-integrable functions, is bounded:</p>
<div class="arithmatex">\[
\|A\|^{2}=\sup \frac{|A \psi|^{2}}{\|\psi\|^{2}}=I(F)&lt;\infty
\]</div>
<p>Hence <span class="arithmatex">\(A\)</span> can be extended by continuity to the whole Hilbert space <span class="arithmatex">\(L_{2}(F)\)</span>, and moreover, by Riesz' theorem, there is a <span class="arithmatex">\(g \in L_{2}(F)\)</span> such that</p>
<div class="arithmatex">\[
A \psi=\int \psi g d F
\]</div>
<p>for all <span class="arithmatex">\(\psi \in L_{2}(F)\)</span>. Note that</p>
<div class="arithmatex">\[
A 1=\int g d F=0
\]</div>
<p>[this follows easily from the continuity of <span class="arithmatex">\(A\)</span> and (4.2), if we approximate 1 by smooth functions with compact support].</p>
<p>We do not know, at this stage of the proof, whether <span class="arithmatex">\(F\)</span> has an absolutely continuous density <span class="arithmatex">\(f\)</span>, but if it has, then integration by parts of (4.2) gives</p>
<div class="arithmatex">\[
A \psi=-\int \psi^{\prime} f d x=\int \psi \frac{f^{\prime}}{f} f d x
\]</div>
<p>hence <span class="arithmatex">\(g=f^{\prime} / f\)</span>. So we define a function <span class="arithmatex">\(f\)</span> by</p>
<div class="arithmatex">\[
f(x)=\int_{y&lt;x} g(y) F(d y)
\]</div>
<p>and we have to check that this is indeed a version of the density of <span class="arithmatex">\(F\)</span>.
The Schwarz inequality applied to (4.6) yields that <span class="arithmatex">\(f\)</span> is bounded,</p>
<div class="arithmatex">\[
|f(x)|^{2} \leqslant F(x) \int g^{2} d F
\]</div>
<p>and tends to 0 for <span class="arithmatex">\(x \rightarrow-\infty\)</span> [and symmetrically also for <span class="arithmatex">\(x \rightarrow+\infty\)</span>; here we use (4.5)]. If <span class="arithmatex">\(\psi \in \dot{C}_{K}^{1}\)</span>, then Fubini's theorem gives</p>
<div class="arithmatex">\[
-\int \psi^{\prime}(x) f(x) d x=-\int_{y&lt;x} \int \psi^{\prime}(x) g(y) F(d y) d x=\int \psi(y) g(y) F(d y)=A \psi
\]</div>
<p>A comparison with the definition (4.2) of <span class="arithmatex">\(A\)</span> now shows that <span class="arithmatex">\(f(x) d x\)</span> and <span class="arithmatex">\(F(d x)\)</span> define the same linear functional on the set <span class="arithmatex">\(\left\{\psi^{\prime} \mid \psi \in \dot{C}_{K}^{1}\right\}\)</span>, which is dense in <span class="arithmatex">\(L_{2}(F)\)</span>. It follows that they define the same measure, and so <span class="arithmatex">\(f\)</span> is a version of the density of <span class="arithmatex">\(F\)</span>.</p>
<p>Evidently, we then have</p>
<div class="arithmatex">\[
I(F)=\|A\|^{2}=\int g^{2} d F=\int\left(\frac{f^{\prime}}{f}\right)^{2} f d x
\]</div>
<p>[This theorem was first proved by Huber (1964); the elegant proof given above is based on an oral suggestion by T. Liggett.]</p>
<p>If the set <span class="arithmatex">\(\mathscr{P}\)</span> is endowed with the vague topology, then Fisher information (4.1) is lower-semicontinuous as a function of <span class="arithmatex">\(F\)</span> (it is the pointwise supremum of a set of vaguely continuous functions).</p>
<p>It follows that <span class="arithmatex">\(I(F)\)</span> attains its infimum on any vaguely compact set <span class="arithmatex">\(\mathscr{P}\)</span>, so we have proved the following proposition.</p>
<p>PROPOSITION 4.3 (EXISTENCE) If <span class="arithmatex">\(\mathscr{P}\)</span> is vaguely compact, then there is an <span class="arithmatex">\(F_{0} \in \mathscr{P}\)</span> minimizing <span class="arithmatex">\(I(F)\)</span>.</p>
<p>We note furthermore that <span class="arithmatex">\(I(F)\)</span> is a convex function of <span class="arithmatex">\(F\)</span>. This follows at once from the remark that <span class="arithmatex">\(\int \psi^{\prime} d F\)</span> and <span class="arithmatex">\(\int \psi^{2} d F\)</span> are linear functions of <span class="arithmatex">\(F\)</span>, and from the following lemma.</p>
<p>LEMMA 4.4 Let <span class="arithmatex">\(u(t), v(t)\)</span> be linear functions of <span class="arithmatex">\(t\)</span> such that <span class="arithmatex">\(v(t)&gt;0\)</span> for <span class="arithmatex">\(0&lt;t&lt;1\)</span>. Then <span class="arithmatex">\(w(t)=u(t)^{2} / v(t)\)</span> is convex for <span class="arithmatex">\(0&lt;t&lt;1\)</span>.</p>
<p>Proof The second derivative of <span class="arithmatex">\(w\)</span> is</p>
<div class="arithmatex">\[
w^{\prime \prime}(t)=\frac{2\left[u^{\prime} v(t)-u(t) v^{\prime}\right]^{2}}{v(t)^{3}} \geqslant 0
\]</div>
<p>for <span class="arithmatex">\(0&lt;t&lt;1\)</span>.
We are now ready to prove also the uniqueness of <span class="arithmatex">\(F_{0}\)</span>.</p>
<h1 id="proposition-45-uniqueness-assume-that">PROPOSITION 4.5 (UNIQUENESS) Assume that</h1>
<p>(1) <span class="arithmatex">\(\mathscr{P}\)</span> is convex.
(2) <span class="arithmatex">\(F_{0} \in \mathscr{P}\)</span> minimizes <span class="arithmatex">\(I(F)\)</span> in <span class="arithmatex">\(\mathscr{P}\)</span>, and <span class="arithmatex">\(0&lt;I\left(F_{0}\right)&lt;\infty\)</span>.
(3) The set where the density <span class="arithmatex">\(f_{0}\)</span> of <span class="arithmatex">\(F_{0}\)</span> is strictly positive is convex and contains the support of every distribution in <span class="arithmatex">\(\mathscr{P}\)</span>. Then <span class="arithmatex">\(F_{0}\)</span> is the unique member of <span class="arithmatex">\(\mathscr{P}\)</span> minimizing <span class="arithmatex">\(I(F)\)</span>.</p>
<p>Proof Assume that <span class="arithmatex">\(F_{1}\)</span> also minimizes <span class="arithmatex">\(I(F)\)</span>. Then by convexity <span class="arithmatex">\(I\left(F_{t}\right)\)</span> must be constant on the segment <span class="arithmatex">\(0 \leqslant t \leqslant 1\)</span>, where <span class="arithmatex">\(F_{t}=(1-t) F_{0}+t F_{1}\)</span>. Without loss of generality we may assume that <span class="arithmatex">\(F_{0}\)</span> is absolutely continuous with respect to <span class="arithmatex">\(F_{1}\)</span> (if not, replace <span class="arithmatex">\(F_{1}\)</span> by <span class="arithmatex">\(F_{t_{0}}\)</span> for some fixed <span class="arithmatex">\(0&lt;t_{0}&lt;1\)</span> ).</p>
<p>Evidently, the integrand in</p>
<div class="arithmatex">\[
I\left(F_{t}\right)=\int \frac{\left(f_{t}^{\prime}\right)^{2}}{f_{t}} d x
\]</div>
<p>is a convex function of <span class="arithmatex">\(t\)</span>. If we may differentiate twice under the integral sign, we obtain</p>
<div class="arithmatex">\[
0=\frac{d^{2}}{d t^{2}} I\left(F_{t}\right)=\int 2\left(\frac{f_{1}^{\prime}}{f_{1}}-\frac{f_{0}^{\prime}}{f_{0}}\right)^{2} \frac{f_{0}^{2} f_{1}^{2}}{f_{t}^{3}} d x
\]</div>
<p>This is indeed permissible; if</p>
<div class="arithmatex">\[
Q(t)=\int q_{t}(x) d x
\]</div>
<p>where <span class="arithmatex">\(q_{t}(x)\)</span> is any function convex in <span class="arithmatex">\(t\)</span>, then the integrand in</p>
<div class="arithmatex">\[
\frac{Q(t+h)-Q(t)}{h}=\int \frac{q_{t+h}-q_{t}}{h} d x
\]</div>
<p>is monotone in <span class="arithmatex">\(h\)</span>. Hence</p>
<div class="arithmatex">\[
Q^{\prime}(t)=\int q_{t}^{\prime} d x
\]</div>
<p>by the monotone convergence theorem. Moreover, the integrand in</p>
<div class="arithmatex">\[
\frac{Q^{\prime}(t+h)-Q^{\prime}(t)}{h}=\int \frac{q_{t+h}^{\prime}-q_{t}^{\prime}}{h} d x
\]</div>
<p>is positive; hence, by Fatou's lemma,</p>
<div class="arithmatex">\[
Q^{\prime \prime}(t) \geqslant \int q_{t}^{\prime \prime} d x \geqslant 0
\]</div>
<p>and (4.8) follows.
Thus we must have</p>
<div class="arithmatex">\[
\frac{f_{1}^{\prime}}{f_{1}}=\frac{f_{0}^{\prime}}{f_{0}} \quad \text { a.e. }
\]</div>
<p>If we integrate this relation, we obtain</p>
<div class="arithmatex">\[
f_{1}=c f_{0}
\]</div>
<p>for some constant <span class="arithmatex">\(c\)</span> (here we have used assumption (3) of Proposition 4.5: the set where <span class="arithmatex">\(f_{0}\)</span> and <span class="arithmatex">\(f_{1}\)</span> are different from 0 is convex and hence, in particular, connected). Since</p>
<div class="arithmatex">\[
I\left(F_{1}\right)=\int\left(\frac{f_{1}^{\prime}}{f_{1}}\right)^{2} f_{1} d x=\int\left(\frac{f_{0}^{\prime}}{f_{0}}\right)^{2} c f_{0} d x=c I\left(F_{0}\right)
\]</div>
<p>it follows that <span class="arithmatex">\(c=1\)</span>.
NOTE 1 We have not assumed that our measures have total mass 1 [note in particular the argument showing that <span class="arithmatex">\(c=1\)</span> in (4.10)]. In principle the minimizing <span class="arithmatex">\(F_{0}\)</span> could be substochastic. However, we do not know of any realistic set <span class="arithmatex">\(\mathscr{F}\)</span> where this occurs, that is, where the least informative <span class="arithmatex">\(F_{0}\)</span> would put pointmasses at <span class="arithmatex">\(\pm \infty\)</span>, and there is a good intuitive reason for this. For a "realistic" <span class="arithmatex">\(\mathscr{F}\)</span>, any masses at <span class="arithmatex">\(\pm \infty\)</span> are not genuinely at infinity, but must have arisen as a limit of contamination that has escaped to infinity, and it is intuitively clear that, by shifting these masses again to finite values, the task of the statistician can be made harder, since they would no longer be immediately recognizable as outliers.</p>
<p>NOTE 2 Proposition 4.5 is wrong without some form of assumption (3); this was overlooked in Huber (1964). For example, let <span class="arithmatex">\(F_{0}\)</span> and <span class="arithmatex">\(F_{1}\)</span> be defined by their densities</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =C x^{2}(1+x)^{2}, &amp; &amp; \text { for }-1 \leqslant x \leqslant 0 \\
&amp; =0, &amp; &amp; \text { otherwise, } \\
f_{1}(x) &amp; =C x^{2}(1-x)^{2}, &amp; &amp; \text { for } 0 \leqslant x \leqslant 1 \\
&amp; =0, &amp; &amp; \text { otherwise, }
\end{aligned}
\]</div>
<p>and let <span class="arithmatex">\(\mathscr{F}=\left\{F_{t} \mid t \in[0,1]\right\}\)</span>. Then <span class="arithmatex">\(I(F)\)</span> is finite and constant on <span class="arithmatex">\(\mathscr{F}\)</span>.</p>
<p>There are several other equivalent expressions for Fisher information if <span class="arithmatex">\(f(x ; \theta)\)</span> is sufficiently smooth. For the sake of reference, we list a few (we denote differentiation with respect to <span class="arithmatex">\(\theta\)</span> by a prime):</p>
<div class="arithmatex">\[
\begin{aligned}
I(F ; \theta) &amp; =\int\left[(\log f)^{\prime}\right]^{2} f d x \\
&amp; =-\int(\log f)^{\prime \prime} f d x \\
&amp; =-4 \int \frac{(\sqrt{f})^{\prime \prime}}{\sqrt{f}} f d x
\end{aligned}
\]</div>
<h1 id="45-determination-of-f_0-by-variational-methods">4.5 DETERMINATION OF <span class="arithmatex">\(F_{0}\)</span> BY VARIATIONAL METHODS</h1>
<p>Assume that <span class="arithmatex">\(\mathscr{P}\)</span> is convex. Because of convexity of <span class="arithmatex">\(I(\cdot), F_{0} \in \mathscr{P}\)</span> minimizes Fisher information iff <span class="arithmatex">\((d / d t) I\left(F_{t}\right) \geqslant 0\)</span> at <span class="arithmatex">\(t=0\)</span> for every <span class="arithmatex">\(F_{1} \in \mathscr{P}_{1}\)</span>, where <span class="arithmatex">\(\mathscr{P}_{1}\)</span> is the set of all <span class="arithmatex">\(F \in \mathscr{P}\)</span> with <span class="arithmatex">\(I(F)&lt;\infty\)</span>. A straightforward differentiation of (4.7) under the integral sign, justified by the monotone convergence theorem, gives</p>
<div class="arithmatex">\[
\left[\frac{d}{d t} I\left(F_{t}\right)\right]_{t=0}=\int\left[2 \frac{f_{0}^{\prime}}{f_{0}}\left(f_{1}^{\prime}-f_{0}^{\prime}\right)-\left(\frac{f_{0}^{\prime}}{f_{0}}\right)^{2}\left(f_{1}-f_{0}\right)\right] d x \geqslant 0
\]</div>
<p>If we introduce <span class="arithmatex">\(\psi(x)=-f_{0}^{\prime}(x) / f_{0}(x)\)</span>, and if <span class="arithmatex">\(\psi\)</span> has a derivative <span class="arithmatex">\(\psi^{\prime}\)</span> so that integration by parts is possible, (5.1) can be rewritten in the more convenient form</p>
<div class="arithmatex">\[
\int\left(2 \psi^{\prime}-\psi^{2}\right)\left(f_{1}-f_{0}\right) d x \geqslant 0
\]</div>
<p>or also as</p>
<div class="arithmatex">\[
-4 \int \frac{\left(\sqrt{f_{0}}\right)^{\prime \prime}}{\sqrt{f_{0}}}\left(f_{1}-f_{0}\right) d x \geqslant 0
\]</div>
<p>for all <span class="arithmatex">\(F_{1} \in \mathscr{P}_{1}\)</span>.</p>
<p>Among the following examples the first one highlights an amusing connection between least informative distributions and the ground-state solution in quantum mechanics; the second one is of central importance to robust estimation.</p>
<p>Example 5.1 Let <span class="arithmatex">\(\mathscr{P}\)</span> be the set of all probability distributions <span class="arithmatex">\(F\)</span> such that</p>
<div class="arithmatex">\[
\int V(x) F(d x) \leqslant 0
\]</div>
<p>where <span class="arithmatex">\(V\)</span> is some given function. For the <span class="arithmatex">\(F_{0}\)</span> minimizing Fisher information in <span class="arithmatex">\(\mathscr{P}\)</span>, we have equality in (5.3) and (5.4). If we combine (5.3), (5.4), and</p>
<div class="arithmatex">\[
\int F(d x)=1
\]</div>
<p>with the aid of Lagrange multipliers <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(\beta\)</span>, we obtain the differential equation</p>
<div class="arithmatex">\[
4 \frac{\sqrt{f_{0}}^{\prime \prime}}{\sqrt{f_{0}}}-\alpha V+\beta=0
\]</div>
<p>or, with <span class="arithmatex">\(u=\sqrt{f_{0}}\)</span>,</p>
<div class="arithmatex">\[
4 u^{\prime \prime}-(\alpha V-\beta) u=0
\]</div>
<p>This is, essentially, the Schrödinger equation for an electron moving in the potential <span class="arithmatex">\(V\)</span>.</p>
<p>If <span class="arithmatex">\(f_{0}\)</span> is a solution of (5.6) satisfying the side conditions (5.4) and (5.5), then (5.3) holds provided <span class="arithmatex">\(\alpha&gt;0\)</span>. If we multiply (5.6) by <span class="arithmatex">\(f_{0}\)</span> and integrate over <span class="arithmatex">\(x\)</span>, we obtain <span class="arithmatex">\(I\left(F_{0}\right)=\beta\)</span>; hence (using the quantum mechanical jargon) we are interested in the ground-state solution corresponding to the lowest eigenvalue <span class="arithmatex">\(\beta\)</span>.</p>
<p>In the particular case <span class="arithmatex">\(V(x)=x^{2}-1\)</span>, the well-known solution for the ground-state of the harmonic oscillator yields the result, which is also well-known, that, among all distributions with variance <span class="arithmatex">\(\leqslant 1\)</span>, the standard normal has the smallest Fisher information for location.</p>
<p>From the point of view of robust estimation, a "box" potential is more interesting:</p>
<div class="arithmatex">\[
\begin{aligned}
V(x) &amp; =-a&lt;0, &amp; &amp; \text { for }|x|&lt;1 \\
&amp; =b&gt;0, &amp; &amp; \text { for }|x|&gt;1
\end{aligned}
\]</div>
<p>It is easy to see that the solution of (5.6) then is of the general form</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =\frac{C}{\cos ^{2}(\omega / 2)} \cos ^{2}\left(\frac{\omega x}{2}\right), \quad \text { for }|x| \leqslant 1 \\
&amp; =C e^{\lambda} e^{-\lambda|x|}, \quad \text { for }|x|&gt;1
\end{aligned}
\]</div>
<p>for some constants <span class="arithmatex">\(\omega\)</span> and <span class="arithmatex">\(\lambda\)</span>. In order that <span class="arithmatex">\(f_{0}\)</span> be strictly positive, we should have <span class="arithmatex">\(0&lt;\omega&lt;\pi\)</span>. We have already arranged the integration constants so that <span class="arithmatex">\(f_{0}\)</span> is continuous; if <span class="arithmatex">\(\psi=-\left(\log f_{0}\right)^{\prime}\)</span> is also to be continuous, we must have</p>
<div class="arithmatex">\[
\lambda=\omega \tan \frac{\omega}{2}
\]</div>
<p>and <span class="arithmatex">\(C\)</span> must be determined such that <span class="arithmatex">\(\int f_{0} d x=1\)</span>, that is,</p>
<div class="arithmatex">\[
C=\frac{\cos ^{2}(\omega / 2)}{1+2 /[\omega \tan (\omega / 2)]}
\]</div>
<p>Note that then</p>
<div class="arithmatex">\[
\begin{aligned}
-4 \frac{\sqrt{f_{0}} "}{\sqrt{f_{0}}} &amp; =\omega^{2}, \quad \text { for }|x|&lt;1 \\
&amp; =-\lambda^{2}, \quad \text { for }|x|&gt;1
\end{aligned}
\]</div>
<p>hence</p>
<div class="arithmatex">\[
I\left(F_{0}\right)=-4 \int \frac{\sqrt{f_{0}} "}{\sqrt{f_{0}}} f_{0} d x=\frac{\omega^{2}}{1+2 /[\omega \tan (\omega / 2)]}
\]</div>
<p>It is now straightforward to check that (5.3) is satisfied, that is, that this <span class="arithmatex">\(F_{0}\)</span> minimizes Fisher information among all probability distributions <span class="arithmatex">\(F\)</span> satisfying</p>
<div class="arithmatex">\[
F\{(-1,1)\} \geqslant F_{0}\{(-1,1)\}=1-\frac{2 C}{\lambda}
\]</div>
<p>Example 5.2 Let <span class="arithmatex">\(G\)</span> be a fixed probability distribution having a twice differentiable density <span class="arithmatex">\(g\)</span>, such that <span class="arithmatex">\(-\log g(x)\)</span> is convex on the convex support of <span class="arithmatex">\(G\)</span>. Let <span class="arithmatex">\(\varepsilon&gt;0\)</span> be given, and let <span class="arithmatex">\(\varphi\)</span> be the set of all probability</p>
<p>distributions arising from <span class="arithmatex">\(G\)</span> through <span class="arithmatex">\(\varepsilon\)</span>-contamination:</p>
<div class="arithmatex">\[
\mathscr{P}=\{F \mid F=(1-\varepsilon) G+\varepsilon H, H \in \mathscr{M}\}
\]</div>
<p>Here <span class="arithmatex">\(\mathscr{M}\)</span> is, as usual, the set of all probability measures on the real line, but we can also take <span class="arithmatex">\(\mathscr{M}\)</span> to be the set of all substochastic measures, in order to make <span class="arithmatex">\(\mathscr{P}\)</span> vaguely compact.</p>
<p>In view of (5.3) it is plausible that the density <span class="arithmatex">\(f_{0}\)</span> of the least informative distribution behaves as follows. There is a central part where <span class="arithmatex">\(f_{0}\)</span> touches the boundary, <span class="arithmatex">\(f_{0}(x)=(1-\varepsilon) g(x)\)</span>; in the tails <span class="arithmatex">\(\left(\sqrt{f_{0}}\right)^{\prime \prime} / \sqrt{f_{0}}\)</span> is constant, that is, <span class="arithmatex">\(f_{0}\)</span> is exponential, <span class="arithmatex">\(f_{0}(x)=C e^{-\lambda|x|}\)</span>. This is indeed so, and we now give the solution <span class="arithmatex">\(f_{0}\)</span> explicitly.</p>
<p>Let <span class="arithmatex">\(x_{0}&lt;x_{1}\)</span> be the endpoints of the interval where <span class="arithmatex">\(\left|g^{\prime} / g\right| \leqslant k\)</span>, and where <span class="arithmatex">\(k\)</span> is related to <span class="arithmatex">\(\varepsilon\)</span> through</p>
<div class="arithmatex">\[
\int_{x_{0}}^{x_{1}} g(x) d x+\frac{g\left(x_{0}\right)+g\left(x_{1}\right)}{k}=\frac{1}{1-\varepsilon}
\]</div>
<p>Either <span class="arithmatex">\(x_{0}\)</span> or <span class="arithmatex">\(x_{1}\)</span> may be infinite. Then put</p>
<div class="arithmatex">\[
\begin{array}{rlr}
f_{0}(x) &amp; =(1-\varepsilon) g\left(x_{0}\right) e^{k\left(x-x_{0}\right)}, &amp; \text { for } x \leqslant x_{0} \\
&amp; =(1-\varepsilon) g(x), &amp; \text { for } x_{0}&lt;x&lt;x_{1} \\
&amp; =(1-\varepsilon) g\left(x_{1}\right) e^{-k\left(x-x_{1}\right)}, &amp; \text { for } x \geqslant x_{1}
\end{array}
\]</div>
<p>Condition (5.16) ensures that <span class="arithmatex">\(f_{0}\)</span> integrates to 1 ; hence the contamination distribution <span class="arithmatex">\(H_{0}=\left[F_{0}-(1-\varepsilon) G\right] / \varepsilon\)</span> also has total mass 1 , and it remains to be checked that its density <span class="arithmatex">\(h_{0}\)</span> is nonnegative. But this follows at once from the remark that the convex function <span class="arithmatex">\(-\log g(x)\)</span> lies above its tangents at the points <span class="arithmatex">\(x_{0}\)</span> and <span class="arithmatex">\(x_{1}\)</span>, that is</p>
<div class="arithmatex">\[
g(x) \leqslant g\left(x_{0}\right) e^{k\left(x-x_{0}\right)} \quad \text { and } \quad g(x) \leqslant g\left(x_{1}\right) e^{-k\left(x-x_{1}\right)}
\]</div>
<p>Clearly, both <span class="arithmatex">\(f_{0}\)</span> and its derivative are continuous; we have</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
\psi(x) &amp; =-\left[\log f_{0}(x)\right]^{\prime}=-k, &amp; &amp; \text { for } x \leqslant x_{0} \\
&amp; =\frac{-g^{\prime}(x)}{g(x)}, &amp; &amp; \text { for } x_{0}&lt;x&lt;x_{1} \\
&amp; =k, &amp; &amp; \text { for } x \geqslant x_{1}
\end{array}
\]</div>
<p>We now check that (5.2) holds. As <span class="arithmatex">\(\psi^{\prime}(x) \geqslant 0\)</span> and as</p>
<div class="arithmatex">\[
\begin{aligned}
k^{2}+2 \psi^{\prime}-\psi^{2} &amp; \geqslant 0, &amp; &amp; \text { for } x_{0} \leqslant x \leqslant x_{1} \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>it follows that</p>
<div class="arithmatex">\[
\begin{aligned}
\int\left(2 \psi^{\prime}-\psi^{2}\right)\left(f_{1}-f_{0}\right) d x= &amp; \int_{x_{0}}^{x_{1}}\left(k^{2}+2 \psi^{\prime}-\psi^{2}\right)\left(f_{1}-f_{0}\right) d x-k^{2} \int\left(f_{1}-f_{0}\right) d x \\
&amp; \geqslant 0
\end{aligned}
\]</div>
<p>since <span class="arithmatex">\(f_{1} \geqslant f_{0}\)</span> in the interval <span class="arithmatex">\(x_{0}&lt;x&lt;x_{1}\)</span>, and since <span class="arithmatex">\(\int\left(f_{1}-f_{0}\right) d x&lt;0\)</span> (we may allow <span class="arithmatex">\(F_{1}\)</span> to be substochastic!).</p>
<p>Because of their importance we state the results for the case where <span class="arithmatex">\(G=\Phi\)</span> is the standard normal cumulative separately. In this case Fisher information is minimized by</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =\frac{1-\varepsilon}{\sqrt{2 \pi}} e^{-x^{2} / 2}, &amp; &amp; \text { for }|x| \leqslant k \\
&amp; =\frac{1-\varepsilon}{\sqrt{2 \pi}} e^{k^{2} / 2-k|x|}, &amp; &amp; \text { for }|x|&gt;k
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(\varepsilon\)</span> connected through</p>
<div class="arithmatex">\[
\frac{2 \varphi(k)}{k}-2 \Phi(-k)=\frac{\varepsilon}{1-\varepsilon}
\]</div>
<p>( <span class="arithmatex">\(\varphi=\Phi^{\prime}\)</span> being the standard normal density). In this case</p>
<div class="arithmatex">\[
\psi(x)=-\left[\log f_{0}(x)\right]^{\prime}=\max [-k, \min (k, x)]
\]</div>
<p>Compare Exhibit 4.5.1 for some numerical results.
Example 5.3 Let <span class="arithmatex">\(\mathscr{P}\)</span> be the set of all distributions differing at most <span class="arithmatex">\(\varepsilon\)</span> in Kolmogorov distance from the standard normal cumulative</p>
<div class="arithmatex">\[
\sup |F(x)-\Phi(x)|&lt;\varepsilon
\]</div>
<p>It is easy to guess that the solution <span class="arithmatex">\(F_{0}\)</span> is symmetric and that there will be two (possibly coinciding) constants <span class="arithmatex">\(0&lt;x_{0}&lt;x_{1}\)</span> such that <span class="arithmatex">\(F_{0}(x)=\Phi(x)-\varepsilon\)</span></p>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(k\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(F_{0}(-k)\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(1 / I\left(F_{0}\right.\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.000</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">2.630</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">1.010</td>
</tr>
<tr>
<td style="text-align: center;">0.002</td>
<td style="text-align: center;">2.435</td>
<td style="text-align: center;">0.008</td>
<td style="text-align: center;">1.017</td>
</tr>
<tr>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">2.160</td>
<td style="text-align: center;">0.018</td>
<td style="text-align: center;">1.037</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">1.945</td>
<td style="text-align: center;">0.031</td>
<td style="text-align: center;">1.065</td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">1.717</td>
<td style="text-align: center;">0.052</td>
<td style="text-align: center;">1.116</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.399</td>
<td style="text-align: center;">0.102</td>
<td style="text-align: center;">1.256</td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">1.140</td>
<td style="text-align: center;">0.164</td>
<td style="text-align: center;">1.490</td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">1.748</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0.862</td>
<td style="text-align: center;">0.256</td>
<td style="text-align: center;">2.046</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.766</td>
<td style="text-align: center;">0.291</td>
<td style="text-align: center;">2.397</td>
</tr>
<tr>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.685</td>
<td style="text-align: center;">0.323</td>
<td style="text-align: center;">2.822</td>
</tr>
<tr>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.550</td>
<td style="text-align: center;">0.375</td>
<td style="text-align: center;">3.996</td>
</tr>
<tr>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.436</td>
<td style="text-align: center;">0.416</td>
<td style="text-align: center;">5.928</td>
</tr>
<tr>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.291</td>
<td style="text-align: center;">0.460</td>
<td style="text-align: center;">12.48</td>
</tr>
<tr>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;">0.487</td>
<td style="text-align: center;">39.0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
</tbody>
</table>
<p>Exhblt 4.5.1 The <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions least informative for location.
for <span class="arithmatex">\(x_{0} \leqslant x \leqslant x_{1}\)</span>, with strict inequality <span class="arithmatex">\(\left|F_{0}(x)-\Phi(x)\right|&lt;\varepsilon\)</span> for all other positive <span class="arithmatex">\(x\)</span>. In view of (5.3) we expect that <span class="arithmatex">\(\sqrt{f_{0}}{ }^{\prime \prime} / \sqrt{f_{0}}\)</span> is constant in the intervals <span class="arithmatex">\(\left(0, x_{0}\right)\)</span> and <span class="arithmatex">\(\left(x_{1}, \infty\right)\)</span>; hence we try a solution of the form</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x)=f_{0}(-x) &amp; =\frac{\varphi\left(x_{0}\right)}{\cos ^{2}\left(\omega x_{0} / 2\right)} \cos ^{2}\left(\frac{\omega x}{2}\right), &amp; &amp; \text { for } 0 \leqslant x \leqslant x_{0} \\
\varphi(x), &amp; &amp; \text { for } x_{0} \leqslant x \leqslant x_{1} \\
&amp; =\varphi\left(x_{1}\right) e^{-\lambda\left(x-x_{1}\right)}, &amp; &amp; \text { for } x \geqslant x_{1}
\end{aligned}
\]</div>
<p>We now distinguish two cases.
Case A Small Values of <span class="arithmatex">\(\varepsilon, x_{0}&lt;x_{1}\)</span> In order that</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x)=-\left[\log f_{0}(x)\right]^{\prime} &amp; =\omega \tan \left(\frac{\omega x}{2}\right), &amp; &amp; \text { for } 0 \leqslant x \leqslant x_{0} \\
&amp; =x, &amp; &amp; \text { for } x_{0} \leqslant x \leqslant x_{1} \\
&amp; =\lambda, &amp; &amp; \text { for } x \geqslant x_{1}
\end{aligned}
\]</div>
<p>be continuous, we must require</p>
<div class="arithmatex">\[
\begin{aligned}
\omega \tan \left(\frac{\omega x_{0}}{2}\right) &amp; =x_{0} \\
\lambda &amp; =x_{1}
\end{aligned}
\]</div>
<p>In order that <span class="arithmatex">\(F_{0}(x)=\Phi(x)-\varepsilon\)</span> for <span class="arithmatex">\(x_{0} \leqslant x \leqslant x_{1}\)</span>, and that its total mass be 1 , we must have</p>
<div class="arithmatex">\[
\int_{0}^{x_{0}} f_{0}(x) d x=\int_{0}^{x_{0}} \varphi(x) d x-\varepsilon
\]</div>
<p>and</p>
<div class="arithmatex">\[
\int_{x_{1}}^{\infty} f_{0}(x) d x=\int_{x_{1}}^{\infty} \varphi(x) d x+\varepsilon
\]</div>
<p>For a given <span class="arithmatex">\(\varepsilon,(5.26)\)</span> to (5.29) determine the four quantities <span class="arithmatex">\(x_{0}, x_{1}, \omega\)</span>, and <span class="arithmatex">\(\lambda\)</span>. For the actual calculation it is advantageous to use</p>
<div class="arithmatex">\[
u=\omega x_{0}
\]</div>
<p>as the independent variable, <span class="arithmatex">\(0&lt;u&lt;\pi\)</span>, and to express everything in terms of <span class="arithmatex">\(u\)</span> instead of <span class="arithmatex">\(\varepsilon\)</span>. Then from (5.26), (5.30), and (5.28), we obtain, respectively,</p>
<div class="arithmatex">\[
\begin{aligned}
x_{0} &amp; =\left(u \tan \frac{u}{2}\right)^{1 / 2} \\
\omega &amp; =\frac{u}{x_{0}} \\
\varepsilon &amp; =\Phi\left(x_{0}\right)-\frac{1}{2}-x_{0} \varphi\left(x_{0}\right) \frac{1+\sin u / u}{1+\cos u}
\end{aligned}
\]</div>
<p>and finally, <span class="arithmatex">\(x_{1}\)</span> has to be determined from (5.29), that is, from</p>
<div class="arithmatex">\[
\varepsilon=\frac{\varphi\left(x_{1}\right)}{x_{1}}-\Phi\left(-x_{1}\right)
\]</div>
<p>It turns out that <span class="arithmatex">\(x_{0}&lt;x_{1}\)</span> so long as <span class="arithmatex">\(\varepsilon&lt;\varepsilon_{0} \cong 0.0303\)</span>. It remains to check (5.23) and (5.3). The first one follows easily from <span class="arithmatex">\(f_{0}\left(x_{0}\right)=\varphi\left(x_{0}\right), f_{0}\left(x_{1}\right)=\)</span> <span class="arithmatex">\(\varphi\left(x_{1}\right)\)</span>, and from the remark that</p>
<div class="arithmatex">\[
-\left[\log f_{0}(x)\right]^{\prime}=\psi(x) \leqslant-\left[\log \varphi(x)\right]^{\prime}, \quad \text { for } x \geqslant 0
\]</div>
<p>If we integrate this relation, we obtain that <span class="arithmatex">\(f_{0}(x) \leqslant \varphi(x)\)</span> for <span class="arithmatex">\(0 \leqslant x \leqslant x_{0}\)</span> and <span class="arithmatex">\(f_{0}(x) \geqslant \varphi(x)\)</span> for <span class="arithmatex">\(x \geqslant x_{1}\)</span>. In conjunction with <span class="arithmatex">\(F_{0}(x)=\Phi(x)-\varepsilon\)</span> for <span class="arithmatex">\(x_{0} \leqslant x \leqslant x_{1}\)</span>, this establishes (5.23). In order to check (5.3), we first note that it suffices to consider symmetric distributions for <span class="arithmatex">\(F_{1}\)</span> (since <span class="arithmatex">\(I(F)\)</span> is convex, the symmetrized distribution <span class="arithmatex">\(\widehat{F}(x)=\frac{1}{2}[F(x)+1-F(-x)]\)</span> has a smaller Fisher information than <span class="arithmatex">\(F\)</span> ). We have</p>
<div class="arithmatex">\[
\begin{aligned}
-4 \frac{\sqrt{f_{0}^{\prime \prime}}}{\sqrt{f_{0}^{\prime}}} &amp; =\omega^{2}, &amp; &amp; \text { for } 0 \leqslant x&lt;x_{0} \\
&amp; =2-x^{2}, &amp; &amp; \text { for } x_{0}&lt;x&lt;x_{1} \\
&amp; =-x_{1}^{2}, &amp; &amp; \text { for } x&gt;x_{1}
\end{aligned}
\]</div>
<p>Thus with <span class="arithmatex">\(G=F_{1}-F_{0}\)</span> the left-hand side of (5.3) becomes twice</p>
<div class="arithmatex">\[
\begin{aligned}
\int_{0}^{x_{0}} \omega^{2} d G &amp; +\int_{x_{0}}^{x_{1}}\left(2-x^{2}\right) d G-\int_{x_{1}}^{\infty} x_{1}^{2} d G \\
&amp; =\left(\omega^{2}+x_{0}^{2}-2\right) G\left(x_{0}\right)+2 G\left(x_{1}\right)-x_{1}^{2} G(\infty)+\int_{x_{0}}^{x_{1}} x G(x) d x
\end{aligned}
\]</div>
<p>We note that</p>
<div class="arithmatex">\[
\omega^{2}+x_{0}^{2}-2=\frac{u}{\tan \left(\frac{1}{2} u\right)}+u \tan \left(\frac{1}{2} u\right)-2=2\left(\frac{u}{\sin u}-1\right) \geqslant 0
\]</div>
<p>that <span class="arithmatex">\(G(x) \geqslant 0\)</span> for <span class="arithmatex">\(x_{0} \leqslant x \leqslant x_{1}\)</span>, and that <span class="arithmatex">\(G(\infty)&lt;0\)</span>. Hence all terms are positive and (5.3) is verified.</p>
<p>Case B Large Values of <span class="arithmatex">\(\varepsilon, x_{0}=x_{1}\)</span> In this case (5.24) simplifies to</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =f_{0}(-x)=\frac{\varphi\left(x_{0}\right)}{\cos ^{2}\left(\omega x_{0} / 2\right)} \cos ^{2}\left(\frac{\omega x}{2}\right), \quad \text { for } 0 \leqslant x \leqslant x_{0} \\
&amp; =\varphi\left(x_{0}\right) e^{-\lambda\left(x-x_{0}\right)}, \quad \text { for } x&gt;x_{0}
\end{aligned}
\]</div>
<p>Apart from a change of scale, this is the distribution already encountered in (5.9).</p>
<p>In order that</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x)=-\left[\log f_{0}(x)\right]^{\prime} &amp; =\omega \tan \left(\frac{\omega x}{2}\right), &amp; &amp; \text { for } 0 \leqslant x \leqslant x_{0} \\
&amp; =\lambda, &amp; &amp; \text { for } x&gt;x_{0}
\end{aligned}
\]</div>
<p>be continuous, we must require that</p>
<div class="arithmatex">\[
\lambda x_{0}=\omega x_{0} \tan \frac{\omega x_{0}}{2}
\]</div>
<p>and <span class="arithmatex">\(f_{0}\)</span> integrates to 1 if</p>
<div class="arithmatex">\[
x_{0} \varphi\left(x_{0}\right)=\cos ^{2}\left(\frac{u}{2}\right) \frac{1}{1+2 /[u \tan (u / 2)]}
\]</div>
<p>with <span class="arithmatex">\(u=\omega x_{0}\)</span>; compare (5.11).
It is again convenient to use <span class="arithmatex">\(u=\omega x_{0}\)</span> instead of <span class="arithmatex">\(\varepsilon\)</span> as the independent variable. We first determine <span class="arithmatex">\(x_{0} \geqslant 1\)</span> from (5.38) (there is also a solution <span class="arithmatex">\(&lt;1\)</span> ), and then <span class="arithmatex">\(\lambda\)</span> from (5.37). From (5.29) we get</p>
<div class="arithmatex">\[
\varepsilon=\frac{\varphi\left(x_{0}\right)}{\lambda}-\Phi\left(-x_{0}\right)
\]</div>
<p>This solution holds for <span class="arithmatex">\(\varepsilon \geqslant \varepsilon_{0} \cong 0.0303\)</span>. It is somewhat tricky to prove that <span class="arithmatex">\(F_{0}\)</span> satisfies (5.23); see Sacks and Ylvisaker (1972). Exhibit 4.5.2 gives some numerical results.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(x_{0}\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(\omega\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(\lambda\left(=x_{1}\right)\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(1 / I\left(F_{0}\right)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.4142</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">1.</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.6533</td>
<td style="text-align: center;">1.3658</td>
<td style="text-align: center;">2.4364</td>
<td style="text-align: center;">1.019</td>
</tr>
<tr>
<td style="text-align: center;">0.002</td>
<td style="text-align: center;">0.7534</td>
<td style="text-align: center;">1.3507</td>
<td style="text-align: center;">2.2317</td>
<td style="text-align: center;">1.034</td>
</tr>
<tr>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.9118</td>
<td style="text-align: center;">1.3234</td>
<td style="text-align: center;">1.9483</td>
<td style="text-align: center;">1.075</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">1.0564</td>
<td style="text-align: center;">1.2953</td>
<td style="text-align: center;">1.7241</td>
<td style="text-align: center;">1.136</td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">1.2288</td>
<td style="text-align: center;">1.2587</td>
<td style="text-align: center;">1.4921</td>
<td style="text-align: center;">1.256</td>
</tr>
<tr>
<td style="text-align: center;">0.03033</td>
<td style="text-align: center;">1.3496</td>
<td style="text-align: center;">1.2316</td>
<td style="text-align: center;">1.3496</td>
<td style="text-align: center;">1.383</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.3216</td>
<td style="text-align: center;">1.1788</td>
<td style="text-align: center;">1.1637</td>
<td style="text-align: center;">1.656</td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">1.3528</td>
<td style="text-align: center;">1.0240</td>
<td style="text-align: center;">0.8496</td>
<td style="text-align: center;">2.613</td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">1.4335</td>
<td style="text-align: center;">0.8738</td>
<td style="text-align: center;">0.6322</td>
<td style="text-align: center;">4.200</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">1.5363</td>
<td style="text-align: center;">0.7363</td>
<td style="text-align: center;">0.4674</td>
<td style="text-align: center;">6.981</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">1.6568</td>
<td style="text-align: center;">0.6108</td>
<td style="text-align: center;">0.3384</td>
<td style="text-align: center;">12.24</td>
</tr>
<tr>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">1.7974</td>
<td style="text-align: center;">0.4950</td>
<td style="text-align: center;">0.2360</td>
<td style="text-align: center;">23.33</td>
</tr>
<tr>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">2.1842</td>
<td style="text-align: center;">0.2803</td>
<td style="text-align: center;">0.0886</td>
<td style="text-align: center;">144.2</td>
</tr>
</tbody>
</table>
<p>Exhibit 4.5.2 Least informative distributions for sup <span class="arithmatex">\(|F(x)-\Phi(x)|&lt;\varepsilon\)</span> [cf. Example 4.5.3; (5.25), (5.35)].</p>
<p>We have now determined a small collection of least informative situations and we should take some time out to reflect how realistic or unrealistic they are.</p>
<p>First, it may surprise us that the least informative <span class="arithmatex">\(F_{0}\)</span> do not have excessively long tails. On the contrary we might perhaps argue that they have unrealistically short tails, since they do not provide for the extreme outliers we sometimes encounter.</p>
<p>Second, we should compare them with actual, supposedly normal, distributions. For that we need very large samples, and these seem to be quite rare; some impressive examples have been collected by Romanowski and Green (1965). Their largest sample ( <span class="arithmatex">\(n=8688\)</span> ), when plotted on normal probability paper (Exhibit 4.5.3), is seen to behave very much like a least informative <span class="arithmatex">\(2 \%\)</span>-contaminated normal distribution [it lies between the slightly different curves for the least favorable <span class="arithmatex">\(F_{0}\)</span> for location and the least favorable one for scale (5.6.15)]. For their smaller samples the conclusions are less clear-cut because of the higher random variability, but there also the sample distribution functions are close to some least informative <span class="arithmatex">\(\varepsilon\)</span>-contaminated <span class="arithmatex">\(F_{0}\)</span> (with <span class="arithmatex">\(\varepsilon\)</span> in the range 0.01 to 0.1 ).</p>
<p>Thus it makes very good sense to use minimax procedures safeguarding against <span class="arithmatex">\(\varepsilon\)</span>-contamination, for an <span class="arithmatex">\(\varepsilon\)</span> in the range just mentioned.
<img alt="img-3.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 4.5.3 1: Normal cumulative. 2: Least favorable for location ( <span class="arithmatex">\(\varepsilon=0.02\)</span> ). 3: Empirical cumulative. 4: Least favorable for scale ( <span class="arithmatex">\(\varepsilon=0.02\)</span> ). <span class="arithmatex">\(n=8688\)</span>. Data from Romanowski and Green (1965).</p>
<p><img alt="img-4.jpeg" src="data:image/jpeg;base64,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" /></p>
<p><img alt="img-5.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 4.5.4 plots, on normal probability paper, the symmetrized empirical distributions of several large samples taken from Romanowski and Green (1965). Also shown are the asymptotic variances of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean and of the logarithm of the <span class="arithmatex">\(\alpha\)</span>-trimmed standard deviation (this corresponds to sampling with replacement from the symmetrized empirical distributions).</p>
<p>These are all good data sets, so the classical estimates do not fare badly, but note that moderate trimming would never do much harm, but sometimes considerable good.</p>
<h1 id="46-asymptotically-minimax-m-estimates">4.6 ASYMPTOTICALLY MINIMAX M-ESTIMATES</h1>
<p>Assume that <span class="arithmatex">\(F_{0}\)</span> has minimal Fisher information for location in the convex set <span class="arithmatex">\(\mathscr{P}\)</span> of distribution functions. We now show that the asymptotically efficient <span class="arithmatex">\(M\)</span>-estimate of location for <span class="arithmatex">\(F_{0}\)</span> in fact possesses certain minimax properties in <span class="arithmatex">\(\mathscr{P}\)</span>.</p>
<p>According to (3.5.11) we must choose</p>
<div class="arithmatex">\[
\psi(x)=\frac{-c f_{0}^{\prime}(x)}{f_{0}^{\prime}(x)}
\]</div>
<p>in order to achieve asymptotic efficiency at <span class="arithmatex">\(F_{0}\)</span> (the value of the constant <span class="arithmatex">\(c \neq 0\)</span> is irrelevant). We do not worry about regularity conditions for the moment, but we note that, in all examples of Section 4.5, the function (6.1) is monotone, so the theory of Section 3.2 is applicable, and the <span class="arithmatex">\(M\)</span>-estimate, defined by</p>
<div class="arithmatex">\[
\int \psi(x-T(F)) F(d x)=0
\]</div>
<p>is asymptotically normal</p>
<div class="arithmatex">\[
\mathcal{E}\left\{\sqrt{n}\left[T\left(F_{n}\right)-T(F)\right]\right\} \rightarrow \mathfrak{R}(0, A(F, T))
\]</div>
<p>with asymptotic variance</p>
<div class="arithmatex">\[
A(F, T)=\frac{\int \psi(x-T(F))^{2} F(d x)}{\left[\lambda^{\prime}(T(F))\right]^{2}}=\frac{\int \psi(x-T(F))^{2} F(d x)}{\left[\int \psi^{\prime}(x-T(F)) F(d x)\right]^{2}}
\]</div>
<p>In particular,</p>
<div class="arithmatex">\[
A\left(F_{0}, T\right)=\frac{1}{I\left(F_{0}\right)}
\]</div>
<p>Without loss of generality we may assume <span class="arithmatex">\(T\left(F_{0}\right)=0\)</span>.
But we now run into an awkward technical difficulty, caused by the variable term <span class="arithmatex">\(T(F)\)</span> in the expression (6.4) for the asymptotic variance. If <span class="arithmatex">\(\mathscr{P}\)</span> consists of symmetric distributions only, then</p>
<div class="arithmatex">\[
T(F)=0, \quad \text { for all } F \in \mathscr{P}
\]</div>
<p>and the difficulty disappears.
Traditionally and conveniently, most of the robustness literature therefore adopts the assumption of symmetry. However, it should be pointed out that a restriction to exactly symmetric distributions:
(1) Violates the very spirit of robustness.
(2) Is out of the question if the model distribution itself already is asymmetric.</p>
<p>We therefore adopt a slightly different approach. We replace <span class="arithmatex">\(\mathscr{P}\)</span> by the convex subset</p>
<div class="arithmatex">\[
\mathscr{P}_{0}=\{F \in \mathscr{P} \mid T(F)=0\}
\]</div>
<p>This enforces (6.6) and eliminates the explicit dependence of (6.4) on <span class="arithmatex">\(T(F)\)</span>. Moreover, it leads to a "cleaner" problem; we do not have to worry about the asymptotic bias of <span class="arithmatex">\(T\left(F_{n}\right)\)</span> while investigating its asymptotic variance on <span class="arithmatex">\(\mathscr{P}_{0}\)</span>. Clearly, the behavior of <span class="arithmatex">\(T(F)\)</span> and <span class="arithmatex">\(A(F, T)\)</span> on <span class="arithmatex">\(\mathscr{P} \backslash \mathscr{P}_{0}\)</span> still must be checked separately (see Section 4.9).</p>
<p>According to Lemma 4.4, <span class="arithmatex">\(1 / A(F, T)\)</span> is a convex function of <span class="arithmatex">\(F \in \mathscr{P}_{0}\)</span>. Let <span class="arithmatex">\(F_{t}=(1-t) F_{0}+t F_{1}\)</span> with <span class="arithmatex">\(F_{1} \in \mathscr{P}_{0} \cap \mathscr{P}_{1}\)</span>, where <span class="arithmatex">\(\mathscr{P}_{1}\)</span> is the subset of <span class="arithmatex">\(\mathscr{P}\)</span> consisting of distributions with finite Fisher information (cf. Section 4.5). Then an explicit calculation and a comparison with (5.1) and (5.2) gives</p>
<div class="arithmatex">\[
\begin{aligned}
{\left[\frac{d}{d t} \frac{1}{A(F, T)}\right]_{t=0} } &amp; =\int\left[2 \psi^{\prime}(x)-\psi(x)^{2}\right]\left[F_{1}(d x)-F_{0}(d x)\right] \\
&amp; =\left[\frac{d}{d t} I\left(F_{t}\right)\right]_{t=0} \geqslant 0
\end{aligned}
\]</div>
<p>It follows from the convexity of <span class="arithmatex">\(1 / A(F, T)\)</span> that</p>
<div class="arithmatex">\[
A(F, T) \leqslant A\left(F_{0}, T\right), \quad \text { for all } F \in \mathscr{P}_{0} \cap \mathscr{P}_{1}
\]</div>
<p>In other words the maximum likelihood estimate for location based on the least informative <span class="arithmatex">\(F_{0}\)</span> minimizes the maximum asymptotic variance for alternatives in <span class="arithmatex">\(\mathscr{P}_{0} \cap \mathscr{P}_{1}\)</span>. If <span class="arithmatex">\(\mathscr{P}_{1}\)</span> is dense in <span class="arithmatex">\(\mathscr{P}\)</span>, the estimate usually is minimax for the whole of <span class="arithmatex">\(\mathscr{P}_{0}\)</span>, but each case seems to need a separate investigation.</p>
<p>For instance, take the case of Example 5.2, assuming that <span class="arithmatex">\((-\log g)^{\prime \prime}\)</span> is continuous. We rely heavily on the asymptotic normality proof given in Section 3.2.</p>
<p>First, it is evident that</p>
<div class="arithmatex">\[
\int \psi(x)^{2} F(d x) \leqslant \int \psi(x)^{2} F_{0}(d x), \quad \text { for all } F \in \mathscr{P}_{0}
\]</div>
<p>since <span class="arithmatex">\(F_{0}\)</span> puts all contamination on the maximum of <span class="arithmatex">\(\psi^{2}\)</span>.
Some difficulties arise with</p>
<div class="arithmatex">\[
\lambda(t, F)=\int \psi(x-t) F(d x)
\]</div>
<p>since it may fail to have a derivative. To see what is going on, put <span class="arithmatex">\(u_{i}=(-\log g)^{\prime \prime}\left(x_{i}\right), i=0,1\)</span>, with <span class="arithmatex">\(x_{i}\)</span> as in Example 5.2. If <span class="arithmatex">\(F\)</span> puts pointmasses <span class="arithmatex">\(\varepsilon_{i}\)</span> at <span class="arithmatex">\(x_{i}\)</span>, then a straightforward calculation shows that <span class="arithmatex">\(\lambda(\cdot, F)\)</span> still has (possibly different) one-sided derivatives at <span class="arithmatex">\(t=0\)</span>; in fact</p>
<div class="arithmatex">\[
\lambda^{\prime}(+0 ; F)-\lambda^{\prime}(-0 ; F)=\varepsilon_{0} u_{0}-\varepsilon_{1} u_{1}
\]</div>
<p>In any case we have</p>
<div class="arithmatex">\[
-\lambda^{\prime}( \pm 0 ; F) \geqslant-\lambda^{\prime}\left(0 ; F_{0}\right)&gt;0
\]</div>
<p>for all <span class="arithmatex">\(F \in \mathscr{P}_{0}\)</span>.
Theorem 3.2.4 remains valid; a closer look at the limiting distribution of <span class="arithmatex">\(\sqrt{n} T\left(F_{n}\right)\)</span> shows that it is no longer normal, but pieced together from the right half of a normal distribution whose variance (6.4) is determined by the right derivative of <span class="arithmatex">\(\lambda\)</span>, and from the left half of a normal distribution whose variance is determined by the left derivative of <span class="arithmatex">\(\lambda\)</span>.</p>
<p>But (6.10) and (6.12) together imply that, nevertheless,</p>
<div class="arithmatex">\[
A(F ; T) \leqslant A\left(F_{0} ; T\right)
\]</div>
<p>even if <span class="arithmatex">\(A(F ; T)\)</span> now may have different values on the left- and the right-hand sides of the median of the distribution of <span class="arithmatex">\(\sqrt{n} T\left(F_{n}\right)\)</span>. Moreover,</p>
<p>there is enough uniformity in the convergence of (3.2.29) to imply</p>
<div class="arithmatex">\[
v(\varepsilon)=v_{1}(\varepsilon)=A\left(F_{0} ; T\right)
\]</div>
<p>(see Section 1.4) when <span class="arithmatex">\(F\)</span> varies over <span class="arithmatex">\(\mathscr{R}_{0}\)</span>.
Remark An interesting limiting case.
Consider the general <span class="arithmatex">\(\varepsilon\)</span>-contaminated case of Example 5.2, and let <span class="arithmatex">\(\varepsilon \rightarrow 1\)</span>. Then <span class="arithmatex">\(k \rightarrow 0\)</span> and <span class="arithmatex">\(f_{0} \rightarrow 0\)</span>, so there is no proper limiting distribution. But the asymptotically efficient <span class="arithmatex">\(M\)</span>-estimate for <span class="arithmatex">\(F_{0}\)</span> tends to a nontrivial limit, namely, apart from an additive constant, to the sample median. This may be seen as follows: <span class="arithmatex">\(\psi\)</span> can be multiplied by a constant, without changing the estimate, and in particular</p>
<div class="arithmatex">\[
\begin{aligned}
\lim _{\varepsilon \rightarrow 0} \frac{1}{k} \psi(x) &amp; =-1, &amp; &amp; \text { for } x&lt;x^{*} \\
&amp; =1, &amp; &amp; \text { for } x&gt;x^{*}
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(x^{*}\)</span> is defined by <span class="arithmatex">\(g^{\prime}\left(x^{*}\right) / g\left(x^{*}\right)=0\)</span>. Hence the limiting estimate is determined as the solution of</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \operatorname{sign}\left(x_{i}-x^{*}-T_{n}\right)=0
\]</div>
<p>and thus</p>
<div class="arithmatex">\[
T_{n}=\operatorname{med}\left\{x_{i}\right\}-x^{*}
\]</div>
<p>Example 6.1 Because of its importance, we single out the minimax <span class="arithmatex">\(M\)</span>-estimate of location for the <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distribution. There, the least informative distribution is given by (5.20) and (5.21), and the estimate <span class="arithmatex">\(T_{n}\)</span> is defined by</p>
<div class="arithmatex">\[
\sum \psi\left(x_{i}-T_{n}\right)=0
\]</div>
<p>with <span class="arithmatex">\(\psi\)</span> given by (5.22).</p>
<h1 id="47-on-the-minimax-property-for-l-and-r-estimates">4.7 ON THE MINIMAX PROPERTY FOR <span class="arithmatex">\(L\)</span> - AND <span class="arithmatex">\(R\)</span>-ESTIMATES</h1>
<p>For <span class="arithmatex">\(L\)</span> - and <span class="arithmatex">\(R\)</span>-estimates <span class="arithmatex">\(1 / A(F ; T)\)</span> is no longer a convex function of <span class="arithmatex">\(F\)</span>. Although (6.8) still holds [this is shown either by explicit calculation, or it</p>
<p>can also be inferred on general grounds from the remark that <span class="arithmatex">\(I(F)=\)</span> <span class="arithmatex">\(\sup _{T} 1 / A(F, T)\)</span>, with <span class="arithmatex">\(T\)</span> ranging over either class of estimates] we can no longer conclude that the asymptotically efficient estimate for <span class="arithmatex">\(F_{0}\)</span> is asymptotically minimax, even if we restrict <span class="arithmatex">\(\varphi\)</span> to symmetric and smooth distributions. In fact Sacks and Ylvisaker (1972) have constructed counterexamples. However, in the important Example 5.2 ( <span class="arithmatex">\(\varepsilon\)</span>-contamination), the conclusion is true (Jaeckel 1971a). We assume throughout that all distributions are symmetric.</p>
<p>Consider first the case of <span class="arithmatex">\(L\)</span>-estimates, where the efficient one (cf. Section 3.5) is characterized by the weight density</p>
<div class="arithmatex">\[
\begin{aligned}
\mathrm{m}\left(\mathrm{~F}_{0}(\mathrm{x})\right) &amp; =-\left(\frac{g^{\prime}(x)}{g(x)}\right)^{\prime} \frac{1}{I\left(F_{0}\right)} \geqslant 0, &amp; &amp; \text { for }|\mathrm{x}| \leqslant \mathrm{x}_{1}=-\mathrm{x}_{0} \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(g\)</span> as in Example 5.2.
The influence function is skew symmetric, and, for <span class="arithmatex">\(x \geqslant 0\)</span>, it satisfies</p>
<div class="arithmatex">\[
I C(x ; F, T)=\int_{0}^{x} m(F(y)) d y
\]</div>
<p>or, for <span class="arithmatex">\(\frac{1}{2} \leqslant t&lt;1\)</span>,</p>
<div class="arithmatex">\[
I C\left(F^{-1}(t) ; F, T\right)=\int_{1 / 2}^{t} \frac{m(s)}{f\left(F^{-1}(s)\right)} d s
\]</div>
<p>We have</p>
<div class="arithmatex">\[
F(x) \geqslant F_{0}(x), \quad \text { for } 0 \leqslant x \leqslant x_{1}
\]</div>
<p>and</p>
<div class="arithmatex">\[
F^{-1}(t) \leqslant F_{0}^{-1}(t), \quad \text { for } \frac{1}{2} \leqslant t \leqslant F_{0}\left(x_{1}\right)
\]</div>
<p>Thus for <span class="arithmatex">\(\frac{1}{2} \leqslant t \leqslant F_{0}\left(x_{1}\right)\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
I C\left(F^{-1}(t) ; F, T\right) &amp; =\int_{1 / 2}^{t} \frac{m(s)}{f\left(F^{-1}(s)\right)} d s \\
&amp; \leqslant \int_{1 / 2}^{t} \frac{m(s)}{f_{0}\left(F^{-1}(s)\right)} d s \leqslant \int_{1 / 2}^{t} \frac{m(s)}{f_{0}\left(F_{0}^{-1}(s)\right)} d s \\
&amp; =I C\left(F_{0}^{-1}(t) ; F, T\right)
\end{aligned}
\]</div>
<p>Since <span class="arithmatex">\(I C\left(F^{-1}(t) ; F, T\right)\)</span> is constant for <span class="arithmatex">\(F_{0}\left(x_{1}\right) \leqslant t \leqslant 1\)</span>, and as</p>
<div class="arithmatex">\[
A(F, T)=2 \int_{1 / 2}^{1} I C\left(F^{-1}(t) ; F, T\right)^{2} d t
\]</div>
<p>it follows that <span class="arithmatex">\(A(F, T) \leqslant A\left(F_{0}, T\right)\)</span>; hence the minimax property holds.
Now consider the <span class="arithmatex">\(R\)</span>-estimate. The optimal scores function <span class="arithmatex">\(J(t)\)</span> is given by</p>
<div class="arithmatex">\[
J\left(F_{0}(x)\right)=-\frac{f_{0}^{\prime}(x)}{f_{0}(x)}
\]</div>
<p>The value of the influence function at <span class="arithmatex">\(x=F^{-1}(t)\)</span> is</p>
<div class="arithmatex">\[
I C\left(F^{-1}(t) ; F, t\right)=\frac{J(t)}{\int J^{\prime}(F(x)) f(x)^{2} d x}=\frac{J(t)}{\int J^{\prime}(s) f\left(F^{-1}(s)\right) d s}
\]</div>
<p>Since <span class="arithmatex">\(J^{\prime}(t)=0\)</span> outside of the interval <span class="arithmatex">\(\left(F_{0}\left(x_{0}\right), F_{0}\left(x_{1}\right)\right)\)</span>, and since in this interval</p>
<div class="arithmatex">\[
f\left(F^{-1}(t)\right) \geqslant f_{0}\left(F^{-1}(t)\right) \geqslant f_{0}\left(F_{0}^{-1}(t)\right)
\]</div>
<p>we conclude that, for <span class="arithmatex">\(t \geqslant \frac{1}{2}\)</span>,</p>
<div class="arithmatex">\[
I C\left(F^{-1}(t) ; F, T\right) \leqslant I C\left(F_{0}^{-1}(t) ; F_{0}, T\right)
\]</div>
<p>hence, as above,</p>
<div class="arithmatex">\[
A(F, T) \leqslant A\left(F_{0}, T\right)
\]</div>
<p>and the minimax property holds.
Example 7.1 In the <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal case, the least informative distribution <span class="arithmatex">\(F_{0}\)</span> is given by (5.20) and (5.21), and all of the following three estimates are asymptotically minimax:
(1) The <span class="arithmatex">\(M\)</span>-estimate with <span class="arithmatex">\(\psi\)</span> given by (5.22).
(2) The <span class="arithmatex">\(\alpha\)</span>-trimmed mean with <span class="arithmatex">\(\alpha=F_{0}(-k)=(1-\varepsilon) \Phi(-k)+\varepsilon / 2\)</span>.
(3) The <span class="arithmatex">\(R\)</span>-estimate defined through the scores generating function <span class="arithmatex">\(J(t)=\psi\left(F_{0}^{-1}(t)\right)\)</span>, that is,</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
J(t) &amp; =-k, &amp; &amp; \text { for } t \leqslant \alpha \\
&amp; =\Phi^{-1}\left(\frac{t-\varepsilon / 2}{1-\varepsilon}\right), &amp; &amp; \text { for } \alpha \leqslant t \leqslant 1-\alpha \\
&amp; =k, &amp; &amp; \text { for } t \geqslant 1-\alpha .
\end{array}
\]</div>
<h1 id="48-descending-m-estimates">4.8 DESCENDING M-ESTIMATES</h1>
<p>We have already noted that the least informative distributions tend to have exponential tails, that is, they might be slimmer (!) than what we would expect in practice. So it might be worthwhile to increase the maximum risk slightly beyond its minimax value in order to gain a better performance at very long-tailed distributions.</p>
<p>This can be done as follows. Consider <span class="arithmatex">\(M\)</span>-estimates, and minimize the maximal asymptotic variance subject to the side condition</p>
<div class="arithmatex">\[
\psi(x)=0, \quad \text { for }|x|&gt;c
\]</div>
<p>where <span class="arithmatex">\(c\)</span> can be chosen arbitrarily.
For <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions, the solution is of the following form:</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x) &amp; =-\psi(-x)=x, &amp; &amp; \text { for } 0 \leqslant x \leqslant a \\
&amp; =b \tanh \left[\frac{1}{2} b(c-x)\right], &amp; &amp; \text { for } a \leqslant x \leqslant c \\
&amp; =0, &amp; &amp; \text { for } x \geqslant c
\end{aligned}
\]</div>
<p>see Exhibit 4.8.1. The values of <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span>, of course, depend on <span class="arithmatex">\(\varepsilon\)</span>.
The above estimate is a maximum likelihood estimate based on a truncated sample, for an underlying density</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(x) &amp; =f_{0}(-x)=(1-\varepsilon) \varphi(x), &amp; &amp; \text { for } 0 \leqslant x \leqslant a \\
&amp; =\frac{(1-\varepsilon) \varphi(a)}{\cosh ^{2}\left[\frac{1}{2} b(c-a)\right]} \cosh ^{2}\left[\frac{1}{2} b(c-x)\right], &amp; &amp; \text { for } a \leqslant x \leqslant c \\
&amp; =(1-\varepsilon) \varphi(x), &amp; &amp; \text { for } x \geqslant c
\end{aligned}
\]</div>
<p>Note that this density is discontinuous at <span class="arithmatex">\(\pm c\)</span>. In order that <span class="arithmatex">\(f_{0}\)</span> integrate to 1 , we must have</p>
<div class="arithmatex">\[
2 \int_{a}^{c}\left[f_{0}(x)-(1-\varepsilon) \varphi(x)\right] d x=\varepsilon
\]</div>
<p>this gives one relation between <span class="arithmatex">\(\varepsilon\)</span> and <span class="arithmatex">\(a, b\)</span>; the other one is continuity of <span class="arithmatex">\(\psi\)</span> at <span class="arithmatex">\(a\)</span> :</p>
<div class="arithmatex">\[
a=b \tanh \left[\frac{1}{2} b(c-a)\right]
\]</div>
<p><img alt="img-6.jpeg" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAMTAtsDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKQnBxXmnin43+GfDOryaaIrrUJ4SVmNqFKxt/dySAT9OlAHplFeNx/tG+GnD79K1RMISvyodzdl+9+tM/wCGkPDuf+QNqn/kP/4qgD2eivF/+GkfDn/QG1T/AMh//FVYtP2i/C082240/U7aPH32RG59MBqAPYKK8uHx+8EGIv5l/kEDZ9m5PuOcY/Gtez+MfgO9kjjXX44ncZxPDJGF4zgsyhQfx+maAO6orirP4t+BL52SLxHaqyjJ85XiH4F1Ga6GHxLodx5fk6xp7+YBsAuUy2emBmgDUopu8frilLY7UALRSBs0o5oAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAppcKSDwAOppJZUhjaSRgqIMsxOAB6k9hXg3jTxzqfxI1Z/BXgqCVrV3xd3gICyICMnp8qAjrnLdMc8gDPiH8U9X1zX5PCPgrc5eQRG6tmJeZ8fMqHoFHc+xOcV3PgP4UaT4c0vzdWtodS1e5Ae5luUEoRjyQu4dM556mtTwV8NtC8FWSfYoBJqJj2TXzj94+euOflHsPQV2QGKAMIeCvDAuTcDw/pYkKhSfsidOe2Md6mXwt4fQgpoemIw6FbSMEfpWvRQBj/APCJ+HP+gBpX/gHH/hVa88CeFL+NUuPDumMqnI22yr/ICuhooA5L/hWHgnBH/CNafz/0yrOm+C3gGeXzG0IKcAYS4lQcD0DAV31FAHnb/A/wA0bqNGdCy4DLdy5X3GWI/PNYF5+zn4ZlkU2mp6nbKBypZHyfXkCvY6KAPCZP2ebqzvDc6P4wuLd1/wBUWgIcZHPzqwx36DvVU+BfjD4fJ/svxL9tjj/eKPtRO5vTEgwT9Tivf8DOeKMUAeCN8Qvi34dDLrXhVbtUAXzFtiQWPOS0ZKn8OlWov2iGt2iGq+Ebu3TJSSRLjJ3gAkBWQdyOM8A969xx+NQz2dvdRPFcQRSxOCGSRAysD1yD1oA870n46+CNSUfaLyfT5DtG25hbGT/tLkYHqcV3mm61pmsxebpt/a3iYDEwTK+AfXB4rl9V+EfgfV5mmn0OKKUgjdbO0OM98KQOPcVwerfAW7029F74M8QzWcigZS4kKtnH99R3PYjvQB7luFKDkV8/f8JV8YPA8jLrOltrFoAFWUxBxweu+Pn/AL65rr/D/wAePCmpxrHqhm0i6B2uk6M6A+m9Rx+IFAHqVFVLHUrPU7ZbmxuobmFukkMgZTxnGR3xz+NWs8ZxQAtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABTJJUiRpJGCooyzMcAD60SSLEjO7BVUZZicAD1NeA+M/Gmq/FDXv+EN8Fhjp7HF1djgSqDySe0Y/Nj9cUAQeMfE+tfFvxKfCnhIldHi+a4mdMKxGfmZhn5M8Adz+FeweCfA+meCNDWwsRvmcA3Nyy/NMw7n0A7DoKd4J8Fad4I8Ppptjl5GO+edussnrjsPQe1dNQAgGBjOaWiigAooooAKKKKACiiigAooooAKKKKACiiigApNozmlooATbz1rltf+HPhTxKGbUtGtjMw/18K+VJn13Lgn8c11VFAHhF/wDBzxJ4Rum1PwF4gm3x/P8AZJmALkdF/uPwTwwHT34taH8c5tOvRpfjfRZtPuUHzTxIcE9OYzyB1OQT0r2wjNZOveF9F8T2f2XWdPgu4wDtLr8yZ6lWHKnp0PagCfR9a07XdNiv9KvIru1kHyyRtkZ9D3B9jzV8HIz2rwvUPhV4o8D6m2r/AA+1R3iUFnsp2BZsA/LjG1/QZwfStvwd8a7G/uRo/im3bR9XRjG7SArEzDPXJyh46Hj35xQB61RTElSSNZI2V0YAqynIIPQg08HIoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACmSSpEjPIwRFGWZjgAepNNnuIrWCSeeRY4o1Lu7HAVQMkn6DmvBfGnjDV/ihrh8IeDFY6Zu23d6MhZAO5btGMHHdj+FAEnjfxlf8AxO1iHwb4JMj2jEm+uvuowB9eoQY/4ESB9fVPBPgfTPA+hrYWA3TuAbm6Iw8zjufQDsO1N8DeBtN8D6L9isWaWaTDT3DqA0jY/QdcDtXUKMKBnNAABgYpaKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBpXJzmuR8bfDrRPG9l5d9H5N4gJivIlG9Tjv/eHOcfyrsKTFAHzlZeK/Gnwd1I6b4gtZ9T0MuUtpJGP3QeDG3ODj+A//Xr3Pw54r0bxVpq3uj3iXMfG9Bw8Z9GXqP644zWhqOm2erWMtlf20VxbSjDxSLkMK8M8S/CbW/BesR+I/h9NPJ5T7jZkhnQdwMn51PTaRn60Ae+g5GaWvMfAPxfs/E95/Y+tW39l65uKrA+QkhHYZ5Df7J9OPSvTd3FAC0UCigAooooAKKKKACiiigAopC2O1Ju744oAdRTd/t3pwORkUAFFIWx1oByAaAFopCcdqM+1AC0UmaM+1AC0UUUAFITg4pawfGGjXuv+GbzTdO1GTTrqYL5dzGWBUgg9Rzg4xQBvUV8//wDCnPiP/wBDz/5PXH+FSQ/Br4hNKBP48dI88tHdTuR+Bx/OgD3yjPNeHRfBfxgzHzfiLfoMAqVMxJPfP7wY/X8KqyfB74iAvHD47Z4N2UaS6nViOxI5wfbJoA97pNwrw61+C3jJ4t138RbyKbP3YWlkXH1Mi/yqve/A/wAWy200KeO5rlZDlo5zKEfpy3zHnr2PQevAB7zu4B/lRu/wr5q1f4b+Ofh1bjxFo2tyXrQqDdC3Dgqi/wB5TkOgUD6fQZr0fwV8TYviDo0+m21wul+JEg48yMSKT3kRSRuA6kHGPegD07NGea4AeF/iKf8Amo0X46JD/jT4/DHj8b/N+IasdvybdGhGG9TzyMZ44oA7vdxS7uM9qqWEF3b6VBBd3gubtIgslwIwnmPjlto4GT2rz4/D/wAcTXQkuPiXeeXuJZYbMRnnPA+cgfkaAPTNw/GkLc9M/jXnFp8OvFCxOL34kazI+flMEYQY9wS3P5V2+jaddabpaWl5qk+oTL/y8zIquR2zgY4oA0N3tS5rz2Twf49muYmk+Iz+VG+4KmlRKSPQ4OD+INSv8Ptdd2c/ETXwWOSFEYH4ADigDvSfQUm/HUH61l6Do9zpGlizu9Wu9Tl3lvtN1gvz0HHHFc3e+CPEc5mMHj/VYvNYZHkRfKu7cQMAEHHGR+vSgDuQc0FsDgZrgP8AhXmudviJ4gH4p/hXReG/D15oUVwt54g1HV3lYEPeFT5YAPCgDjOefoKANwNkZ/rSg5rldX8O+JLi5ubjSvGNxY+YR5cMljDNHGB25AJ6nv6elZX/AAi3xFx/yUaL/wAEsP8AjQB3+aN1cz4d0bxTp95LJrvipNXgZNqRDT0g2t65U8/Squs6B41vNUmn0zxpDp9mx/d239lRylRjuzHJoA7HNIWAOK4AeFviKP8Amo0P/gkh/wAa6Hw3pWv6dDcjXvEI1iSQjynWzS38oDOR8vXOe/pQBuhs0u7muLTwX4gSGaIePdWKykklreAsM+h25HTtVj/hGvE4cY8dXmzGCDp9tknjnOygDq93OO+KA2QD681l6LpV/p0c41DW7nVHlcMrTRRxiPjGFCAda5xvBPiOGeeez8f6ssr52LPBFKi5/wBkgDj8KAO4z7UgbPauUTw14oMYEvju8L9ymn2wH4fJkfnVvTfDmo2Og3enTeJdQu7icsY72VU82HIA+XjHqefWgDocnHvS1wcvw+1hm/dfEDxDGvPG5D347VH/AMK813/ooviH80/woA7/ADzijdWH4b0C80O3nivNfv8AV2lbIe825QY6DA/n+nfJvvBeuXl89wnjvWYVIIWOOOEKoPsFAz749KAOyzTZJUijaR2VUQEsxOAAOprgrjwFqsab/wDhYPiCCOOP52Z0xwOW6cCvMdU1/VviBe2fgDw1qd7e2sLSfbtWnbm5TOcsBjCDkD+98vSgDU8TeJdZ+LXiWXwl4TkaHRITtvb4ZKyrwcngEDIIC5+bvx09c8K+FdM8H6JFpelw7I1O6SRvvzP3Zj3P/wCrgDFcp4Z+D2n+GYJhp/iHW4XuCDI9vOkYcDO3I2npk/ma2ZfAtyzxtF4x8RoFbMgNyjbx6fc4/wD10AdcCABxxilzWP4g0OfW7FYLbWb/AEuVX3CazYBj7HIORWDL8OXuojFeeMPE0sWVZVS8WPBHuFoA7bd14oBzXAx/CewidHXxN4pDKQQf7TJ5/KuivvC8V/4ch0V9U1SKKIIPtMNzsnfb/ecDnPegDb3jOMdaA2fx75rh/wDhXV1bW4g0zxr4jtUJy/mXCzEntgsMimP8P9ckkLt8QtfGTkhfLUfQccUAd5u5xRn2rF1jQrvU9OtbO312/sDCymSe3K+ZKAMEEkcZ61lt4C3TJKfFfibeilQReqOD/wAAoA67OaN3NcofAzF1Y+K/E2V6f6av/wARW3baSbfR/wCz21C+m+Vl+0yzZm5JOdwA5GeOOwoA0AcijNcr/wAIQ/8A0Nnib/wNX/4iqs3w3guJ2mk8UeKC7p5ZP9o4yvpgL/8AXoA7TcM4pC2KytE8Pw6Do4063vb6dQSfPup/NlyfduOOMcdu9ZE3gad4XWLxf4kjdgQG+1IcH1xsoA63NIWA68fjXG3nw6i1CNY7nxT4ndVORi/C8/gorU8NeE4fDCXCQapqt6s5DEX9z52wjP3eBjOefoKAN/dx0xSFiDjFcvN4JMzSf8VR4kRXz8qXoAUHsPlqrc/De1vIis3iPxKZCynzRqTK2ACAvAAxyT0z70Adlu4zil3e351z/hzwha+GmnaDUdVvGmABN/eNNtA7KDwPrVLXfh9Z69qkl/JrOu2ckgAaOyv2ij4GM7eQOnagDrc0ZrgT8JtPJ58TeK//AAat/hWv4d8D2vhu/e7g1jWrxmQpsvr1pkHIOQOOeKAOm3deKN3OK5288Faff6xc6lc3uql51VTFFqEsUaYXb8qowxkdevNZ178NNPvZ5Jf7c8RwblVVSHVJAqYAHAOfTvmgDtN3tSBs44HPvWPoXhiy8PCb7JcX83nKiubu8kn5XPI3E4JzzjFYuo/DTTtRupLj+2vEVs0rs7rb6pIFJYk9DnAGcADHFAHZ5ppPzdO1cOPhdaA5HifxTkY/5iXoCP7voa39L8MxaVY3lsmp6pcNdMWee5uS8qkjHynjbj2FAHMfEL4VaV43ja8iIsdZAAW7VSQ4HZ1HXjjPUfpXNeAfiTd6Jqj+DPHMhgv7Z/Kt7yTJWUZwAzenox4x1rvf+FeaHj/Xawfc6xdf/HKq+KPhl4f8UaKlhcxOk8Eey2vS7STR+hLE5cezH6YoA7MN8oPBHYjvQXHPtXhNp8DfFMcEcR8eTQRxSYjSHzCqp2I+cYPbH61M3wF1yQS7vH90fOTZLmBzvXnIP73kZJ49z60Ae4bv8ijdXgn/AAoDxBpgabR/GjpcsRnEckGR3yyuT+lXZfgX4iuolS5+Id7KoIbZJFIwDDoRmXt60Ae3hgRSbucV4JJ+zjezStJJ4yZ3clmZrMkknqSfMqSH9nBlRxP4rlZiRgpa7RjvwXPPTnt70Ae7luARjn3pwORXAeAPh9qng27uZL7xTd6tBLCIo7eVWVI8HOQC7fTtXf0AeR/Giz1PVtT8L6Rpd9NbS3TXT4jY4do0V1BAIzyvGenWqvi7xVc+KfhLpEOnzNHqWuHypQBsI8lS0/B52goRxnqB3rtvE+h3+oeN/CGp20IktdOluTcncMqHi2qcHryMViaD4J1C0+JGp3F9BC/h21WR9KiIXakk+0y7VHQcMDnru46mgChomp2Vt4D+HD6nbT3ck95DDbyrcMpikKuFY4PzjHylTxg/gehuPH+oT6pq2naF4WutTm0qQpcu9wkMZO3OEOCWY9hgfWsCz8MeJo/CngW1lstl1pesJNdRxTKPKtwXGSd2D8pAIGepFdX4W0K70jxN4qupk/0fULyO4gkyPmXyxkYzng8c0AZWreK/D3iDwDp2uX1hdz2FxexItujlJI5hIVGSGHAYHvg1e1fxrqVp43XwvpXh9dQuDZC8aV7zyVVdxXB+Ru4/WuZHgPW4fhNYaCyRSaha6mty0ayAhk+0FsAnuFOfwNddF4fvl+Kk/iJvL+wyaOtmCG+bzBLuPHpigDmZfib4hk0O81u18IbLHTZjHqBmvAWyjYkEYC/Njj5vY8cV1GveItQ0yC5uIrSzhsYrVJkvL25CJLIWOYdo5DYA59SBisq08I6ungjxbolxNC0upXN69kQ/yokwJUHjj5mbP1pdR8Ma6mvavqNibC5XUdNhs0W7dgbcq2GxgHKkMzfUCgBb34hNa+F9D8VLprvol2B9udWy9mGwFYAfeUNkHp245rY8L+IbrxMbvUYrZYtFZgunzMGElwo+85U9FJ6dyOcVzlv4F1S78DeHPCt/dRw2VuoOqCI7jMqtlI1JH3SeSf8AZx3rovC2gXfhqS+05JopNFEnmafGM+ZBuOXQ9toJ+XuAcZoA6UdBS0g6CloAKTANLRQAYpCCR1paKAE280YpaKAExQRnvS0UANZA4KsAQRggjqK8a+IXwbE0413wUP7P1SJvMeCFzGsh/vIR9xvYYB9uc+z0mOc5oA8Y+Hvxi864Hh7xkosdTj2xJcSIVErdMOMfK3Tnoc9q9mB5x+lcR8QfhlpPjm0MjBbTVlAEN6q5PGcKw4yOT7j1ry7SfHHiz4T63D4d8Xxy32ltjyZs72WP+9G38QBP3T06ccUAfRI5FGKz9G1zTdf0+O/0q8iu7aTo8Z6exB5B9iM1og5FACYoxS0UAFFFFABRRRQAUUUUAFGKKKACjFFFABijHNFFABRRRQAUUUUAFFFFABRRRQAVDdXUFlbyXFzKkMESl3kdsKoAySTRdXUNlbyXFzIkUESl5JHbAUDqT7V8/eJPEGs/GXxQ3hrw2Wh8OwMGuLkgqHA/jfOD1+6vXPJ9gCLxR4j174y+IH8O+FEeLQ4GDTTvlFkx0dzjO3+6vU9centHgzwZp3gzw/BptmqPKF/f3OwB5mySSe+OcAdhU/hTwppnhHRItN0yLai8ySMPnlbuzH1rcAwAKAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApCKWigBMe9AGBS0UAJigClooAMUUUUAGKKKKAEK5OaQr706igBNtJt49O/HFOooAaV9/0pdvGM5paKAG7felx70tFADdp9aXHqaWigAooooAKKKKACiiigAooooAKKKKACiiigArP1jRbDXtMuNO1K3We1nQo6MP1Hoff2rQooA+eNd+Gnif4b6p/b3ge7mu7OIb5YGILqByQyDAdcdwM+3euw8D/ABx0XxC0NhrCDS9RYBdzt+5lbvhv4SfQ/nXq2Oa868c/B7QPF/m3USLp2qMOLmFcKx/20HX68GgD0TcMZpwORXzZBrvxE+D1wLPVbZ9S0JWG13JePb22ydUPba3Ht3r2bwl8RvDfjCGJdOvkW8ZSWs5iFmXHX5e/1XIoA62ikJx2pQcigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACo5JkiV3kYKiLuZmOAB7+lRX+oWml2Ut5f3MVtbRDLyysFVR7k18/wDiHxFrfxo8Tf8ACN+Gd9v4fgYNPckEBwP439v7qdzyfYAl8V+KdV+LfipfCXhaR4NJgdvtV0snyzx5VS5HHyjnC5+bP5ezeFPCemeENCi0vTIdiLzJI3Lyt3Zj3P6CmeEvBuj+DdKSy0m3CEgedOwzJMw7sfxPHQdq6BRtUAdqAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoxRRQBBdWdve27291DHNBIMPHKodWHoQeK8g8XfAayvJ1v/Cd1/ZN4r7jEzN5ecjlSOUI56Z9OK9mpCM96APng/ED4ifDC6t7HxZZJqVk3Mcrt8zjvtlHUjP8AECa9D8OfGrwdr7RwG8k0+5chVjvU2Ak5/jGVHTuR1rv5raK4jaOaNJI2BDK6ggg9QR6V594h+Cfg/XF3Q2jabcc4ksztBJ9VPHftigD0OKeOeJZYnWSNxlWRgQw9QR2p+a+fJvhp8SfA07P4P1yS9swAywiQIc5PHluShx6/pS2/xt8Y+H2ki8U+Ft+3ClwjWxDEDGSQwJ79qAPoOivLdH+Png3UUH217rTJMZInhLrn0ymf5Cu60rxVoOuBf7L1eyuixwFjmBbOM4x16UAbFFN3exp2aACikzS0AFFFFABRRRQAUUUUAFQXV3BZW0tzcypDBEpeSSRsKoHcmpJZUhjeSRgqIpZmJwAAMk188+IvEesfGjxSPDHhxmttBgbfPOwIEij/AJaOODtz91e5wTjsAQ6lqOtfHPxg+k6ZL9i8OWTb97AkY6B3Axljzhe2Tz3r3Xw54W0nwrpI07SLYQQZ3MSSzO3csTyTTPCvhPS/CGhxaZpcW2NRl5GALyt3Zj3J/wD1YrdHFAABgYooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAQrn/9VNeJJFKuqsp7MMin0UAcdq/ws8Fa1Isl3oNsrj+K3zAT9dhGa4jVv2ddEmLPo+r3li+OFlUTKP5Hpx1r2ikIzQB4AfBHxd8HAyaBr39po/yeWJg+1R0O2b5Rx6GnQfEb4uaUrNqfhF7qKFdrubKRCSO+VOD+AxXvu3PXmjaBQB4HB+0LqVjMI9d8JtFvIK+XI0bbe52sp3fpXS2v7Qng2aINPFqNu391oA36qTXqrwpIRuVTjpkVg3/gTwpqYH2zw/p0hzu3fZ1Uk+pI5NAHJw/HrwNLKqNc3kQP8clscD8s1pj4yeATGz/8JDGAvJBt5QT9Bsyfwp958IPAl6io/h+CMKc/uHeM/wDjpFU/+FH/AA//AOgK/wD4Fzf/ABdAHQWnj/wlfMi23iPTHZwCF+0qDz0yCcitD/hItE/6DGn/APgSn+NedS/s8+DX8wxz6pEWztxOpC+nVe1QN+zr4VJk23+qLlsp+8T5Rtxj7vPzc/pQB6SnijQZGKprWnFh1H2pPUj19QacfEeiAEjV9PPGeLlOf1ry+P8AZz8Nqq79V1NiIyCQUGWzw3Tt6d6Y37OPh8whV1nUQ4IyxCEYxjGMeuT+NAGJ4w8U6v8AF3W/+EV8Ghzo0eDd3ToQkhzkMxxuVQV4HGT+FeveDvBOk+C9IWy0yEK7gG4mOd8rgckk8geg7ZpfB3gvS/BWjLp+nJuY8zXDKA8zZJBYj0zj6V0QGBigBRwKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApM0FgDzwPWvGfGHx0XTPER0jw1pyas0W5ZpcsQXHJCBeuMHJ6flQB7NmlrxJ/jzqZDJH4C1ATbcgGZiBnoSPL6VHZ/Fv4h30HnWnw+lljzjcsM2P5UAe40V4r/AMLP+Jn/AETe4/78zf4VTuPjJ49tJzBceAnjlC7yjRTZ29c9PY0Ae7UV4Gnxw8aSOqJ4J3MxwAIpuvbtUsXxn8d3FytvD4Dd5mGVQRTZIxn09KAPds0teHp8TPikLiaST4ezNC23Yn2aYFMdee+fpUifFL4luoZfhxOR6+TN/hQB7ZRXiv8Aws/4l5/5JxcZ/wCuM3+Fafhj44aXeXB03xTavoWqI21hKCIj6DJ5U4x97jvmgD1eio4p4riFJoZElicBldG3KwPQgjrUgOaACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKY8ixqzOwVVGSSeAPWh5VjDM5Coo3FicACvBPGfjfWfiRr3/CI+B/M+wb9l1fIWVZB3O4dIxg/wC99OoBN48+JereKdcl8E+CYDJJI7W892jA+YuMNtI4VBzls9uMd/Qvh58OdO8C6QEXbcanMo+03eOSf7q+ij9e9WfA/wAP9I8EaYkNnGJbxlxcXbrh5T/Qeg/nXWjgUAN2DO7+I9TilAApaKACkIyaWigBMUbRx0paKAADHSjGKKKAExyT61z3ijwRoHjC3EWs2CTMn+rlUlJEPsw5x7dPauiooA8IbwV8QfhpN9p8KX7a3pKZ3afLkkL1+5nB6nlcH2roPDXx10G/aKy1+GbR9R3mOUSqfJVv948qP94DFerEZ71z3iTwN4d8VwNHq2mwyuRgTqu2VfTDjn8Dke1AG1a3ttfW0dzazxzwSLuSSJgysPUEdasV4TcfDTxv4AuZbvwFrDXdmzhmsZsBjxjkH5W69Rg103hf41aJqMg03xAj6LrCP5UsUykxl92OGHT/AIFj+tAHqFFMSVJUR42DI4yrKcgj1Bp/agAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACo5p47eJpZnSONRlndgAB7k9KV5ViVnchUUbmZjgAeprwjxf4j1L4t68fB/hPI0eKQG91A/ccDvkfwZ6D+IgdB1AKvjPxPrfxU8Uf8ACK+D3lGkQttuLpNwjlzwWcgcJ1AH8WM89vX/AAX4K03wRoY07Ttzsz+ZNPJy0rdMn04AAA9Kn8J+EtL8HaHHpmlxbUHzSSt9+Vu7MfX+VbqjaoUdhigBQMDFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFADSoJzXLeLfh54e8Zw/8AEzsx9qVSIruP5ZEJHHI+8B6HIrq6KAPAZ/DnxF+FU5l8NXUmt6Grf8ejIZGUdTlByvOeVPuRXT+GfjtoOpz/AGLXbeTRLxSF/fnMRPu2Bt59Rj3r1YjPeuZ8U/D/AMOeMYSNWsEacDCXMXySr/wLv9DkUAdFDcRXESywyLLE4BV0YMGHqCOtSKdyg14S/g/4h/DG5E/hO+fXNJOd9jKMlByfuZ9SeU5J7V0vhP426Jq8kena3G+jaqCVkS44iyP9o/dPswHPHpQB6lRUcU0c8ayROskbcqynII9jUgORmgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACms2089OpOajubqGzt5bi4kSKGJS7u7BVUAckk14Bq/i/xJ8X9ffw34XDWOhqxFzcn+NAeHY4yoOOEHJ7+wBf8AGPivU/ib4p/4QjwhdImmqA19qEb5WRBgnBH8IzjH8R9ua9Y8J+EtL8HaHHpmlxbUHMkrD55X7sxH+R2pnhPwbpHg/SI7HS7dUO0CWdlHmTH1Y/nx2roAMDFAABgYpaKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAExz1rlfFPw68NeL4WGpWCLckgi8gASYEY/ixzwMc59sV1dFAHhN34I8ffDY/aPBeqzatpuPnsJlDFADnAQnnJycphq6Dwt8cNJ1G7/svxHayaJqiP5bCUHyi+cYyeVPs3516qVzXK+Mfh9oPja1WPU7cpcR58q6hO2SPPv3Hsc/hQB1EcqyxrJGQyMMqynIIPQjHan14DBoPxO+Fqk6RMut6HE29rZF3HbyTheWX1+U+9dd4S+OPhrxA6WuobtHvWJAW5fMbHtiTGB9Gx6DNAHqFFMWVXQSIwZGAYMDwQe/0p4ORmgAooooAKKKKACiiigAooooAKKQnB6UZ9v1oAWikByM0tABRRRQAUUUUAFFISAaWgAooooAKaWxTq5jx5oGq+JPDb2GjavLpd55qus0bsu4DqpKnIHf8KAOmLUhfb1FeJn4J+KnDZ+JF+Q5BYYlOcdM/veegpZPgl4pmRUm+I9/IqsGCuspAIxg/wCt6jA/KgD2veOPelByK8PufgZ4kvEK3XxDvJweoljkYHv3l9ean/4Uz4v/AOim6l/5G/8AjtAHtBbHWkaREQuzAIBksTwBXh918Bdc1DB1Dx7dXTIMRtNE77OQTjMh9KYP2dG+xhH8Vzm4ydx+znYVIPGN+fTv60Ae67uOmfpSb+M4r57m8N/FD4XSfatFv5Nb0pBlosM6gdTmIkkc55U1tWPxg0zxjYLpd7qt14S1MOu65UK6MR1UMw+Xn1HHrQB7XmjdzXn0HgXW5bZXj+I2tyKwDRyIIypGO3HI96ki8A+IY3DH4ha0/GCGijOf0/zxQB3uaM4rO1zTLnVdIms7TU7jTZ3Klbq3ALpggnGfUZH41yqeANcEUof4g68zsBsYCMbefTHNAHd5o3VwH/CvvEB6/EXXffCR/wCFdpb2UkGlx2jXs0sqRCM3L48xmxjf0xmgC3kGjPOK4D/hX3iH/oouu/8AfEf+FOvvhncagI/P8beJsoGGUuwmcrgfdA6Nz+nvQB3u4Yz/ADozkZrH8O6DJoFg9o+rX2pKZCyPeuHdEwAFzjnGOvesnVfBepXsry2fjTXrNncsVDxsgB7AbRgUAddmjd/nNcEvw/18E7/iHrrDBxhYxg9j0rpdB0KfRoHS41rUNTkcLue8dTgjOSoAGM5756CgDYzg4ozXN3Ph/XnmZ7TxheW6MSSjWdu4HPGPkGMDH161F/wjvif/AKHe5/8ABdb/APxNAHUk4oz04rJ0fTNUsXmbUdem1PeAED28cQT1+4Bmsq80Pxbca5cXEHjAWumscxWsemxM0fHTe2c857UAdXnnpRu/H6VwZ8NfEEs+PH8GCfkH9jxZAz3561taXoviC11BZ7/xVLfWwzm3ayhjDcY5ZRnrz+FAHRZ9qTdx0rl/Efh/xFqt+r6X4rk0u08tleBLSNzuIwGDHkf56Vlt4T8cLLvi+ID7RCIwr6bERnnk+/Tnrx15oA73NG72rl9A8Maxpmpi91LxXfaoph8s20kSJFu4+YAd+P1qbXtH8R30rS6N4obTQVAWJrKKZQe5ycHke9AHRFsCk3c9O+K4tPDnjbY2/wAefPuBXbpUGMZ5BHfjirOieEdW03V0vr3xfqmoxKGH2SVUSIkgjkKO2f0FAHV7valzWVrOm6pfmA6drsumBM+YEto5fM6Y++DjGD09ay/+Ed8T/wDQ73P/AILrf/4mgDqd3OKTd7Gud0/QNcttWgvL3xXdXsMQZWtmtIo0cEdyoByDg1P4j0LUdaigjsPEN3pAQkubaNGMnpywyAOenrQBubqrX2oWumWM17ezJBbQIXlkfooHU1xGseGdZtLW51C++IupW1vFFuldbaFFVRyTgDr/AJ714/pdn4r+KHiO70aDxJqF54bt58S3k3yq0YPGVGMs2OB+dAG9f6zrvxw15tI0cTad4WgYfapXwfMwcgnHUnjCcgYBPSva/D/h3SvC+lRadpNqsEKAAnHzyH+8x7n61lr4FtbPw7baPoWpX2iw24OGsym6Rjj5nJUlj+I6+wxDJ4N1wLJFbeOdWjhYEASQQu65xn59oPUcemaAOwyFGP60u7jPauDj8Aa8JVZ/iFrjJuyyhYxkZ5GccV2l5atd2UtuLmaAyKV86AhXT3UkHBoAsZozXHXfga/lgC2vjfxHBJn77TRuMfTYKZZ+BNUiL/bPHXiG4zjbseOPbj/gJzQB2m76UbhWZo+jSaRHKj6vqOoCQgg3ro5T6FVX9c1z154L1+61KS8Tx5q0CtJvWCOGPYg7LjHIx+dAHaA56UbhiuVPhzxOf+Z4use2n2//AMTVjw34b1HRJbh7/wAS3+riUDat0qgR4z0wKAOizRmue1rw1favqkNzF4l1TT7ZIyj21mUUOefmyVPqPXpVGTwhrqxywWvjjVY4H6ebBDJIvH98qD15oA6/PNG7PSuYsvDviG2lg87xld3EMZG6NrGAFwOxO3I+taWt6NcatFEttrN/prxtu32hT5+nDBlOR+VAGrmkLYrjbjwLqMlsqweOPEUU/GZDJGwPr8uwY/OqsfgDX1kUyfEPXXQNllCxjI9M44oA70N7flRmsHXvDt7rNzaSW3iLUdMjhJ82O02DzgcdSQcHj9elZx8D3mwAeNPEm7B5M8ZHtxsoA67d/nPf0pc1x2keDNa07VILu58b6vfQxElreZE2ScEYPH41va7ov9uae1n/AGlf2CufmksZBHIRgjG4g8c0AaRbApd2f/11wsPwvgt1lWPxb4sAlQo+dSydvoMrx9RzUieAdSjdFXx14i8hSAEMiE7R23beuOM0Adru4zijd7VQOlOdF/s4anfK/lhPtgdfP+uduM/hXLr8PtQOoLPL468RvCgISNZUVgT3LbcHp3FAHcZozXIf8IPe4hx408R5X/WHz4/n4/3OOcHvW1aaEbPRJNMGq6lKX3f6XLMGnG70bGBjtxQBq59OnrTScZ4z3rkLr4fm9h8qfxd4oK5z8l6ifqEzVM/DF4gps/GfieKSMlomkvBLtY8MSCvzcYAB6UAd4eOa5DxX8NPDPjBGa+sRDe7QFvLfCSjHAyf4vT5gfwroItMlTQl019SvHlEPlG93ATE4+/nGM/hWL/whU/8A0N/iX/wKj/8AjdAHlreAvH3wyvXv/CF+dX08sGlsyvzMB2KHIPHdTn2r0Pwf8VPD3ilobA3P2PWCAslncKYz5n8SqT97nPGc+1Nn+F1vcTNLJ4s8Wb2bcSup7f0C4HQVneJ/groev2SPFPJaaug51BUG6Y+sijCk9yRgk896APTAcgHHWlrxOP4K+LIo1jj+JWopGgCqiiUBQOgA82nf8KY8X/8ARTdS/wDI3/x2gD2qkzzXhN78HviBHIosviFcTKR8xnup4iD6ABmzUtv8GfGs1qBe/EW8jkbIeOOSaRPzLrnj2oA9xzRu5rwN/wBnbUpGLP4zLMe5tWJ/9GVJa/s/a1YzedaeOpYJcEb4rd1OD1GRJQB7uGyMgcU4HIrifh34HvvBGn3dpea7LqizSB4wyFRH1zjLE8k5612oGBQBznj7VX0XwHreoRXBt5obRzDKoyVkIwmOP7xA/GsnUvF9vbfDOfUrbWbWfUE0ozJIXUM8nl5zsB4JPOO1bPjm0nv/AANr1rbQNPPLYzJHEqkl2KHAA7k9qxIfA2gD4fpbp4ctWuv7MCjzrNPtBk8v+IgZ35689aAJdL8bJp/hHw1Lq8dzd6nqVqrLFYwmd5CEBZsL9Rn3NaH/AAn2gnwjceJhNMdPtmMc48oiSNwwUqyHkEFhx7159aQa5p3hvwZp17p+tDSFspBfR6bG4nWUH5Q5XDKh9iCT9Kjs/DWoQfCrxHaXGhX7THXDdwWUq+bNJF5kR9TvO0EE5OcGgDtj8U/D0bxRXUOqWs88YktoZrCQPcqf+eYAOf0qZ/iX4ej0G41Z2uljtbkWlxbtbsJ4pScBWTqM1U8UaddXfj3wNeW9lM9taS3RndYyVhDQgDdj7uSMc1zHjzTL/wAjxndCzcRLe6bc2btwtxIojTYM4GMnk5/lQB3Nh43trrXLfSb3TL/S7i8RpLP7YEAuFXk42sSGA52tg4/KmWPj/T9Ru9SMFpd/2XprOlzqrBRbqyAFgOdxx6hcd+hrJmXXPEni/wAN3T6Bc6ZaaXJLPcSXbQsXLR7FCFGZu5yDgcDPIGOb8N/D+Tw+PEumXHhq4vPtbXAtr5bwCOaB1wInwwIPqdp5wewoA6vw7fXNz8V/GFs11NJaxW9i0URkLIm6MklR0Gfau7FcdoehXenfEfxJqbw7bK+tbNYX3DG5FZWXrn05IHWuxoAKKKKACkIzS0UAFFFFABRRRQAUmKWigBMVxni34XeGPF6vJd2Ytr0jAvLbCSA++OG/EGu0oxQB87yeFfiT8KZXuPD122r6OPmeEKXAHvFnI+q/p0ruPBfxs0HxCEs9W26Pqe7b5c7fu3Ps5AAOcjB5+teoYrifF3ws8M+MMzXVsbW97XdqFRzwQN3GG69xngc0AdorhxuUgjsQetOr58k0H4kfCi5W40a5k17REGPswDyBF5JzHklOh5U49fSuy8KfHLw7rs8djqMcuk3xOzE3zRFs4wHHT/gQFAHqNFNWRXUMhDKRwQc5p1ABRRRQAUUUUAFFFFABRRRQAUUUUAJiloooAKMUUUAFFFFABiiiigAoopM+1ABn2rO1zXdP8OaTPqep3CwWsK5Zz3PYAdST0AFGua5p3h7SZ9S1S4SC1hHzMx5PoAO5PYV4ba2GvfHHxFHqV+JNP8JWcn7iLH+twRlRyPnIzlui9BnrQBZj1LxD8ctTe0jjl0jwfbSBp2U/vJyMYXd0J74HC55zxXs3h7w9p3hnRYNL0u3EFtEOnUs3dmPcn1qfStJstF02DT9OgWC0gXbHGg4H+J7596vAYGKAEAwAM596WiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAQj3oxS0UAFFFFABRRRQAhXmjb6nmlooAbt5oC+/brTqKAG7arahplrqtk9neRCWByCy9M4IYcj3Aq3RQA3bznNAX1PPrTqKAG7fenAYFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRiiigBNvoa4zxd8L/DPjBXlvLMW98QALy3+WT23dm/Gu0oxQB8+yaB8SfhVObrR7t9e0SIHdbsWcKnU/u8kr35T8a7bwf8bfDXiQxWt6/9lag52iO4ceW57bZOnPocHPHNellc1w/jP4V+HPGKtLcQG0vuCLu2UK7f7wx8/wCPPvQB2+75c+1OByM189/Y/iR8IZJZbRv7d8PqSSpZnWNc9SM7kPrjK813HhL42eG/ELJaagx0jUSdhiuWHls3s/T8Djn1oA9MopqyKyB1IKkZBB4I9acDkUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFJnnFABmsfxJ4m0rwrpMmpavciGBeAOryHsqjuf89KqeMPGujeCtLa91Sf5zgRW0ZBllOeignp156cV5HovhfWvjNrA8SeJ5JbPQUbFlZoceYmeQp9Djlup7dBQA210/Xvjf4ij1PUUey8I2c2IoCxUzY6hcdWOOT0XOBk171Z2dvY2cNraQxw28KBI441wqqOwosrK2sLKG0s4UgtoVCxRRjCqo6ACrA4FAABgdc0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFIRmlooAaUBznoeorh/F/wo8L+LiZp7U2V4Mn7TZgIzE85YYw3PPr713VIRmgDwLyPiZ8J2P2Vjr/AIejJwhy/loOnH3k49MrXe+DfjB4a8WvHaGU6dqTkKLW5ON7HsjdG/Q+1egba8+8Y/CDw34s33Cw/wBnaiQ224tVChmPQuv8XP0PvQB6Bu9qcOR0xXgKN8UvhYiRsg8Q6FApxsy4Qe5xvXGAe6816D4L+LPh3xhGkCzLY6keDZ3LhST/ALJ4DD9fagDvaKbup1ABRRRQAUUUUAFFFFABRRSE89KAAnB6VzPjbxvpvgjQm1C+zJIx2wWysA8rcdPYZyT2+uAYfHXj/SPAumLcX5M1zNkQWkZG+U+vso4yf515t4G8F6x4/wBaj8ZePN8sARXsbR1ARxzyU7KMA4x82cn0IA3wx4G1T4mawvjDxs7paOQbXTwcboh0B9Ez+Le1e6RQpFEscSrHGoCqiDAUDsB2pyqFAA4A7DpTqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApMUtFADdvoa898Z/B/w94sd7uFTpmp44uLZQFY9cunQn3GD716JSYoA8BPijx38IJIdO1y2TXNEB/dXmW3KpONvmHhf91h9Ditr/AIaP8LjrpOsf98Rf/F17E8ayKVcBlPUGmfZLb/n3i/74FAHkP/DR/hjGf7J1j/viL/4uj/ho/wAL/wDQJ1j/AL4j/wDi69WvNF0vUIfJvNNs7mLOdk0CuufoRVL/AIQ3wv8A9C3o/wD4Axf/ABNAHnP/AA0Z4W8oMNM1bdkgr5cfAxwfv9/6U3/ho7wv20nWP++I/wD4uvRv+EL8Lk5/4RvR/wDwBi/+Jq9DoumW7q0On2kbJGIlKQKuE/ujA6e3SgDy+T9orwmkQZbDVXbjKiNOOPd6Q/tF+FRCr/2dq24n7hjjyBzz9/2H516bL4c0SaeSeXR9PklkxvdrVCzYGBkkc8cVW/4QvwuM48N6OM9f9Ai5/wDHaAPPbn9orwpDOyRafqs0Y6SLGgB4yeC4Peq11+0V4d/s64ktdN1E3YXEUU6oqs3PJIY4A49znpXpv/CH+GdoT/hHtJ2jJA+xR8Z6/wANEfg/w1FIskfh/SUkUhlZbKMEEdDnFAHj3gLwDqPjfWj428cEzLKQ9raScBx/CSp6R+i9+/v7wqAAY4A6D0pQuOnSnUAAGBiiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCaAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCcUALSZrlfFPxH8M+Dy8Wqagn2pV3C1h+eU+mQPu5zxkjNeU618eNY12cWPgrQ5hK52+ZNH5shyBjai8A57kmgD3ya4jt4mlmdY416u7YA/GuN1P4u+BtL3CTXre4dQDttczZBOOCoI/DOa8otPhN8QfGs63Pi/WZLWHrsnl85+wIVAdq52g9a7/Q/gP4O0rbJdR3OpS4GftMmEzz/AArj17k0AZWp/tGeHLYsunaXqF6QRhn2xIRjnk5PH0rMH7Q9zK32qLwfcNYKpEjicnB/3tmBXr9l4T8Paa6vZaJp1u6rsDxWqK2PQnGTWmLeJUKCNAh6qF4P4UAeGJ+0nEqAyeFpeclSLwAEZxn7la+mftFeGbpymoafqFiecNtEq9uODnOc9u1etGytjgG3iIHQbBxWFqPgDwlqkMkd14e00+Ycu8dusbk887lwe/rQBDpHxJ8Ia5tWx16zMjcCKZ/KfOM4w+M/hmupDAgEdDXket/s+eF71UOlT3Wluud2HMysPoxyPwNcofhv8UPBcn2jw5rZvolYkQxTEA9OTE/y557E9KAPofdS14TpHxx1fQ7k2PjrQJ7eUYAmgiMbDgfeRjg8HOQe/Ar2bSdc0zXLNbvS72C7gYZDQuGx7Edj7GgDQopN2R0paACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApM0E815P4++NNr4c1KTRNEsxqWqKNrsG/dwydAuAMu3t68UAeia74i0rw3p73urXkVrAoJBdsFyOyjufYV4rf/Ejxr8SLqbTfA2lzWVjgLJdvgSLz1L52pkY4GT707w/8J/EPjbUF1z4h312inmOz3gPj+7/ANMx7AZ+h5r2/S9I0/RdPjsdNtIrW2jGFjiXAHv9ffrQB5R4Y+Amn21wuo+Kb+XVb0tvaIN+6J5zuJ+Z+SD26d69U0rQtM0OzS00qxgs4EGAsKBfzPc/XNaGMUtACbeaWiigAooooAKKKKAExzQVB60tFAGbrOgaV4hsmtNWsYLyEggCVAxXIxlT1U+45rxLX/gtr3hq/Or+AdUn8xSW+zmXZIozkAN0cezfrXv9IVzQB4p4X+OD2dx/ZPjywl029TC/aFiYKeoy6nkfUZHXpXslpe299bR3NpNHPBIMpJGwZWHsRWN4m8E6D4utvJ1iwSVwMJcJ8ssf+63UfTpXjN34X8cfB24fUPDlw2raGfmnt2jJA6/fQHjA/iHtmgD6HHI6YorjPAPxF0vx1pYktv3F/Eo+02jHmM+oPcHt+uK7IH2oAWigciigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCcUABOKoa1ren+H9Kn1PU7lLe1hGWdj1PYAdyewrnvHXxF0fwLp5lu5FnvmAMFjG+JHz3P8AdX1J/nxXlGj+FvFHxh12LXvFDSWfh4EmG3jYqGXAwIwexxy319sABrPj7xV8VtRm8P8Ag2zks9PD/vboOVdo+gMjD7q9eBnNelfD34W6X4Ht/tLN9r1iVAJrpxkL7IOw6c9Tjt0rrNH0LTNBsY7PS7OG1gjUIFjTGQPU9Sfc1pUAIAAKWiigAooooAKKKKACiiigAooooAKKKKACiiigAppQHOQCCMEEcGnUUAeOeO/g35t4Nf8ABUv9m6tEwk+zxt5cblRkeXj7rZH0Ptzk8FfF+VL9PDvjm2bTtXV/LFzImxJGJI+YYwv16HrXsRXJzXJ+OPh/o/jnTmhvoxHeomLe8QfPEf6rnsffGKAOqjdXRWRgVYZUg9RT6+e9B8Va/wDCHxGnhrxa0tzoTjFtdKCwjXP3k9QM4K9Rn6Z9+t7mC6to7i2lSWCRQ6SIwZWB6EEdRQBNRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFJk56UABYA4rz74l/Eyw8E6dLbwOk+uSxg29sVyFB/jf/Z4PHU4/Govin8S4fBOnfZLIrLrdymYY2BKxqTjecenYVy/w0+F11f3cXjHxlLLeX0+JoLe4ySCeQ756npheAPyoApeAPhVqPiLVI/F3jl2uDNiWO0myXkP8JkHYYwQv0z3Fe8RQxwwpFCiJGgCqiDAUDjAHYU4DAHJz706gAHSiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACjFFFAGN4k8L6T4q0xrDWLVZ4vvI3Ro2xjcp7HmvG9F1jWvgrrsWheIne88M3Jzb3iKSIj3IHbGeV98jPSvfMVleIfD+neJtIn0vVbYT20oHHdT/eU9mHr/SgC7Y39pqNnFd2VzFcW0i7klicMrD1BFWa+fbDUtf8Agbq50/VYn1Dwpcz4guVYkx55O1c4B6krgZ5INe7abqdnq2nw31hcR3FrMu9JYzlSKALlFIDkZpaACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKQnB6UAGeeleafFP4pW3gu0bT9PMc+uTr8iHlYB/ff39BR8U/ilbeDLNtP08pPrc6fIh5EA/vP7+grlvhZ8Lbm9vF8YeMVee8mbz7e2n5O48iSQHv0wv0+gAJvhb8Nbu/u38YeNI/tV7c4ktoLkbmU5yJHHY8cDHQ/hXtqj5etKBxS0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUhHNLRQBl69oWn+ItJuNM1O3We3mTacqNyk5G5SejDPBrw60OufAvxEUu1a/8JX8xxJGdzRc4B7AOBjI6Ht7fQhHNZ2t6JYa/pVxpmpQia2nXa47joQR7g8igCbTtTtNV0+C+sJ0uLWdQ8cqHIYH/P51cr568JarqXwf8ayeFteV30PUJf8ARLgcqCSAHBJGByN46jA/H6EByKAFoo7UUAFFFFABRRRQAUUUUAFFFIWwcYoAWikByM0tABRSZ5xQDmgBaKQnFKOaACiikzQAtFFFABVa+1C00y1kur65htraMZeaaQIq/Unj0qzWB4v8Iab410X+ytTe4SDzVlDW7hWDDPqCOhI5H9KAI/8AhYHg7/oaNG/8DY/8aP8AhYHg7/oadG/8DY/8a4b/AIZ18Hnre6z/AN/4/wD43Sf8M6eDv+f3Wf8Av/H/APG6APQbXxn4YvpfKtPEGlzyY3bI7uMnHTPWrh1zSgCTqVkABnP2hf8AGvMW/Z18JbcR6hq6nI+9LGQR6fcFMj/Zz8KiKISalqzOP9YRJGA/B6DYcc89+lAHo9x4w8N2iK9zr2mxKxABe6QZyMjvVb/hYHg4D/kadG4/6fY/8a4Rf2dfCIZib/WCuflAmjGP/HOaiu/2dfCxtpBa6jqsc+35HkljZQfcbBkfjQB65a3lvfWkd1aTRz28i7kljYMrD1BFTbucYr5z8BeNNR+F2vzeEfGO+HTkyYZdpcREnhlPdDyeK9o8Q+D9D8Y/ZJtTjlmWBSYWhuXQYbHPyEZ+6KAOkzRmuAHwZ8GY/wCPW+/8D5v/AIqr1n8L/DNjNaSQx3xFpKJoY5L+Z0Vwc52lsdRQB2O7jNMWeN4w6uhU8Ahu9Z+veH7DxLpb6bqaSPauwYrHK0ZyDnqpBrkh8FvBQXaLK7Cg5A+3TYB/76oA9ALYHTP9aA2fxrgf+FM+DcY+y3v/AIHzf/FV0V74R0nUPDMPh64jmOnQoiIizurAL0+YHJ6d6ANsSBs7ecHBx2NVjqlgJzAb2280NtKeau7PpjOa4ofBnwYGLfZLzJO4/wCnTcn/AL6qS6+Dnga7YM+jBG37y0c0iknHc7s+/wBaAO63e1IsqOzqrKWQ4YA8r35qAafbjTRp5QtbeT5BRiSSmNuCevTvXHv8IPBj3puhp00bMwdkjupVQkDHK7qAOvl1SwgmaKa9to5F6o8qqR36E1YjmSWNZI2V0YZDKcg1wEvwS8CTM7PpUpLvvJ+1SZ+n3ulbnhnwF4f8IzSS6RbzRPIgQ+ZcSSDb6AMSKAOlzSb+nBrnvEPgnSfFEyvqj3zqoGIorySOPg5ztUgZ9+vvVL/hW2iHy/8AS9bxGcoP7XucIc54+fjpQB127p70u72rjR8NtNh8gWWseIbNIZBJ5cOqylH5yQysSME5JxjrXR6to8GsWot55ruFN4fda3LwPkf7SEHHtQBfzQTgZrlf+Ff6X/0EvEH/AIOrn/4uqV18JvC99N512NTuJcY8ybU53bH1L0Advu9qAcjNUrfS4LXSY9NiecQRwiBWMzGQKBj7+c5x3zmuPf4OeD5HZ5Le/d2OWY6hMST6/eoA7wuFzmgt7Vwq/CDwkkTxLDqAichmQajOASOhI3c9TWjpHgO00XWY9Qt9Z16WONdsdlcag8tuvy7futz09TQB1JbFLmsLXfCWn+IpY3vp9QUIhQJb3skKEEEElVYAkgkZ9Diuff4N+DHYt9jvBnst/MB/6FQB3ufQUbq4iy+E3hTT76C8toL1JoJBJGxvpTgg56FuRW54o8Kaf4u0k6dqL3KRbtytbylGBwRn0PXuDQBt5o3HoBn8a8/T4L+DVRVa3v3IHLG/lBPvwwH5Uv8Awprwb/z63uP+v+b/AOKoA70PkDgZPbNeefE/4m2ngvS/Is5I59YuFYRRhg3k4/jcduTwDjOD6UvxR1jSvCnw3n0+5luZXuYTbWqtO7SO4HBLk5OOpJPPSvLvhZ8H18SwDXfEySDT5VJtrcMVabP8ZPXb6ep9uoBe+Eng211e5PjTxbdxzzzStJaR3Ui/vXDENKwPXDAgD2z6V9DA56Vxh+E3gZ5IpD4ft/3SlVTe+3n1Gf8AOTW/oXhvS/DdtLb6VAYIpX8xwZGfLYAzlifQUAaYkXJGR8vXnpUL6jZRjMl3AgGOWkA6jI/SuZ1D4Y+FdU1p9WurGQ3Ujb3K3Eiqx9SoOKqwfCDwPA8zHRVlErbis0zuF9hk8CgDsoL22ulLW08UyjgmNw2PyqKTVdOikaOS/tUdThlaZQQffms7Q/Bvh/w3LLLo2mRWbyrtcxk8j8TWfc/DDwVeXUtzceHrSSeZzJI7bssxOSetAHTw3UFym+3mjmTON0bhhn8KlLfnXCz/AAe8FTSbk0yW3XH3Le6ljX64Dda0vD3w98PeF9Qa+0uC4S4ZDHukuZJOD7MSKAOn3c4xSg+1c1r3gTRfEl99r1H7a0nliPEV5LGmBu/hVgOjMPxPrWT/AMKd8G/Z/J+x3WN27f8AbZt357qAO73UZ9RXI6T8M/C2i3UNzZ2UvnwyiVJJLmRyCOnVsY9sVb8SeBdC8VzwTarBM8kClUaK4eLg9jtIzQB0eaN3OMVwI+DPgwDH2S9/8D5v/iqt6X8K/Cuj6pb6jaW10J7dt8e+8ldc+pBbBoA7Ld6ChpFUAswAzjk/hXMeIfh74e8U36X2q20z3CoI90dxJHkDPUKR61lSfBrwZK7M1necndj7dNgHOePmoA7zeCxXI3AZxnml3exrlPD/AMOfDnhjVP7R0yC4S62GPdJdSSfKfZiRVjxJ4F0LxZNBNq0EzywKVRop3i4PXO0jNAHRlgO4phnjCoxdQrkBSTjJPQCuE/4Uz4Mxj7Le4/6/5v8A4qrOnfCfwhplzHPDp0sjxlTH51zI4QqcggFqAOvmvLe3aNZ5o4jIcIJHClj6DPU1NmsLXvBnh/xNJHLrGmxXUsaFI3YkMgJzwQRiue/4Uz4MA/49L3/wPm/+KoA74tiopbuCFkSWWNGkOEV3ALH0GetcdY/Cbwnp1/Be21teLNBIJIy19MwDA55BbmtrXPBug+JLq2udW09Lma24idmYFRzxwfU5/AUAbTyKilm4UdSTgCq0Wq2E8oiivbaSRuiJKrE/hXHRfB3wbE+77FdMNpXa97KVwRg8bqn0j4TeDtD1m21Ww0147q35jJndgDt25wTjofzoA7BrmFJlhaaNZXGVjLAMw9h1NSCRSSoILDqM1z2p+BPDOs6k2o6jpMNxeMADMxYNgDAxgjHFULr4V+DrqModJ8onq8M8iN+YagDr1mRyQjKxxnAOfX/A0oO4ZxXJ6D8NPDXhrVU1LTLa4juUUoC91I4wc5BDMQepqPVfhf4W1nWJdUvbW4a5mcPJsu5FViP9kNigCx4z0LRfGGkT6Ffz2y3DjNuzOvmQy4+VlGc59u4Ned/C34kXFhdv4N8YyzQalDIUt7i7bk+kbk9D6Enn8s91J8J/BMqEPocW8rt80SPvHuG3ZB96i8U/Cnw94ss7SO++0pdWsSwpeRuPNZQAMOSMN07igDqW13SUj3tqdkE67jcLj+dU38Z+GY2mV/EGlqYADJm8j+QEgAnnjkgV56n7OnhEKQ9/rDEk8iWMcdv+WdMT9nTwuLiVpNT1ZoWwY0EkYZeOctt5z9B+NAHqQ1rSz01KzP0nX/Gqt54t8O6cE+2a5ptvvzt8y6Rd30ya8zP7OPhrz2I1bU/J3KVQlCwA+8M7ec+uOPepof2dPCaxATahq0j85ZZI1H5bD/OgDvP+E/8AB+f+Ro0f/wADY/8AGpY/G3haaCWePxHpLRQgGV1vIyEzwM88c1wy/s9eC1VAZNUYqckm4XLdeDhPcdPQe+Yv+GdvCGMfbtZ/7/x//G6APStM8QaRrRkGl6nZ3pj++LedX2/XBrSHIrifBfwu0LwLf3F7pc17LNPF5TG5kVsLkHA2qO4HXNdtQAhOO1eKeP7rUvGviHVLbw9fyw/8Inbi5+RwFlus52+vCq457jHfNey3byx2k7wRebMiFkjJxuYDIH54rzfwp8LbWPSJL7W5NRj1rUy0+oi3vpIVLOxJQhGAIGT1z1NAG/N49tLX4aR+MhbyT2/kRytErANlnCMM9Mgk/lS23jW4HiTTtJ1PQp9PTU4neymedJC7IAxRlX7pwc9TXGweEfEWi+DPEvhSzsGvLKC6gn0iR5F/fIZUd0P+7tPXHU12XiHQb/U/GXhDVIY4/s+mSXDXR342h4tq4HfmgDD1n4jTXp12x0bw5f6jY2KS211fwSIPLkCHcFRsFgDjnj15rL0Xx1P4V+H3gi1h0ebVrvVomiijSYIdykdcg5zu/SrGlaTr3g7Tdf8ADdnoFxfwX1xNPY3sc8flL5q4CybmDDbjkgHPpUmh+D9ait/hw89ssZ0VLj7ajuN0e9MKAB1/pQBqah431iLVrbRINO06DVTZG+uRfXuyKJd5UIGCncxI+nWpdI+JEWqaf4avP7NaGHWrqW0LvOuIJU3YHT5txUgYx29ap+KvCl7N46j8Q2+hafrsL6d9ja1vnRRE6uWV13KQc5we9Wk8HX954EsrK6NlZaxaTi+t/sFsixW8wZmRVXGMDO0nvyeaAEtfijp1x4g1/SZLcQnSoZJY53mGy58vO8Djgj6nofSsSb4p6vdRaTDpGi2kmoX2nm/aG5uvKAQuVVUJA3NxnFUNX+GGv3fg7w5Z2lzHFqsZmi1ScuG3x3BLTEsRlue3qxrY+Ivg7WdesbTS9M0fR73T47by4XmZoZrOQAAOrA4KYA+UAdO9AHpNnK89lBNLA0Ekkas0LkFoyRkqcEjI6cGpqpaPaTafolhZXFwbie3to4pJicmRlUAt+JGau0AFFFFABRRRQAUUUUAFJt5zS0UAcZ8Qvh/Y+O9HFvM/2e9gJe3uQoZlOOV5/hJx3HI/PzT4YePdS8L66vgXxfmEI3lW007cxHshJ6of4T2yO3T30jPpXBfEn4a2PjuwWRXFvq1uh+zzgDDeivxkr1+hOfagDvAeP8KcDmvDfhn8TLzStR/4QvxoXgvLdhDbXNxwfZHzzzkbWPUYr3AHgcUAOooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiijNACZrD8U+LNI8IaU2o6vOYozlY0UZaVsZ2qPXj6VJ4m8TaZ4T0abVNVnEUEY+VRjfI3ZVHcn/AOvXh2jaNrfxu8TLreu+ZaeG7WQiGBSQG55RPUnA3N7YHsAT+GfC2q/FvxWfFviiOaLQgT9ktWcjeoI2ovT5epJ7nNe/QwR28KQwoscSKFRFGAoHQCktbWG0tIbe3jEcMSBEReiqOABU1AABgYooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAEKgnPtijHNLRQAm3nrSbPU5p1FADdvvS4460tFADdvvS7aWigBNo4z2oK5xS0UAA4FFFFABRRRQAUUUUAFFFFABRRRQAUhXNLRQBwXxH+Gmn+OLBpU22+sRIPIuv72M4RvUHJ+n6Vx3w4+Jc+j36+B/GXmQahbOYIruZ+D02ox/Hhu4xXtuOc1518S/hVZeOIReWsiWWsRDC3BX5ZVH8MmOfoe3vQB6Lu9aUc18/+FviTrPw+1geEfHUcjQRNsivc7mRDnDE/wAaH16j8MV75DNFPAk0MiSRONyurZVh6g9xQBJRQDkZooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoopCaADNZPiLxJpfhbSn1LV7gQW6kKB1Z2PRVXqT7D0qLxN4p0vwppEupapP5caD5EHLyt2VR3J/TvXh2m6X4i+OOvnUtYkmsPDVuzCCOMfKSD91c9W55c/T6ADYoNb+PHi1LqZJLDwzp74RgOQDjIU9DI2B7KMde/0Lp2n22madb2NnEsNtbxrHHGo4UAYqLSdHsdD02DT9Nt1t7SBdqRr0HufUnqSeTmr4GBQAgGBS0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSEZpaKAOW8a+BNI8b6WbXUU2ToD9nukUeZCT6HHQkDI7/ljxvSvEnij4Kaquj+I4Jb7RJVP2ZkcEKN3VCenBOUPqK+jMVQ1rRNP8Q6XNpuqWyXFrMMMjD9QexHYigBdH1mw13S4NR024S4tZ13JIhz+B9CO47VeByM1896j4b8VfBjU5NY8OSNqugy5+02zxkiNep3gHjAzhx07+/qfgn4laH42st1pL9nvkA82zmYB1z6f3h7j9KAOyopA2Rnt60tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRSZpryLGrM5CooyWY4AHegBxPtXBfET4n6Z4GtmgULd6vIoMVoGxgf3nPYdeOpP51yXj340qJjofgpf7Q1CU+X9riXeqHj/VgffPJGen1qb4c/CWaC8PiTxmBeatM/mLbznf5TZBDMc4LcdOgzQBh+F/hr4g8d+IE8VeO2dbV/njs3YhpFwNq4/gTnkdT+Oa97t7aK2gSGCNIooxtWNECqo9ABxipAvfJGeTTulABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUANZA+c8gjBB6EV5V41+C2n6rMdV8Myro+sI/mqUYrE75znjlD7j1r1ekIyaAPDdJ+LWv8Ag3U49B+IemSArlV1CJfmdR/ER0ce649xmvYNF8Q6R4htDdaRqFveQjAYwvnYTyAw6g+xpda0DS/EWnvY6tZQ3Vu4+668r7qeoPPUc14pr3wl1/wPfHX/AIf391KY2BazJzJt9PSRfYjP1oA98zS14h4b+O0lrdrpnjfSpNOuF+U3EcTKAc4yyHkD6Z+leu6Vr2k65btPpWo2t7EmA7W8ofaTzg46H60AaVFN3etOByKACiiigAooooAKKTNIWx2oAdSbucVzPiT4g+GfCiD+1NTiWYnAt4v3kp5x91fx6+leW3vxK8beP7hrHwLos1lbEYa9mA3gdAd5+RO/TJ4ODxQB6r4u8caJ4L003Wq3I8wj91axsDLL2+Vc9B3PQV4vc+IfHHxpnOnaPaHStBD4nmVm2sMjIkbo+Ac7B/8AXrrfDvwPtTMNS8Y6nPruoMBlXlYxcepJ3P8AoMdq9XtrK2srdLe0git4EGEiiQIqj2A4oA5PwL8NdF8EWga1T7TqDj97ezKC5OOQv91fb867IKAMU4DAooABxRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAU0qGPPpinUUAZGveGNH8TWRtNYsIbuP+EuvzIfVW6qfoa8n1L4EXek3w1DwR4iuLCdDuEdw5GD7OnOME8EH617fSY560AeFP40+KngaLy/EOgLq9uFG26hBO3t8zoCP++hXQaX8ffCdwBFqEN/ptwCFdJYdwUnryvYe4B9q9U21hax4J8Na+xfVdFsrmUkEytCBIf+BjDY9s0AJpnjnwvrKqdP17T5mZSwTzwr4HqpwR+VaY1jTD/zELT/AL/r/jXnd/8AAHwTeyB4kv7Prlbe44Of98Nj8Kw7n9m3RXuHa216+ihP3UeJXI+p4z+VAHsX9qWGzf8AbrbZnbu81cZ9M5rB1j4jeEdC3C+16yEi9YYpPMk6Z+6uSOPXFecD9m3TtgQ+JL3ZnO3yFxn169a6TTfgP4JsHDy293esH3D7TOcfTChRigDG1n9oXRYiIdB0u81K4YfLvHlpn07sT7YrFW9+MPxCRBbwpoOnPx5ihoNwPfJy549MV7VpXhnRNDjCaXpNlaYABaGFVZsdMtjJPua0wuBjrQB5R4Z+Avh7TH+061PLrF0w+YSfLGCRg8A5Pfkn8M16pDbQ20CQQRpFCg2pGihVUegA4FS0UAIBj60tFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFJuwcYoAWisrVvEui6Cqtq2qWdlvUsonmClgOu0dT+Fed63+0F4V053i0+3vNTkXo0aiOM8/3m56c8KaAPWCaUGvnm//AGgfEV8d+g+GYkhLYDziSfPqPl296mHxP+LxGR4IyD0xpVx/8VQB7/nnpS184XPxv+Imm3Jj1Hw1aQNGR5kclnNG2DyBy/GfpW/o/wC0dp0s0cOt6JPadRJNBJ5gU54+UgHGPegD3CisDQPG3hzxOo/sjVra4k27jCHxIB3+Q8/pW7u5xigB1FFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSE80hYA4/WvKPHPxv0nQhNp+ggalqwYxjC5hjYHHJBBY9eF4460AekaxrumeH7Br7Vb2C0tlON8r43H0A7n2HNeLa78Zdb8T6lLo3w/wBKmkdhj7U0e6THcqp4Tk9W/Sq+j/DPxd8QtSi1vx7ez29pwUtD8ku3dnbs6Rjr155r2vQPDOj+GrFbXSLCC1jA+Yxr8z+pZupPHegDxfSPgPq2uyJqXjPX7hriUAyRI5llHsZHyAccdDXovh/4ReDfDziWHTFu7gAfvr0+ccj+IA/KD7gV3O2loAjit4oVKxRoinkhVAFPxS0UANZFcYZQwPY8isbVvCHh7XVxqejWVycY3vCN4Gc4DDkc+hrbooA8X8SfAGwaU3/hPUZ9Mvlbekcjkxg+isPmX9etY1n498d/DPUY7PxzZzX+mScJcKQzAD+444Y+obBr6AxUF3Y21/bvb3cEVxA4w0cqBlYe4PFAGN4X8a6B4vtDNo9/HKyk74WO2VOe6nn8eldBurwzxj8E7nTr1dc8A3ElrdxN5htTMVKngjym/A8Mcc4z2qz4B+M6PL/YXjXNhqMTeX9qkTy0bjGJM/cbjqcDntQB7XRTEkV0DKQwYZGD1HrTxzQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUmTnpQAE+1UdW1nT9D06XUNTuo7a0iHzySHAHoPc+1ZnjDxhpngvRJNT1F/m5WGBSN8zegz+p7V4Lptj4o+OXiZbvVJHstCtjg+UCI0XP3UzwznuT/ACAFAGj4k+I2vfFLUx4V8H2cttazPiW43ENJGOpYj7id8dTnHtXo3w7+E2leDLVLq6Ed9rLjL3DKCsZ5/wBXkZHB69T7dK6rw74U0bwtp4s9Jso7dCBvYDLSEDGWY8knH0rbAwKAECgDApRRRQAUUUUAFFFFABRRRQAUUUUAJjnOa4/x18OtG8c2JW8QQ38akW94g+aMn1/vLx0PvjB5rsaTHPWgD5z0/VfG3wWu1tNZtn1Lw2z7UZGDKgz1U/wHn7p45r3Xw74n0nxTpUeoaRdrcQt1HRkPoynkHj+vQ1fvbC21KzltLyFJ7eVSkkci5DAjFeB+Jvh/4g+F2oS+J/BF7K+nIAbi2c73Vc5IZcYdOOvUfgTQB9Cg5FFcL4C+KOi+N4Et42NrqqrmSzk4LED5ih/iH6jvXc5z0oAWiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooppbB6UABbGc1wvxI+JOn+BtMZVMdzq8oIgtc5x/tP3C/z7eorfE34n2Pgixa1tmW41uZT5MKupEXT5pBnIGDkDHP0yRxHgH4WX/ibVf8AhMPHLPM9wRNHaSjmT08xccAALhfTGfSgCt4T8Ba/8S9Xh8WeNbiQ6a7F4bQuys68YCD+CP6cnHvmvfLGwttNsobOygjt7aFQkcUYwqgdgKmRAqKq/KBxgdu2KeOlAABgYooooAKKKKACiiigAooooAKKKKACiiigAooooAKayBwQ3IPUU6igDxr4g/B4XV22veDX/s/V42MskUchjEhx1jI+4/5Dnt3rfDb4wXE99JoHjeWO0vUKpDPLF5Zds8rIOgPIwcAH+ftpXJ61xvjf4b6D43t2N7CIL5ExHexAB19m/vD2PqcYoA7EMCOKcORmvnbSvFfiz4N6kuleK7efUNGlb9zOjl9oA/5Zk+meVOMV7roXiHSvEmnJfaTeRXMDAElGBKE84Ydj7GgDUooByKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiijNABRRRQAUUmaWgAopM0ZoAWiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiikLYB9qAAnHbivJ/it8V08Mo+iaGyza5KAruo3C2B6ZHdzngds5PbMfxM+MUHh/zdG8OstzrW8I77dyQdOP9p+cY7HrzxVD4W/C3UYNafxd4vBfUZT5sEE2GZWbkyP6N6L2+vQAi+GfwqvLjUX8VeN4Wmv5HEsFvcHcwbOd8gz19F7cfSvbwMqKFBx1p1AAOKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKQjNLRQBR1TR9P1qwlsdStY7q1lGHilGQfT6H37V4fr3w28TfDzXDr/w+llmtDt8yxBLyY6lSuMOvH+8M/jXv1IRk9aAPKvBHxu0jXpo9N1yMaTqQATdM2IpHGdwyfuHI6N9M5r1RZFdA6nKkZB9RXEeL/hV4Z8YP591btaXoH/HzaBUZuONwwQ3Qde1eUrf+PvgtfJaXCtrHhzJMZwTHjGTtbkxkeh44/GgD6OByMilrhPCvxb8KeKIUVL5bG8Iwba9YRtnOOD0b8Ofau4WRWAIOVIyDngigB9FJmjNAC0UUUAFFFITigBaKKKACiiigAopksqQxtJK6oigszMcBQOpJ7Vg/wDCd+Ef+ho0X/wPi/8AiqAOhoqpYanY6rai60+7gu7csVEsEgdCR1GRkcVPJMsUbySkIiDczMQAAOpye1AElFQWl5b39rHdWc8VxbyjdHLE4ZWHqCODUu6gB1FJn2o3c4oAWiiigAooooAK5fx74rm8G+HG1WDS5tRYSiPy4zjZkE7mOD8uQB+NdRSFQevP1oA8Cb9oHXiQYvBpKFQQTI/PHPRemaYf2gvEC9fBwHbmST/4mvoAAAADoKGUN1AOORmgDwSP9oq7tv8AkJ+FHiJPy7ZyuRjn7y+uKux/tEwyIzR+Er51UZLLOCAP++favaZ7S3uSpngil29N6BsfnRHawRIVjhjRSMMFQAEf5JoA8Puf2gtQYH7F4OudwbB82Vjjj2XrVQftE6nbTI194TEUJPJ85lJ/Na9/CAEkADJycDrTJraC4AE0McoXoHUN/OgDxW1/aS0h51F3oF7FCc7njmWRh6YUgZ/MV1+hfGfwXriov9omwmc48q+Xy8H/AHuV7evpXTXfhDw3fzGa70HS55SNpeS0Rmx9cVxetfAnwZqcbm2t59NmI+V7aUkA47q2Rj8vwoA2NT+I8Wn6lPaQ+F/EmopEQPtVhZCaF8gH5XDYPXH1BrHh+NmmXF0LWDwt4oluOR5SWKs2R14D1wdz8PPiD8NZJdS8Kaob+zXlreIEuy/7UJyrY9V55PSuu8G/HTRtVUWfiNRpGopw7vxCxyB1PKnnoeBjrQB2fh3xqfEGotZnwz4h03EZk87UbLyYzggbc5PPPT2NHiHxr/wj1+lr/wAI34g1IMgfztOsvNjGSRtJyPm46V0cUsc8SSwurxuAyupyCOxB7ipcZ56UAcEPizpMSE6lo3iHTHBHyXemuCR/eG3dx2q1/wALN0XEJNhroE7bIj/ZU/zt6D5eT9K7LaMY7Uu3nNAFS51FLXTGvjb3UirH5nlRQs8p9gg5z7VxMvxWWGN5JPBHjFUQZZm0zAA9eWr0AKB06U7FAHmEHxx0Kd40TQvEXmOSFjFkCxPbGG5JPA+hzivQbPU477Sl1CO3ukRlLCKaBo5eM8FCMg8cevFXCnPWl2+9AHBN8UNshX/hCPGRGcBhpfBHr97OKt3XxK0uzVXn0nxDGmCzM+kzKEAHJOVHAOBxnqO1djt96Nhyfm/SgDF8P+LNN8Swb7IXKOEV5I57d4ygbpksMcjkYPIINY2qfFLw5o+p3Gn3i6ktxA+xwthKwz7EDkV2m0UvagDz/wD4XJ4T/wCop/4L5f8ACt3w1430bxXNPFpjXW+FQzie2eLgnHG4DNdHSY5zQBy3iH4haD4Y1EWOoteGfYHIgtZJAAfcDFZP/C5PCf8A1FP/AAXy/wCFd8F6cnj9aUDAAzQBx+j/ABM0DXdSisLCLU5JpPWwlCqPVjjge9bPiDxFF4esDdy2Go3g5xHYWzTNwCeccAYHUkCtfbzmkKZ68j0oA8zj+OGgGbyptG8QW7B9jeZZg7euSdrHgY+ta1h8V/Deo30FnbrqRmnkWNAbGQAknGSccDnrXb49zSFfQ0AVdS1KHSrCW8njneOIAlYImkc5OAAqgk81x4+JwMxQ+CvGIQEjzP7KO36/ez+ld3tB680beQe9AHBN8XfD0Mhhu7LWrS5U4ME2nSBx6ZwCORg9ehrsLrVYLTR31SVJjAkPnFVjLPtxn7o5z7Vd20m3nPegDkbb4jaXeQLPbaX4gmhfO149InYNjg4IXnnIqlJ8XvDMQy8erL8xTnTpQdwxkdOvIrvCoP8AOmOwTLFgABkknp3zQBj3fiqztvCbeJEt725sxAJxHDATKUOP4TjHByc4wATXifi/483Gt2h0rwjp15BNdgR/aJQDKCeNsarnk+ufoAeaPiH8Q9S8c61/whfgzdPazERyzQjBnIPzYbOBGO574PY16J8NvhVp/ge1a5uWjvdXm+/cbMLGM52oD05A56/SgDyz4a28HgqWbV/EnhDxLPqG7CT/ANmForZP4mySDk564z19TXv3h/xHZeJLBr3T47tbfeVDXFs0W49yNwG4Dpx6Vr7ODnHPXilxzQBzOv8AjOPQL+K0/sHXtQLAM0thYtLHGCe7cDPXgZPH0rHX4qRSxCSDwd4unUnB8vTCcEcHndjg5X6g9ua73bznNAQAADjFAHP6F4ui1y4EA0bXLGTZvJvtPeJR6jdjbn8aXxL4q/4Rv7LjQtZ1T7Ru/wCQZa+d5e3H3+RjO7j1wfSug2gUm3nOaAOB/wCFweHof3d9Y65Y3I+/b3GmyCRPTIAI5GD171bsPir4X1G7gtopb1JJ5PLXzbKVQD2ydvAPSu0AwKCM0AZ2s63baHpkl/dpcNChAIghaVuTjooJrkrj4weHLe1Wf7LrLhwTGo06QGTBwcEgDqPWu+2++frSbRx7UAeY23x08PzzpHLo3iC3Q9ZJLMED/vlif0r0TTdRi1TToL6BJlimXcomiaNgPdWAIq3gUY4oA4D/AIXJ4TH/AEFP/BfL/hSN8ZfCoHyJqrt/dXT5M/yr0EDAwKQjNAGJ4b8V6b4rs5rnTBceXC/luJ4WiIbAPRhz1rH1X4o+HdG1S4068XURcQNtcJYyMPXggYNdnj3paAOGT4raFNC8ttY65cBV3Yj0uY5+9jtjna3t8p9Ku+FfH1h4ru7i0h07VLC4gjEpjv7by9yHGGBBIwcjvXVFATmjb70Acdq3xQ8O6Lqtxp16upLcQNtcLYyMOmcggYIwRVNvi5o0iRnT9H8Q6i7sV2WumvkYGSfm2j9a74DAoxznNAHH+FviJaeK9QktLfQ9cs/LQs015abIweDtLAnBwehqTxX8Q9J8IXMNtfW2ozzSgMFtbYvhScZzwOMdAc11mKMUAedxfGjwxIVDW+rx5zkNYOdpzwOM9e30rTi+JmjTyWqRWOtM10SLfGmTfvcddvy846muw24/LHNKFx3J470Ac94h8Y2Xhy8tbSey1K6nulZoksrRpi20Ekcd+OnvWD/wtI/9CL4z/wDBX/8AZV322lA460Acdo3j46zq0Fh/wifiex84sPtF7YeVEuFJ+Zt3HTH1qXxB450jQtSXTtRstTYycB47B5I24BwGA+bqAcZx0OK6wjNIVyc5oA+dvGug+C9UR7iy8K+KdIvpJljh8jSWVJyQfuxsQP5HjpXIaPF8UdCuFstGt/EVvHKxWJJLZ0U++1wVU4H/ANevrjbxx26UoUAcUAeA/wDCa/GbQIWudT8OpdwdW3WoYoByT+5bI47txUU/7Sc3lR+R4cTzOfM8y649tuFr6CKArtIBHTBFVv7LsP8Anytv+/S/4UAeLD9pSy2Fv+EZucDgn7UuM/8AfPsaT/hpWw/6Fq5/8Cl/+Jr2sabZBdv2S3x1x5Qxn6fiaT+zLD/nytv+/S/4UAeNz/tJ6QpXyPD97JkAnfMqYOOR0NVZP2lLYsvleG5uo3brodM/7te3/wBmWGMfYrb/AL9L/hTTpdgT/wAeVt/35X/CgDxb/hpK1iCpN4YuVk2gkfaQOoz/AHaP+GlrD/oWrn/wKX/4mvbH0+zkOXtYGOMZMYNJ/Zth/wA+Vt/36X/CgDzXwX8bbPxj4lg0ZNEubVplYiUyiQAgE84HHTrXqgORUEVnbQOWht4o2PBKIFJH4VOBgYoAZJEk0bRyIrxsCrKwyGB6gjuK8h8WeE9Etvit4KtovD+lRadc/aRKiWqBZWEZOHXGCBweRXsNct4g8O3Wq+MvC2rwyQLBpUly06ux3OJIwo2gDnnrkigCvquq/wDCN+JvCnh/S7O1t7PUprhZVRAoVY49wCgYwSSPy96r6t4ju28W6x4dMcH2NPD73wcKfM3lmXBOcYwPTPvV/wAaeGrvX7WxvNKuktdZ0u4F1ZSyLlC2MFGPXYw4OOvFY+leBtYXxJrWv6zrVtdXWo6ebGOOCApHCpxyMseOAfck0Act8N/Hkuo6F4f8KeG7aOa/trfdqE90CI7eNWwSAOXY5AHQZNdB4o+IVxYeM5PD2n6jodgttZfabi51QsVLnG2NQrLzgg9+D0plt8NL3S/DWkzaRex2HinTbcRfaY2Pk3KhifLlX+JT9ODVvxB4P15fEk/iHw1LpLXd9bpDeQapGzxZUYDoQMg44x0NAFfQ/iFqV7L4Vn1C0hhstaEtq7CNkaO6QnGCxxtfHyjrW94Y1+91/wAS+I2UxnRbGdLK2IXDNMgPnZ9RkgCsjxxo08XwiurbUbm61PU7aNJI7iFMSNcbxsZQOg3EDj+HNdF4H0J/D3hDT7Kd3kuynnXUkjFmeZ/mcknknJIz7UAdEOBRQOlFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFACFc964rxh8LvDfjFHkubYWt+ckXlsqrISf73Hzjjvz7121JjmgD5qlj8bfBDWQ0Tyap4elI6hvJbjGCefLcduecd+g9s8EePNI8b6St1p7+XOnE9rIw3xH+o9x/9aukuLSC7glguYkmhlUo8cihlZT1BB6ivCPG3wav9BvZPEfgO4lgkh/e/Y43YSJjr5R6t/un6DPSgD3zNLXlXw1+Ltt4li/svX3hsNah4HmHYk46ZGejdMr+I9B6mG56UAOooHIooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApM0E1k+IvEemeGNIl1LVbhYYEHAJGZGwcKo7k4oAt6lqllo9jNfajcxWtpCu6SaVsKvIA/UgfUivnzxf4/134o62fDPgqOcacykSHGxpx3Zz/Cgx06nPvgUrm+8UfHjxGLO0T+z9EtDuOeY4sgcuf43ODgdufc1714Q8G6T4O0WLT9NhwQMyzuo8yV+7MfwHHQYGKAMn4c/Diw8B6VgbZ9VnUfarrHX/ZT0Ufr19MdxQOBRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSbeSc0tFACBec96TbTqKAEK+5oxS0UAJt96UcDFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFIRnvS0UAeZfEr4Taf4vtnv9OjitNbjywlVABcn+7J6nphuvrmuI8GfEzWvA2qjwv48guQgYeXdTEu8Knpk870zjkHjnrjFfQZGe9c14y8EaP410prPUoFEwB8i6VR5sJ9VPp0yOh/I0AdBBcw3ECTW8iTQuNySRncrD1BHBqUHIr5r0vVvE3wO8RHTdXhlvtAuGBRo2JTGeWQngMATleMnHsa+gNA8QaZ4j0mLUdJuVuLaTI3Dgqw6qwPIPsaANWikByM0tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSZoJx2rkPHvj7TPA2jvc3TLLeSAi2tFPzSN6n0UZGTQBq+JfE+l+FdIm1LVbgRQoPlQH55G/uqO5P+eK8Cih8VfHfxCJZj9g0Czf+HO2PP8Adz9+QjGe307p4Y8N6/8AGXxL/b3iW4kXR4G2ZTKh8HPlxDtz1P8AWvonSNGsdD0qDTtNt0trWFdqIn8/ck9T3oAg8OeHNN8L6NBpelQ+TbxD/gTserMe5P8AnoK1wMDFIBgdc0tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUmKWigDI8R+HbDxRodzpGpIWtrhcMVOGUg5BB9Qea+e3g8S/AfxOZIg2oaBd43kjCSqOx67HGePX8xX03iquoabZ6rYzWV/bpcWsylZIpBkMDQBk+EvGGleMdFi1DTJgcjEsLMPMibuGA/n0Oa6AdK+ePFHw18R/DrVX8S+B7ueS1XJlhAzJEmMkMOjpx0xkYH1r0L4efFnS/Gsa2cyLZauo+a3ZuJfUxk9e/HUYNAHotFNDZGad1oAKKKKACiiigAooooAKKKTPtQAtNLY7VW1DUrPSrKW9v7iK2tYlLPLK20AV4H4t+KWu+PtQfw34EtLkW8oKSzhcSSKcAn/pmvueeeo6UAdP8AEv4xQ6MZtC8MsbrWWIRpo1DpCT2H95+gx2+vFZvg34M3Wq3X9v8Aj+ea6vJW3C0aXdkdvMYfoqn056iuj+GfwjsPB8cWqahtutbZOSQGS3JzkJxnOOC35defTtvvQBFb20NtbpDBEsMKKFWOMbQo9AB0qagDFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAhGa8h+IvwYg1u4k1rwy62Or8M0QbZHKQOowMq59eh+vNev0m3JoA8H8KfGXU/D98nh/x/YzQyw4i+27P3gPHMg6EY/iX8j1r23TtVsNWso7zTruG6tpBlZYXDqfxH8utZnifwfovi7TjZavaLKv/LOVeJIjjqrduv09q8Qvfh/4/wDhldzah4QvZb6wZtzRRDe5UdA8R4bHqoz16UAfRoORmlrx/wAL/HzQ71EtPEMMmmXygK8gXdCzdD6svOeDnGOteo2Gt6VqqB9P1Kzu1LFQYJ1fJHUcHr7UAX6Kbu/L1pc+1AC0hOKqX+q6fpUHn6he21pD08yeVY1/M4HevP8AxD8cfB+jxOLO5fVLnosdqp2/i5wAPpn6UAelFgPrXmvjj4z6B4VM9nZN/aeqodvkxH93G3o7/nwMnPBxXnY134o/FSR49LjOk6TIChZMxREHsZCNzf8AAfyr0DwJ8FNF8LPDqF+51LVFXIaQfuojjnap6n3b8hQB57Y+EvHHxf1Ial4knl0zSk+aFWiKrg9o0J56feP8q9z8J+D9I8G6SlhpMG1eS8sgBkkY92YDnoPyrdC4GAcU4dKAADAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKQg5zmlooA4/xJ8MPCfigO17pUUVw5Zjc2wEUhY9WJH3j/vZryzVP2dL63cy6B4hQuM7VukaM4P+0ue3tzX0HSYoA+cU+H3xl0mbybHWp5YYl2IY9UPl7SMcK5GMZ9OCMjsa0f8AhA/jLqkCPdeK1tGVmxH9udGAJyeYlwR+PHTFe/UmKAPC7T9n661G6+1eJfFVzduSGbyQWYk9cO5PtzjtXb+HPg74O8OSrPFYG9uFGBLfES85znbgKCMDkCu9xS0AMjjSJFSNQqKMBVAAApwGBgUtFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/Z" /></p>
<p>Exhibit 4.8.1</p>
<p>This solution can be found by essentially the same variational methods as used in Section 4.5; for a given <span class="arithmatex">\(F\)</span> the best choice of <span class="arithmatex">\(\psi\)</span> is</p>
<div class="arithmatex">\[
\begin{aligned}
\psi_{F}(x) &amp; =-\frac{f^{\prime}(x)}{f(x)}, &amp; &amp; \text { for }|x|&lt;c \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>and the corresponding asymptotic variance is <span class="arithmatex">\(1 / I_{c}(F)\)</span>, with</p>
<div class="arithmatex">\[
I_{c}(F)=\int \psi_{F}^{2} d F
\]</div>
<p>compare Section 6.3. Now minimize <span class="arithmatex">\(I_{c}(F)\)</span>; the variational conditions imply that <span class="arithmatex">\(-4 \sqrt{f_{0}}{ }^{\prime \prime} / \sqrt{f_{0}}=\)</span> const. on the set where <span class="arithmatex">\(f_{0}(x)&gt;(1-\varepsilon) \varphi(x)\)</span>, and that <span class="arithmatex">\(\psi_{F_{0}}( \pm c)=0\)</span>. This yields (8.2) to (8.5), and it only remains to check that this indeed is a solution. For details see Collins (1976).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(c\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(b\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(a\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(1 / I_{c}\left(F_{0}\right)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon=0.01\)</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2.747</td>
<td style="text-align: center;">1.539</td>
<td style="text-align: center;">1.727</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.451</td>
<td style="text-align: center;">2.032</td>
<td style="text-align: center;">1.166</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">2.123</td>
<td style="text-align: center;">2.055</td>
<td style="text-align: center;">1.082</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.991</td>
<td style="text-align: center;">1.982</td>
<td style="text-align: center;">1.068</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">1.945</td>
<td style="text-align: center;">1.945</td>
<td style="text-align: center;">1.065</td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon=0.05\)</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1.714</td>
<td style="text-align: center;">1.105</td>
<td style="text-align: center;">2.640</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1.693</td>
<td style="text-align: center;">1.460</td>
<td style="text-align: center;">1.503</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1.550</td>
<td style="text-align: center;">1.488</td>
<td style="text-align: center;">1.314</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.461</td>
<td style="text-align: center;">1.445</td>
<td style="text-align: center;">1.271</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">1.399</td>
<td style="text-align: center;">1.399</td>
<td style="text-align: center;">1.256</td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon=0.10\)</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1.307</td>
<td style="text-align: center;">0.838</td>
<td style="text-align: center;">4.129</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1.376</td>
<td style="text-align: center;">1.171</td>
<td style="text-align: center;">1.963</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1.289</td>
<td style="text-align: center;">1.220</td>
<td style="text-align: center;">1.621</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.217</td>
<td style="text-align: center;">1.194</td>
<td style="text-align: center;">1.532</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">1.140</td>
<td style="text-align: center;">1.140</td>
<td style="text-align: center;">1.490</td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon=0.25\)</span></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.692</td>
<td style="text-align: center;">0.356</td>
<td style="text-align: center;">21.741</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">0.711</td>
<td style="text-align: center;">4.575</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.905</td>
<td style="text-align: center;">0.810</td>
<td style="text-align: center;">3.089</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.865</td>
<td style="text-align: center;">0.820</td>
<td style="text-align: center;">2.683</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">0.766</td>
<td style="text-align: center;">0.766</td>
<td style="text-align: center;">2.397</td>
</tr>
</tbody>
</table>
<p>Exhibit 4.8.2 The minimax descending <span class="arithmatex">\(M\)</span>-estimate [cf. (8.2) and (8.3)].</p>
<p>Exhibit 4.8.2 shows some of the quantitative aspects. The last column gives the maximal risk <span class="arithmatex">\(1 / I_{c}\left(F_{0}\right)\)</span>. Clearly, a choice <span class="arithmatex">\(c \geqslant 5\)</span> will increase it only by a negligible amount beyond its minimax value <span class="arithmatex">\((c=\infty)\)</span>, but a choice <span class="arithmatex">\(c&lt;3\)</span> may have quite poor consequences. In other words it appears that descending <span class="arithmatex">\(\psi\)</span>-functions are much more sensitive to wrong scaling than monotone ones.</p>
<p>The actual performance of such an estimate does not seem to depend very much on the exact shape of <span class="arithmatex">\(\psi\)</span>. Other proposals for redescending <span class="arithmatex">\(M\)</span>-estimates have been Hampel's piecewise linear function:</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x)=-\psi(-x) &amp; =x, &amp; &amp; \text { for } 0 \leqslant x \leqslant a \\
&amp; =a, &amp; &amp; \text { for } a \leqslant x&lt;b \\
&amp; =\frac{c-x}{c-b} a, &amp; &amp; \text { for } b \leqslant x&lt;c \\
&amp; =0, &amp; &amp; \text { for } x \geqslant c
\end{aligned}
\]</div>
<p>Andrews' sine wave:</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x) &amp; =\sin (x), &amp; &amp; \text { for }-\pi \leqslant x \leqslant \pi \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>and Tukey's biweight:</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x) &amp; =x\left(1-x^{2}\right)^{2}, &amp; &amp; \text { for }|x| \leqslant 1 \\
&amp; =0, &amp; &amp; \text { otherwise. }
\end{aligned}
\]</div>
<p>Compare Andrews et al. (1972) and Exhibit 4.8.1.
When choosing a redescending <span class="arithmatex">\(\psi\)</span>, we must take care that it does not descend too steeply; if it does contamination sitting on the slopes may play havoc with the denominator in the expression for the asymptotic variance</p>
<div class="arithmatex">\[
A(F, T)=\frac{\int \psi^{2} d F}{\left(\int \psi^{\prime} d F\right)^{2}}
\]</div>
<p>This effect is particularly harmful when a large negative value <span class="arithmatex">\(\psi^{\prime}(x)\)</span> combines with a large positive value <span class="arithmatex">\(\psi(x)^{2}\)</span>, and there is a cluster of outliers near <span class="arithmatex">\(x\)</span>. (Some people have used quite dangerous Hampel estimates in their computer programs, with slopes between <span class="arithmatex">\(b\)</span> and <span class="arithmatex">\(c\)</span> that are much too steep.)</p>
<h1 id="a-word-of-caution">A Word of Caution</h1>
<p>It seems to me that, in some discussions, the importance of using redescending <span class="arithmatex">\(\psi\)</span>-functions has been exaggerated beyond all proportion. They are certainly beneficial if there are extreme outliers, but the improvement is relatively minor (a few percent of the asymptotic variance) and is counterbalanced by an increase of the minimax risk. If we are really interested in these few percentage points of potential improvement, then a removal of the "impossible" data points through a careful data screening based on physical expertise might be more effective and less risky than the routine use of a poorly tuned redescending <span class="arithmatex">\(\psi\)</span>. Note, in particular, the increased sensitivity to a wrong scale. Unless we are careful we may even get trapped in a local minimum of <span class="arithmatex">\(\sum \rho\left(x_{i}-T_{n}\right)\)</span>. The situation gets particularly acute in multiparameter regression.</p>
<h1 id="49-questions-of-asymmetric-contamination">4.9 QUESTIONS OF ASYMMETRIC CONTAMINATION</h1>
<p>In the preceding sections we have determined estimates minimizing the maximal asymptotic variance over some subset of <span class="arithmatex">\(\mathscr{P}=\mathscr{P}_{\varepsilon}\)</span>; only symmetric <span class="arithmatex">\(F\)</span>, or, slightly more generally, only those <span class="arithmatex">\(F \in \mathscr{P}\)</span> were admitted whose bias for the selected estimate was zero, <span class="arithmatex">\(T(F)=0\)</span>. We now check the behavior of these estimates over the rest of <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span>.</p>
<p>We have to answer two questions:
(1) How large is the maximal asymptotic bias <span class="arithmatex">\(b(\varepsilon)\)</span> and how does it compare to the bias of the median (which is minimax, Section 4.2)?
(2) How large is the maximal asymptotic variance <span class="arithmatex">\(v_{\alpha}(\varepsilon)\)</span> when <span class="arithmatex">\(F\)</span> ranges over all of <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span>, and how does it compare to the restricted maximal asymptotic variance <span class="arithmatex">\(v_{\varepsilon}(\varepsilon)\)</span>, where <span class="arithmatex">\(F\)</span> ranges only over the symmetric <span class="arithmatex">\(F \in \mathscr{P}_{\varepsilon}\)</span> ?</p>
<p>The discussion of breakdown properties (Sections 3.2 to 3.4) suggests that <span class="arithmatex">\(L\)</span>-estimates are more sensitive to asymmetries than either <span class="arithmatex">\(M\)</span> - or <span class="arithmatex">\(R\)</span>-estimates. We therefore restrict ourselves to <span class="arithmatex">\(\alpha\)</span>-trimmed means and <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions.</p>
<p>For small <span class="arithmatex">\(\varepsilon\)</span> we have [see (1.5.8)]</p>
<div class="arithmatex">\[
b(\varepsilon) \cong \varepsilon \sup _{x}|I C(x ; \Phi, T)|
\]</div>
<p>We thus tabulate <span class="arithmatex">\(b(\varepsilon) / \varepsilon\)</span> in order to obtain more nearly constant numbers; see Exhibit 4.9.1. The bottom row <span class="arithmatex">\((\alpha=0.5)\)</span> corresponds to the median.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\alpha\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">2.37</td>
<td style="text-align: center;">2.71</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">2.14</td>
<td style="text-align: center;">2.26</td>
<td style="text-align: center;">2.51</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.88</td>
<td style="text-align: center;">1.94</td>
<td style="text-align: center;">2.27</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">1.60</td>
<td style="text-align: center;">1.63</td>
<td style="text-align: center;">1.66</td>
<td style="text-align: center;">1.78</td>
<td style="text-align: center;">2.13</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">1.48</td>
<td style="text-align: center;">1.50</td>
<td style="text-align: center;">1.53</td>
<td style="text-align: center;">1.60</td>
<td style="text-align: center;">1.77</td>
<td style="text-align: center;">2.10</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">1.40</td>
<td style="text-align: center;">1.42</td>
<td style="text-align: center;">1.44</td>
<td style="text-align: center;">1.50</td>
<td style="text-align: center;">1.63</td>
<td style="text-align: center;">1.80</td>
<td style="text-align: center;">2.12</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">1.35</td>
<td style="text-align: center;">1.37</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">1.44</td>
<td style="text-align: center;">1.54</td>
<td style="text-align: center;">1.67</td>
<td style="text-align: center;">1.85</td>
<td style="text-align: center;">2.18</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">1.31</td>
<td style="text-align: center;">1.33</td>
<td style="text-align: center;">1.34</td>
<td style="text-align: center;">1.39</td>
<td style="text-align: center;">1.48</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">1.73</td>
<td style="text-align: center;">1.93</td>
<td style="text-align: center;">2.29</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">1.26</td>
<td style="text-align: center;">1.28</td>
<td style="text-align: center;">1.29</td>
<td style="text-align: center;">1.33</td>
<td style="text-align: center;">1.41</td>
<td style="text-align: center;">1.51</td>
<td style="text-align: center;">1.62</td>
<td style="text-align: center;">1.76</td>
<td style="text-align: center;">1.95</td>
<td style="text-align: center;">2.73</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">1.25</td>
<td style="text-align: center;">1.26</td>
<td style="text-align: center;">1.28</td>
<td style="text-align: center;">1.32</td>
<td style="text-align: center;">1.39</td>
<td style="text-align: center;">1.48</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">1.72</td>
<td style="text-align: center;">1.89</td>
<td style="text-align: center;">2.42</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
</tbody>
</table>
<p>Exhibit 4.9.1 Maximal bias of <span class="arithmatex">\(\alpha\)</span>-trimmed means for <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions (tabulated: <span class="arithmatex">\(b(\varepsilon) / \varepsilon\)</span> ).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\alpha\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.004 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.08 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.009 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.07 \\ 1.0065 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.14 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.027 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.07 \\ 1.0017 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.12 \\ 1.0084 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.30 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.061 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.09 \\ 1.0007 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.13 \\ 1.0031 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.26 \\ 1.027 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.54 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.03 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.100 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.13 \\ 1.0004 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.16 \\ 1.0019 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.27 \\ 1.014 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.49 \\ 1.08 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.80 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.25 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 3.07 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.144 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.17 \\ 1.0003 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.20 \\ 1.0013 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.30 \\ 1.010 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.50 \\ 1.05 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.75 \\ 1.18 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.08 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.56 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 3.28 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.195 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.22 \\ 1.0003 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.25 \\ 1.0010 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.35 \\ 1.007 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.53 \\ 1.04 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.76 \\ 1.11 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.05 \\ 1.29 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.42 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.93 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 4.81 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} \infty \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.252 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.28 \\ 1.0002 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.31 \\ 1.0009 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.40 \\ 1.006 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.58 \\ 1.03 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.79 \\ 1.08 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.06 \\ 1.18 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.40 \\ 1.45 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.83 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 4.20 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 7.26 \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.393 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.42 \\ 1.0002 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.45 \\ 1.0007 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.55 \\ 1.005 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.73 \\ 1.02 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.94 \\ 1.06 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.20 \\ 1.12 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.51 \\ 1.24 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.90 \\ 1.47 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 4.01 \\ \infty \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 5.94 \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.571 \\ 1 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.60 \\ 1.0002 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.64 \\ 1.0007 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.74 \\ 1.004 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.94 \\ 1.02 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.17 \\ 1.05 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.45 \\ 1.11 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.79 \\ 1.20 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 3.21 \\ 1.38 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 4.36 \\ 2.55 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 6.28 \\ \infty \end{gathered}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">Minimax <br> bound for <span class="arithmatex">\(v_{s}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.000 \\ 1.000 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.065 \\ 1.065 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.116 \\ 1.116 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.256 \\ 1.256 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.490 \\ 1.490 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 1.748 \\ 1.748 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.046 \\ 2.046 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.397 \\ 2.397 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 2.822 \\ 2.822 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 3.996 \\ 3.996 \end{gathered}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{gathered} 5.928 \\ \text { 5.928 } \end{gathered}\)</span></td>
</tr>
</tbody>
</table>
<p>Exhibit 4.9.2 Maximal symmetric and asymmetric variance of <span class="arithmatex">\(\alpha\)</span>-trimmed means for <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions [tabulated: <span class="arithmatex">\(v_{s}(\varepsilon), v_{\alpha}(\varepsilon) / v_{s}(\varepsilon)\)</span> ].</p>
<p>Exhibit 4.9.2 is concerned with asymptotic variances; it tabulates <span class="arithmatex">\(v_{s}(\varepsilon)\)</span> and <span class="arithmatex">\(v_{\alpha}(\varepsilon) / v_{s}(\varepsilon)\)</span> (cf. the second question above).</p>
<p>For the <span class="arithmatex">\(\alpha\)</span>-trimmed mean, asymptotic bias and variance apparently are maximized if the entire contaminating mass <span class="arithmatex">\(\varepsilon\)</span> is put at <span class="arithmatex">\(+\infty\)</span>. This is trivially true for the bias, and highly plausible (but not yet proved) for the variance. Calculating Exhibits 4.9.1 and 4.9.2 is, by the way, an instructive exercise in the use of several formulas derived in Section 3.3.</p>
<p>The following features deserve some comments. Note that <span class="arithmatex">\(b(\varepsilon) / \varepsilon\)</span> increases only very slowly with <span class="arithmatex">\(\varepsilon\)</span> and in fact stays bounded right up to the breakdown point.</p>
<p>For small <span class="arithmatex">\(\varepsilon\)</span> the excess of <span class="arithmatex">\(v_{a}\)</span> beyond <span class="arithmatex">\(v_{s}\)</span> is negligible (it is of the order <span class="arithmatex">\(\varepsilon^{2}\)</span> ). This gives an a posteriori justification for restricting attention to symmetric distributions when minimizing asymptotic variances. For larger <span class="arithmatex">\(\varepsilon\)</span>, however, the discrepancies can become sizeable. Take <span class="arithmatex">\(\varepsilon=0.2\)</span>, and the <span class="arithmatex">\(25 \%\)</span>-trimmed mean, which is very nearly minimax there for symmetric contamination; then <span class="arithmatex">\(v_{a} / v_{s} \cong 1.29\)</span>.</p>
<p>Exhibits 4.9.1 and 4.9.2 also illustrate the two breakdown points <span class="arithmatex">\(\varepsilon^{*}\)</span> and <span class="arithmatex">\(\varepsilon^{* *}\)</span>, defined in Section 1.4: <span class="arithmatex">\(b(\varepsilon)=\infty\)</span> for <span class="arithmatex">\(\varepsilon&gt;\varepsilon^{*}=\alpha\)</span>, and <span class="arithmatex">\(v_{s}(\varepsilon)=\infty\)</span> for <span class="arithmatex">\(\varepsilon \geqslant \varepsilon^{* *}=2 \alpha\)</span>.</p>
<h1 id="chapter-5">CHAPTER 5</h1>
<h2 id="scale-estimates">Scale Estimates</h2>
<h3 id="51-general-remarks">5.1 GENERAL REMARKS</h3>
<p>By scale estimate we denote any positive statistic <span class="arithmatex">\(S_{n}\)</span> that is equivariant under scale transformations:</p>
<div class="arithmatex">\[
S_{n}\left(a x_{1}, \ldots, a x_{n}\right)=a S_{n}\left(x_{1}, \ldots, x_{n}\right), \quad \text { for } \quad a&gt;0
\]</div>
<p>Many scale estimates are also invariant under changes of sign and shifts:</p>
<div class="arithmatex">\[
\begin{aligned}
S_{n}\left(-x_{1}, \ldots,-x_{n}\right) &amp; =S_{n}\left(x_{1}, \ldots, x_{n}\right) \\
S_{n}\left(x_{1}+b, \ldots, x_{n}+b\right) &amp; =S_{n}\left(x_{1}, \ldots, x_{n}\right)
\end{aligned}
\]</div>
<p>Pure scale problems are rare; in practice scale usually occurs as a nuisance parameter in location, and, more generally, in regression problems. Therefore we should tune the properties of the scale estimate to that of the location estimate to which it is subordinated. For instance, we would not want to spoil the good breakdown properties of a location estimate by an early breakdown of the scale estimate. For related reasons it appears to be more important to keep the bias of the scale estimate small than to strive for a small (asymptotic) variance.</p>
<p>As a result the so-called median absolute deviation (MAD) has emerged as the single most useful ancillary estimate of scale. It is defined as the median of the absolute deviations from the median:</p>
<div class="arithmatex">\[
\mathrm{MAD}_{n}=\operatorname{med}\left\{\left|x_{i}-M_{n}\right|\right\}
\]</div>
<p>where</p>
<div class="arithmatex">\[
M_{n}=\operatorname{med}\left\{x_{i}\right\}
\]</div>
<p>For symmetric distributions this is asymptotically equivalent to one-half of the interquartile distance, but it has better breakdown properties under <span class="arithmatex">\(\varepsilon\)</span>-contamination ( <span class="arithmatex">\(\varepsilon^{*}=0.5\)</span>, as against <span class="arithmatex">\(\varepsilon^{*}=0.25\)</span> for the interquartile distance).</p>
<p>Note that this clashes with the widespread opinion that, because most of the information for scale sits in the tails, we should give more consideration to the tails, and thus use a lower rejection or trimming rate in scale problems. This may be true for the pure scale problem, but is not so when scale is just a nuisance parameter.</p>
<p>The pure scale problem is a kind of stepping stone toward more complex estimation problems. It has the advantage that it can be converted into a location problem by taking logarithms, so the machinery of the preceding chapters is applicable. But the distributions resulting from this transformation are highly asymmetric, and there is no natural scale (corresponding to the center of symmetry). In most cases it is convenient to standardize the estimates such that they are consistent at the ideal model distribution (cf. the remarks at the end of Section 1.2). For instance, in order to make MAD consistent at the normal distribution, we must divide it by <span class="arithmatex">\(\Phi^{-1}\left(\frac{3}{4}\right) \cong\)</span> 0.6745 .</p>
<p>This chapter closely follows and parallels many sections of the preceding two chapters; we again concentrate on estimates that are functionals of the empirical distribution function, <span class="arithmatex">\(S_{n}=S\left(F_{n}\right)\)</span>, and we again exploit the heuristic approach through influence functions.</p>
<p>As the asymptotic variance <span class="arithmatex">\(A(F, S)\)</span> of <span class="arithmatex">\(\sqrt{n}\left[S\left(F_{n}\right)-S(F)\right]\)</span> depends on the arbitrary standardization of <span class="arithmatex">\(S\)</span>, it is a poor measure of asymptotic performance. We use the relative asymptotic variance of <span class="arithmatex">\(S\)</span> instead, that is, the asymptotic variance</p>
<div class="arithmatex">\[
A(F, \log S)=\frac{A(F, S)}{S(F)^{2}}
\]</div>
<p>of</p>
<div class="arithmatex">\[
\sqrt{n} \log \frac{S\left(F_{n}\right)}{S(F)}
\]</div>
<p>Another important scale-type problem concerns the estimation of the variability of a given estimate; we have briefly touched upon this topic in Section 1.5. In the classical normal theory, the two cases are often confounded-after all, the classical estimates for the standard error of a single observation and of the sample mean differ only by a factor <span class="arithmatex">\(\sqrt{n}\)</span>-but we must keep them conceptually separate. We defer the discussion of this kind of problem till the end of Chapter 6.</p>
<h1 id="52-m-estimates-of-scale">5.2 M-ESTIMATES OF SCALE</h1>
<p>An <span class="arithmatex">\(M\)</span>-estimate <span class="arithmatex">\(S\)</span> of scale is defined by an implicit relation of the form</p>
<div class="arithmatex">\[
\int \chi\left(\frac{x}{S(F)}\right) F(d x)=0
\]</div>
<p>Typically (but not necessarily), <span class="arithmatex">\(\chi\)</span> is an even function <span class="arithmatex">\(\chi(-x)=\chi(x)\)</span>.
From (3.2.13) we obtain the influence function</p>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{\chi(x / S(F)) S(F)}{\int \chi^{\prime}(x / S(F))(x / S(F)) F(d x)}
\]</div>
<p>Example 2.1 The maximum likelihood estimate of <span class="arithmatex">\(\sigma\)</span> for the scale family of densities <span class="arithmatex">\(\sigma^{-1} f(x / \sigma)\)</span> is an <span class="arithmatex">\(M\)</span>-estimate with</p>
<div class="arithmatex">\[
\chi(x)=-x \frac{f^{\prime}(x)}{f(x)}-1
\]</div>
<p>Example 2.2 Huber (1964) proposed the choice</p>
<div class="arithmatex">\[
\begin{aligned}
\chi(x) &amp; =x^{2}-\beta, &amp; &amp; \text { for }|x| \leqslant k \\
&amp; =k^{2}-\beta, &amp; &amp; \text { for }|x|&gt;k
\end{aligned}
\]</div>
<p>for some constant <span class="arithmatex">\(k\)</span>, with <span class="arithmatex">\(\beta\)</span> determined such that <span class="arithmatex">\(S(\Phi)=1\)</span>, that is, <span class="arithmatex">\(\int \chi(x) \Phi(d x)=0\)</span>.</p>
<p>Example 2.3 The choice</p>
<div class="arithmatex">\[
\chi(x)=\operatorname{sign}(|x|-1)
\]</div>
<p>yields the median absolute deviation <span class="arithmatex">\(S=\operatorname{med}(|X|)\)</span>, that is, that number <span class="arithmatex">\(S\)</span> for which <span class="arithmatex">\(F(S)-F(-S)=\frac{1}{2}\)</span>. (More precisely, this is the median absolute deviation from 0 , to be distinguished from the median absolute deviation from the median.)</p>
<p>Continuity and breakdown properties can be worked out just as in the location case in Section 3.2, except that everything is slightly more complicated. Therefore we only show how the breakdown point under <span class="arithmatex">\(\varepsilon\)</span> contamination can be worked out.</p>
<p>Assume that <span class="arithmatex">\(\chi\)</span> is even and monotone increasing for positive arguments. Let <span class="arithmatex">\(\|\chi\|=\chi(\infty)-\chi(0)\)</span>. We write (2.1) as</p>
<div class="arithmatex">\[
\int\left[\chi\left(\frac{x}{S(F)}\right)-\chi(0)\right] F(d x)+\chi(0)=0
\]</div>
<p>Assuming the gross error model, it is easy to see that a contamination <span class="arithmatex">\(\varepsilon&gt;-\chi(0) /\|\chi\|\)</span> at <span class="arithmatex">\(|x|=\infty\)</span> forces the left-hand side of (2.6) to be greater than 0 for all values of <span class="arithmatex">\(S(F)\)</span>. Similarly, a contamination <span class="arithmatex">\(\varepsilon&gt;1+\chi(0) /\|\chi\|\)</span> at 0 forces it to be less than 0 for all values of <span class="arithmatex">\(S(F)\)</span>. [As <span class="arithmatex">\(0&lt;-\chi(0) /\|\chi\| \leqslant \frac{1}{2}\)</span> in the more interesting cases, we can usually disregard the second contingency.] On the other hand if <span class="arithmatex">\(\varepsilon\)</span> satisfies the opposite strict inequalities, then the solution <span class="arithmatex">\(S(F)\)</span> of (2.6) is bounded away from 0 and <span class="arithmatex">\(\infty\)</span>.</p>
<p>We conclude that, for <span class="arithmatex">\(\varepsilon\)</span>-contamination (and also for Prohorov distance), the breakdown point is given by</p>
<div class="arithmatex">\[
\varepsilon^{*}=\frac{-\chi(0)}{\|\chi\|} \leqslant \frac{1}{2}
\]</div>
<p>For indeterminacy in terms of Kolmogorov or Lévy distance, this number must be halved:</p>
<div class="arithmatex">\[
\varepsilon^{*}=-\frac{1}{2} \frac{\chi(0)}{\|\chi\|} \leqslant 0.25
\]</div>
<p>The reason for this different behavior is as follows. By taking away a mass <span class="arithmatex">\(\varepsilon\)</span> from the central part of a distribution <span class="arithmatex">\(F\)</span> and moving one-half of it to the extreme left, the other half to the extreme right, we get a distribution that is within Prohorov distance <span class="arithmatex">\(\varepsilon\)</span>, but within Lévy distance <span class="arithmatex">\(\varepsilon / 2\)</span>, of the original <span class="arithmatex">\(F\)</span>.</p>
<h1 id="53-l-estimates-of-scale">5.3 L-ESTIMATES OF SCALE</h1>
<p>The general results of Section 3.3 apply without much change. In view of scale invariance (1.1), only the following types of functionals appear feasible:</p>
<div class="arithmatex">\[
\begin{array}{ll}
S(F)=\left[\int F^{-1}(t)^{q} M(d t)\right]^{1 / q}, &amp; \text { with integral } q \neq 0 \\
S(F)=\left[\int\left|F^{-1}(t)\right|^{q} M(d t)\right]^{1 / q}, &amp; \text { with real } q \neq 0 \\
S(F)=\exp \left[\int \log \left|F^{-1}(t)\right| M(d t)\right], &amp; \text { with } M\{(0,1)\}=1
\end{array}
\]</div>
<p>We encounter estimates of both the first type (interquantile range, trimmed variance) and the second type (median deviation), but in what follows now we consider only (3.1).</p>
<p>From (3.3.11) and the chain rule, we obtain the influence function</p>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{1}{S(F)^{q-1}}\left[\int s \frac{F^{-1}(s)^{q-1}}{f\left(F^{-1}(s)\right)} M(d s)-\int_{F(x)}^{1} \frac{F^{-1}(s)^{q-1}}{f\left(F^{-1}(s)\right)} M(d s)\right]
\]</div>
<p>Or if <span class="arithmatex">\(M\)</span> has a density <span class="arithmatex">\(m\)</span>, then</p>
<div class="arithmatex">\[
\frac{d}{d x} I C(x ; F, S)=\frac{x^{q-1}}{S(F)^{q-1}} m(F(x))
\]</div>
<p>Example 3.1 The <span class="arithmatex">\(t\)</span>-quantile range</p>
<div class="arithmatex">\[
S(F)=F^{-1}(1-t)-F^{-1}(t), \quad 0&lt;t&lt;\frac{1}{2}
\]</div>
<p>has the influence function</p>
<div class="arithmatex">\[
\begin{aligned}
I C(x ; F, S) &amp; =\frac{1}{f\left(F^{-1}(t)\right)}-c(F), &amp; &amp; \text { for } x&lt;F^{-1}(t) \\
&amp; =-c(F), &amp; &amp; \text { for } F^{-1}(t)&lt;x&lt;F^{-1}(1-t) \\
&amp; =\frac{1}{f\left(F^{-1}(1-t)\right)}-c(F), &amp; &amp; \text { for } x&gt;F^{-1}(1-t)
\end{aligned}
\]</div>
<p>where</p>
<div class="arithmatex">\[
c(F)=t\left(\frac{1}{f\left(F^{-1}(t)\right)}+\frac{1}{f\left(F^{-1}(1-t)\right)}\right)
\]</div>
<p>If <span class="arithmatex">\(F\)</span> is symmetric these formulas simplify to</p>
<div class="arithmatex">\[
\begin{aligned}
I C(x ; F, S) &amp; =\frac{1-2 t}{f\left(F^{-1}(t)\right)}, &amp; &amp; \text { for } x&lt;F^{-1}(t) \text { or } x&gt;F^{-1}(1-t) \\
&amp; =\frac{-2 t}{f\left(F^{-1}(t)\right)}, &amp; &amp; \text { for } F^{-1}(t)&lt;x&lt;F^{-1}(1-t)
\end{aligned}
\]</div>
<p>Then the asymptotic variance of <span class="arithmatex">\(\sqrt{n}\left[S\left(F_{n}\right)-S(F)\right]\)</span> is given by</p>
<div class="arithmatex">\[
A(F, S)=\frac{2 t(1-2 t)}{f\left(F^{-1}(t)\right)^{2}}
\]</div>
<p>and that of <span class="arithmatex">\(\sqrt{n} \log \left[S\left(F_{n}\right) / S(F)\right]\)</span> is</p>
<div class="arithmatex">\[
A(F, \log S)=\frac{2 t(1-2 t)}{\left[2 F^{-1}(t) f\left(F^{-1}(t)\right)\right]^{2}}
\]</div>
<p>Some numerical results are given in Exhibit 5.7.3. For example, the interquartile range <span class="arithmatex">\((t=0.25)\)</span> has an asymptotic variance <span class="arithmatex">\(A(\Phi, \log S)=1.361\)</span> and an asymptotic relative efficiency (relative to the standard deviation) of <span class="arithmatex">\(0.5 / 1.361=0.3674\)</span>. The same is true for the MAD.</p>
<p>Example 3.2 The <span class="arithmatex">\(\alpha\)</span>-trimmed variance is defined as the suitably scaled variance of the <span class="arithmatex">\(\alpha\)</span>-trimmed sample:</p>
<div class="arithmatex">\[
S(F)^{2}=\gamma(\alpha) \int_{\alpha}^{1-\alpha} F^{-1}(s)^{2} d s
\]</div>
<p>The normalizing factor is fixed such that <span class="arithmatex">\(S(\Phi)=1\)</span>, that is,</p>
<div class="arithmatex">\[
\frac{1}{\gamma(\alpha)}=\int_{-\xi}^{\xi} x^{2} \varphi(x) d x=1-2 \alpha-2 \xi \varphi(\xi)
\]</div>
<p>with <span class="arithmatex">\(\xi=\Phi^{-1}(1-\alpha)\)</span>. According to (3.5) the influence function of the <span class="arithmatex">\(\alpha\)</span> trimmed variance then satisfies</p>
<div class="arithmatex">\[
\begin{aligned}
\frac{d}{d x} I C(x ; F, S) &amp; =\gamma(\alpha) \frac{x}{S(F)}, &amp; &amp; \text { for } \alpha&lt;F(x)&lt;1-\alpha \\
&amp; =0, &amp; &amp; \text { otherwise }
\end{aligned}
\]</div>
<p>hence</p>
<div class="arithmatex">\[
\begin{array}{rlr}
I C(x ; F, S) &amp; =\frac{\gamma(\alpha)}{2 S(F)}\left[F^{-1}(\alpha)^{2}-c(F)\right], &amp; &amp; \text { for } x&lt;F^{-1}(\alpha) \\
&amp; =\frac{\gamma(\alpha)}{2 S(F)}\left[x^{2}-c(F)\right], &amp; &amp; \text { for } F^{-1}(\alpha)&lt;x&lt;F^{-1}(1-\alpha) \\
&amp; =\frac{\gamma(\alpha)}{2 S(F)}\left[F^{-1}(1-\alpha)^{2}-c(F)\right], &amp; &amp; \text { for } x&gt;F^{-1}(1-\alpha)
\end{array}
\]</div>
<p>where</p>
<div class="arithmatex">\[
c(F)=\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)} x^{2} d F+\alpha\left[F^{-1}(\alpha)^{2}+F^{-1}(1-\alpha)^{2}\right]
\]</div>
<p>is the <span class="arithmatex">\(\alpha\)</span>-Winsorized variance.
Example 3.3 Define</p>
<div class="arithmatex">\[
S(F)=\gamma(\alpha) \int_{\alpha}^{1-\alpha} F^{-1}(t) \Phi^{-1}(t) d t
\]</div>
<p>with <span class="arithmatex">\(\gamma(\alpha)\)</span> as in (3.13). Then the influence function can be found by integrating</p>
<div class="arithmatex">\[
\begin{aligned}
\frac{d}{d x} I C(x ; F, S) &amp; =\gamma(\alpha) \Phi^{-1}(F(x)), &amp; &amp; \text { for } \alpha&lt;F(x)&lt;1-\alpha \\
&amp; =0, &amp; &amp; \text { otherwise. }
\end{aligned}
\]</div>
<p>All of the above functionals <span class="arithmatex">\(S\)</span> also have a symmetrized version <span class="arithmatex">\(\tilde{S}\)</span>, which is obtained as follows. Put</p>
<div class="arithmatex">\[
\tilde{F}(x)=1-F(-x+0)
\]</div>
<p>and</p>
<div class="arithmatex">\[
\tilde{F}(x)=\frac{1}{2}[F(x)+\tilde{F}(x)]
\]</div>
<p>We say that <span class="arithmatex">\(\tilde{F}\)</span> is obtained from <span class="arithmatex">\(F\)</span> by symmetrizing at the origin (alternatively, we could also symmetrize at the median, etc.). Then define</p>
<div class="arithmatex">\[
\tilde{S}(F)=S(\tilde{F})
\]</div>
<p>It is immediate that</p>
<div class="arithmatex">\[
I C(x ; F, \tilde{S})=\frac{1}{2}[I C(x ; \tilde{F}, S)+I C(-x ; \tilde{F}, S)]
\]</div>
<p>Thus if <span class="arithmatex">\(S\)</span> is symmetric [i.e., <span class="arithmatex">\(S(F)=S(\tilde{F})\)</span> for all <span class="arithmatex">\(F\)</span> ], and if the true underlying <span class="arithmatex">\(F\)</span> is symmetric <span class="arithmatex">\((F=\tilde{F})\)</span>, then <span class="arithmatex">\(\tilde{S}(F)=S(F)\)</span>, and <span class="arithmatex">\(S\)</span> and <span class="arithmatex">\(\tilde{S}\)</span> have the same influence function at <span class="arithmatex">\(F\)</span>. Hence for symmetric <span class="arithmatex">\(F\)</span> their asymptotic properties agree.</p>
<p>For asymmetric <span class="arithmatex">\(F\)</span> (and also for small samples from symmetric underlying distributions) the symmetrized and nonsymmetrized estimates behave</p>
<p>quite differently. This is particularly evident in their breakdown behavior. For example, take an estimate of the form (3.1), where <span class="arithmatex">\(M\)</span> is either a positive measure ( <span class="arithmatex">\(q\)</span> even), or positive on <span class="arithmatex">\(\left[\frac{1}{2}, 1\right]\)</span>, negative on <span class="arithmatex">\(\left[0, \frac{1}{2}\right](q\)</span> odd <span class="arithmatex">\()\)</span>, and let <span class="arithmatex">\(\alpha\)</span> be the largest real number such that <span class="arithmatex">\([\alpha, 1-\alpha]\)</span> contains the support of <span class="arithmatex">\(M\)</span>. Then according to Theorem 3.3.1 and the remarks preceding it, for a nonsymmetrized estimate of scale, breakdown occurs at <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span> (for <span class="arithmatex">\(\varepsilon\)</span>-contamination, total variation, Prohorov, Lévy, or Kolmogorov distance).</p>
<p>For the symmetrized version breakdown still happens at <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span> with Lévy and Kolmogorov distance, but is boosted to <span class="arithmatex">\(\varepsilon^{*}=2 \alpha\)</span> in the other three cases. It appears therefore that symmetrized scale estimates are generally preferable.</p>
<p>Example 3.4 Let <span class="arithmatex">\(S\)</span> be one-half of the interquartile distance:</p>
<div class="arithmatex">\[
S(F)=\frac{1}{2}\left[F^{-1}\left(\frac{3}{4}\right)-F^{-1}\left(\frac{1}{4}\right)\right]
\]</div>
<p>Then <span class="arithmatex">\(\hat{S}\)</span> is the median absolute deviation (Example 2.3).</p>
<h1 id="54-r-estimates-of-scale">5.4 R-ESTIMATES OF SCALE</h1>
<p>Rank tests for scale compare relative scale between two or more samples; there is no substitute for the left-right symmetry that makes one-sample rank-tests and estimates of location possible (though we can obtain surrogate one-sample rank tests and estimates for scale if we use a synthetic second sample, e.g., expected order statistics from a normal distribution). A brief sketch of a possible approach should suffice.</p>
<p>Let <span class="arithmatex">\(\left(x_{1}, \ldots, x_{m}\right)\)</span> and <span class="arithmatex">\(\left(y_{1}, \ldots, y_{n}\right)\)</span> be the two samples, and let <span class="arithmatex">\(R_{i}\)</span> be the rank of <span class="arithmatex">\(x_{i}\)</span> in the pooled sample of size <span class="arithmatex">\(N=m+n\)</span>. Then form the test statistic</p>
<div class="arithmatex">\[
\sum_{i=1}^{m} a\left(R_{i}\right)
\]</div>
<p>with <span class="arithmatex">\(a_{i}=a(i)\)</span> defined by</p>
<div class="arithmatex">\[
a_{i}=N \int_{(i-1) / N}^{i / N} J(s) d s
\]</div>
<p>for some scores generating function <span class="arithmatex">\(J\)</span>, just as in Section 3.4. Typically, <span class="arithmatex">\(J\)</span> is</p>
<p>a function of <span class="arithmatex">\(\left|t-\frac{1}{2}\right|\)</span>, for example,</p>
<div class="arithmatex">\[
\begin{array}{ll}
J(t)=\left|t-\frac{1}{2}\right|-\frac{1}{4} &amp; \text { (Ansari-Bradley-Siegel-Tukey) } \\
J(t)=\left(t-\frac{1}{2}\right)^{2}-\frac{1}{12} &amp; (\text { Mood }) \\
J(t)=\Phi^{-1}(t)^{2}-1 &amp; (\text { Klotz })
\end{array}
\]</div>
<p>We convert such tests into estimates of relative scale. Let <span class="arithmatex">\(0&lt;\lambda&lt;1\)</span> be fixed (we shall later choose <span class="arithmatex">\(\lambda=m / N\)</span> ), and define a functional <span class="arithmatex">\(S=S(F, G)\)</span> such that</p>
<div class="arithmatex">\[
\int J\left[\lambda F(x)+(1-\lambda) G\left(\frac{x}{S}\right)\right] F(d x)=0
\]</div>
<p>or, preferably [after substituting <span class="arithmatex">\(F(x)=t\)</span> ],</p>
<div class="arithmatex">\[
\int J\left(\lambda t+(1-\lambda) G\left(\frac{F^{-1}(t)}{S}\right)\right) d t=0
\]</div>
<p>If we assume that <span class="arithmatex">\(\int J(t) d t=0\)</span>, then <span class="arithmatex">\(S(F, G)\)</span>, if well defined by (4.7), is a measure of relative scale satisfying</p>
<div class="arithmatex">\[
S\left(F_{a X}, F_{X}\right)=a
\]</div>
<p>where <span class="arithmatex">\(F_{a X}\)</span> denotes the distribution of the random variable <span class="arithmatex">\(a X\)</span>.
We now insert <span class="arithmatex">\(F_{u}=(1-u) F+u F_{1}\)</span> and <span class="arithmatex">\(G_{u}=(1-u) G+u G_{1}\)</span> into (4.7) and differentiate with respect to <span class="arithmatex">\(u\)</span> at <span class="arithmatex">\(u=0\)</span>. If <span class="arithmatex">\(F=G\)</span>, the resulting expressions remain quite manageable; we obtain</p>
<div class="arithmatex">\[
\dot{S}=\left[\frac{d}{d u} S\left(F_{u}, G_{u}\right)\right]_{u=0}=\frac{\int J(F(x)) F_{1}(d x)-\int J(F(x)) G_{1}(d x)}{\int J^{\prime}(F(x)) x f(x)^{2} d x}
\]</div>
<p>The Gâteaux derivatives of <span class="arithmatex">\(S(F, G)\)</span> with respect to <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(G\)</span>, at <span class="arithmatex">\(F=G\)</span>, can now be read off from (4.9).</p>
<p>If both samples come from the same <span class="arithmatex">\(F\)</span>, and if we insert the respective empirical distributions <span class="arithmatex">\(F_{m}\)</span> and <span class="arithmatex">\(G_{n}\)</span> for <span class="arithmatex">\(F_{1}\)</span> and <span class="arithmatex">\(G_{1}\)</span>, we obtain the Taylor expansion (with <span class="arithmatex">\(u=1\)</span> )</p>
<div class="arithmatex">\[
S\left(F_{m}, G_{n}\right)=1+\dot{S}+\cdots
\]</div>
<p>or, approximately (with <span class="arithmatex">\(\lambda=m / N\)</span> ),</p>
<div class="arithmatex">\[
\sqrt{N}\left(S\left(F_{m}, G_{n}\right)-1\right) \cong \frac{\sqrt{\frac{1}{\lambda}} \frac{1}{\sqrt{m}} \sum J\left(F\left(x_{i}\right)\right)-\sqrt{\frac{1}{1-\lambda}} \frac{1}{\sqrt{n}} \sum J\left(F\left(y_{j}\right)\right)}{\int J^{\prime}(F(x)) x f(x)^{2} d x}
\]</div>
<p>We thus can expect that (4.11) is asymptotically normal with mean 0 and variance</p>
<div class="arithmatex">\[
A(F, S)=\frac{1}{\lambda(1-\lambda)} \frac{\int J(t)^{2} d t}{\int J^{\prime}(F(x)) x f(x)^{2} d x]^{2}}
\]</div>
<p>This should hold if <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(n\)</span> go to <span class="arithmatex">\(\infty\)</span> comparably fast; if <span class="arithmatex">\(m / n \rightarrow 0\)</span>, then <span class="arithmatex">\(\sqrt{m}\left[S\left(F_{m}, G_{n}\right)-1\right]\)</span> will be asymptotically normal with the same variance (4.12), except that the factor <span class="arithmatex">\(1 /[\lambda(1-\lambda)]\)</span> is replaced by 1 .</p>
<p>The above derivations of course are only heuristic; for a rigorous theory we would have to refer to the extensive literature on the behavior of rank tests under alternatives, in particular Hájek (1968) and Hájek and Dupač (1969). These results on tests can be translated in a relatively straightforward way into results about the behavior of estimates; compare Section 10.6 .</p>
<h1 id="55-asymptotically-efficient-scale-estimates">5.5 ASYMPTOTICALLY EFFICIENT SCALE ESTIMATES</h1>
<p>The parametric pure scale problem corresponds to estimating <span class="arithmatex">\(\sigma\)</span> for the family of densities</p>
<div class="arithmatex">\[
p(x ; \sigma)=\frac{1}{\sigma} f\left(\frac{x}{\sigma}\right), \quad \sigma&gt;0
\]</div>
<p>As</p>
<div class="arithmatex">\[
\frac{\partial}{\partial \sigma} \log p(x ; \sigma)=-\frac{f^{\prime}(x / \sigma)}{f(x / \sigma)} \frac{x}{\sigma^{2}}-\frac{1}{\sigma}
\]</div>
<p>Fisher information for scale is</p>
<div class="arithmatex">\[
I(F ; \sigma)=\frac{1}{\sigma^{2}} \int\left[-\frac{f^{\prime}(x)}{f(x)} x-1\right]^{2} f(x) d x
\]</div>
<p>Without loss of generality we assume now that the true scale is <span class="arithmatex">\(\sigma=1\)</span>. Evidently, in order to obtain full asymptotic efficiency at <span class="arithmatex">\(F\)</span>, we should arrange that</p>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{1}{I(F ; 1)}\left[-\frac{f^{\prime}(x)}{f(x)} x-1\right]
\]</div>
<p>see Section 3.5 .
Thus for <span class="arithmatex">\(M\)</span>-estimates (2.1) it suffices to choose, up to a multiplicative constant,</p>
<div class="arithmatex">\[
\chi(x)=-\frac{f^{\prime}(x)}{f(x)} x-1
\]</div>
<p>For an <span class="arithmatex">\(L\)</span>-estimate (3.1) the proper choice is a measure <span class="arithmatex">\(M\)</span> with density <span class="arithmatex">\(m\)</span> given by</p>
<div class="arithmatex">\[
m(F(x))=-\frac{\left[f^{\prime}(x) / f(x)\right]^{\prime} x^{-q+1}}{I(F ; 1)}
\]</div>
<p>For <span class="arithmatex">\(R\)</span>-estimates of relative scale, one should choose, up to an arbitrary multiplicative constant,</p>
<div class="arithmatex">\[
J(F(x))=-\frac{f^{\prime}(x)}{f(x)} x-1
\]</div>
<p>Example 5.1 Let <span class="arithmatex">\(f(x)=\varphi(x)\)</span> be the standard normal density. Then the asymptotically efficient <span class="arithmatex">\(M\)</span>-estimate is, of course,</p>
<div class="arithmatex">\[
S\left(F_{n}\right)^{2}=\frac{1}{n} \sum x_{i}^{2}
\]</div>
<p>The efficient <span class="arithmatex">\(L\)</span>-estimate for <span class="arithmatex">\(q=2\)</span> is exactly the same. With <span class="arithmatex">\(q=1\)</span>, we obtain <span class="arithmatex">\(m(t)=\Phi^{-1}(t)\)</span>, that is,</p>
<div class="arithmatex">\[
S(F)=\int F^{-1}(t) \Phi^{-1}(t) d t
\]</div>
<p>thus</p>
<div class="arithmatex">\[
S\left(F_{n}\right)=\sum a_{i} x_{(i)}
\]</div>
<p>with</p>
<div class="arithmatex">\[
a_{i}=\int_{(i-1) / n}^{i / n} \Phi^{-1}(t) d t
\]</div>
<p>The efficient <span class="arithmatex">\(R\)</span>-estimate corresponds to the Klotz test (4.5).</p>
<h1 id="56-distributions-minimizing-fisher-information-for-scale">5.6 DISTRIBUTIONS MINIMIZING FISHER INFORMATION FOR SCALE</h1>
<p>Let <span class="arithmatex">\(\mathscr{P}\)</span> be a convex set of distribution functions that is such that, with each <span class="arithmatex">\(F \in \mathscr{P}\)</span>, it also contains its mirror image <span class="arithmatex">\(\bar{F}\)</span> and thus its symmetrization <span class="arithmatex">\(\bar{F}\)</span> [cf. (3.19) and (3.20)]. Assume that the observations <span class="arithmatex">\(X_{t}\)</span> are distributed according to <span class="arithmatex">\(F(x / \sigma)\)</span>, where <span class="arithmatex">\(\sigma\)</span> is to be estimated.</p>
<p>We note that, for any parametric family of densities <span class="arithmatex">\(f(x ; \theta)\)</span>, Fisher information is convex: on any segment <span class="arithmatex">\(f_{t}(x, \theta)=(1-t) f_{0}(x, \theta)+t f_{1}(x, \theta)\)</span>, <span class="arithmatex">\(0 \leqslant t \leqslant 1\)</span>,</p>
<div class="arithmatex">\[
I\left(f_{t} ; \theta\right)=\int \frac{\left[\partial / \partial \theta f_{t}(x ; \theta)\right]^{2}}{f_{t}(x ; \theta)} d x
\]</div>
<p>is a convex function of <span class="arithmatex">\(t\)</span> according to Lemma 4.4.4.
Clearly, <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(\bar{F}\)</span> have the same Fisher information for scale, and it follows that</p>
<div class="arithmatex">\[
I(\bar{F} ; \sigma) \leqslant I(F ; \sigma)=I(\bar{F} ; \sigma)
\]</div>
<p>Hence it suffices to consider symmetric distributions <span class="arithmatex">\(F\)</span> when minimizing Fisher information for scale.</p>
<p>Then <span class="arithmatex">\(Y_{t}=\log \left|X_{t}\right|\)</span> is a sufficient statistic for <span class="arithmatex">\(X_{t}\)</span>, and it has the distribution function <span class="arithmatex">\(F^{*}(y-\tau)\)</span>, where</p>
<div class="arithmatex">\[
F^{*}(y)=F\left(e^{y}\right)-F\left(-e^{y}\right)
\]</div>
<p>and</p>
<div class="arithmatex">\[
\tau=\log \sigma
\]</div>
<p>The corresponding density is</p>
<div class="arithmatex">\[
f^{*}(y)=2 e^{y} f\left(e^{y}\right)
\]</div>
<p>Note that Fisher information for scale <span class="arithmatex">\(\sigma\)</span></p>
<div class="arithmatex">\[
I(F ; \sigma)=\frac{1}{\sigma^{2}} \int\left[-x \frac{f^{\prime}(x)}{f(x)}-1\right]^{2} f(x) d x
\]</div>
<p>agrees, apart from the factor <span class="arithmatex">\(1 / \sigma^{2}\)</span>, with Fisher information for location <span class="arithmatex">\(\tau\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
I\left(F^{*} ; \tau\right) &amp; =\int\left[\frac{d}{d y} \log f^{*}(y)\right]^{2} f^{*}(y) d y \\
&amp; =\int\left[-x \frac{f^{\prime}(x)}{f(x)}-1\right]^{2} f(x) d x
\end{aligned}
\]</div>
<p>Thus minimizing <span class="arithmatex">\(I\left(F^{*} ; \tau\right)\)</span> is equivalent to minimizing <span class="arithmatex">\(\sigma^{2} I(F ; \sigma)\)</span>; for reasons of scale invariance we should prefer this latter expression to <span class="arithmatex">\(I(F ; \sigma)\)</span> anyway.</p>
<p>Moreover, if a set <span class="arithmatex">\(\mathscr{P}\)</span> of distributions is convex, then the transformed set <span class="arithmatex">\(\mathscr{P}^{*}=\left\{F^{*} \mid F \in \mathscr{P}\right\}\)</span> is also convex, and the methods and results of Sections 4.4 and 4.5 apply to <span class="arithmatex">\(\mathscr{P}^{*}\)</span>. In particular, as <span class="arithmatex">\(\varepsilon\)</span>-contamination in <span class="arithmatex">\(F\)</span> is transformed into <span class="arithmatex">\(\varepsilon\)</span>-contamination in <span class="arithmatex">\(F^{*}\)</span>, the treatment of the gross error model goes through without change. For the other neighborhoods some more care is needed.</p>
<p>We consider only the <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal case. Let <span class="arithmatex">\(\varphi\)</span> be the standard normal density; then</p>
<div class="arithmatex">\[
\varphi^{*}(y)=\sqrt{\frac{2}{\pi}} \exp \left(y-\frac{1}{2} e^{2 y}\right)
\]</div>
<p>thus</p>
<div class="arithmatex">\[
-\log \varphi^{*}(y)=\frac{1}{2} e^{2 y}-y+\frac{1}{2} \log \left(\frac{1}{2} \pi\right)
\]</div>
<p>is convex, and</p>
<div class="arithmatex">\[
\left[-\log \varphi^{*}(y)\right]^{\prime}=e^{2 y}-1
\]</div>
<p>is monotone.</p>
<p>Example 4.5.2 now shows how to find a distribution minimizing Fisher information. We have to distinguish two cases.</p>
<p>Case A. Large <span class="arithmatex">\(\varepsilon\)</span>. Define two numbers <span class="arithmatex">\(y_{0} \leqslant y_{1}\)</span> by</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; e^{2 y_{0}}-1=-k \\
&amp; e^{2 y_{1}}-1=k
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(k&lt;1\)</span> is related to <span class="arithmatex">\(\varepsilon\)</span> by</p>
<div class="arithmatex">\[
\int_{y_{0}}^{y_{1}} \varphi^{*}(y) d y+\frac{\varphi^{*}\left(y_{0}\right)+\varphi^{*}\left(y_{1}\right)}{k}=\frac{1}{1-\varepsilon}
\]</div>
<p>The least informative element of <span class="arithmatex">\(\mathscr{P}^{*}\)</span> then has the density</p>
<div class="arithmatex">\[
\begin{array}{rlrl}
f_{0}^{*}(y) &amp; =(1-\varepsilon) \varphi^{*}\left(y_{0}\right) e^{k\left(y-y_{0}\right)}, &amp; &amp; \text { for } y&lt;y_{0} \\
&amp; =(1-\varepsilon) \varphi^{*}(y), &amp; &amp; \text { for } y_{0} \leqslant y \leqslant y_{1} \\
&amp; =(1-\varepsilon) \varphi^{*}\left(y_{1}\right) e^{-k\left(y-y_{1}\right)}, &amp; &amp; \text { for } y&gt;y_{1}
\end{array}
\]</div>
<p>If we transform these equations back into <span class="arithmatex">\(x\)</span>-space, we obtain, instead of (6.10) to (6.12),</p>
<div class="arithmatex">\[
\begin{aligned}
x_{0}^{2} &amp; =(1-k)^{+}, \\
x_{1}^{2} &amp; =1+k, \\
2 \int_{x_{0}}^{x_{1}} \varphi(x) d x+\frac{2 x_{0} \varphi\left(x_{0}\right)+2 x_{1} \varphi\left(x_{1}\right)}{x_{1}^{2}-1} &amp; =\frac{1}{1-\varepsilon} \\
f_{0}(x) &amp; =(1-\varepsilon) \varphi\left(x_{0}\right)\left(\frac{x_{0}}{|x|}\right)^{\left(x_{0}^{2}\right)}, &amp; &amp; \text { for }|x|&lt;x_{0} \\
&amp; =(1-\varepsilon) \varphi(x), &amp; &amp; \text { for } x_{0} \leqslant|x| \leqslant x_{1} \\
&amp; =(1-\varepsilon) \varphi\left(x_{1}\right)\left(\frac{x_{1}}{|x|}\right)^{\left(x_{1}^{2}\right)}, &amp; &amp; \text { for }|x|&gt;x_{1}
\end{aligned}
\]</div>
<p>Case B. Small <span class="arithmatex">\(\varepsilon\)</span> In this case, the left boundary point is <span class="arithmatex">\(y_{0}=-\infty\)</span>, and correspondingly <span class="arithmatex">\(x_{0}=0\)</span>. Nothing else is changed, and formulas (6.13) to (6.15) remain valid as they stand (with <span class="arithmatex">\(k \geqslant 1\)</span> ).</p>
<p>Note that Case A yields a highly pathological least informative distribution <span class="arithmatex">\(F_{0}\)</span>; its density is <span class="arithmatex">\(\infty\)</span> at <span class="arithmatex">\(x=0\)</span>. In Case B, <span class="arithmatex">\(F_{0}\)</span> corresponds to a distribution that is normal in the middle and behaves like a <span class="arithmatex">\(t\)</span>-distribution with <span class="arithmatex">\(k=x_{1}^{2}-1 \geqslant 1\)</span> degrees of freedom in the tails. The boundary case between Cases A and B corresponds to <span class="arithmatex">\(x_{0}=0, x_{1}=\sqrt{2}\)</span>, and <span class="arithmatex">\(\varepsilon=0.205\)</span>. Exhibit 5.6 .1 shows some numerical results.</p>
<p>We now determine the asymptotically efficient <span class="arithmatex">\(M\)</span> - and <span class="arithmatex">\(L\)</span>-estimates of scale for these least informative distributions (cf. Section 5.5). The efficient <span class="arithmatex">\(M\)</span>-estimate (2.1) of scale is defined by</p>
<div class="arithmatex">\[
\begin{aligned}
\chi(x)=-x \frac{f_{0}^{\prime}(x)}{f_{0}(x)}-1 &amp; =x_{0}^{2}-1, &amp; &amp; \text { for }|x|&lt;x_{0} \\
&amp; =x^{2}-1, &amp; &amp; \text { for } x_{0} \leqslant|x| \leqslant x_{1} \\
&amp; =x_{1}^{2}-1, &amp; &amp; \text { for }|x|&gt;x_{1}
\end{aligned}
\]</div>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(x_{0}\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(x_{1}\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(F_{0}\left(-x_{0}\right)\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(F_{0}\left(-x_{1}\right)\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(1 / I\left(F_{0}^{*}\right)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.50</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2.88</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.002</td>
<td style="text-align: center;">0.52</td>
</tr>
<tr>
<td style="text-align: center;">0.002</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2.70</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">0.53</td>
</tr>
<tr>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2.46</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.009</td>
<td style="text-align: center;">0.56</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2.27</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.016</td>
<td style="text-align: center;">0.60</td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2.07</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.029</td>
<td style="text-align: center;">0.66</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.81</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.059</td>
<td style="text-align: center;">0.81</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.62</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">1.02</td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.50</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.132</td>
<td style="text-align: center;">1.23</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.42</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;">1.45</td>
</tr>
<tr>
<td style="text-align: center;">0.205</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.414</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.165</td>
<td style="text-align: center;">1.472</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">1.37</td>
<td style="text-align: center;">0.388</td>
<td style="text-align: center;">0.182</td>
<td style="text-align: center;">1.72</td>
</tr>
<tr>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">1.34</td>
<td style="text-align: center;">0.357</td>
<td style="text-align: center;">0.192</td>
<td style="text-align: center;">1.98</td>
</tr>
<tr>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">1.28</td>
<td style="text-align: center;">0.313</td>
<td style="text-align: center;">0.210</td>
<td style="text-align: center;">2.82</td>
</tr>
<tr>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">1.23</td>
<td style="text-align: center;">0.299</td>
<td style="text-align: center;">0.223</td>
<td style="text-align: center;">4.16</td>
</tr>
<tr>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">1.16</td>
<td style="text-align: center;">0.267</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">8.72</td>
</tr>
<tr>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">1.09</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.246</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
</tbody>
</table>
<p>Exhibit 5.6.1 The <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions that are least favorable for scale.</p>
<p>The efficient <span class="arithmatex">\(L\)</span>-estimate [(3.1) with <span class="arithmatex">\(q=2\)</span> ] is a kind of trimmed variance, in Case A trimmed also on the inside; its weight density is given by</p>
<div class="arithmatex">\[
\begin{aligned}
m(t) &amp; =\frac{2}{I\left(F_{0}^{*}, \tau\right)}, &amp; &amp; \text { for } F_{0}\left(x_{0}\right)&lt;t&lt;F_{0}\left(x_{1}\right) \\
&amp; =0, &amp; &amp; \text { and for } F_{0}\left(-x_{1}\right)&lt;t&lt;F_{0}\left(-x_{0}\right) \\
&amp; \text { otherwise. }
\end{aligned}
\]</div>
<p>The limiting case <span class="arithmatex">\(\varepsilon \rightarrow 1\)</span> leads to an interesting nontrivial estimate, just as in the location case: the limiting <span class="arithmatex">\(M\)</span> - and <span class="arithmatex">\(L\)</span>-estimates of <span class="arithmatex">\(\tau\)</span> then coincide with the median of <span class="arithmatex">\(\left\{\log \left|x_{i}\right|\right\}\)</span>, so the corresponding estimate of <span class="arithmatex">\(\sigma\)</span> is the median of <span class="arithmatex">\(\left\{\left|x_{i}\right|\right\}\)</span>. Hence the median absolute deviation [cf. (1.4), Example 2.3, and Example 3.4] is the candidate for being the "most robust estimate of scale."</p>
<p>Note that the above estimates (6.16) and (6.17) are biased when applied to normal data; in order to make them asymptotically unbiased at <span class="arithmatex">\(\Phi\)</span>, we have to divide them by a suitable constant, namely <span class="arithmatex">\(S(\Phi)\)</span> (see Exhibits 5.7.1 to 5.7.3 for these constants). Equivalently, we could replace the subtractive constant 1 in (6.16) by a different number <span class="arithmatex">\(\beta\)</span> such that <span class="arithmatex">\(E_{\Phi} \chi=0\)</span>.</p>
<h1 id="57-minimax-properties">5.7 MINIMAX PROPERTIES</h1>
<p>The general results of Section 4.6 show that the <span class="arithmatex">\(M\)</span>-estimate determined in the preceding section is minimax with regard to asymptotic variance for the collection of <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions satisfying <span class="arithmatex">\(S(F)=1\)</span>, that is,</p>
<div class="arithmatex">\[
\int \chi(x) F(d x)=0
\]</div>
<p>This is a rather restrictive condition, particularly in Case B, where <span class="arithmatex">\(x_{0}=0\)</span> and <span class="arithmatex">\(x_{1}&gt;\sqrt{2}\)</span>; it means that those and only those distributions <span class="arithmatex">\(F=(1-\varepsilon) \Phi\)</span> <span class="arithmatex">\(+\varepsilon H\)</span> that put all their contaminating mass <span class="arithmatex">\(\varepsilon H\)</span> outside of <span class="arithmatex">\(\left[-x_{1}, x_{1}\right]\)</span> are admitted for competition. For any such distribution the asymptotic behavior of <span class="arithmatex">\(S\)</span> is the same:</p>
<div class="arithmatex">\[
\begin{aligned}
S(F) &amp; =S\left(F_{0}\right)=1 \\
A(F, S) &amp; =A\left(F_{0}, S\right)=\frac{1}{I\left(F_{0} ; 1\right)}
\end{aligned}
\]</div>
<p>Is it possible to remove this inconvenient condition (7.1)? We have the partial answer that this is indeed the case, provided <span class="arithmatex">\(\varepsilon\)</span> is sufficiently small ( <span class="arithmatex">\(\varepsilon&lt;0.04\)</span> and thus <span class="arithmatex">\(x_{1} \geqslant 1.88\)</span> suffices); it would be interesting to know the precise range of <span class="arithmatex">\(\varepsilon\)</span>-values for which it is true.</p>
<p>The point of the whole problem is, of course, that we defined our asymptotic loss as <span class="arithmatex">\(A(F, S) / S(F)^{2}\)</span>. Thus if we move some contamination from the outside to the inside of <span class="arithmatex">\(\left[-x_{1}, x_{1}\right]\)</span>, we decrease both the numerator and the denominator, and it is not evident whether the quotient decreases or increases.</p>
<p>From the influence function (2.2) we obtain that</p>
<div class="arithmatex">\[
\frac{S(F)^{2}}{A(F, S)}=\frac{\left[\int \chi^{\prime}(x / S)(x / S) F(d x)\right]^{2}}{\int \chi(x / S)^{2} F(d x)}
\]</div>
<p>with the side condition (determining <span class="arithmatex">\(S\)</span> )</p>
<div class="arithmatex">\[
\int \chi\left(\frac{x}{S}\right) f(d x)=0
\]</div>
<p>where</p>
<div class="arithmatex">\[
\begin{aligned}
\chi(x) &amp; =x^{2}-1, &amp; &amp; \text { for }|x| \leqslant x_{1} \\
&amp; =x_{1}^{2}-1, &amp; &amp; \text { for }|x|&gt;x_{1} \geqslant \sqrt{2}
\end{aligned}
\]</div>
<p>We have to show that <span class="arithmatex">\(F_{0}\)</span> minimizes (7.2) among all</p>
<div class="arithmatex">\[
F \in \mathscr{P}_{\varepsilon}=\{F \mid F=(1-\varepsilon) \Phi+\varepsilon H, H \in \mathscr{P} \mathbb{R}\}
\]</div>
<p>not only among those <span class="arithmatex">\(F\)</span> satisfying (7.1).
We first note that the subsets of <span class="arithmatex">\(\mathscr{P}_{\varepsilon}\)</span> for which <span class="arithmatex">\(S(F)\)</span> has a given fixed value are convex, and that on each of them (7.2) is a convex function of <span class="arithmatex">\(F\)</span> (Lemma 4.4.4).</p>
<p>Moreover, if we keep <span class="arithmatex">\(S(F)\)</span> fixed, then (7.2) is minimized by a contamination <span class="arithmatex">\(\varepsilon H\)</span> sitting on <span class="arithmatex">\(\{0\} \cup\left[-x_{1}, x_{1}\right]^{c}\)</span>. The intuitive reason for this is that such a contamination evidently minimizes the numerator under the side condition <span class="arithmatex">\(S(F)=\)</span> const., and it also maximizes the variance of <span class="arithmatex">\(\chi(x / S)\)</span>, that is, the denominator, as it sits on the extreme values of <span class="arithmatex">\(\chi\)</span> [note that <span class="arithmatex">\(S(F) \leqslant 1]\)</span>. It is not difficult to make this intuitive reasoning precise by a variational argument (in view of convexity, local properties suffice); the details are left to the reader.</p>
<p>It is convenient to substitute</p>
<div class="arithmatex">\[
\chi(x)=\psi(x)^{2}-1
\]</div>
<p>then (7.2) and (7.3) can be rewritten as</p>
<div class="arithmatex">\[
\begin{gathered}
\frac{S(F)^{2}}{A(F, S)}=\frac{\left[\int_{-S x_{1}}^{S x_{1}}(x / S)^{2} F(d x)\right]^{2}}{\int \psi(x / S)^{4} F(d x)-1} \\
\int \psi\left(\frac{x}{S}\right)^{2} F(d x)=1
\end{gathered}
\]</div>
<p>As it suffices to minimize (7.5) over contaminations sitting on <span class="arithmatex">\(\{0\} \cup\)</span> <span class="arithmatex">\(\left[-x_{1}, x_{1}\right]^{\varepsilon}\)</span>, we now assume that <span class="arithmatex">\(\varepsilon H\)</span> puts mass <span class="arithmatex">\(\varepsilon-\varepsilon_{1}\)</span> on <span class="arithmatex">\(\{0\}\)</span>, and mass <span class="arithmatex">\(\varepsilon_{1}\)</span> on <span class="arithmatex">\(\left[-x_{1}, x_{1}\right]^{\varepsilon}\)</span>. then (7.5) and (7.6) are further transformed into</p>
<div class="arithmatex">\[
\begin{gathered}
\frac{S(F)^{2}}{A(F, S)}=\frac{\left[(1-\varepsilon) \int_{-S x_{1}}^{S x_{1}}(x / S)^{2} \Phi(d x)\right]^{2}}{(1-\varepsilon) \int \psi(x / S)^{4} \Phi(d x)+\varepsilon_{1} x_{1}^{4}-1} \\
(1-\varepsilon) \int \psi\left(\frac{x}{S}\right)^{2} \Phi(d x)+\varepsilon_{1} x_{1}^{2}=1
\end{gathered}
\]</div>
<p>We now have to find out for which values of <span class="arithmatex">\(\varepsilon\)</span> the choice <span class="arithmatex">\(\varepsilon_{1}=\varepsilon\)</span> minimizes (7.7) subject to the side condition (7.8).</p>
<p>From (7.8) we can determine the derivative of <span class="arithmatex">\(S\)</span> with respect to <span class="arithmatex">\(\varepsilon_{1}\)</span>. If <span class="arithmatex">\(\varepsilon&lt;0.04\)</span>, we find (with the aid of some numerical calculations) that the numerator and denominator of (7.7) have a negative and a positive derivative with respect to <span class="arithmatex">\(\varepsilon_{1}\)</span>, respectively, and this is true over the entire range possible for <span class="arithmatex">\(S\)</span>. Hence for <span class="arithmatex">\(\varepsilon&lt;0.04\)</span> the minimum of (7.7) is reached at <span class="arithmatex">\(\varepsilon_{1}=\varepsilon\)</span>. For larger <span class="arithmatex">\(\varepsilon\)</span> the situation becomes more complicated, and we do not know whether the result remains true.</p>
<p>Exhibits 5.7.1 to 5.7.3 compare the asymptotic performances of several estimates of scale for a normal distribution, symmetrically <span class="arithmatex">\(\varepsilon\)</span>-contaminated near <span class="arithmatex">\(\pm \infty\)</span>. To facilitate comparisons, the values of <span class="arithmatex">\(x_{1}\)</span> in Exhibit 5.7.1 were adjusted so that the performance at the normal distribution agrees with that of an <span class="arithmatex">\(\alpha\)</span>-trimmed standard deviation. In Exhibits 5.7.1 and 5.7.2 the value <span class="arithmatex">\(\varepsilon_{\min }\)</span> indicates for which least informative distribution the estimate is asymptotically efficient (cf. Exhibit 5.6.1).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(S(F) / S(\Phi)\)</span> and <span class="arithmatex">\(A(F, \log S)\)</span> for</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(x_{1}\)</span> <br> <span class="arithmatex">\((\alpha)\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon_{\text {min }}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(S(\Phi)\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.20</td>
</tr>
<tr>
<td style="text-align: center;">2.370</td>
<td style="text-align: center;">0.0069</td>
<td style="text-align: center;">0.982</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.013</td>
<td style="text-align: center;">1.027</td>
<td style="text-align: center;">1.056</td>
<td style="text-align: center;">1.163</td>
<td style="text-align: center;">1.458</td>
<td style="text-align: center;">2.361</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">(0.01)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.530</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.697</td>
<td style="text-align: center;">1.138</td>
<td style="text-align: center;">3.677</td>
<td style="text-align: center;">38.14</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">2.130</td>
<td style="text-align: center;">0.016</td>
<td style="text-align: center;">0.964</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.011</td>
<td style="text-align: center;">1.022</td>
<td style="text-align: center;">1.046</td>
<td style="text-align: center;">1.128</td>
<td style="text-align: center;">1.323</td>
<td style="text-align: center;">1.690</td>
<td style="text-align: center;">3.045</td>
</tr>
<tr>
<td style="text-align: center;">(0.02)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.557</td>
<td style="text-align: center;">0.581</td>
<td style="text-align: center;">0.607</td>
<td style="text-align: center;">0.665</td>
<td style="text-align: center;">0.909</td>
<td style="text-align: center;">1.854</td>
<td style="text-align: center;">6.059</td>
<td style="text-align: center;">91.43</td>
</tr>
<tr>
<td style="text-align: center;">1.804</td>
<td style="text-align: center;">0.051</td>
<td style="text-align: center;">0.912</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.008</td>
<td style="text-align: center;">1.017</td>
<td style="text-align: center;">1.035</td>
<td style="text-align: center;">1.094</td>
<td style="text-align: center;">1.215</td>
<td style="text-align: center;">1.384</td>
<td style="text-align: center;">1.650</td>
</tr>
<tr>
<td style="text-align: center;">(0.05)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.640</td>
<td style="text-align: center;">0.654</td>
<td style="text-align: center;">0.668</td>
<td style="text-align: center;">0.698</td>
<td style="text-align: center;">0.810</td>
<td style="text-align: center;">1.110</td>
<td style="text-align: center;">1.741</td>
<td style="text-align: center;">3.525</td>
</tr>
<tr>
<td style="text-align: center;">1.555</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.824</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.007</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.028</td>
<td style="text-align: center;">1.075</td>
<td style="text-align: center;">1.165</td>
<td style="text-align: center;">1.276</td>
<td style="text-align: center;">1.419</td>
</tr>
<tr>
<td style="text-align: center;">(0.10)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.796</td>
<td style="text-align: center;">0.805</td>
<td style="text-align: center;">0.813</td>
<td style="text-align: center;">0.831</td>
<td style="text-align: center;">0.892</td>
<td style="text-align: center;">1.031</td>
<td style="text-align: center;">1.244</td>
<td style="text-align: center;">1.608</td>
</tr>
<tr>
<td style="text-align: center;">1.414</td>
<td style="text-align: center;">0.205</td>
<td style="text-align: center;">0.736</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.013</td>
<td style="text-align: center;">1.025</td>
<td style="text-align: center;">1.066</td>
<td style="text-align: center;">1.144</td>
<td style="text-align: center;">1.235</td>
<td style="text-align: center;">1.346</td>
</tr>
<tr>
<td style="text-align: center;">(0.149)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.989</td>
<td style="text-align: center;">0.995</td>
<td style="text-align: center;">1.001</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.056</td>
<td style="text-align: center;">1.146</td>
<td style="text-align: center;">1.269</td>
<td style="text-align: center;">1.449</td>
</tr>
<tr>
<td style="text-align: center;">1.311</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.642</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.012</td>
<td style="text-align: center;">1.024</td>
<td style="text-align: center;">1.061</td>
<td style="text-align: center;">1.131</td>
<td style="text-align: center;">1.212</td>
<td style="text-align: center;">1.308</td>
</tr>
<tr>
<td style="text-align: center;">(0.20)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.257</td>
<td style="text-align: center;">1.262</td>
<td style="text-align: center;">1.266</td>
<td style="text-align: center;">1.276</td>
<td style="text-align: center;">1.308</td>
<td style="text-align: center;">1.372</td>
<td style="text-align: center;">1.455</td>
<td style="text-align: center;">1.566</td>
</tr>
<tr>
<td style="text-align: center;">1.234</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.547</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.011</td>
<td style="text-align: center;">1.022</td>
<td style="text-align: center;">1.058</td>
<td style="text-align: center;">1.124</td>
<td style="text-align: center;">1.199</td>
<td style="text-align: center;">1.285</td>
</tr>
<tr>
<td style="text-align: center;">(0.25)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.630</td>
<td style="text-align: center;">1.633</td>
<td style="text-align: center;">1.637</td>
<td style="text-align: center;">1.645</td>
<td style="text-align: center;">1.669</td>
<td style="text-align: center;">1.718</td>
<td style="text-align: center;">1.778</td>
<td style="text-align: center;">1.855</td>
</tr>
</tbody>
</table>
<p>Exhlbl 5.7.1 Huber's scale; <span class="arithmatex">\(\int \chi[x / S(F)] F(d x)=0\)</span> with <span class="arithmatex">\(\chi\)</span> as in (6.16), <span class="arithmatex">\(x_{0}=0\)</span>; asymptotic values and asymptotic variances for far-out symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(S(F) / S(\Phi)\)</span> and <span class="arithmatex">\(A(F, \log S)\)</span> for</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\alpha\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon_{\text {min }}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(S(\Phi)\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.25</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.925</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.029</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.530</td>
<td style="text-align: center;">0.565</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.013</td>
<td style="text-align: center;">0.873</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.011</td>
<td style="text-align: center;">1.023</td>
<td style="text-align: center;">1.048</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.557</td>
<td style="text-align: center;">0.579</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.678</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.041</td>
<td style="text-align: center;">0.749</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.008</td>
<td style="text-align: center;">1.017</td>
<td style="text-align: center;">1.035</td>
<td style="text-align: center;">1.097</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.640</td>
<td style="text-align: center;">0.652</td>
<td style="text-align: center;">0.664</td>
<td style="text-align: center;">0.691</td>
<td style="text-align: center;">0.816</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.103</td>
<td style="text-align: center;">0.592</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.007</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.029</td>
<td style="text-align: center;">1.076</td>
<td style="text-align: center;">1.169</td>
<td style="text-align: center;">1.293</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.796</td>
<td style="text-align: center;">0.803</td>
<td style="text-align: center;">0.810</td>
<td style="text-align: center;">0.825</td>
<td style="text-align: center;">0.879</td>
<td style="text-align: center;">1.022</td>
<td style="text-align: center;">1.351</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.180</td>
<td style="text-align: center;">0.466</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.013</td>
<td style="text-align: center;">1.025</td>
<td style="text-align: center;">1.067</td>
<td style="text-align: center;">1.145</td>
<td style="text-align: center;">1.238</td>
<td style="text-align: center;">1.356</td>
<td style="text-align: center;">1.513</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.994</td>
<td style="text-align: center;">0.998</td>
<td style="text-align: center;">1.003</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.049</td>
<td style="text-align: center;">1.128</td>
<td style="text-align: center;">1.249</td>
<td style="text-align: center;">1.462</td>
<td style="text-align: center;">1.963</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.359</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.012</td>
<td style="text-align: center;">1.024</td>
<td style="text-align: center;">1.061</td>
<td style="text-align: center;">1.132</td>
<td style="text-align: center;">1.213</td>
<td style="text-align: center;">1.310</td>
<td style="text-align: center;">1.428</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.257</td>
<td style="text-align: center;">1.261</td>
<td style="text-align: center;">1.264</td>
<td style="text-align: center;">1.272</td>
<td style="text-align: center;">1.298</td>
<td style="text-align: center;">1.352</td>
<td style="text-align: center;">1.425</td>
<td style="text-align: center;">1.530</td>
<td style="text-align: center;">1.693</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.267</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.005</td>
<td style="text-align: center;">1.011</td>
<td style="text-align: center;">1.022</td>
<td style="text-align: center;">1.058</td>
<td style="text-align: center;">1.124</td>
<td style="text-align: center;">1.199</td>
<td style="text-align: center;">1.286</td>
<td style="text-align: center;">1.388</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.630</td>
<td style="text-align: center;">1.633</td>
<td style="text-align: center;">1.636</td>
<td style="text-align: center;">1.642</td>
<td style="text-align: center;">1.662</td>
<td style="text-align: center;">1.702</td>
<td style="text-align: center;">1.753</td>
<td style="text-align: center;">1.820</td>
<td style="text-align: center;">1.912</td>
</tr>
</tbody>
</table>
<p>Exhlbl 5.7.2 Trimmed standard deviations <span class="arithmatex">\(S(F)=\left[\int_{\alpha}^{1-\alpha} F^{-1}(t)^{2} d t\right]^{1 / 2}\)</span>; asymptotic values and asymptotic variances for far-out symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="arithmatex">\(S(F) / S(\Phi)\)</span> and <span class="arithmatex">\(A(F, \log S)\)</span> for</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\alpha\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(S(\Phi)\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">2.327</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.045</td>
<td style="text-align: center;">1.106</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.277</td>
<td style="text-align: center;">1.940</td>
<td style="text-align: center;">3.556</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">2.054</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.026</td>
<td style="text-align: center;">1.055</td>
<td style="text-align: center;">1.129</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">1.162</td>
<td style="text-align: center;">1.433</td>
<td style="text-align: center;">2.531</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.645</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">1.028</td>
<td style="text-align: center;">1.059</td>
<td style="text-align: center;">1.178</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.782</td>
<td style="text-align: center;">0.828</td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">1.008</td>
<td style="text-align: center;">1.786</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">1.282</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.009</td>
<td style="text-align: center;">1.018</td>
<td style="text-align: center;">1.037</td>
<td style="text-align: center;">1.102</td>
<td style="text-align: center;">1.243</td>
<td style="text-align: center;">1.475</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.791</td>
<td style="text-align: center;">0.808</td>
<td style="text-align: center;">0.827</td>
<td style="text-align: center;">0.867</td>
<td style="text-align: center;">1.026</td>
<td style="text-align: center;">1.548</td>
<td style="text-align: center;">3.465</td>
<td style="text-align: center;"><span class="arithmatex">\(\infty\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">1.036</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.007</td>
<td style="text-align: center;">1.015</td>
<td style="text-align: center;">1.030</td>
<td style="text-align: center;">1.080</td>
<td style="text-align: center;">1.178</td>
<td style="text-align: center;">1.304</td>
<td style="text-align: center;">1.480</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.899</td>
<td style="text-align: center;">0.909</td>
<td style="text-align: center;">0.920</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">1.021</td>
<td style="text-align: center;">1.213</td>
<td style="text-align: center;">1.554</td>
<td style="text-align: center;">2.306</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0.841</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.013</td>
<td style="text-align: center;">1.026</td>
<td style="text-align: center;">1.069</td>
<td style="text-align: center;">1.150</td>
<td style="text-align: center;">1.247</td>
<td style="text-align: center;">1.367</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.081</td>
<td style="text-align: center;">1.088</td>
<td style="text-align: center;">1.095</td>
<td style="text-align: center;">1.110</td>
<td style="text-align: center;">1.160</td>
<td style="text-align: center;">1.268</td>
<td style="text-align: center;">1.425</td>
<td style="text-align: center;">1.672</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.674</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">1.006</td>
<td style="text-align: center;">1.012</td>
<td style="text-align: center;">1.024</td>
<td style="text-align: center;">1.062</td>
<td style="text-align: center;">1.134</td>
<td style="text-align: center;">1.217</td>
<td style="text-align: center;">1.316</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.361</td>
<td style="text-align: center;">1.366</td>
<td style="text-align: center;">1.371</td>
<td style="text-align: center;">1.382</td>
<td style="text-align: center;">1.417</td>
<td style="text-align: center;">1.488</td>
<td style="text-align: center;">1.583</td>
<td style="text-align: center;">1.713</td>
</tr>
</tbody>
</table>
<p>Exhibit 5.7.3 Interquantile distances; <span class="arithmatex">\(S(F)=\frac{1}{2}\left[F^{-1}(1-\alpha)-F^{-1}(\alpha)\right]\)</span>; asymptotic values and asymptotic variances for far-out symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination.</p>
<h1 id="chapter-6">CHAPTER 6</h1>
<h2 id="multiparameter-problems-in-particular-joint-estimation-of-location-and-scale">Multiparameter Problems, in Particular Joint Estimation of Location and Scale</h2>
<h3 id="61-general-remarks">6.1 GENERAL REMARKS</h3>
<p>We have already mentioned (Section 5.1) that <span class="arithmatex">\(M\)</span>-estimates of location in practice will have to be supplemented by a simultaneous estimate of scale, since they are not scale invariant [except the median, <span class="arithmatex">\(\psi(x)=\operatorname{sign}(x)\)</span> ]. Thus we are faced with a two-parameter problem.</p>
<p>The step going from one to two (or more) parameters is a troublesome one-we lose the technical advantages offered by the natural ordering of the real line, and proofs get more complicated.</p>
<p>L- and <span class="arithmatex">\(R\)</span>-estimates of location are scale invariant, so this difficulty does not exist. On the other hand they rely so heavily on ordering that they do not generalize well beyond one-parameter location or scale problems. In fact they lose their advantages, for example the simplicity of <span class="arithmatex">\(L\)</span>-estimates like the trimmed mean, or the existence of nonparametric confidence intervals for <span class="arithmatex">\(R\)</span>-estimates, and their computation is quite complicated.</p>
<p>We therefore deal exclusively with <span class="arithmatex">\(M\)</span>-estimates in this chapter. Sections 6.2 and 6.3 give some very general results (without proofs) on consistency and asymptotic normality of multiparameter <span class="arithmatex">\(M\)</span>-estimates; the remaining sections discuss simultaneous estimates of location and scale (the latter being considered as a nuisance parameter).</p>
<h3 id="62-consistency-of-m-estimates">6.2 CONSISTENCY OF M-ESTIMATES</h3>
<p>In this section we state two theorems on consistency of <span class="arithmatex">\(M\)</span>-estimates. The first one is concerned with estimates defined through a minimum property, the second one with estimates defined through a system of implicit equations. Proofs can be found in Huber (1967).</p>
<p>Case A. Estimates Defined Through a Minimum Property Assume that the parameter set <span class="arithmatex">\(\Theta\)</span> is a locally compact space with a countable base (e.g., an open subset of a Euclidean space), <span class="arithmatex">\((\mathscr{K}, \mathscr{Q}, P)\)</span> is a probability space, and <span class="arithmatex">\(\rho(x, \theta)\)</span> is some real-valued function on <span class="arithmatex">\(\mathscr{K} \times \Theta\)</span>.</p>
<p>Assume that <span class="arithmatex">\(x_{1}, x_{2}, \ldots\)</span> are independent random variables with values in <span class="arithmatex">\(\mathscr{K}\)</span>, having the common probability distribution <span class="arithmatex">\(P\)</span>. Let <span class="arithmatex">\(T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span> be any sequence of functions <span class="arithmatex">\(T_{n}: \mathscr{K}^{n} \rightarrow \Theta\)</span>, measurable or not, such that</p>
<div class="arithmatex">\[
\frac{1}{n} \sum_{i=1}^{n} \rho\left(x_{i}, T_{n}\right)-\inf _{\theta} \frac{1}{n} \sum_{i=1}^{n} \rho\left(x_{i}, \theta\right) \rightarrow 0
\]</div>
<p>almost surely (or in probability). In most cases the left-hand side of (2.1)-let us denote it by <span class="arithmatex">\(Z_{n}\)</span>-will be identically zero, but it is simpler to work with (2.1) than to add extraneous conditions only to guarantee the existence of a <span class="arithmatex">\(T_{n}\)</span> minimizing <span class="arithmatex">\(1 / n \sum \rho\left(x_{i}, \theta\right)\)</span>. Since <span class="arithmatex">\(Z_{n}\)</span> need not be measurable, we should more precisely speak of convergence in outer probability <span class="arithmatex">\(\left[P^{*}\left(\left|Z_{n}\right|&gt;\varepsilon\right) \rightarrow 0\right.\)</span> for all <span class="arithmatex">\(\left.\varepsilon\right]\)</span> instead of convergence in probability.</p>
<p>We now give sufficient conditions that each sequence <span class="arithmatex">\(T_{n}\)</span> satisfying (2.1) will converge almost surely (or in probability, respectively) to some constant <span class="arithmatex">\(\theta_{0}\)</span>, which is characterized below.</p>
<h1 id="assumptions_1">ASSUMPTIONS</h1>
<p>(A-1) For each fixed <span class="arithmatex">\(\theta \in \Theta, \rho(x, \theta)\)</span> is <span class="arithmatex">\(\mathscr{Q}\)</span>-measurable, and <span class="arithmatex">\(\rho\)</span> is separable in the sense of Doob; that is, there is a <span class="arithmatex">\(P\)</span>-null set <span class="arithmatex">\(N\)</span> and a countable subset <span class="arithmatex">\(\Theta^{\prime} \subset \Theta\)</span> such that, for every open set <span class="arithmatex">\(U \subset \Theta\)</span> and every closed interval <span class="arithmatex">\(A\)</span>, the sets</p>
<div class="arithmatex">\[
\{x \mid \rho(x, \theta) \in A, \forall \theta \in U\}, \quad\{x \mid \rho(x, \theta) \in A, \forall \theta \in U \cap \Theta^{\prime}\}
\]</div>
<p>differ by at most a subset of <span class="arithmatex">\(N\)</span>.
This assumption ensures measurability of the infima and limits occurring in (A-2) and (A-5). For a fixed <span class="arithmatex">\(P, \rho\)</span> might always be replaced by a separable version [see Doob (1953), p. 56 ff].
(A-2) The function <span class="arithmatex">\(\rho\)</span> is a.s. lower semicontinuous in <span class="arithmatex">\(\theta\)</span>, that is,</p>
<div class="arithmatex">\[
\inf _{\theta^{\prime} \in U} \rho\left(x, \theta^{\prime}\right) \rightarrow \rho(x, \theta) \quad \text { a.s. }
\]</div>
<p>as the neighborhood <span class="arithmatex">\(U\)</span> of <span class="arithmatex">\(\theta\)</span> shrinks to <span class="arithmatex">\(\{\theta\}\)</span>.</p>
<p>(A-3) There is a measurable function <span class="arithmatex">\(a(x)\)</span> such that</p>
<div class="arithmatex">\[
\begin{array}{ll}
E(\rho(x, \theta)-a(x))^{-}&lt;\infty, &amp; \text { for all } \theta \in \Theta \\
E(\rho(x, \theta)-a(x))^{+}&lt;\infty, &amp; \text { for some } \theta \in \Theta
\end{array}
\]</div>
<p>Thus <span class="arithmatex">\(\gamma(\theta)=E(\rho(x, \theta)-a(x))\)</span> is well defined for all <span class="arithmatex">\(\theta\)</span>.
(A-4) There is a <span class="arithmatex">\(\theta_{0} \in \Theta\)</span> such that <span class="arithmatex">\(\gamma(\theta)&gt;\gamma\left(\theta_{0}\right)\)</span> for all <span class="arithmatex">\(\theta \neq \theta_{0}\)</span>.
If <span class="arithmatex">\(\Theta\)</span> is not compact, let <span class="arithmatex">\(\infty\)</span> denote the point at infinity in its one-point compactification.
(A-5) There is a continuous function <span class="arithmatex">\(b(\theta)&gt;0\)</span> such that:
(i)</p>
<div class="arithmatex">\[
\inf _{\theta \in \Theta} \frac{\rho(x, \theta)-a(x)}{b(\theta)} \geqslant h(x)
\]</div>
<p>for some integrable function <span class="arithmatex">\(h\)</span>.
(ii)</p>
<div class="arithmatex">\[
\liminf _{\theta \rightarrow \infty} b(\theta)&gt;\gamma\left(\theta_{0}\right)
\]</div>
<div class="arithmatex">\[
E\left\{\liminf _{\theta \rightarrow \infty} \frac{\rho(x, \theta)-a(x)}{b(\theta)}\right\} \geqslant 1
\]</div>
<p>If <span class="arithmatex">\(\Theta\)</span> is compact, then (ii) and (iii) are redundant.
Example 2.1 Let <span class="arithmatex">\(\Theta=\mathscr{C}\)</span> be the real axis, and let <span class="arithmatex">\(P\)</span> be any probability distribution having a unique median <span class="arithmatex">\(\theta_{0}\)</span>. Then (A-1) to (A-5) are satisfied for <span class="arithmatex">\(\rho(x, \theta)=|x-\theta|, a(x)=|x|, b(\theta)=|\theta|+1, h(x)=-1\)</span>. This will imply that the sample median is a consistent estimate of the median.</p>
<p>Taken together (A-2), (A-3), and (A-5) (i) imply by monotone convergence the following strengthened version of (A-2).
(A-2') As the neighborhood <span class="arithmatex">\(U\)</span> of <span class="arithmatex">\(\theta\)</span> shrinks to <span class="arithmatex">\(\{\theta\}\)</span>,</p>
<div class="arithmatex">\[
E \inf _{\theta^{\prime} \in U}\left\{\rho\left(x, \theta^{\prime}\right)-a(x)\right\} \rightarrow E\{\rho(x, \theta)-a(x)\}
\]</div>
<p>Note that the set <span class="arithmatex">\(\{\theta \in \Theta|E[|\rho(x, \theta)-a(x)|]&lt;\infty\}\)</span> is independent of the particular choice of <span class="arithmatex">\(a(x)\)</span>; if there is an <span class="arithmatex">\(a(x)\)</span> satisfying (A-3), then we might take <span class="arithmatex">\(a(x)=\rho\left(x, \theta_{0}\right)\)</span>.</p>
<p>For the sake of simplicity we absorb <span class="arithmatex">\(a(x)\)</span> into <span class="arithmatex">\(\rho(x, \theta)\)</span> from now on.</p>
<p>LEMMA 2.1 If (A-1), (A-3), and (A-5) hold, then there is a compact set <span class="arithmatex">\(C \subset \Theta\)</span> such that every sequence <span class="arithmatex">\(T_{n}\)</span> satisfying (2.1) ultimately almost surely stays in <span class="arithmatex">\(C\)</span> (or, with probability tending to 1 , respectively).</p>
<p>THEOREM 2.2 If (A-1), (A-2'), (A-3), and (A-4) hold, then every sequence <span class="arithmatex">\(T_{n}\)</span> satisfying (2.1) and the conclusion of Lemma 2.1 converges to <span class="arithmatex">\(\theta_{0}\)</span> almost surely (or, in probability, respectively).</p>
<p>Quite often (A-5) is not satisfied-in particular, if location and scale are estimated simultaneously-but the conclusion of Lemma 2.1 can be verified without too much trouble by ad hoc methods. I do not know of any fail-safe replacement for (A-5).</p>
<p>In the location-scale case this problem poses itself as follows. To be specific take the maximum likelihood estimate of <span class="arithmatex">\(\theta=(\xi, \sigma), \sigma&gt;0\)</span>, based on a density <span class="arithmatex">\(f_{0}\)</span> (the true underlying distribution <span class="arithmatex">\(P\)</span> may be different). Then</p>
<div class="arithmatex">\[
\rho(x, \theta)=\rho(x ; \xi, \sigma)=\log \sigma-\log f_{0}\left(\frac{x-\xi}{\sigma}\right)
\]</div>
<p>The trouble is that, if <span class="arithmatex">\(\theta\)</span> tends to "infinity," that is, to the boundary <span class="arithmatex">\(\sigma=0\)</span> by letting <span class="arithmatex">\(\xi=x, \sigma \rightarrow 0\)</span>, then <span class="arithmatex">\(\rho \rightarrow-\infty\)</span>. If <span class="arithmatex">\(P\)</span> is continuous, so that the probability of ties between the <span class="arithmatex">\(x_{i}\)</span> 's is zero, the following trick helps: take pairs <span class="arithmatex">\(y_{n}=\left(x_{2 n-1}, x_{2 n}\right)\)</span> of the original observations as our new observations. Then the corresponding <span class="arithmatex">\(\rho_{2}\)</span>,</p>
<div class="arithmatex">\[
\rho_{2}(y, \theta)=\rho\left(x_{1} ; \xi, \sigma\right)+\rho\left(x_{2} ; \xi, \sigma\right)
\]</div>
<p>will avoid the above-mentioned difficulty. Somewhat more generally we are saved if we can show directly that the ML estimate <span class="arithmatex">\(\hat{\theta}_{n}=\left(\hat{\xi}_{n}, \hat{\sigma}_{n}\right)\)</span> ultimately satisfies <span class="arithmatex">\(\hat{\sigma}_{n} \geqslant \delta&gt;0\)</span> for some <span class="arithmatex">\(\delta\)</span>. (This again is tricky if the true underlying distribution is discontinuous and <span class="arithmatex">\(f_{0}\)</span> has very long tails.)
Case B. Estimates Defined Through Implicit Equations Let <span class="arithmatex">\(\Theta\)</span> be locally compact with a countable base, let <span class="arithmatex">\((\mathscr{R}, \mathscr{Q}, P)\)</span> be a probability space, and let <span class="arithmatex">\(\psi(x, \theta)\)</span> be some function on <span class="arithmatex">\(\mathscr{R} \times \Theta\)</span> with values in <span class="arithmatex">\(m\)</span>-dimensional Euclidean space <span class="arithmatex">\(\mathbb{R}^{m}\)</span>.</p>
<p>Assume that <span class="arithmatex">\(x_{1}, x_{2}, \ldots\)</span> are independent random variables with values in <span class="arithmatex">\(\mathscr{R}\)</span>, having the common probability distribution <span class="arithmatex">\(P\)</span>. We intend to give sufficient conditions that any sequence of functions <span class="arithmatex">\(T_{n}: \mathbb{X}^{n} \rightarrow \Theta\)</span> such that</p>
<div class="arithmatex">\[
\frac{1}{n} \sum_{1}^{n} \psi\left(x_{i} ; T_{n}\right) \rightarrow 0
\]</div>
<p>almost surely (or in probability) converges almost surely (or in probability) to some constant <span class="arithmatex">\(\theta_{0}\)</span>.</p>
<p>If <span class="arithmatex">\(\Theta\)</span> is an open subset of <span class="arithmatex">\(\mathbb{R}^{m}\)</span>, and if <span class="arithmatex">\(\psi(x, \theta)=(\partial / \partial \theta) \log f(x, \theta)\)</span> for a differentiable parametric family of probability densities, then the ML estimate of course will satisfy (2.8). However, our <span class="arithmatex">\(\psi\)</span> need not be a total differential. (This is important; for instance, it allows us to piece together joint estimates of location and scale from two essentially unrelated <span class="arithmatex">\(M\)</span> estimates of location and scale, respectively.)</p>
<h1 id="assumptions_2">ASSUMPTIONS</h1>
<p>(B-1) For each fixed <span class="arithmatex">\(\theta \in \Theta, \psi(x, \theta)\)</span> is <span class="arithmatex">\(\mathcal{G}\)</span>-measurable in <span class="arithmatex">\(x\)</span>, and <span class="arithmatex">\(\psi\)</span> is separable (see A-1).
(B-2) The function <span class="arithmatex">\(\psi\)</span> is a.s. continuous in <span class="arithmatex">\(\theta\)</span> :</p>
<div class="arithmatex">\[
\lim _{\theta^{\prime} \rightarrow \theta}\left|\psi\left(x, \theta^{\prime}\right)-\psi(x, \theta)\right|=0 \quad \text { a.s. }
\]</div>
<p>(B-3) The expected value <span class="arithmatex">\(\lambda(\theta)=E \psi(x, \theta)\)</span> exists for all <span class="arithmatex">\(\theta \in \Theta\)</span>, and has a unique zero at <span class="arithmatex">\(\theta=\theta_{0}\)</span>.
(B-4) There exists a continuous function <span class="arithmatex">\(b(\theta)\)</span> that is bounded away from zero, <span class="arithmatex">\(b(\theta) \geqslant b_{0}&gt;0\)</span>, such that</p>
<div class="arithmatex">\[
\sup _{\theta} \frac{|\psi(x, \theta)|}{b(\theta)} \text { is integrable }
\]</div>
<div class="arithmatex">\[
\liminf _{\theta \rightarrow \infty} \frac{|\lambda(\theta)|}{b(\theta)} \geqslant 1
\]</div>
<div class="arithmatex">\[
E\left[\limsup _{\theta \rightarrow \infty} \frac{|\psi(x, \theta)-\lambda(\theta)|}{b(\theta)}&lt;1\right]
\]</div>
<p>In view of (B-4) (i), (B-2) can be strengthened to
(B-2') As the neighborhood <span class="arithmatex">\(U\)</span> of <span class="arithmatex">\(\theta\)</span> shrinks to <span class="arithmatex">\(\{\theta\}\)</span>,</p>
<div class="arithmatex">\[
E\left[\sup _{\theta^{\prime} \in U}\left|\psi\left(x, \theta^{\prime}\right)-\psi(x, \theta)\right|\right] \rightarrow 0
\]</div>
<p>It follows from (B-2') that <span class="arithmatex">\(\lambda\)</span> is continuous. Moreover, if there is a function <span class="arithmatex">\(b\)</span> satisfying (B-4), we can take</p>
<div class="arithmatex">\[
b(\theta)=\max \left(|\lambda(\theta)|, b_{0}\right)
\]</div>
<p>LEMMA 2.3 If (B-1) and (B-4) hold, then there is a compact set <span class="arithmatex">\(C \subset \Theta\)</span> such that any sequence <span class="arithmatex">\(T_{n}\)</span> satisfying (2.8) a.s. ultimately stays in <span class="arithmatex">\(C\)</span>.
THEOREM 2.4 If (B-1), (B-2'), and (B-3) hold, then every sequence <span class="arithmatex">\(T_{n}\)</span> satisfying (2.8) and the conclusion of Lemma 2.3 converges to <span class="arithmatex">\(\theta_{0}\)</span> almost surely. An analogous statement is true for convergence in probability.</p>
<h1 id="63-asymptotic-normality-of-m-estimates">6.3 ASYMPTOTIC NORMALITY OF M-ESTIMATES</h1>
<p>In the following <span class="arithmatex">\(\Theta\)</span> is an open subset of <span class="arithmatex">\(m\)</span>-dimensional Euclidean space <span class="arithmatex">\(\mathbb{R}^{m},(\mathscr{H}, \mathscr{Q}, P)\)</span> is a probability space, and <span class="arithmatex">\(\psi: \mathscr{H} \times \Theta \rightarrow \mathbb{R}^{m}\)</span> is some function.</p>
<p>Assume that <span class="arithmatex">\(x_{1}, x_{2}, \ldots\)</span> are independent random variables with values in <span class="arithmatex">\(\mathscr{H}\)</span> and common distribution <span class="arithmatex">\(P\)</span>. We give sufficient conditions to ensure that every sequence <span class="arithmatex">\(T_{n}=T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span> satisfying</p>
<div class="arithmatex">\[
\frac{1}{\sqrt{n}} \sum \psi\left(x_{i}, T_{n}\right) \rightarrow 0
\]</div>
<p>in probability is asymptotically normal; we assume that consistency of <span class="arithmatex">\(T_{n}\)</span> has already been proved by some other means.</p>
<h2 id="assumptions_3">ASSUMPTIONS</h2>
<p>(N-1) For each fixed <span class="arithmatex">\(\theta \in \Theta, \psi(x, \theta)\)</span> is <span class="arithmatex">\(\mathscr{Q}\)</span>-measurable, and <span class="arithmatex">\(\psi\)</span> is separable [see the preceding section, (A-1)].</p>
<p>Put</p>
<div class="arithmatex">\[
\begin{aligned}
\lambda(\theta) &amp; =E \psi(x, \theta) \\
u(x, \theta, d) &amp; =\sup _{|\tau-\theta|&lt;d}|\psi(x, \tau)-\psi(x, \theta)| .
\end{aligned}
\]</div>
<p>Expectations are always taken with respect to the true underlying <span class="arithmatex">\(P\)</span>.
(N-2) There is a <span class="arithmatex">\(\theta_{0}\)</span> such that <span class="arithmatex">\(\lambda\left(\theta_{0}\right)=0\)</span>.
(N-3) There are strictly positive numbers <span class="arithmatex">\(a, b, c, d_{0}\)</span> such that
(i)</p>
<div class="arithmatex">\[
|\lambda(\theta)| \geqslant a\left|\theta-\theta_{0}\right|, \quad \text { for } \quad\left|\theta-\theta_{0}\right| \leqslant d_{0}
\]</div>
<p>(ii)</p>
<div class="arithmatex">\[
E u(x, \theta, d) \leqslant b d, \quad \text { for } \quad\left|\theta-\theta_{0}\right|+d \leqslant d_{0}
\]</div>
<p>(iii)</p>
<div class="arithmatex">\[
E\left[U(x, \theta, d)^{2}\right] \leqslant c d \quad \text { for } \quad\left|\theta-\theta_{0}\right|+d \leqslant d_{0}
\]</div>
<p>Here, <span class="arithmatex">\(|\theta|\)</span> denotes any norm equivalent to Euclidean norm. Condition (iii) is somewhat stronger than needed; the proof can still be pushed through with <span class="arithmatex">\(E\left[u(x, \theta, d)^{2}\right] \leqslant o\left(|\log d|^{-1}\right)\)</span>.
(N-4) The expectation <span class="arithmatex">\(E\left(\left|\psi\left(x, \theta_{0}\right)\right|^{2}\right)\)</span> is nonzero and finite.
THEOREM 3.1 Assume that ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ) to ( <span class="arithmatex">\(\mathrm{N}-4\)</span> ) hold and that <span class="arithmatex">\(T_{n}\)</span> satisfies (3.1). If <span class="arithmatex">\(P\left(\left|T_{n}-\theta_{0}\right| \leqslant d_{0}\right) \rightarrow 1\)</span>, then</p>
<div class="arithmatex">\[
\frac{1}{\sqrt{n}} \sum_{i=1}^{n} \psi\left(x_{i}, \theta_{0}\right)+\sqrt{n} \lambda\left(T_{n}\right) \rightarrow 0
\]</div>
<p>in probability.</p>
<h1 id="proof-see-huber-1967">Proof See Huber (1967).</h1>
<p>COROLLARY 3.2 In addition to the assumptions of Theorem 3.1, assume that <span class="arithmatex">\(\lambda\)</span> has a nonsingular derivative matrix <span class="arithmatex">\(\Lambda\)</span> at <span class="arithmatex">\(\theta_{0}\)</span> [i.e., <span class="arithmatex">\(\left.\left|\lambda(\theta)-\lambda\left(\theta_{0}\right)\right.\right.\)</span> <span class="arithmatex">\(\left.\left.-\Lambda \cdot\left(\theta-\theta_{0}\right)\right|=o\left(\left|\theta-\theta_{0}\right|\right)\right]\)</span>. Then <span class="arithmatex">\(\sqrt{n}\left(T_{n}-\theta_{0}\right)\)</span> is asymptotically normal with mean 0 and covariance matrix <span class="arithmatex">\(\Lambda^{-1} C\left(\Lambda^{T}\right)^{-1}\)</span>, where <span class="arithmatex">\(C\)</span> is the covariance matrix of <span class="arithmatex">\(\psi\left(x, \theta_{0}\right)\)</span>.</p>
<p>Consider now the ordinary ML estimator, that is, assume that <span class="arithmatex">\(d P=\)</span> <span class="arithmatex">\(f\left(x, \theta_{0}\right) d \mu\)</span> and that <span class="arithmatex">\(\psi(x, \theta)=(\partial / \partial \theta) \log f(x, \theta)\)</span>. Assume that <span class="arithmatex">\(\psi(x, \theta)\)</span> is jointly measurable, that ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ), ( <span class="arithmatex">\(\mathrm{N}-3\)</span> ), and ( <span class="arithmatex">\(\mathrm{N}-4\)</span> ) hold locally uniformly in <span class="arithmatex">\(\theta_{0}\)</span>, and that the ML estimator is consistent. Assume furthermore that the Fisher information matrix</p>
<div class="arithmatex">\[
I(\theta)=\int \psi(x, \theta) \psi(x, \theta)^{T} f(x, \theta) d \mu
\]</div>
<p>is continuous at <span class="arithmatex">\(\theta_{0}\)</span>.
PROPOSITION 3.3 Under the assumptions just mentioned, we have <span class="arithmatex">\(\lambda\left(\theta_{0}\right)=0, \Lambda=-C=-I\left(\theta_{0}\right)\)</span>, and, in particular, <span class="arithmatex">\(\Lambda^{-1} C\left(\Lambda^{T}\right)^{-1}=I\left(\theta_{0}\right)^{-1}\)</span>. That is, the ML estimator is efficient.</p>
<h2 id="proof-see-huber-1967_1">Proof See Huber (1967).</h2>
<p>Example 3.1 <span class="arithmatex">\(L_{p}\)</span>-Estimates Define an <span class="arithmatex">\(m\)</span>-dimensional estimate <span class="arithmatex">\(T_{n}\)</span> of location by the property that it minimizes <span class="arithmatex">\(\Sigma\left|x_{i}-T_{n}\right|^{p}\)</span>, where <span class="arithmatex">\(1 \leqslant p \leqslant 2\)</span>, and || denotes the usual Euclidean norm. Equivalently, we could define it through <span class="arithmatex">\(\Sigma \psi\left(x_{i} ; T_{n}\right)=0\)</span> with</p>
<div class="arithmatex">\[
\psi(x, \theta)=-\frac{1}{p} \frac{\partial}{\partial \theta}\left(|x-\theta|^{p}\right)=|x-\theta|^{p-2}(x-\theta)
\]</div>
<p>Assume that <span class="arithmatex">\(m \geqslant 2\)</span>.</p>
<p>A straightforward calculation shows that <span class="arithmatex">\(u\)</span> and <span class="arithmatex">\(u^{2}\)</span> satisfy Lipschitz conditions of the form</p>
<div class="arithmatex">\[
\begin{gathered}
u(x, \theta, d) \leqslant c_{1} \cdot d \cdot|x-\theta|^{p-2} \\
u^{2}(x, \theta, d) \leqslant c_{2} \cdot d \cdot|x-\theta|^{p-2}
\end{gathered}
\]</div>
<p>for <span class="arithmatex">\(0 \leqslant d \leqslant d_{0}&lt;\infty\)</span>. Thus assumptions ( <span class="arithmatex">\(\mathrm{N}-3\)</span> ) (ii) and (iii) are satisfied, provided</p>
<div class="arithmatex">\[
E\left(|x-\theta|^{p-2}\right) \leqslant K&lt;\infty
\]</div>
<p>in some neighborhood of <span class="arithmatex">\(\theta_{0}\)</span>. This certainly holds if the true underlying distribution has a density with respect to Lebesgue measure. Furthermore under the same condition (3.9), we have</p>
<div class="arithmatex">\[
\frac{\partial}{\partial \theta} \lambda(\theta)=E \frac{\partial \psi(x, \theta)}{\partial \theta}
\]</div>
<p>Thus</p>
<div class="arithmatex">\[
\operatorname{tr} \frac{\partial \lambda}{\partial \theta}=E \operatorname{tr} \frac{\partial \psi}{\partial \theta}=-(m+p-2) E\left(|x-\theta|^{p-2}\right)&lt;0
\]</div>
<p>hence (N-3) (i) is also satisfied.
Assumption ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ) is immediate, ( <span class="arithmatex">\(\mathrm{N}-2\)</span> ) and ( <span class="arithmatex">\(\mathrm{N}-4\)</span> ) hold if <span class="arithmatex">\(E\left(|x|^{2 p-2}\right)&lt;\infty\)</span>, and consistency follows either from verifying (B-1) to (B-4) [with <span class="arithmatex">\(b(\theta)=\)</span> <span class="arithmatex">\(\left.\max \left(1,|\theta|^{p-1}\right)\right]\)</span> or from an easy ad hoc proof using convexity of <span class="arithmatex">\(\rho(x, \theta)=\)</span> <span class="arithmatex">\(|x-\theta|^{p}\)</span>.</p>
<p>Occasionally, the theorems of this and of the preceding section are also useful in the one-dimensional case.
Example 3.2 Let <span class="arithmatex">\(\mathscr{R}=\Theta=\mathbb{R}\)</span>, and let</p>
<div class="arithmatex">\[
\begin{aligned}
\rho(x, \theta) &amp; =\frac{1}{2}(x-\theta)^{2}, &amp; &amp; \text { for } \quad|x-\theta| \leqslant k \\
&amp; =\frac{1}{2} k^{2} &amp; &amp; \text { for } \quad|x-\theta|&gt;k .
\end{aligned}
\]</div>
<p>Assumption (A-4) of Section 6.2, namely unicity of <span class="arithmatex">\(\theta_{0}\)</span>, imposes a restriction on the true underlying distribution; the other assumptions (A-1), (A-2), (A-3), and (A-5) are trivially satisfied [with <span class="arithmatex">\(a(x) \equiv 0, b(\theta) \equiv \frac{1}{2} k^{2}\)</span>, <span class="arithmatex">\(h(x) \equiv 0\)</span> ]. Then the <span class="arithmatex">\(T_{n}\)</span> minimizing <span class="arithmatex">\(\Sigma \rho\left(x_{i}, T_{n}\right)\)</span> is a consistent estimate of <span class="arithmatex">\(\theta_{0}\)</span>.</p>
<p>Under slightly more stringent conditions, it is also asymptotically normal. Assume for simplicity that <span class="arithmatex">\(\theta_{0}=0\)</span>, and assume that the true underlying distribution function <span class="arithmatex">\(F\)</span> has a density <span class="arithmatex">\(F^{\prime}\)</span> in some neighborhoods of the points <span class="arithmatex">\(\pm k\)</span>, and that <span class="arithmatex">\(F^{\prime}\)</span> is continuous at these points. Assumptions ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ), (N-2), (N-3) (ii), (iii), and (N-4) are obviously satisfied with <span class="arithmatex">\(\psi(x, \theta)=\)</span> <span class="arithmatex">\((\partial / \partial \theta) \rho(x, \theta)\)</span>. If</p>
<div class="arithmatex">\[
\int_{-k}^{k} F(d x)-k F^{\prime}(-k)-k F^{\prime}(k)&gt;0
\]</div>
<p>then (N-3) (i) is also satisfied. We can easily check that Corollary 3.2 is applicable; hence <span class="arithmatex">\(T_{n}\)</span> is asymptotically normal.</p>
<h1 id="64-simultaneous-m-estimates-of-location-and-scale">6.4 SIMULTANEOUS M-ESTIMATES OF LOCATION AND SCALE</h1>
<p>In order to make an <span class="arithmatex">\(M\)</span>-estimate of location scale invariant, we must couple it with an estimate of scale.</p>
<p>If the underlying distribution <span class="arithmatex">\(F\)</span> is symmetric, location estimates <span class="arithmatex">\(T\)</span> and scale estimates <span class="arithmatex">\(S\)</span> typically are asymptotically independent, and the asymptotic behavior of <span class="arithmatex">\(T\)</span> depends on <span class="arithmatex">\(S\)</span> only through the asymptotic value <span class="arithmatex">\(S(F)\)</span>. We can therefore afford to choose <span class="arithmatex">\(S\)</span> on criteria other than low statistical variability.</p>
<p>Consider the simultaneous maximum likelihood estimates of <span class="arithmatex">\(\theta\)</span> and <span class="arithmatex">\(\sigma\)</span> for a family of densities</p>
<div class="arithmatex">\[
\frac{1}{\sigma} f\left(\frac{x-\theta}{\sigma}\right)
\]</div>
<p>that is, the values <span class="arithmatex">\(\hat{\theta}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> maximizing</p>
<div class="arithmatex">\[
\prod_{i&lt;n} \frac{1}{\sigma} f\left(\frac{x_{i}-\theta}{\sigma}\right)
\]</div>
<p>Evidently, these satisfy the following system of equations [with <span class="arithmatex">\(\psi(x)=\)</span> <span class="arithmatex">\(-(d / d x) \log f(x)]\)</span></p>
<div class="arithmatex">\[
\begin{gathered}
\sum \psi\left(\frac{x_{i}-\theta}{\sigma}\right)=0 \\
\sum\left[\psi\left(\frac{x_{i}-\theta}{\sigma}\right) \frac{x_{i}-\theta}{\sigma}-1\right]=0
\end{gathered}
\]</div>
<p>We generalize this and call simultaneous M-estimate of location and scale any pair of statistics ( <span class="arithmatex">\(T_{n}, S_{n}\)</span> ) determined by two equations of the form</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \sum \psi\left(\frac{x_{i}-T_{n}}{S_{n}}\right)=0 \\
&amp; \sum \chi\left(\frac{x_{i}-T_{n}}{S_{n}}\right)=0
\end{aligned}
\]</div>
<p>Evidently, <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> and <span class="arithmatex">\(S_{n}=S\left(F_{n}\right)\)</span> can be expressed in terms of functionals <span class="arithmatex">\(T\)</span> and <span class="arithmatex">\(S\)</span>, defined by</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \int \psi\left(\frac{x-T(F)}{S(F)}\right) F(d x)=0 \\
&amp; \int \chi\left(\frac{x-T(F)}{S(F)}\right) F(d x)=0
\end{aligned}
\]</div>
<p>Neither <span class="arithmatex">\(\psi\)</span> nor <span class="arithmatex">\(\chi\)</span> need be determined by a probability density as in (4.3) and (4.4). In most cases, however, <span class="arithmatex">\(\psi\)</span> will be an odd and <span class="arithmatex">\(\chi\)</span> an even function.</p>
<p>As before the influence functions can be found straightforwardly by inserting <span class="arithmatex">\(F_{t}=(1-t) F+t \delta_{x}\)</span> for <span class="arithmatex">\(F\)</span> into (4.7) and (4.8), and then taking the derivative with respect to <span class="arithmatex">\(t\)</span> at <span class="arithmatex">\(t=0\)</span>. We obtain that the two influence curves <span class="arithmatex">\(I C(x ; F, T)\)</span> and <span class="arithmatex">\(I C(x ; F, S)\)</span> satisfy the system of equations</p>
<div class="arithmatex">\[
I C(x ; F, T) \int \psi^{\prime}(y) F(d x)+I C(x ; F, S) \int \psi^{\prime}(y) y F(d x)=\psi(y) S(F)
\]</div>
<div class="arithmatex">\[
I C(x ; F, T) \int \chi^{\prime}(y) F(d x)+I C(x ; F, S) \int \chi^{\prime}(y) y F(d x)=\chi(y) S(F)
\]</div>
<p>where <span class="arithmatex">\(y\)</span> is short for <span class="arithmatex">\(y=[x-T(F)] / S(F)\)</span>.
If <span class="arithmatex">\(F\)</span> is symmetric, <span class="arithmatex">\(\psi\)</span> is odd, and <span class="arithmatex">\(\chi\)</span> is even, some integrals vanish for reasons of symmetry and there are considerable simplifications:</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\psi\left(\frac{x}{S(F)}\right) S(F)}{\int \psi^{\prime}\left(\frac{x}{S(F)}\right) F(d x)}
\]</div>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{\chi\left(\frac{x}{S(F)}\right) S(F)}{\int \chi^{\prime}\left(\frac{x}{S(F)}\right) \frac{x}{S(F)} F(d x)}
\]</div>
<p>Example 4.1 Let</p>
<div class="arithmatex">\[
\psi(x)=\max [-k, \min (k, x)]
\]</div>
<p>and</p>
<div class="arithmatex">\[
\chi(x)=\min \left(c^{2}, x^{2}\right)-\beta
\]</div>
<p>where <span class="arithmatex">\(0&lt;\beta&lt;c^{2}\)</span>. With <span class="arithmatex">\(\beta=\beta(c)\)</span>,</p>
<div class="arithmatex">\[
\beta(c)=\int \min \left(c^{2}, x^{2}\right) \Phi(d x)
\]</div>
<p>we obtain consistency of the scale estimate at the normal model.
This example is a combination of the asymptotic minimax estimates of location (Section 4.6) and of scale (Section 5.7); <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(c=x_{1}\)</span> might be determined from (4.5.21) and (5.6.14), respectively. A simplified version of this estimate uses <span class="arithmatex">\(c=k\)</span> [Huber (1964), p. 96 "Proposal 2"], that is,</p>
<div class="arithmatex">\[
\chi(x)=\psi(x)^{2}-\beta(k)
\]</div>
<p>Example 4.2 Median and Median Absolute Deviation Let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi(x)=\operatorname{sign}(x) \\
&amp; \chi(x)=\operatorname{sign}(|x|-1)
\end{aligned}
\]</div>
<p>A (formal) evaluation of (4.9) and (4.10) gives</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\operatorname{sign}(x-T(F))}{2 f(T(F))}
\]</div>
<p>and</p>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{\operatorname{sign}(|x-T|-S)-\frac{f(T+S)-f(T-S)}{f(T)} \operatorname{sign}(x-T)}{2[f(T+S)+f(T-S)]}
\]</div>
<p>If <span class="arithmatex">\(F\)</span> is symmetric, (4.20) simplifies to</p>
<div class="arithmatex">\[
I C(x ; F, S)=\frac{\operatorname{sign}(|x|-S(F))}{4 f(S(F))}
\]</div>
<h1 id="existence-and-uniqueness-of-the-solutions-of-47-and-48">Existence and Uniqueness of the solutions of (4.7) and (4.8)</h1>
<p>We follow Scholz (1971). Assume that <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are differentiable, that <span class="arithmatex">\(\psi^{\prime}&gt;0\)</span>, that <span class="arithmatex">\(\psi\)</span> has a zero at <span class="arithmatex">\(x=0\)</span> and <span class="arithmatex">\(\chi\)</span> has a minimum at <span class="arithmatex">\(x=0\)</span>, and that <span class="arithmatex">\(\chi^{\prime} / \psi^{\prime}\)</span> is strictly monotone. [In the particular case <span class="arithmatex">\(\chi(x)=\psi(x)^{2}-\beta\)</span>, this last assumption follows from <span class="arithmatex">\(\psi^{\prime}&gt;0\)</span> ]. <span class="arithmatex">\(F\)</span> is indifferently either the true or the empirical distribution.</p>
<p>The Jacobian of the map</p>
<div class="arithmatex">\[
(t, s) \rightarrow\left(\int \psi\left(\frac{x-t}{s}\right) F(d x), \int \chi\left(\frac{x-t}{s}\right) F(d x)\right)
\]</div>
<p>is</p>
<div class="arithmatex">\[
-\frac{1}{s}\left\{\begin{array}{ll}
\int \psi^{\prime}(y) d F &amp; \int y \psi^{\prime}(y) d F \\
\int \chi^{\prime}(y) d F &amp; \int y \chi^{\prime}(y) d F
\end{array}\right\}
\]</div>
<p>with <span class="arithmatex">\(y=(x-t) / s\)</span>. We define a new probability measure <span class="arithmatex">\(F^{*}\)</span> by</p>
<div class="arithmatex">\[
F^{*}(d y)=\frac{\psi^{\prime}(y)}{E_{F}\left[\psi^{\prime}(y)\right]} F(d x)
\]</div>
<p>then the Jacobian can be written as</p>
<div class="arithmatex">\[
-\frac{1}{s} E_{F}\left[\psi^{\prime}(y)\right]\left\{\begin{array}{cc}
1 &amp; E_{F^{*}}(y) \\
E_{F^{*}}\left(\frac{\chi^{\prime}}{\psi^{\prime}}\right) &amp; E_{F^{*}} y\left(\frac{\chi^{\prime}}{\psi^{\prime}}\right)
\end{array}\right\}
\]</div>
<p>Its determinant</p>
<div class="arithmatex">\[
\left[\frac{E_{F} \psi^{\prime}(y)}{s}\right]^{2} \operatorname{cov}_{F^{*}}\left(y, \frac{\chi^{\prime}}{\psi^{\prime}}\right)
\]</div>
<p>is strictly positive unless <span class="arithmatex">\(F\)</span> is concentrated at a single point. To prove this, let <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> be any two strictly monotone functions, and let <span class="arithmatex">\(Y_{1}\)</span> and <span class="arithmatex">\(Y_{2}\)</span> be two independent, identically distributed random variables. As <span class="arithmatex">\(\left[f\left(Y_{1}\right)-\right.\)</span> <span class="arithmatex">\(\left.f\left(Y_{2}\right)\right]\left[g\left(Y_{1}\right)-g\left(Y_{2}\right)\right]&gt;0\)</span> unless <span class="arithmatex">\(Y_{1}=Y_{2}\)</span>, we have</p>
<div class="arithmatex">\[
\operatorname{cov}\left[f\left(Y_{1}\right), g\left(Y_{1}\right)\right]=\frac{1}{2} E\left\{\left[f\left(Y_{1}\right)-f\left(Y_{2}\right)\right]\left[g\left(Y_{1}\right)-g\left(Y_{2}\right)\right]\right\}&gt;0
\]</div>
<p>unless <span class="arithmatex">\(P\left(Y_{1}=Y_{2}\right)=1\)</span>.
Thus as the diagonal elements of the Jacobian are strictly negative, and its determinant is strictly positive, we conclude [cf. Gale and Nikaidô (1965), Theorem 4] that (4.22) is a one-to-one map.</p>
<p>The existence of a solution now follows from the observations (1) that, for each fixed <span class="arithmatex">\(s\)</span>, the first component of (4.22) has a unique zero at some <span class="arithmatex">\(t=t(s)\)</span> that depends continuously on <span class="arithmatex">\(s\)</span>, and (2) that the second component <span class="arithmatex">\(\int \chi\{[x-t(s)] / s\} F(d x)\)</span> ranges from <span class="arithmatex">\(\chi(0)\)</span> to (at least) <span class="arithmatex">\((1-\eta) \chi( \pm \infty)+\eta \chi(0)\)</span>, where <span class="arithmatex">\(\eta\)</span> is the largest pointmass of <span class="arithmatex">\(F\)</span>, when <span class="arithmatex">\(s\)</span> varies from <span class="arithmatex">\(\infty\)</span> to 0 . We now conclude from the intermediate value theorem for continuous functions that <span class="arithmatex">\([T(F), T(S)]\)</span> exists uniquely, provided <span class="arithmatex">\(\chi(0)&lt;0&lt;\chi( \pm \infty)\)</span> and <span class="arithmatex">\(F\)</span> does not have pointmasses that are too large; the largest one should satisfy <span class="arithmatex">\(\eta&lt;\chi( \pm \infty) /[\chi( \pm \infty)-\chi(0)]\)</span>.</p>
<p>The special case of Example 4.1 is not covered by this proof, as <span class="arithmatex">\(\psi\)</span> is not strictly monotone, but the result remains valid [approximate <span class="arithmatex">\(\psi\)</span> by strictly monotone functions; for a direct proof see Huber (1964), p. 98; cf. also Section 7.7].</p>
<p>It is intuitively obvious (and easy to check rigorously) that the map <span class="arithmatex">\(F \rightarrow(T(F), S(F))\)</span> is not only well defined but also weakly continuous, provided <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are bounded; hence <span class="arithmatex">\(T\)</span> and <span class="arithmatex">\(S\)</span> are qualitatively robust in Hampel's sense. The Glivenko-Cantelli theorem then implies consistency of <span class="arithmatex">\(\left(T_{n}, S_{n}\right)\)</span>. The monotonicity and differentiability properties of <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> make it relatively easy to check assumptions ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ) to ( <span class="arithmatex">\(\mathrm{N}-4\)</span> ) of Section 6.3, and, since the map (4.22) is differentiable by assumption, <span class="arithmatex">\(\left(T_{n}, S_{n}\right)\)</span> is asymptotically normal in virtue of Corollary 3.2. The special case of Example 4.1 is again not quite covered; if <span class="arithmatex">\(F\)</span> puts pointmasses on the discontinuities of <span class="arithmatex">\(\psi^{\prime}\)</span>, asymptotic normality is destroyed just as in the case of location alone (Section 3.2), but for finite <span class="arithmatex">\(n\)</span> the case is now milder, because the random fluctuations in the scale estimate smooth away these discontinuities.</p>
<p>If <span class="arithmatex">\(F\)</span> is symmetric, and <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> skew symmetric and symmetric, respectively, the location and scale estimates are uncorrelated for symmetry reasons, and hence asymptotically independent.</p>
<h1 id="65-m-estimates-with-preliminary-estimates-of-scale">6.5 M-ESTIMATES WITH PRELIMINARY ESTIMATES OF SCALE</h1>
<p>The simultaneous solution of two equations (4.5) and (4.6) is perhaps unnecessarily complicated. A somewhat simplified variant is an <span class="arithmatex">\(M\)</span>-estimate of location with a preliminary estimate of scale: take any estimate <span class="arithmatex">\(S_{n}=S\left(F_{n}\right)\)</span> of scale, and determine location from (4.5) or (4.7), respectively. If the influence function of the scale estimate is known, then the influence function of the location estimate can be determined from (4.9), or, in the symmetric case, simply from (4.11). Note that, in the symmetric case, only the limiting value <span class="arithmatex">\(S(F)\)</span>, but neither the influence function nor the asymptotic variance of <span class="arithmatex">\(S\)</span>, enters into the expression for the influence function of <span class="arithmatex">\(T\)</span>.</p>
<p>Another, even simpler, variant is the so-called one-step <span class="arithmatex">\(M\)</span>-estimate. Here, we start with some preliminary estimates <span class="arithmatex">\(T_{0}(F)\)</span> and <span class="arithmatex">\(S_{0}(F)\)</span> of location and scale, and then we solve (4.7) approximately for <span class="arithmatex">\(T\)</span> by applying Newton's rule just once. Since the Taylor expansion of (4.7) with respect to <span class="arithmatex">\(T\)</span> at <span class="arithmatex">\(T_{0}=T_{0}(F)\)</span> begins with
<span class="arithmatex">\(\int \psi\left(\frac{x-T}{S_{0}}\right) F(d x)=\int \psi\left(\frac{x-T_{0}}{S_{0}}\right) F(d x)-\frac{T-T_{0}}{S_{0}} \int \psi^{\prime}\left(\frac{x-T_{0}}{S_{0}}\right) F(d x)+\cdots\)</span>,
this estimate can be formally defined by the functional</p>
<div class="arithmatex">\[
T(F)=T_{0}(F)+\frac{S_{0} \int \psi\left(\frac{x-T_{0}}{S_{0}}\right) F(d x)}{\int \psi^{\prime}\left(\frac{x-T_{0}}{S_{0}}\right) F(d x)}
\]</div>
<p>The influence function corresponding to (5.1) can be calculated straightforwardly, if those of <span class="arithmatex">\(T_{0}\)</span> and <span class="arithmatex">\(S_{0}\)</span> are known. In the general asymmetric case this leads to unpleasantly complicated expressions:</p>
<div class="arithmatex">\[
\begin{aligned}
I C(x ; F, T)= &amp; \frac{S_{0}}{\int \psi^{\prime}} \psi-\frac{S_{0} \int \psi}{\left(\int \psi^{\prime}\right)^{2}} \psi^{\prime}+\frac{\int \psi \int \psi^{\prime \prime}}{\left(\int \psi^{\prime}\right)^{2}} I C\left(x ; F, T_{0}\right) \\
&amp; +\left[\frac{\int \psi}{\int \psi^{\prime}}-\frac{\int y \psi^{\prime}}{\int \psi^{\prime}}+\frac{\int \psi \int y \psi^{\prime \prime}}{\left(\int \psi^{\prime}\right)^{2}}\right] I C\left(x ; F, S_{0}\right)
\end{aligned}
\]</div>
<p>where the argument of <span class="arithmatex">\(\psi, \psi^{\prime}\)</span>, and <span class="arithmatex">\(\psi^{\prime \prime}\)</span> in all instances is <span class="arithmatex">\(y=\)</span> <span class="arithmatex">\(\left[x-T_{0}(F)\right] / S_{0}(F)\)</span>, and all integrals are with respect to <span class="arithmatex">\(d F\)</span>.</p>
<p>If we assume that <span class="arithmatex">\(T_{0}\)</span> is translation invariant and odd,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; T\left(F_{X+c}\right)=T\left(F_{X}\right)+c \\
&amp; T\left(F_{-X}\right)=-T\left(F_{X}\right)
\end{aligned}
\]</div>
<p>that <span class="arithmatex">\(\psi\)</span> is odd, and that <span class="arithmatex">\(F\)</span> is symmetric, then all terms except the first vanish, and the formula simplifies again to (4.11):</p>
<div class="arithmatex">\[
I C(x ; F, T)=\frac{\psi\left(\frac{x}{S_{0}(F)}\right) S_{0}(F)}{\int \psi^{\prime}\left(\frac{x}{S_{0}(F)}\right) F(d x)}
\]</div>
<p>It is intuitively clear from the influence functions that the estimate with preliminary scale and the corresponding one-step estimate will both be asymptotically normal and asymptotically equivalent to each other if <span class="arithmatex">\(T_{0}\)</span> is consistent. Asymptotic normality proofs utilizing one-step estimates as auxiliary devices are usually relatively straightforward to construct.</p>
<h1 id="66-quantitative-robustness-properties-of-simultaneous-estimates-for-location-and-scale">6.6 QUANTITATIVE ROBUSTNESS PROPERTIES OF SIMULTANEOUS ESTIMATES FOR LOCATION AND SCALE</h1>
<p>The breakdown properties of the estimates considered in the preceding two sections are mainly determined by the breakdown of the scale part. Thus they can differ considerably from those of fixed-scale <span class="arithmatex">\(M\)</span>-estimates of location.</p>
<p>To be specific consider first joint <span class="arithmatex">\(M\)</span>-estimates, assume that both <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are continuous, that <span class="arithmatex">\(\psi\)</span> is odd and <span class="arithmatex">\(\chi\)</span> is even, and that both are monotone increasing for positive arguments. We only consider <span class="arithmatex">\(\varepsilon\)</span>-contamination (the results for Prohorov- <span class="arithmatex">\(\varepsilon\)</span>-neighborhoods are the same). We regard scale as a nuisance parameter and concentrate on the location aspects.</p>
<p>Let <span class="arithmatex">\(\varepsilon_{S}^{*}\)</span> and <span class="arithmatex">\(\varepsilon_{T}^{*}\)</span> be the infima of the set of <span class="arithmatex">\(\varepsilon\)</span>-values for which <span class="arithmatex">\(S(F)\)</span>, or <span class="arithmatex">\(T(F)\)</span>, respectively, can become infinitely large. We first note that <span class="arithmatex">\(\varepsilon_{S}^{*} \leqslant \varepsilon_{T}^{*}\)</span>. Otherwise <span class="arithmatex">\(T(F)\)</span> would break down while <span class="arithmatex">\(S(F)\)</span> stays bounded; therefore we would have <span class="arithmatex">\(\varepsilon_{T}^{*}=0.5\)</span> as in the fixed-scale case, but <span class="arithmatex">\(\varepsilon_{S}^{*}&gt;0.5\)</span> is impossible (5.2.7). Scale breakdown by "implosion," <span class="arithmatex">\(S \rightarrow 0\)</span>, is uninteresting in the present context because then the location estimate is converted into the highly robust sample median.</p>
<p>Now let <span class="arithmatex">\(\{F\}\)</span> be a sequence of <span class="arithmatex">\(\varepsilon\)</span>-contaminated distributions, <span class="arithmatex">\(F=\)</span> <span class="arithmatex">\((1-\varepsilon) F_{0}+\varepsilon H\)</span>, such that <span class="arithmatex">\(T(F) \rightarrow \infty, S(F) \rightarrow \infty\)</span>, and <span class="arithmatex">\(\varepsilon \rightarrow \varepsilon_{T}^{*}=\varepsilon^{*}\)</span>. Without loss of generality we assume that the limit</p>
<div class="arithmatex">\[
0 \leqslant \lim \frac{T(F)}{S(F)}=y \leqslant \infty
\]</div>
<p>exists (if necessary we pass to a subsequence).
We write the defining equations (4.7) and (4.8) as</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; (1-\varepsilon) \int \psi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \int \psi\left(\frac{x-T}{S}\right) H(d x)=0 \\
&amp; (1-\varepsilon) \int \chi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \int \chi\left(\frac{x-T}{S}\right) H(d x)=0
\end{aligned}
\]</div>
<p>If we replace the coefficients of <span class="arithmatex">\(\varepsilon\)</span> by their upper bounds <span class="arithmatex">\(\psi(\infty)\)</span> and <span class="arithmatex">\(\chi(\infty)\)</span>, respectively, we obtain from (6.2) and (6.3), respectively,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; (1-\varepsilon) \int \psi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \psi(\infty) \geqslant 0 \\
&amp; (1-\varepsilon) \int \chi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \chi(\infty) \geqslant 0
\end{aligned}
\]</div>
<p>In the limit we have</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \left(1-\varepsilon^{*}\right) \psi(-y)+\varepsilon^{*} \psi(\infty) \geqslant 0 \\
&amp; \left(1-\varepsilon^{*}\right) \chi(-y)+\varepsilon^{*} \chi(\infty) \geqslant 0
\end{aligned}
\]</div>
<p>hence using the symmetry and monotonicity properties of <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span>,</p>
<div class="arithmatex">\[
\chi^{-1}\left(-\frac{\varepsilon^{*}}{1-\varepsilon^{*}} \chi(\infty)\right) \leqslant y \leqslant \psi^{-1}\left(\frac{\varepsilon^{*}}{1-\varepsilon^{*}} \psi(\infty)\right)
\]</div>
<p>It follows that the solution <span class="arithmatex">\(\varepsilon_{0}\)</span> of</p>
<div class="arithmatex">\[
\chi^{-1}\left(-\frac{\varepsilon}{1-\varepsilon} \chi(\infty)\right)=\psi^{-1}\left(\frac{\varepsilon}{1-\varepsilon} \psi(\infty)\right)
\]</div>
<p>is a lower bound for <span class="arithmatex">\(\varepsilon^{*}\)</span> (assume for simplicity that <span class="arithmatex">\(\varepsilon_{0}\)</span> is unique).
It is not difficult to check that this is also an upper bound for <span class="arithmatex">\(\varepsilon^{*}\)</span>. Assume that <span class="arithmatex">\(\varepsilon\)</span> is small enough so that the solution <span class="arithmatex">\([T(F), S(F)]\)</span> of (6.2)</p>
<p>and (6.3) stays bounded for all <span class="arithmatex">\(H\)</span>. In particular, if we let <span class="arithmatex">\(H\)</span> tend to a pointmass at <span class="arithmatex">\(+\infty,(6.2)\)</span> and (6.3) then converge to</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; (1-\varepsilon) \int \psi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \psi(\infty)=0 \\
&amp; (1-\varepsilon) \int \chi\left(\frac{x-T}{S}\right) F_{0}(d x)+\varepsilon \chi(\infty)=0
\end{aligned}
\]</div>
<p>Now let <span class="arithmatex">\(\varepsilon\)</span> increase until the solutions <span class="arithmatex">\(T(F)\)</span> and <span class="arithmatex">\(S(F)\)</span> of (6.8) and (6.9) begin to diverge. We can again assume that (6.1) holds for some <span class="arithmatex">\(y\)</span>. The limiting <span class="arithmatex">\(\varepsilon\)</span> must be at least as large as the breakdown point, and it will satisfy (6.4) and (6.5), with equality signs. It follows that the solution <span class="arithmatex">\(\varepsilon_{0}\)</span> of (6.7) is an upper bound for <span class="arithmatex">\(\varepsilon^{*}\)</span>, and that it is the common breakdown point of <span class="arithmatex">\(T\)</span> and <span class="arithmatex">\(S\)</span>.</p>
<p>Example 6.1 Continuation of Example 4.1 In this case we have <span class="arithmatex">\(\psi(\infty)=k\)</span>,</p>
<div class="arithmatex">\[
\psi^{-1}\left[\frac{\varepsilon}{1-\varepsilon} \psi(\infty)\right]=\frac{\varepsilon}{1-\varepsilon} k
\]</div>
<p>hence (6.7) can be written</p>
<div class="arithmatex">\[
\left[\left(\frac{\varepsilon}{1-\varepsilon}\right)^{2} k^{2}-\beta(c)\right]+\frac{\varepsilon}{1-\varepsilon}\left[c^{2}-\beta(c)\right]=0
\]</div>
<p>If <span class="arithmatex">\(c=k\)</span>, the solution of (6.10) is simply</p>
<div class="arithmatex">\[
\varepsilon^{*}=\frac{\beta(k)}{\beta(k)+k^{2}}
\]</div>
<p>For symmetric contamination the variance of the location estimate breaks down <span class="arithmatex">\([(v(\varepsilon) \rightarrow \infty]\)</span> for</p>
<div class="arithmatex">\[
\varepsilon^{* *}=\frac{\beta(k)}{k^{2}}
\]</div>
<p>These values should be compared quantitatively to the corresponding breakdown points <span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span> and <span class="arithmatex">\(\varepsilon^{* *}=2 \alpha\)</span> of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean. To facilitate this comparison, the following table of breakdown points (Exhibit 6.6.1) also gives the "equivalent trimming rate" <span class="arithmatex">\(\alpha_{\Phi}=\Phi(-k)\)</span>, for which the corresponding <span class="arithmatex">\(\alpha\)</span>-trimmed mean has the same influence function and the same asymptotic performance at the normal model.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Example 6.1 <br> "Proposal 2"</th>
<th style="text-align: center;">Example 6.2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Trimmed Mean Equivalent for <span class="arithmatex">\(\Phi\)</span>, <span class="arithmatex">\(\alpha=\Phi(-k)\)</span></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Scale: <br> Interquartile <br> Range</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Scale: <br> Median <br> Deviation</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(k\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{*}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{* *}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{*}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{* *}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{*}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{* *}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{*}=\alpha\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon^{* *}=2 \alpha\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">0.111</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.003</td>
</tr>
<tr>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">0.135</td>
<td style="text-align: center;">0.156</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.006</td>
<td style="text-align: center;">0.012</td>
</tr>
<tr>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">0.187</td>
<td style="text-align: center;">0.230</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.023</td>
<td style="text-align: center;">0.046</td>
</tr>
<tr>
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">0.227</td>
<td style="text-align: center;">0.294</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.045</td>
<td style="text-align: center;">0.090</td>
</tr>
<tr>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.257</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.067</td>
<td style="text-align: center;">0.134</td>
</tr>
<tr>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">0.273</td>
<td style="text-align: center;">0.375</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.081</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">1.3</td>
<td style="text-align: center;">0.290</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.097</td>
<td style="text-align: center;">0.194</td>
</tr>
<tr>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">0.307</td>
<td style="text-align: center;">0.441</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.115</td>
<td style="text-align: center;">0.230</td>
</tr>
<tr>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">0.324</td>
<td style="text-align: center;">0.478</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.136</td>
<td style="text-align: center;">0.272</td>
</tr>
<tr>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.340</td>
<td style="text-align: center;">0.516</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.318</td>
</tr>
<tr>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.392</td>
<td style="text-align: center;">0.645</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.242</td>
<td style="text-align: center;">0.484</td>
</tr>
</tbody>
</table>
<p>Exhibit 6.6.1 Breakdown points for the estimates of Examples 6.1 and 6.2, and for the trimmed mean with equivalent performance at the normal distribution.</p>
<p>Also the breakdown of <span class="arithmatex">\(M\)</span>-estimates with preliminary estimates of scale is governed by the breakdown of the scale part, but the situation is much simpler. The following example will suffice to illustrate this.</p>
<p>Example 6.2 With the same <span class="arithmatex">\(\psi\)</span> as in Example 6.1, but with the interquartile range as scale [normalized such that <span class="arithmatex">\(S(\Phi)=1\)</span> ], we have <span class="arithmatex">\(\varepsilon^{*}=0.25\)</span> and <span class="arithmatex">\(\varepsilon^{* *}=0.5\)</span>. For the symmetrized version <span class="arithmatex">\(\hat{S}\)</span> (the median absolute deviation, cf. Sections 5.1 and 5.3) breakdown is pushed up to <span class="arithmatex">\(\varepsilon^{*}=\varepsilon^{* *}=0.5\)</span>. See Exhibit 6.6.1.</p>
<p>As a further illustration Exhibit 6.6.2 compares the suprema <span class="arithmatex">\(v_{s}(\varepsilon)\)</span> of the asymptotic variances for symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination, for various estimates whose finite sample properties had been investigated by Andrews et al. (1972). Among these estimates:</p>
<ul>
<li>H14, H10, and H07 are Huber's "Proposal 2" with <span class="arithmatex">\(k=1.4,1.0\)</span>, and 0.7 respectively; see Examples 4.1 and 6.1.</li>
<li>A14, A10, and A07 have the same <span class="arithmatex">\(\psi\)</span> as the corresponding H-estimates, but use MAD/0.6745 as a preliminary estimate of scale (cf. Section 6.5).</li>
</ul>
<p><img alt="img-7.jpeg" src="data:image/jpeg;base64,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" /></p>
<ul>
<li>25A, 21A, 17A, and 12A are descending Hampel estimates, with the constants <span class="arithmatex">\((a, b, c)\)</span> given in parentheses [cf. Section 4.8, especially (4.8.8)]; they use MAD as a preliminary estimate of scale.</li>
</ul>
<h1 id="67-the-computation-of-m-estimates">6.7 THE COMPUTATION OF M-ESTIMATES</h1>
<p>We describe several variants, beginning with some where the median absolute deviation is used as an auxiliary estimate of scale.</p>
<h2 id="variant-1-modified-residuals-let">Variant 1 Modified Residuals Let</h2>
<div class="arithmatex">\[
\begin{aligned}
&amp; T^{(0)}=\operatorname{med}\left\{x_{i}\right\} \\
&amp; S^{(0)}=\operatorname{med}\left\{\left|x_{i}-T^{(0)}\right|\right\}
\end{aligned}
\]</div>
<p>Perform at least one Newton step, that is, one iteration of</p>
<div class="arithmatex">\[
T^{(m+1)}=T^{(m)}+\frac{\frac{1}{n} \sum \psi\left(\frac{x_{i}-T^{(m)}}{S^{(0)}}\right) S^{(0)}}{\frac{1}{n} \sum \psi^{\prime}\left(\frac{x_{i}-T^{(m)}}{S^{(0)}}\right)}
\]</div>
<p>Compare Section 6.5 and note that the one-step estimate <span class="arithmatex">\(T^{(1)}\)</span> is asymptotically <span class="arithmatex">\((n \rightarrow \infty)\)</span> equivalent to the iteration limit <span class="arithmatex">\(T^{(\infty)}\)</span>, provided that the underlying distribution is symmetric and <span class="arithmatex">\(\psi\)</span> is skew symmetric. The denominator in (7.3) is not very critical, and it might be replaced by a constant. If <span class="arithmatex">\(0 \leqslant \psi^{\prime} \leqslant 1\)</span>, then any constant denominator <span class="arithmatex">\(&gt;\frac{1}{2}\)</span> will give convergence (for a proof, see Section 7.8). However, if <span class="arithmatex">\(\psi\)</span> is piecewise linear, then (7.3) will lead to the exact solution of</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{x_{i}-T}{S^{(0)}}\right)=0
\]</div>
<p>in a finite number of steps (if it converges at all).
Variant 2 Modified Weights Let <span class="arithmatex">\(T^{(0)}\)</span> and <span class="arithmatex">\(S^{(0)}\)</span> be defined as above. Perform a few iterations of</p>
<div class="arithmatex">\[
T^{(m+1)}=\frac{\sum w_{i}^{(m)} x_{i}}{\sum w_{i}^{(m)}}
\]</div>
<p>with</p>
<div class="arithmatex">\[
w_{i}^{(m)}=\frac{\psi\left[\left(x_{i}-T^{(m)}\right) / S^{(0)}\right]}{\left(x_{i}-T^{(m)}\right) / S^{(0)}}
\]</div>
<p>A convergence proof is also given in Section 7.8; the iteration limit <span class="arithmatex">\(T^{(\infty)}\)</span>, of course, is a solution of (7.4).</p>
<p>Variant 3 Joint M-Estimates of Location and Scale Assume that we want to solve the system</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \sum \psi\left(\frac{x_{i}-T}{S}\right)=0 \\
&amp; \sum \psi^{2}\left(\frac{x_{i}-T}{S}\right)=(n-1) \beta
\end{aligned}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\beta=E_{\Phi}\left(\psi^{2}\right)
\]</div>
<p>and where <span class="arithmatex">\(\psi\)</span> is assumed to be skew symmetric and monotone, <span class="arithmatex">\(0&lt;\psi^{\prime}&lt;1\)</span>.
Start with <span class="arithmatex">\(T^{(0)}\)</span> and <span class="arithmatex">\(S^{(0)}\)</span> as above. Let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; {\left[S^{(m+1)}\right]^{2}=\frac{1}{(n-1) \beta} \sum \psi^{2}\left(\frac{x_{i}-T^{(m)}}{S^{(m)}}\right)\left[S^{(m)}\right]^{2}} \\
&amp; T^{(m+1)}=T^{(m)}+\frac{\frac{1}{n} \sum \psi\left(\frac{x_{i}-T^{(m)}}{S^{(m)}}\right) S^{(m)}}{\frac{1}{n} \sum \psi^{\prime}\left(\frac{x_{i}-T^{(m)}}{S^{(m)}}\right)}
\end{aligned}
\]</div>
<p>For a convergence proof [with a constant denominator in (7.10)] see Section 7.8.</p>
<p>Variant 4 Joint M-Estimates of Location and Scale, Continued Assume that <span class="arithmatex">\(\psi(x)=\max [-c, \min (c, x)]\)</span>. Let <span class="arithmatex">\(m_{1}, m_{2}\)</span>, and <span class="arithmatex">\(m_{3}\)</span> be the number of observations satisfying <span class="arithmatex">\(x_{i}&lt;T-c S, T-c S&lt;x_{i}&lt;T+c S\)</span>, and <span class="arithmatex">\(T+c S&lt;x_{i}\)</span>,</p>
<p>respectively. Then (7.7) and (7.8) can be written</p>
<div class="arithmatex">\[
\begin{gathered}
\sum^{\prime} x_{i}-m_{2} T+\left(m_{3}-m_{1}\right) c S=0 \\
\sum^{\prime}\left(x_{i}-T\right)^{2}+\left(m_{1}+m_{3}\right) c^{2} S^{2}-(n-1) \beta S^{2}=0
\end{gathered}
\]</div>
<p>Here, the primed summation sign indicates that the sum is extended only over the observations for which <span class="arithmatex">\(\left|x_{i}-T\right|&lt;c S\)</span>. If we determine <span class="arithmatex">\(T\)</span> from (7.11) and insert it into (7.12), we obtain the equivalent system</p>
<div class="arithmatex">\[
\begin{aligned}
\bar{x}^{\prime} &amp; =\frac{\sum^{\prime} x_{i}}{m_{2}} \\
S^{2} &amp; =\frac{\sum^{\prime}\left(x_{i}-\bar{x}^{\prime}\right)^{2}}{(n-1) \beta-\left[m_{1}+m_{3}+\frac{\left(m_{3}-m_{1}\right)^{2}}{m_{2}}\right] c^{2}} \\
T &amp; =\bar{x}^{\prime}+c S \frac{\left(m_{3}-m_{1}\right)}{m_{2}}
\end{aligned}
\]</div>
<p>These three last equations now are used to calculate <span class="arithmatex">\(T\)</span> and <span class="arithmatex">\(S\)</span>. Assume that we have already determined <span class="arithmatex">\(T^{(m)}\)</span> and <span class="arithmatex">\(S^{(m)}\)</span>. Find the corresponding partition of the sample according to <span class="arithmatex">\(T^{(m)} \pm c S^{(m)}\)</span>, then evaluate (7.13) and (7.14) to find <span class="arithmatex">\(S^{(m+1)}\)</span>, and finally find <span class="arithmatex">\(T^{(m+1)}\)</span> through (7.15), using <span class="arithmatex">\(S^{(m+1)}\)</span>.</p>
<p>The convergence of this procedure has not yet been proved, and in fact, there are counterexamples for small values of <span class="arithmatex">\(c\)</span>. But in practice it converges extremely fast and reaches the exact solution in a finite number of steps.</p>
<h1 id="68-studentizing">6.8 STUDENTIZING</h1>
<p>As a matter of principle each estimate <span class="arithmatex">\(T_{n}=T_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span> of any parameter <span class="arithmatex">\(\theta\)</span> should be accompanied by an estimate <span class="arithmatex">\(D_{n}=D_{n}\left(x_{1}, \ldots, x_{n}\right)\)</span> of its own variability. Since <span class="arithmatex">\(T_{n}\)</span> will often be asymptotically normal, <span class="arithmatex">\(D_{n}\)</span> should be standardized such that it estimates the (asymptotic) standard deviation of <span class="arithmatex">\(T_{n}\)</span>, that is</p>
<div class="arithmatex">\[
\mathcal{C}\left\{\sqrt{n}\left[T_{n}-T(F)\right]\right\} \rightarrow \mathbb{R}[0, A(F, T)]
\]</div>
<p>and</p>
<div class="arithmatex">\[
n D_{n}^{2} \rightarrow A(F, T)
\]</div>
<p>Most likely <span class="arithmatex">\(D_{n}\)</span> will be put to either of two uses:
(1) For finding confidence intervals ( <span class="arithmatex">\(T_{n}-c D_{n}, T_{n}+c D_{n}\)</span> ) for the unknown true parameter estimated by <span class="arithmatex">\(T_{n}\)</span>.
(2) For finding (asymptotic) standard deviations for functions of <span class="arithmatex">\(T_{n}\)</span> by the so-called <span class="arithmatex">\(\Delta\)</span>-method:</p>
<div class="arithmatex">\[
\sigma\left(h\left(T_{n}\right)\right) \approx\left|h^{\prime}\left(T_{n}\right)\right| \sigma\left(T_{n}\right)
\]</div>
<p>In Section 1.2 we have proposed standardizing an estimate <span class="arithmatex">\(T\)</span> of <span class="arithmatex">\(\theta\)</span> such that it would be Fisher consistent at the model, that is, <span class="arithmatex">\(T\left(F_{\theta}\right)=\theta\)</span>, and otherwise defining the estimand in terms of the limiting value of the estimate.</p>
<p>For <span class="arithmatex">\(D\)</span> we do not have this freedom; the estimand is asymptotically fixed by (8.2). If <span class="arithmatex">\(A\left(F_{n}, T\right) \rightarrow A(F, T)\)</span>, our estimate should therefore satisfy</p>
<div class="arithmatex">\[
\sqrt{n} D_{n} \approx A\left(F_{n}, T\right)^{1 / 2}
\]</div>
<p>and we might in fact define <span class="arithmatex">\(D_{n}\)</span> by this relation, that is,</p>
<div class="arithmatex">\[
D_{n}^{2}=\frac{1}{n(n-1)} \sum I C\left(x_{i}, F_{n}, T\right)^{2}
\]</div>
<p>The factor <span class="arithmatex">\(n-1\)</span> (instead of <span class="arithmatex">\(n\)</span> ) was substituted to preserve equivalence with the classical formula for the estimated standard deviation of the sample mean.</p>
<p>Almost equivalently, we can use the jackknife method (Section 1.5).
In some cases both (8.5) and the jackknife fail, for instance for the sample median. In this particular case we can take recourse to the well-known nonparametric confidence intervals for the median, given by the interval between two selected order statistics ( <span class="arithmatex">\(x_{(i)}, x_{(n+1-i)}\)</span> ). If we then divide <span class="arithmatex">\(x_{(n+1-i)}-x_{(i)}\)</span> by a suitable constant <span class="arithmatex">\(2 c\)</span>, we may also get an estimate <span class="arithmatex">\(D_{n}\)</span> satisfying (8.2). In view of the central limit theorem, the proper choice is, asymptotically,</p>
<div class="arithmatex">\[
c=\Phi^{-1}\left(\frac{1}{2}+\frac{1}{2} \alpha\right)
\]</div>
<p>where <span class="arithmatex">\(\alpha\)</span> is the level of the confidence interval.</p>
<p>If <span class="arithmatex">\(T_{n}\)</span> and <span class="arithmatex">\(D_{n}\)</span> are jointly asymptotically normal, they will be asymptotically independent in the symmetric case (for reasons of symmetry, their covariance is 0 ). We can expect that the quotient</p>
<div class="arithmatex">\[
\frac{T_{n}-T(F)}{D_{n}}
\]</div>
<p>will behave very much like a <span class="arithmatex">\(t\)</span>-statistic, but with how many degrees of freedom?</p>
<p>This question is tricky and probably does not have a satisfactory answer. The difficulties are connected with the following points: (1) we intend to use (8.5) not only for normal data; and (2) the answer is interesting only for relatively small sample sizes, where the asymptotic approximations are poor and depend very much on the actual underlying <span class="arithmatex">\(F\)</span>.</p>
<p>The common opinion is that the appropriate number of degrees of freedom is somewhat smaller than the classical <span class="arithmatex">\(n-1\)</span>, but by how much is anybody's guess. Since we are typically interested in a 95 or <span class="arithmatex">\(99 \%\)</span> confidence interval, it is really the tail behavior of (8.7) that matters. For small <span class="arithmatex">\(n\)</span> this is overwhelmingly determined by the density of <span class="arithmatex">\(D_{n}\)</span> near 0 . Huber's approach (1970), which determined an equivalent number of degrees of freedom by matching the asymptotic moments of <span class="arithmatex">\(D_{n}^{2}\)</span> with those of a <span class="arithmatex">\(\chi^{2}\)</span>-distribution, might therefore be rather misleading.</p>
<p>All this notwithstanding, (8.5) and (8.7) work remarkably well for <span class="arithmatex">\(M\)</span>-estimates; compare the extensive Monte Carlo study by Shorack (1976). [Shorack's definition and the use of his number of degrees of freedom <span class="arithmatex">\(d f^{*}\)</span> in formula (5) are unsound <span class="arithmatex">\(-d f^{*}\)</span> is not only unstable under small perturbations of <span class="arithmatex">\(\psi\)</span>, but even gives wrong asymptotic results when used in (5). But for his favorite Hampel estimate, the difference between <span class="arithmatex">\(d f^{*}\)</span> and <span class="arithmatex">\(n-1\)</span> is negligible.]
Example 8.1 For an <span class="arithmatex">\(M\)</span>-estimate <span class="arithmatex">\(T\)</span> of location we obtain, from (8.5) and the influence function (4.11),</p>
<div class="arithmatex">\[
n D_{n}^{2}=\frac{\frac{1}{n-1} \sum \psi\left(\frac{x_{i}-T_{n}}{S_{n}}\right)^{2} S_{n}^{2}}{\left[\frac{1}{n} \sum \psi^{\prime}\left(\frac{x_{i}-T_{n}}{S_{n}}\right)\right]^{2}}
\]</div>
<p>Example 8.2 In the case of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean <span class="arithmatex">\(\bar{x}_{\alpha}\)</span>, an instructive, explicit comparison between the scatter estimates derived from the jack-</p>
<p>knife and from the influence function is possible. Assume that the sample is ordered, <span class="arithmatex">\(x_{1} \leqslant x_{2} \leqslant \cdots \leqslant x_{n}\)</span>. We distinguish two cases:
Case <span class="arithmatex">\(\boldsymbol{A} \quad g-1 \leqslant(n-1) \alpha&lt;n \alpha \leqslant g, g\)</span> integral Then, with <span class="arithmatex">\(p=g-n \alpha\)</span>, <span class="arithmatex">\(q=g-(n-1) \alpha\)</span>, we have</p>
<div class="arithmatex">\[
(1-2 \alpha) n \bar{x}_{\alpha, n}=p x_{g}+x_{g+1}+\cdots+x_{n-g}+p x_{n-g+1}
\]</div>
<p>The jackknifed pseudo-observations can be represented as</p>
<div class="arithmatex">\[
T_{n i}^{*}=\frac{1}{1-2 \alpha}\left(x_{i}^{W}-\Delta\right)
\]</div>
<p>where <span class="arithmatex">\(\left\{x_{i}^{W}\right\}\)</span> is the <span class="arithmatex">\(\alpha^{\prime}\)</span>-Winsorized sample [with <span class="arithmatex">\(\alpha^{\prime}=\alpha(n-1) / n\)</span> ]</p>
<div class="arithmatex">\[
\begin{aligned}
x_{i}^{W} &amp; =q x_{g}+(1-q) x_{g+1}, &amp; &amp; \text { for } i \leqslant g \\
&amp; =x_{i}, &amp; &amp; \text { for } g&lt;i&lt;n-g+1 \\
&amp; =(1-q) x_{n-g}+q x_{n-g+1} &amp; &amp; \text { for } i \geqslant n-g+1
\end{aligned}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\Delta=\alpha\left(x_{g}+x_{n-g+1}\right)
\]</div>
<p>Thus</p>
<div class="arithmatex">\[
T_{n}^{*}=\frac{1}{n} \sum T_{n i}^{*}=\bar{x}_{\alpha, n}+\frac{g(1-q)}{(1-2 \alpha) n}\left[-x_{g}+x_{g+1}+x_{n-g}-x_{n-g+1}\right]
\]</div>
<p>and we obtain the jackknifed variance</p>
<div class="arithmatex">\[
n D_{n}^{2}=\frac{1}{n-1} \sum\left(T_{n i}^{*}-T_{n}^{*}\right)^{2}=\frac{1}{n-1} \frac{1}{(1-2 \alpha)^{2}} \sum\left(x_{i}^{W}-\bar{x}^{W}\right)^{2}
\]</div>
<p>Case B <span class="arithmatex">\((n-1) \alpha=g-q \leqslant g \leqslant g+p=n \alpha, g\)</span> integral Then</p>
<div class="arithmatex">\[
(1-2 \alpha) n \bar{x}_{\alpha, n}=(1-p) x_{g+1}+x_{g+2}+\cdots+x_{n-g-1}+(1-p) x_{n-g}
\]</div>
<p>Formulas (8.9) to (8.13) remain valid with the following changes:</p>
<div class="arithmatex">\[
\Delta=q x_{g}+p x_{g+1}+p x_{n-g}+q x_{n-g+1}
\]</div>
<p>and in (8.12) for <span class="arithmatex">\(T_{n}^{*}\)</span> the factor in front of the square bracket is changed into <span class="arithmatex">\((n-g) q /(1-2 \alpha) n\)</span>.</p>
<p>The influence function approach (8.5) works as follows. The influence function of the <span class="arithmatex">\(\alpha\)</span>-trimmed mean is given by (3.3.18). There is a question of taste whether we should define <span class="arithmatex">\(F_{n}^{-1}(\alpha)=x_{1 n \alpha 1}=x_{g}\)</span> or, by linear interpolation, <span class="arithmatex">\(F_{n}^{-1}(\alpha)=p x_{g}+(1-p) x_{g+1}\)</span>, with <span class="arithmatex">\(g\)</span> and <span class="arithmatex">\(p\)</span> as in Case A. For either choice we obtain the representation</p>
<div class="arithmatex">\[
n D_{n}^{2}=\frac{n}{n-1} \int I C_{n}^{2} d F_{n}=\frac{1}{n-1} \frac{1}{(1-2 \alpha)^{2}} \sum\left(x_{i}^{W}-\bar{x}^{W}\right)^{2}
\]</div>
<p>where the Winsorizing parameter used in the definition of <span class="arithmatex">\(x_{i}^{W}\)</span> is <span class="arithmatex">\(g / n\)</span> or <span class="arithmatex">\(\alpha\)</span>, respectively. The difference to the jackknifed variance clearly is negligible and has mostly to do with the fine print in the definition of the estimates and sample distribution functions. But obviously, the influence function approach, when available, is cheaper to calculate.</p>
<h1 id="chapter-7">CHAPTER 7</h1>
<h2 id="regression">Regression</h2>
<h3 id="71-general-remarks">7.1 GENERAL REMARKS</h3>
<p>Regression poses some peculiar and difficult robustness problems. Consider the following example. Assume that a straight line is to be fitted through six points, whose coordinates are given in Exhibit 7.1.1. A least squares fit (fit 1) yields the line shown in Exhibit 7.1.2a. A casual scan of the values in Exhibit 7.1.1 leaves the impression that everything is fine; in particular, none of the residuals <span class="arithmatex">\(r_{i}=y_{i}-\hat{y}_{i}\)</span> is exceptionally large when compared to the estimated standard deviation <span class="arithmatex">\(\hat{\sigma}\)</span> of the observations. A closer scrutiny, in particular, a closer look at Exhibit 7.1.2a, may, however, lead to the suspicion that there could be something wrong either with point 1 (which has the largest residual), or, perhaps, with point 6 . If we drop point 6 from the fit, we obtain fit 2 (shown in Exhibit 7.1.2b). But, possibly, a linear model was inappropriate to start with, and we should have fitted a parabola (fit 3, Exhibit 7.1.2c). It is fairly clear that the available data do not suffice to distinguish between these three possibilities. Because of the low residual error <span class="arithmatex">\(\hat{\sigma}\)</span>, we might perhaps lean towards</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Point</th>
<th style="text-align: center;"><span class="arithmatex">\(x\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(y\)</span></th>
<th style="text-align: center;">Fit 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Fit 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Fit 3</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{y}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(y-\hat{y}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{y}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(y-\hat{y}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{y}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(y-\hat{y}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-4</td>
<td style="text-align: center;">2.48</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">2.09</td>
<td style="text-align: center;">2.04</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">2.23</td>
<td style="text-align: center;">0.25</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">-3</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">1.06</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.33\)</span></td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.26\)</span></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">-2</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.04\)</span></td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.27\)</span></td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.12\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-0.09\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-0.13\)</span></td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;"><span class="arithmatex">\(-1.44\)</span></td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;"><span class="arithmatex">\(-1.59\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-0.90\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-0.54\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-1.00\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-0.44\)</span></td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"><span class="arithmatex">\(-1.32\)</span></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;"><span class="arithmatex">\(-1.39\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(-1.87\)</span></td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;"><span class="arithmatex">\(-1.74\)</span></td>
<td style="text-align: center;">0.42</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.75\)</span></td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;"><span class="arithmatex">\(-11.64\)</span></td>
<td style="text-align: center;">(11.64)</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;"><span class="arithmatex">\(-0.01\)</span></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">e.s.d.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{\sigma}=1.55\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{\sigma}=0.55\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(\hat{\sigma}=0.41\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(r_{\max } / \hat{\sigma}=1.35\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(r_{\max } / \hat{\sigma}=1.00\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="arithmatex">\(r_{\max } / \hat{\sigma}=1.08\)</span></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Exhibit 7.1.1</p>
<p><img alt="img-8.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 7.1.2 (a) Fit 1. (b) Fit 2. (c) Fit 3.</p>
<p>the third variant. In actual fact the example is synthetic and the points have been generated by taking the line <span class="arithmatex">\(y=-2-x\)</span>, adding random normal errors (with mean 0 and standard error 0.6 ) to points 1 to 5 , and a gross error of 12 to point 6 . Thus fit 2 is the appropriate one, and it happens to hit the true line almost perfectly.</p>
<p>In this case, only two parameters were involved, and a graph like Exhibit 7.1.2 helped to spot the potentially troublesome point number 6 , even if the corresponding residual was quite unobtrusive. But what can be done in more complicated multiparameter problems? The difficulty is of course that a gross error does not necessarily show up through a large residual; by causing an overall increase in the size of other residuals, it can even hide behind a veritable smokescreen. In order to disentangle the issues, we must:
(1) Find analytical methods for identifying so-called leverage points, that is, points in the design space where an observation, by virtue of its position, has an overriding influence on the fit and in particular on its own fitted value. Such an observation may be the most important one in the sample (e.g., an isolated astronomical observation from remote antiquity), but on the other hand its value is difficult or impossible to crosscheck.
(2) Find routine methods for robust estimation of regression coefficients when there are no leverage points.
(3) Find estimation methods that work reasonably well and robustly also in the presence of moderately bad leverage points.</p>
<p>Not surprisingly, the treatment of the last part is the least satisfactory of the three.</p>
<p>We leave aside all issues connected with ridge regression, Stein estimation, and the like. These questions and robustness seem to be sufficiently orthogonal to each other that it should be possible to superimpose them without very serious interactions.</p>
<h1 id="72-the-classical-linear-least-squares-case">7.2 THE CLASSICAL LINEAR LEAST SQUARES CASE</h1>
<p>The main purpose of this section is to discuss and clarify some of the issues connected with the leverage points.</p>
<p>Assume that <span class="arithmatex">\(p\)</span> unknown parameters <span class="arithmatex">\(\theta_{1}, \ldots, \theta_{p}\)</span> are to be estimated from <span class="arithmatex">\(n\)</span> observations <span class="arithmatex">\(y_{1}, \ldots, y_{n}\)</span> to which they are related by</p>
<div class="arithmatex">\[
y_{i}=\sum_{j=1}^{p} x_{i j} \theta_{j}+u_{i}
\]</div>
<p>where the <span class="arithmatex">\(x_{i j}\)</span> are known coefficients and the <span class="arithmatex">\(u_{i}\)</span> are independent random variables with (approximately) identical distributions. We also use matrix notation,</p>
<div class="arithmatex">\[
\mathbf{y}=X \boldsymbol{\theta}+\mathbf{u}
\]</div>
<p>Classically, the problem is solved by minimizing the sum of squares</p>
<div class="arithmatex">\[
\sum_{i}\left(y_{i}-\sum x_{i j} \theta_{j}\right)^{2}=\min !
\]</div>
<p>or, equivalently, by solving the system of <span class="arithmatex">\(p\)</span> equations obtained by differentiating (2.3),</p>
<div class="arithmatex">\[
\sum_{i}\left(y_{i}-\sum x_{i k} \theta_{k}\right) x_{i j}=0
\]</div>
<p>or, in matrix notation,</p>
<div class="arithmatex">\[
X^{T} X \boldsymbol{\theta}=X^{T} \mathbf{y}
\]</div>
<p>We assume that <span class="arithmatex">\(X\)</span> has full rank <span class="arithmatex">\(p\)</span>, so the solution can be written</p>
<div class="arithmatex">\[
\hat{\boldsymbol{\theta}}=\left(X^{T} X\right)^{-1} X^{T} \mathbf{y}
\]</div>
<p>and, in particular, the fitted values [the least squares estimates <span class="arithmatex">\(\hat{y}_{i}\)</span> of the expected values <span class="arithmatex">\(E y_{i}=(X \boldsymbol{\theta})_{i}\)</span> of the observations] are given by</p>
<div class="arithmatex">\[
\hat{\mathbf{y}}=X\left(X^{T} X\right)^{-1} X^{T} \mathbf{y}=H \mathbf{y}
\]</div>
<p>with</p>
<div class="arithmatex">\[
H=X\left(X^{T} X\right)^{-1} X^{T}
\]</div>
<p>The matrix <span class="arithmatex">\(H\)</span> is often called "hat matrix" (since it puts the hat on <span class="arithmatex">\(\mathbf{y}\)</span> ).
We note that <span class="arithmatex">\(H\)</span> is a symmetric <span class="arithmatex">\(n \times n\)</span> projection matrix, that is, <span class="arithmatex">\(H H=H\)</span>, and that it has <span class="arithmatex">\(p\)</span> eigenvalues equal to 1 and <span class="arithmatex">\(n-p\)</span> eigenvalues equal to 0 . Its diagonal elements, denoted by <span class="arithmatex">\(h_{i}=h_{i i}\)</span>, satisfy</p>
<div class="arithmatex">\[
0 \leqslant h_{i} \leqslant 1
\]</div>
<p>and the trace of <span class="arithmatex">\(H\)</span> is</p>
<div class="arithmatex">\[
\operatorname{tr}(H)=p
\]</div>
<p>We now assume that the errors <span class="arithmatex">\(u_{i}\)</span> are independent and have a common distribution <span class="arithmatex">\(F\)</span> with mean <span class="arithmatex">\(E u_{i}=0\)</span> and variance <span class="arithmatex">\(E u_{i}^{2}=\sigma^{2}&lt;\infty\)</span>. Assume that our regression problem is imbedded in an infinite sequence of similar problems, such that the number <span class="arithmatex">\(n\)</span> of observations, and possibly also the number <span class="arithmatex">\(p\)</span> of parameters, tend to infinity; we suppress the index that gives the position of our problems in this sequence.</p>
<p>Questions When is a fitted value <span class="arithmatex">\(\hat{y}_{i}\)</span> consistent, in the sense that</p>
<div class="arithmatex">\[
\hat{y}_{i}-E\left(y_{i}\right) \rightarrow 0
\]</div>
<p>in probability? When are all fitted values consistent?
Since <span class="arithmatex">\(E \mathbf{u}=0, \hat{\mathbf{y}}\)</span> is unbiased:</p>
<div class="arithmatex">\[
E \hat{\mathbf{y}}=E \mathbf{y}=X \boldsymbol{\theta}
\]</div>
<p>We have</p>
<div class="arithmatex">\[
\hat{y}_{i}=\sum h_{i k} y_{k}
\]</div>
<p>and thus</p>
<div class="arithmatex">\[
\operatorname{var}\left(\hat{y}_{i}\right)=\sum_{k} h_{i k}^{2} \sigma^{2}=h_{i} \sigma^{2}
\]</div>
<p>(note that <span class="arithmatex">\(\sum_{k} h_{i k}^{2}=h_{i}\)</span>, since <span class="arithmatex">\(H\)</span> is symmetric and idempotent). Hence by Chebyshev's inequality,</p>
<div class="arithmatex">\[
P\left[\left|\hat{y}_{i}-E\left(y_{i}\right)\right| \geqslant \varepsilon\right] \leqslant \frac{h_{i} \sigma^{2}}{\varepsilon^{2}}
\]</div>
<p>and we have proved the sufficiency part of the following proposition.
PROPOSITION 2.1 Assume that the errors <span class="arithmatex">\(u_{i}\)</span> are independent with mean 0 and common variance <span class="arithmatex">\(\sigma^{2}&lt;\infty\)</span>. Then <span class="arithmatex">\(\hat{y}_{i}\)</span> is consistent iff <span class="arithmatex">\(h_{i} \rightarrow 0\)</span>, and the fitted values <span class="arithmatex">\(\hat{y}_{i}\)</span> are all consistent iff</p>
<div class="arithmatex">\[
h=\max _{1&lt;i&lt;n} h_{i} \rightarrow 0
\]</div>
<p>Proof We have to show necessity of the condition. This follows easily from</p>
<div class="arithmatex">\[
\hat{y}_{i}-E \hat{y}_{i}=h_{i} u_{i}+\sum_{k \neq i} h_{i k} u_{k}
\]</div>
<p>and the remark that, for independent random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, we have</p>
<div class="arithmatex">\[
\begin{aligned}
P(|X+Y| \geqslant \varepsilon) &amp; \geqslant P(X \geqslant \varepsilon) P(Y \geqslant 0)+P(X \leqslant-\varepsilon) P(Y&lt;0) \\
&amp; \geqslant \min [P(X \geqslant \varepsilon), P(X \leqslant-\varepsilon)]
\end{aligned}
\]</div>
<p>Thus</p>
<div class="arithmatex">\[
P\left(\left|\hat{y}_{i}-E \hat{y}_{i}\right| \geqslant \varepsilon\right) \geqslant \min \left[P\left(u_{i} \geqslant \frac{\varepsilon}{h_{i}}\right), P\left(u_{i} \leqslant-\frac{\varepsilon}{h_{i}}\right)\right]
\]</div>
<p>Note that <span class="arithmatex">\(h=\max h_{i} \geqslant\)</span> ave <span class="arithmatex">\(h_{i}=\operatorname{tr}(H) / n=p / n\)</span>; hence <span class="arithmatex">\(h\)</span> cannot converge to 0 unless <span class="arithmatex">\(p / n \rightarrow 0\)</span>.</p>
<p>The following formulas are straightforward to establish (under the assumptions of the preceding proposition):</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{var} \hat{y}_{i} &amp; =h_{i} \sigma^{2} \\
\operatorname{var}\left(y_{i}-\hat{y}_{i}\right) &amp; =\left(1-h_{i}\right) \sigma^{2} \\
\operatorname{cov}\left(\hat{y}_{i}, \hat{y}_{k}\right) &amp; =h_{i k} \sigma^{2} \\
\operatorname{cov}\left(y_{i}-\hat{y}_{i}, y_{k}-\hat{y}_{k}\right) &amp; =\left(\delta_{i k}-h_{i k}\right) \sigma^{2} \\
\operatorname{cov}\left(\hat{y}_{i}, y_{k}-\hat{y}_{k}\right) &amp; =0, \quad \text { for all } i, k
\end{aligned}
\]</div>
<p>Now let</p>
<div class="arithmatex">\[
\hat{\alpha}=\sum a_{j} \hat{\theta}_{j}=\mathbf{a}^{T} \hat{\boldsymbol{\theta}}
\]</div>
<p>be the least squares estimate of an arbitrary linear combination <span class="arithmatex">\(\alpha=\mathbf{a}^{T} \boldsymbol{\theta}\)</span>.
If <span class="arithmatex">\(F\)</span> is normal, then <span class="arithmatex">\(\hat{\alpha}\)</span> is automatically normal.</p>
<p>Question Assume that <span class="arithmatex">\(F\)</span> is not normal. Under which conditions is <span class="arithmatex">\(\hat{\alpha}\)</span> asymptotically normal (as <span class="arithmatex">\(p, n \rightarrow \infty\)</span> )?</p>
<p>Without restricting generality we can choose the coordinate system in the parameter space such that <span class="arithmatex">\(X^{T} X=I\)</span> is the <span class="arithmatex">\(p \times p\)</span> identity matrix. Further-</p>
<p>more assume <span class="arithmatex">\(\mathbf{a}^{T} \mathbf{a}=1\)</span>. Then <span class="arithmatex">\(\hat{\boldsymbol{\theta}}=X^{T} \mathbf{y}\)</span>, and</p>
<div class="arithmatex">\[
\hat{\alpha}=\mathbf{a}^{T} \hat{\boldsymbol{\theta}}=\mathbf{a}^{T} X^{T} \mathbf{y}=\mathbf{s}^{T} \mathbf{y}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\mathbf{s}=X \mathbf{a}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\mathbf{s}^{T} \mathbf{s}=\mathbf{a}^{T} X^{T} X \mathbf{a}=\mathbf{a}^{T} \mathbf{a}=1
\]</div>
<p>Thus</p>
<div class="arithmatex">\[
\operatorname{var}(\hat{\alpha})=\sigma^{2}
\]</div>
<p>PROPOSITION 2.2 <span class="arithmatex">\(\hat{\alpha}\)</span> is asymptotically normal iff <span class="arithmatex">\(\max _{i}\left|s_{i}\right| \rightarrow 0\)</span>.
Proof If <span class="arithmatex">\(\max _{i}\left|s_{i}\right| \rightarrow 0\)</span>, then <span class="arithmatex">\(\hat{\alpha}\)</span> either does not have a limiting distribution at all, or, if it has, the limiting distribution can be written as a convolution of two parts one of which is <span class="arithmatex">\(F\)</span> (apart from a scale factor); hence it cannot be normal [see, e.g., Feller (1966), p. 498]. If <span class="arithmatex">\(\gamma=\max _{i}\left|s_{i}\right| \rightarrow 0\)</span>, then we can easily check Lindeberg's condition:</p>
<div class="arithmatex">\[
\begin{aligned}
\frac{1}{\sigma^{2}} \sum_{i} E\left\{s_{i}^{2} u_{i}^{2} 1_{\left\{\left|s_{i} u_{i}\right|&gt;\varepsilon \sigma\right\}}\right\} &amp; &lt;\frac{1}{\sigma^{2}} \sum_{i} s_{i}^{2} E\left\{u_{i}^{2} 1_{\left\{\left|u_{i}\right|&gt;\varepsilon \sigma / \gamma\right\}}\right\} \\
&amp; =\frac{1}{\sigma^{2}} E\left\{u^{2} 1_{\left\{|u|&gt;\varepsilon \sigma / \gamma\right\}}\right\} \rightarrow 0
\end{aligned}
\]</div>
<p>This finishes the proof of the proposition.
Note that the Schwarz inequality gives</p>
<div class="arithmatex">\[
s_{i}^{2}=\left(\sum_{k} x_{i k} a_{k}\right)^{2} \leqslant \sum_{k} x_{i k}^{2} \sum_{k} a_{k}^{2}=h_{i}
\]</div>
<p>Hence we obtain, as a corollary, the following theorem.
THEOREM 2.3 If <span class="arithmatex">\(h=\max _{i} h_{i} \rightarrow 0\)</span>, then all least squares estimates <span class="arithmatex">\(\hat{\alpha}=\)</span> <span class="arithmatex">\(\sum a_{j} \hat{\theta}_{j}=\mathbf{a}^{T} \hat{\boldsymbol{\theta}}\)</span> are asymptotically normal. If not, then, in particular, some of the fitted values are not asymptotically normal.</p>
<p>Proof The direct part is an immediate consequence of the preceding proposition. For the converse recall that <span class="arithmatex">\(\hat{y}_{i}=\sum h_{i k} y_{k}\)</span>. For each <span class="arithmatex">\(n\)</span> choose <span class="arithmatex">\(i\)</span> such that <span class="arithmatex">\(h_{i}=h\)</span>. Then the standardized sequence <span class="arithmatex">\(\left[\left(\hat{y}_{i}-E\left(\hat{y}_{i}\right)\right] / \sqrt{h_{i}}\right.\)</span> has expectation 0 and variance <span class="arithmatex">\(\sigma^{2}\)</span>, but cannot be asymptotically normal.</p>
<h1 id="residuals-and-outliers">Residuals and Outliers</h1>
<p>The <span class="arithmatex">\(i\)</span> th residual can be written</p>
<div class="arithmatex">\[
r_{i}=y_{i}-\hat{y}_{i}=\left(1-h_{i}\right) y_{i}-\sum_{k \neq i} h_{i k} y_{k}
\]</div>
<p>Hence if <span class="arithmatex">\(h_{i}\)</span> is close to 1 , a gross error in <span class="arithmatex">\(y_{i}\)</span> will not necessarily show up in <span class="arithmatex">\(r_{i}\)</span>. But it might show up elsewhere, say in <span class="arithmatex">\(r_{k}\)</span>, if <span class="arithmatex">\(h_{k i}\)</span> happens to be large. For instance, in the introductory example of Section 7.1 (fit 1), we have <span class="arithmatex">\(h_{k}=0.936\)</span>. Points with large <span class="arithmatex">\(h_{i}\)</span> are, by definition, leverage points.</p>
<p>We may say that <span class="arithmatex">\(1 / h_{i}\)</span> is the equivalent number of observations entering into the determination of <span class="arithmatex">\(\hat{y}_{i}\)</span>. We show later that, if <span class="arithmatex">\(h_{i}=1 / k\)</span> and if we duplicate the <span class="arithmatex">\(i\)</span> th row of <span class="arithmatex">\(X\)</span> (make an additional observation there), then <span class="arithmatex">\(h_{i}\)</span> is changed to <span class="arithmatex">\(1 /(k+1)\)</span>. In other words if <span class="arithmatex">\(h_{i}\)</span> is large, it can easily be decreased by duplication or triplication of the observation <span class="arithmatex">\(y_{i}\)</span>. (In practice approximate duplication, i.e., observing under slightly varied conditions, is to be preferred over exact duplication, since this helps to avoid repetition of systematic errors.)</p>
<p>We now work this out in detail. We have</p>
<div class="arithmatex">\[
H=X\left(X^{T} X\right)^{-1} X^{T}
\]</div>
<p>What happens if we add another row vector <span class="arithmatex">\(\mathbf{x}^{T}\)</span> to <span class="arithmatex">\(X\)</span> :</p>
<div class="arithmatex">\[
\tilde{X}=\binom{X}{\mathbf{x}^{T}} ?
\]</div>
<p>Without loss of generality we assume <span class="arithmatex">\(X^{T} X=I\)</span>; then</p>
<div class="arithmatex">\[
\tilde{X}^{T} \tilde{X}=I+\mathbf{x x}^{T}
\]</div>
<p>We can easily check that</p>
<div class="arithmatex">\[
\left(\tilde{X}^{T} \tilde{X}\right)^{-1}=I-\frac{\mathbf{x x}^{T}}{1+\mathbf{x}^{T} \mathbf{x}}
\]</div>
<p>The modified hat matrix <span class="arithmatex">\(\tilde{H}\)</span> is also easy to work out:</p>
<div class="arithmatex">\[
\begin{aligned}
\tilde{H} &amp; =\tilde{X}\left(\tilde{X}^{T} \tilde{X}\right)^{-1} \tilde{X}^{T} \\
&amp; =\left(\frac{X}{\mathbf{x}^{T}}\right)\left(I-\frac{\mathbf{x} \mathbf{x}^{T}}{1+\mathbf{x}^{T} \mathbf{x}}\right)\left(X^{T} \mid \mathbf{x}\right) \\
&amp; =\left(\begin{array}{c|c}
X X^{T}-\frac{(X \mathbf{x})(X \mathbf{x})^{T}}{1+\mathbf{x}^{T} \mathbf{x}} &amp; \frac{X \mathbf{x}}{1+\mathbf{x}^{T} \mathbf{x}} \\
\frac{(X \mathbf{x})^{T}}{1+\mathbf{x}^{T} \mathbf{x}} &amp; \frac{\mathbf{x}^{T} \mathbf{x}}{1+\mathbf{x}^{T} \mathbf{x}}
\end{array}\right)
\end{aligned}
\]</div>
<p>Example 2.1 Duplication of a row, say row <span class="arithmatex">\(n\)</span>. Then (still assuming <span class="arithmatex">\(\left.X^{T} X=I\right)\)</span> we have <span class="arithmatex">\(\mathbf{x}^{T} \mathbf{x}=h_{n}\)</span>, and thus</p>
<div class="arithmatex">\[
\tilde{h}_{n+1}=\frac{h_{n}}{1+h_{n}}
\]</div>
<p>Since there is no possibility of confusion, we omit the tilde on <span class="arithmatex">\(h_{n+1}\)</span> from now on. In particular, if <span class="arithmatex">\(h_{n}=1 / k\)</span>, we obtain <span class="arithmatex">\(h_{n+1}=1 /(k+1)\)</span>.
Example 2.2 Leaving out a row (say row <span class="arithmatex">\(n+1\)</span>, after we have added it):
(1) With row <span class="arithmatex">\(n+1\)</span> in we obtain, from (2.31),</p>
<div class="arithmatex">\[
\operatorname{var}\left(\hat{y}_{n+1}\right)=h_{n+1} \sigma^{2}=\frac{\mathbf{x}^{T} \mathbf{x}}{1+\mathbf{x}^{T} \mathbf{x}} \sigma^{2}
\]</div>
<p>(2) With row <span class="arithmatex">\(n+1\)</span> out, let <span class="arithmatex">\(\hat{\alpha}_{n+1}\)</span> be the estimate of <span class="arithmatex">\(E\left(y_{n+1}\right)\)</span> based on the remaining observations <span class="arithmatex">\(y_{1}, \ldots, y_{n}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
\hat{\alpha}_{n+1} &amp; =\mathbf{x}^{T} \hat{\boldsymbol{\theta}} \\
\operatorname{var}\left(\hat{\alpha}_{n+1}\right) &amp; =\mathbf{x}^{T} \mathbf{x} \sigma^{2}=\frac{h_{n+1}}{1-h_{n+1}} \sigma^{2}
\end{aligned}
\]</div>
<p>Note that <span class="arithmatex">\(\operatorname{var}\left(\hat{\alpha}_{n+1}\right)\)</span> is larger than <span class="arithmatex">\(\operatorname{var}\left(y_{n+1}\right)\)</span> if <span class="arithmatex">\(h_{n+1}&gt;\frac{1}{2}\)</span>.
We have</p>
<div class="arithmatex">\[
\hat{y}_{n+1}=\left(1-h_{n+1}\right) \hat{\alpha}_{n+1}+h_{n+1} y_{n+1}
\]</div>
<p>that is the <span class="arithmatex">\((n+1)\)</span> th fitted value is a convex linear combination of the "predicted" value <span class="arithmatex">\(\hat{\alpha}_{n+1}\)</span> (which disregards <span class="arithmatex">\(y_{n+1}\)</span> ) and the observation <span class="arithmatex">\(y_{n+1}\)</span>, with weights <span class="arithmatex">\(1-h_{n+1}\)</span> and <span class="arithmatex">\(h_{h+1}\)</span>, respectively. This is shown by a look at the last row of the matrix <span class="arithmatex">\(\hat{H}\)</span>.</p>
<p>In terms of residuals the above formula reads</p>
<div class="arithmatex">\[
r_{n+1}=y_{n+1}-\hat{y}_{n+1}=\left(1-h_{n+1}\right)\left(y_{n+1}-\hat{\alpha}_{n+1}\right)
\]</div>
<p>This relation is important; it connects the ordinary residual <span class="arithmatex">\(y_{n+1}-\hat{y}_{n+1}\)</span> with the residual <span class="arithmatex">\(y_{n+1}-\hat{\alpha}_{n+1}\)</span> relative to the "interpolated" value <span class="arithmatex">\(\hat{\alpha}_{n+1}\)</span> ignoring <span class="arithmatex">\(y_{n+1}\)</span>.</p>
<p>Of course, all these relations hold for arbitrary indices, not only for <span class="arithmatex">\(i=n+1\)</span>.</p>
<p>We may conclude from this discussion that the diagonal of the hat matrix contains extremely useful information. In particular, large values of <span class="arithmatex">\(h_{i}\)</span> should serve as warning signals that the <span class="arithmatex">\(i\)</span> th observation may have a decisive, yet hardly checkable, influence. Values <span class="arithmatex">\(h_{i}&lt;0.2\)</span> appear to be safe, values between 0.2 and 0.5 are risky, and if we can control the design at all, we had better avoid values above 0.5 .</p>
<h1 id="73-robustizing-the-least-squares-approach">7.3 ROBUSTIZING THE LEAST SQUARES APPROACH</h1>
<p>The classical equations (2.3) and (2.4) can be robustized in a straightforward way; instead of minimizing a sum of squares, we minimize a sum of less rapidly increasing functions of the residuals:</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \rho\left(y_{i}-\sum x_{i j} \theta_{j}\right)=\min !
\]</div>
<p>or, after taking derivatives, we solve</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \psi\left(y_{i}-\sum x_{i j} \theta_{j}\right) x_{i k}=0, \quad k=1, \ldots, p
\]</div>
<p>with <span class="arithmatex">\(\psi=\rho^{\prime}\)</span>. If <span class="arithmatex">\(\rho\)</span> is convex, the two approaches are essentially equivalent; otherwise the selection of the "best" solution of (3.2) may create problems.</p>
<p>We denote the <span class="arithmatex">\(i\)</span> th residual by</p>
<div class="arithmatex">\[
r_{i}=r_{i}(\theta)=y_{i}-\sum_{j} x_{i j} \theta_{j}
\]</div>
<p>Note that (3.2) can be viewed as a robustized version of the cross product</p>
<p>of the residual vector <span class="arithmatex">\(\mathbf{r}\)</span> with the <span class="arithmatex">\(k\)</span> th column vector of <span class="arithmatex">\(X\)</span>; the residuals <span class="arithmatex">\(r_{i}\)</span> have been replaced by metrically Winsorized versions <span class="arithmatex">\(\psi\left(r_{i}\right)\)</span>.</p>
<p>Ordinarily, scale will not be known, so it will be necessary to make (3.2) scale invariant by introducing some estimate <span class="arithmatex">\(s\)</span> of scale:</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{r_{i}}{s}\right) x_{i k}=0
\]</div>
<p>Possibly we might use individual scales <span class="arithmatex">\(s_{i}\)</span>, and even more generally, we might use different functions <span class="arithmatex">\(\rho_{i}\)</span> and <span class="arithmatex">\(\psi_{i}\)</span> for different observations.</p>
<p>We are acting under the assumption that the <span class="arithmatex">\(x_{i j}\)</span> are known and error-free. If this is not so, it might be advisable to modify not only the residual vector <span class="arithmatex">\(\mathbf{r}\)</span>, but also the column vectors <span class="arithmatex">\(\mathbf{x}_{j}\)</span> in order to gain robustness also with regard to errors in the coefficients <span class="arithmatex">\(x_{i j}\)</span>. There are several obvious proposals for doing so; they may look plausible, but they hitherto lack a sound theoretical underpinning. Conceivably they might do more harm (by introducing bias) than good.</p>
<p>We obtain <span class="arithmatex">\(R\)</span>-estimates of regression if we minimize, instead of (3.1),</p>
<div class="arithmatex">\[
\sum_{i} a_{n}\left(R_{i}\right) r_{i}=\min !
\]</div>
<p>Here, <span class="arithmatex">\(R_{i}\)</span> is the rank of <span class="arithmatex">\(r_{i}\)</span> in <span class="arithmatex">\(\left(r_{1}, \ldots, r_{n}\right)\)</span>, and <span class="arithmatex">\(a_{n}(\cdot)\)</span> is some monotone scores function satisfying <span class="arithmatex">\(\Sigma_{i} a_{n}(i)=0\)</span> [see Jaeckel (1972)]. Note, however, that these estimates are unable to estimate an additive main effect and thus do not contain estimates of location as particular cases. On the contrary the additive main effect has to be estimated by applying an estimate of location to the residuals.</p>
<p>If we differentiate (3.5), which is a piecewise linear convex function of <span class="arithmatex">\(\boldsymbol{\theta}\)</span>, we obtain the following approximate equalities at the minimum:</p>
<div class="arithmatex">\[
\sum_{i} a_{n}\left(R_{i}\right) x_{i k} \approx 0, \quad k=1, \ldots, p
\]</div>
<p>These approximate equations in turn can be reconverted into a minimum problem, for example,</p>
<div class="arithmatex">\[
\sum_{k}\left|\sum_{i} a_{n}\left(r_{i}\right) x_{i k}\right|=\min !
\]</div>
<p>This last variant was investigated by Jurečková (1971), and asymptotic equivalence between (3.6) and (3.7) was shown by Jaeckel (1972). The task</p>
<p>of solving (3.6) or (3.7) by linear programming techniques appears to be very formidable, however, unless <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(n\)</span> are quite small.</p>
<p>All of the regression estimates allow one-step versions: start with some reasonably good preliminary estimate <span class="arithmatex">\(\theta^{*}\)</span>, and then apply one step of Newton's method to (3.2), and so on, just as in the location case. A one-step <span class="arithmatex">\(L\)</span>-estimate of regression has been investigated by Bickel (1973). However, in the regression case it is very difficult to find a good starting value. We know from the location case that the least squares estimate, that is, the sample mean, will not do for one-step estimates, and the analogue of the sample median, which gives an excellent starting point for location, would be the so-called <span class="arithmatex">\(L_{1}\)</span>-estimate [corresponding to <span class="arithmatex">\(\rho(X)=|X|]\)</span>, which itself may be harder to compute than most of the robust regression estimates we want to use.</p>
<p>It appears that <span class="arithmatex">\(M\)</span>-estimates offer enough flexibility and are by far the easiest to cope with, simultaneously, with regard to computation, asymptotic theory, and intuitive interpretation; moreover, the step from (2.3) to (3.1) is easily explainable to nonstatisticians also. We therefore restrict ourselves to <span class="arithmatex">\(M\)</span>-estimates of regression.</p>
<h1 id="74-asymptotics-of-robust-regression-estimates">7.4 ASYMPTOTICS OF ROBUST REGRESSION ESTIMATES</h1>
<p>The obvious approach to asymptotics is: keep the number <span class="arithmatex">\(p\)</span> of parameters fixed, let the number <span class="arithmatex">\(n\)</span> of observations go to infinity. However, in practice <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(n\)</span> tend to become large simultaneously; in crystallography, where some of the largest least squares problems occur (with hundreds or thousands of parameters) we find the explicit recommendation that there should be at least five observations per parameter (Hamilton 1970). This suggests that a meaningful asymptotic theory should be in terms of <span class="arithmatex">\(p / n \rightarrow 0\)</span>, or, perhaps better, in terms of <span class="arithmatex">\(h=\max h_{c} \rightarrow 0\)</span>. The point we make here, which is given some technical substantiation later, is that, if the asymptotic theory requires, say, <span class="arithmatex">\(p^{3} / n \rightarrow 0\)</span>, and if it is able to give a useful approximation for <span class="arithmatex">\(n=20\)</span> if <span class="arithmatex">\(p=1\)</span>, then, for <span class="arithmatex">\(p=10\)</span>, we would need <span class="arithmatex">\(n=20,000\)</span> to get an equally good approximation! In an asymptotic theory that keeps <span class="arithmatex">\(p\)</span> fixed such distinctions do not become visible at all.</p>
<p>We begin with a short discussion of the overall regularity conditions. They separate into three parts, conditions on: the design matrix <span class="arithmatex">\(X\)</span>, the estimate, and the error laws.</p>
<h1 id="conditions-on-the-design-matrix-x">Conditions on the Design Matrix <span class="arithmatex">\(X\)</span></h1>
<p><span class="arithmatex">\(X\)</span> has full rank <span class="arithmatex">\(p\)</span>, and the diagonal elements of the hat matrix</p>
<div class="arithmatex">\[
H=X\left(X^{T} X\right)^{-1} X^{T}
\]</div>
<p>are assumed to be uniformly small:</p>
<div class="arithmatex">\[
\max _{i&lt;i&lt;n} h_{i}=h \ll 1
\]</div>
<p>The precise order of smallness will be specified from case to case. Without loss of generality we choose the coordinate system in the parameter space such that the true parameter point is <span class="arithmatex">\(\boldsymbol{\theta}^{0}=0\)</span>, and such that <span class="arithmatex">\(X^{T} X\)</span> is the <span class="arithmatex">\(p \times p\)</span> identity matrix.</p>
<h2 id="conditions-on-the-estimate">Conditions on the Estimate</h2>
<p>The function <span class="arithmatex">\(\rho\)</span> is assumed to be convex and nonmonotone and to possess bounded derivatives of sufficiently high order (approximately four). In particular, <span class="arithmatex">\(\psi(x)=(d / d x) \rho(x)\)</span> should be continuous and bounded. Convexity of <span class="arithmatex">\(\rho\)</span> serves to guarantee equivalence between (3.1) and (3.2) and asymptotic uniqueness of the solution. If we are willing to forego this and are satisfied with local uniqueness, the convexity assumption can be omitted. Higher order derivatives are technically convenient, since they make Taylor expansions possible, but their existence does not seem to be essential for the results to hold.</p>
<h2 id="conditions-on-the-error-laws">Conditions on the Error Laws</h2>
<p>We assume that the errors <span class="arithmatex">\(u_{i}\)</span> are independent, identically distributed, such that</p>
<div class="arithmatex">\[
E\left[\psi\left(u_{i}\right)\right]=0
\]</div>
<p>We require this in order that the expectation of (3.1) reaches its minimum and the expectation of (3.2) vanishes, at the true value <span class="arithmatex">\(\boldsymbol{\theta}^{0}\)</span>.</p>
<p>The assumption of independence is a serious restriction. The assumption that the errors are identically distributed simplifies notations and calculations, but could easily be relaxed: "random" deviations (i.e., not related to the structure of <span class="arithmatex">\(X\)</span> ) can be modeled by identical distributions (take the "averaged" cumulative distribution). Nonrandom deviations (e.g., changes</p>
<p>in scale that depend on <span class="arithmatex">\(X\)</span> in a systematic fashion) can be handled by a minimax approach if the deviations are small; if they are large, they transgress our notion of robustness.</p>
<h1 id="the-case-h-p2-rightarrow-0-and-h-p-rightarrow-0">The Case <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span> and <span class="arithmatex">\(h p \rightarrow 0\)</span></h1>
<p>A simple but rigorous treatment is possible if <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span>, or, with slightly weaker results, if <span class="arithmatex">\(h p \rightarrow 0\)</span>. Note that this implies <span class="arithmatex">\(p^{3} / n \rightarrow 0\)</span> and <span class="arithmatex">\(p^{2} / n \rightarrow 0\)</span>, respectively. Thus quite moderate values of <span class="arithmatex">\(p\)</span> already lead to very large and impractical values for <span class="arithmatex">\(n\)</span>.</p>
<p>The idea is to compare the zeros of two vector-valued random functions <span class="arithmatex">\(\boldsymbol{\Phi}\)</span> and <span class="arithmatex">\(\boldsymbol{\Psi}\)</span> of <span class="arithmatex">\(\boldsymbol{\theta}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \Phi_{j}(\boldsymbol{\theta})=\frac{-1}{E\left(\psi^{\prime}\right)} \sum_{i} \psi\left(y_{i}-\sum x_{i k} \theta_{k}\right) x_{i j} \\
&amp; \Psi_{j}(\boldsymbol{\theta})=\theta_{j}-\frac{1}{E\left(\psi^{\prime}\right)} \sum_{i} \psi\left(y_{i}\right) x_{i j}
\end{aligned}
\]</div>
<p>The zero <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> of <span class="arithmatex">\(\boldsymbol{\Phi}\)</span> is our estimate. The zero <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> of <span class="arithmatex">\(\boldsymbol{\Psi}\)</span>,</p>
<div class="arithmatex">\[
\tilde{\theta}_{j}=\frac{1}{E\left(\psi^{\prime}\right)} \sum_{i} \psi\left(y_{i}\right) x_{i j}
\]</div>
<p>of course is not a genuine estimate, but according to Theorem 2.3 all linear combinations <span class="arithmatex">\(\hat{\alpha}=\sum a_{j} \hat{\theta}_{j}\)</span> are asymptotically normal if <span class="arithmatex">\(h \rightarrow 0\)</span>. So we can prove asymptotic normality of <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> (or, better, of <span class="arithmatex">\(\hat{\alpha}=\sum a_{j} \hat{\theta}_{j}\)</span> ) by showing that the difference between <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> and <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> is small.</p>
<p>Let <span class="arithmatex">\(a_{j}\)</span> be indeterminate coefficients satisfying <span class="arithmatex">\(\sum a_{j}^{2}=1\)</span> and write for short</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; s_{i}=\sum x_{i j} a_{j} \\
&amp; t_{i}=\sum x_{i j} \theta_{j}
\end{aligned}
\]</div>
<p>Since <span class="arithmatex">\(X^{T} X=I\)</span>, we have</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \|\mathbf{t}\|^{2}=(X \boldsymbol{\theta})^{T} X \boldsymbol{\theta}=\|\boldsymbol{\theta}\|^{2} \\
&amp; \|\mathbf{s}\|^{2}=1
\end{aligned}
\]</div>
<p>We expand <span class="arithmatex">\(\sum a_{j} \Phi_{j}(\boldsymbol{\theta})\)</span> into a Taylor series with remainder term</p>
<div class="arithmatex">\[
\sum a_{j} \Phi_{j}(\boldsymbol{\theta})=\frac{-1}{E\left(\psi^{\prime}\right)}\left[\sum \psi\left(y_{i}\right) s_{i}-\sum \psi^{\prime}\left(y_{i}\right) t_{i} s_{i}+\frac{1}{2} \sum \psi^{\prime \prime}\left(y_{i}-\eta t_{i}\right) t_{i}^{2} s_{i}\right]
\]</div>
<p>with <span class="arithmatex">\(0&lt;\eta&lt;1\)</span>. This can be rearranged to give</p>
<div class="arithmatex">\[
\sum a_{j}\left[\Phi_{j}(\boldsymbol{\theta})-\Psi_{j}(\boldsymbol{\theta})\right]=\sum_{j k} \Delta_{j k} a_{j} \theta_{k}-\frac{1}{2 E\left(\psi^{\prime}\right)} \sum_{i} \psi^{\prime \prime}\left(y_{i}-\eta t_{i}\right) t_{i}^{2} s_{i}
\]</div>
<p>where</p>
<div class="arithmatex">\[
\Delta_{j k}=\frac{1}{E\left(\psi^{\prime}\right)} \sum_{i}\left[\psi^{\prime}\left(y_{i}\right)-E \psi^{\prime}\left(y_{i}\right)\right] x_{i j} x_{i k}
\]</div>
<p>We now intend to show that <span class="arithmatex">\(\boldsymbol{\Phi}-\boldsymbol{\Psi}\)</span> is uniformly small in a neighborhood of <span class="arithmatex">\(\boldsymbol{\theta}=0\)</span>, or more precisely, that (4.12) is uniformly small on sets of the form</p>
<div class="arithmatex">\[
\{(\boldsymbol{\theta}, \mathbf{a}) \mid\|\boldsymbol{\theta}\|^{2} \leqslant K p,\|\mathbf{a}\|=1\}
\]</div>
<p>By the Schwarz inequality the first term on the right-hand side of (4.12) can be bounded as follows:</p>
<div class="arithmatex">\[
\left(\sum \Delta_{j k} a_{j} \theta_{k}\right)^{2} \leqslant \sum \Delta_{j k}^{2} \sum a_{j}^{2} \sum \theta_{k}^{2}=\sum \Delta_{j k}^{2}\|\boldsymbol{\theta}\|^{2}
\]</div>
<p>We have</p>
<div class="arithmatex">\[
E\left(\sum \Delta_{j k}^{2}\right)=\sum E\left(\Delta_{j k}^{2}\right)=\sum_{j k i} x_{i j}^{2} x_{i k}^{2} \cdot \frac{\operatorname{var}\left(\psi^{\prime}\right)}{\left(E \psi^{\prime}\right)^{2}}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\sum_{j k i} x_{i j}^{2} x_{i k}^{2}=\sum h_{i}^{2} \leqslant \max \left(h_{i}\right) \sum h_{i}=h p
\]</div>
<p>Now let <span class="arithmatex">\(\delta&gt;0\)</span> be given. Markov's inequality then yields that there is a constant <span class="arithmatex">\(K_{1}\)</span>, namely</p>
<div class="arithmatex">\[
K_{1}=\frac{\operatorname{var}\left(\psi^{\prime}\right)}{\left(E \psi^{\prime}\right)^{2}} \cdot \frac{1}{\delta}
\]</div>
<p>such that</p>
<div class="arithmatex">\[
P\left\{\sum \Delta_{j k}^{2} \geqslant K_{1} h p\right\} \leqslant \delta
\]</div>
<p>We conclude that, with probability greater than <span class="arithmatex">\(1-\delta\)</span>,</p>
<div class="arithmatex">\[
\left(\sum \Delta_{j k} a_{j} \theta_{k}\right)^{2} \leqslant K K_{1} h p^{2}
\]</div>
<p>holds simultaneously for all (a, <span class="arithmatex">\(\boldsymbol{\theta}\)</span> ) in (4.14).
Assume that <span class="arithmatex">\(\psi^{\prime \prime}\)</span> is bounded, say <span class="arithmatex">\(\left|\psi^{\prime \prime}(x)\right| \leqslant 2\left|E\left(\psi^{\prime}\right)\right| M\)</span> for some <span class="arithmatex">\(M\)</span>; then</p>
<div class="arithmatex">\[
\left|\frac{1}{2 E\left(\psi^{\prime}\right)} \sum \psi^{\prime \prime}\left(y_{i}-\eta t_{i}\right) t_{i}^{2} s_{i}\right| \leqslant M \max \left|s_{i}\right| \sum t_{i}^{2} \leqslant M h^{1 / 2}\|\boldsymbol{\theta}\|^{2}
\]</div>
<p>[see (4.9) and recall that <span class="arithmatex">\(s_{i}^{2} \leqslant \sum x_{i j}^{2} \sum a_{j}^{2}=h_{i}\)</span> ].
If we put things together, we obtain that, with probability <span class="arithmatex">\(&gt;1-\delta\)</span>, (4.12) is bounded in absolute value by</p>
<div class="arithmatex">\[
r=\left[\left(K K_{1}\right)^{1 / 2}+M K\right]\left(h p^{2}\right)^{1 / 2}
\]</div>
<p>and this uniformly on the set (4.14). Since the results hold simultaneously for all a with <span class="arithmatex">\(\|\mathbf{a}\|=1\)</span>, we have in fact shown that, with probability greater than <span class="arithmatex">\(1-\delta\)</span>,</p>
<div class="arithmatex">\[
\|\boldsymbol{\Phi}(\boldsymbol{\theta})-\boldsymbol{\Psi}(\boldsymbol{\theta})\| \leqslant r, \quad \text { for }\|\boldsymbol{\theta}\|^{2} \leqslant K p
\]</div>
<p>If <span class="arithmatex">\(K\)</span> is chosen large enough, and since</p>
<div class="arithmatex">\[
E\left(\|\tilde{\boldsymbol{\theta}}\|^{2}\right)=\frac{E\left(\psi^{2}\right)}{\left[E\left(\psi^{\prime}\right)\right]^{2}} p
\]</div>
<p>it follows from Markov's inequality that</p>
<div class="arithmatex">\[
P\left\{\|\tilde{\boldsymbol{\theta}}\|^{2} \leqslant K p / 4\right\}
\]</div>
<p>can be made arbitrarily large. Moreover, then</p>
<div class="arithmatex">\[
\|\Phi(\boldsymbol{\theta})-\boldsymbol{\theta}\| \leqslant\|\boldsymbol{\Phi}(\boldsymbol{\theta})-\boldsymbol{\Psi}(\boldsymbol{\theta})\|+\|\tilde{\boldsymbol{\theta}}\| \leqslant r+\frac{1}{2}(K p)^{1 / 2}
\]</div>
<p>on the set <span class="arithmatex">\(\|\boldsymbol{\theta}\|^{2} \leqslant K p\)</span>.
If <span class="arithmatex">\(h p \rightarrow 0\)</span>, then <span class="arithmatex">\(r\)</span> can be made smaller than <span class="arithmatex">\(\frac{1}{2}(K p)^{1 / 2}\)</span>, so that (4.26) implies</p>
<div class="arithmatex">\[
\|\boldsymbol{\theta}-\boldsymbol{\Phi}(\boldsymbol{\theta})\|&lt;(K p)^{1 / 2}
\]</div>
<p>on the set <span class="arithmatex">\(\|\boldsymbol{\theta}\| \leqslant(K p)^{1 / 2}\)</span>.
But this is precisely the premiss of Brouwer's fixed point theorem: we conclude that the map <span class="arithmatex">\(\boldsymbol{\theta} \rightarrow \boldsymbol{\theta}-\boldsymbol{\Phi}(\boldsymbol{\theta})\)</span> has a fixed point <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span>, which necessarily then is a zero of <span class="arithmatex">\(\boldsymbol{\Phi}(\boldsymbol{\theta})\)</span>, with <span class="arithmatex">\(\|\tilde{\boldsymbol{\theta}}\|&lt;(K p)^{1 / 2}\)</span>.</p>
<p>If we substitute <span class="arithmatex">\(\tilde{\boldsymbol{\theta}}\)</span> for <span class="arithmatex">\(\boldsymbol{\theta}\)</span> into (4.23), we obtain</p>
<div class="arithmatex">\[
\|\tilde{\boldsymbol{\theta}}-\tilde{\boldsymbol{\theta}}\| \leqslant r
\]</div>
<p>We thus obtain the following proposition.</p>
<h1 id="proposition-41">PROPOSITION 4.1</h1>
<p>(1) If <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span>, then</p>
<div class="arithmatex">\[
\|\tilde{\boldsymbol{\theta}}-\tilde{\boldsymbol{\theta}}\| \rightarrow 0
\]</div>
<p>in probability.
(2) If <span class="arithmatex">\(h p \rightarrow 0\)</span>, then</p>
<div class="arithmatex">\[
\frac{\|\tilde{\boldsymbol{\theta}}-\tilde{\boldsymbol{\theta}}\|}{p^{1 / 2}} \rightarrow 0
\]</div>
<p>in probability. [Note that <span class="arithmatex">\(\left\|\tilde{\boldsymbol{\theta}}-\boldsymbol{\theta}^{0}\right\| \sim p^{1 / 2}\)</span> in view of (4.24).]
Now let <span class="arithmatex">\(\hat{\alpha}=\sum a_{j} \hat{\theta}_{j}\)</span> and <span class="arithmatex">\(\tilde{\alpha}=\sum a_{j} \tilde{\theta}_{j}\)</span>, with <span class="arithmatex">\(\|\mathbf{a}\|=1\)</span>. Recall that <span class="arithmatex">\(\hat{\alpha}\)</span> is the estimate to be investigated, while <span class="arithmatex">\(\tilde{\alpha}\)</span> is a sum of independent random variables and is asymptotically normal if <span class="arithmatex">\(h \rightarrow 0\)</span>.</p>
<h2 id="proposition-42">PROPOSITION 4.2</h2>
<p>(1) If <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span>, then</p>
<div class="arithmatex">\[
\sup _{\|\mathbf{a}\| \rightarrow 1}|\hat{\alpha}-\tilde{\alpha}| \rightarrow 0
\]</div>
<p>in probability.</p>
<p>(2) If <span class="arithmatex">\(\mathbf{a}\)</span> is chosen at random with respect to the invariant measure on the sphere <span class="arithmatex">\(\|\mathbf{a}\|=1\)</span>, and if <span class="arithmatex">\(h p \rightarrow 0\)</span>, then</p>
<div class="arithmatex">\[
\hat{\alpha}-\bar{\alpha} \rightarrow 0
\]</div>
<p>in probability.
Both (1) and (2) imply that <span class="arithmatex">\(\hat{\alpha}\)</span> is asymptotically normal.
Proof (1) is an immediate consequence of part (1) of the preceding proposition; similarly, (2) follows from part (2) and the fact that the average of <span class="arithmatex">\(|\hat{\alpha}-\bar{\alpha}|^{2}\)</span> over the unit sphere <span class="arithmatex">\(\|\mathbf{a}\|=1\)</span> is <span class="arithmatex">\(\|\hat{\boldsymbol{\theta}}-\hat{\boldsymbol{\theta}}\|^{2} / p\)</span>.
Remark 1 In essence we have shown that <span class="arithmatex">\(\boldsymbol{\Phi}(\boldsymbol{\theta})\)</span> is asymptotically linear in a neighborhood of the true parameter point <span class="arithmatex">\(\boldsymbol{\theta}^{0}\)</span>. Actually, the assumption that <span class="arithmatex">\(\boldsymbol{\theta}^{0}=0\)</span> was used only once, namely, in (4.27). If <span class="arithmatex">\(\boldsymbol{\theta}^{*}\)</span> is any estimate satisfying <span class="arithmatex">\(\left\|\boldsymbol{\theta}^{*}-\boldsymbol{\theta}^{0}\right\|=O_{p}\left(p^{1 / 2}\right)\)</span>, then we can show in the same way that just one step of Newton's method for solving <span class="arithmatex">\(\boldsymbol{\Phi}(\boldsymbol{\theta})=0\)</span>, with trial value <span class="arithmatex">\(\boldsymbol{\theta}^{*}\)</span>, leads to an estimate <span class="arithmatex">\(\hat{\boldsymbol{\theta}}^{*}\)</span> satisfying</p>
<div class="arithmatex">\[
\left\|\hat{\boldsymbol{\theta}}^{*}-\hat{\boldsymbol{\theta}}\right\| \rightarrow 0, \quad\left\|\hat{\boldsymbol{\theta}}^{*}-\hat{\boldsymbol{\theta}}\right\| \rightarrow 0
\]</div>
<p>in probability, provided <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span>.
Remark 2 Recently Yohai and Maronna (1979) have improved this result and shown that <span class="arithmatex">\(\hat{\alpha}\)</span> is asymptotically normal for arbitrary choices of a, assuming only <span class="arithmatex">\(h p^{3 / 2} \rightarrow 0\)</span>, instead of <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span>. My conjecture is that <span class="arithmatex">\(h p \rightarrow 0\)</span> is sufficient for (4.32) to hold for arbitrary a, and that <span class="arithmatex">\(h p^{1 / 2} \rightarrow 0\)</span> is necessary, if either the distribution of the <span class="arithmatex">\(u_{i}\)</span> or <span class="arithmatex">\(\rho\)</span> are allowed to be asymmetric. If both the distribution of the <span class="arithmatex">\(u_{i}\)</span> and <span class="arithmatex">\(\rho\)</span> are symmetric, then perhaps already <span class="arithmatex">\(h \rightarrow 0\)</span> is sufficient, as in the classical least squares case.</p>
<h1 id="75-conjectures-and-empirical-results">7.5 CONJECTURES AND EMPIRICAL RESULTS</h1>
<p>An asymptotic theory that requires <span class="arithmatex">\(h p^{2} \rightarrow 0\)</span> (and hence <span class="arithmatex">\(a\)</span> fortiori <span class="arithmatex">\(p^{3} / n \rightarrow 0\)</span> ) is for all practical purposes worthless and the situation is only a little more favorable for <span class="arithmatex">\(h p \rightarrow 0\)</span>; already for a moderately large number of parameters we would need an impossibly large number of observations. Of course, my inability to prove theorems assuming only <span class="arithmatex">\(h \rightarrow 0\)</span> does not imply that then the robustized estimates fail to be consistent and asymptotically normal, but what if they should fail? In order to get some insight into what is going on, we may resort to asymptotic expansions. These are without remainder terms, so the results are nonrigorous, but they can be verified by Monte</p>
<p>Carlo simulations. The expansions are reported in some detail in Huber (1973a); here we only summarize the salient points.</p>
<h1 id="the-question-of-bias">The Question of Bias</h1>
<p>Assume that either the distribution of the errors <span class="arithmatex">\(u_{i}\)</span> or the function <span class="arithmatex">\(\rho\)</span>, or both, are asymmetric. Then the parameters to be estimated are not intrinsically defined by symmetry considerations; we chose to fix them through the convention that <span class="arithmatex">\(E \psi\left(u_{i}\right)=0\)</span>. Then, for instance, a location estimate <span class="arithmatex">\(T_{n}\)</span>, defined by</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \psi\left(u_{i}-T_{n}\right)=0
\]</div>
<p>is asymptotically normal with mean 0 , but its distribution for finite <span class="arithmatex">\(n\)</span> is asymmetric and not exactly centered at 0 .</p>
<p>Take now the following simple regression design (which actually represents the worst possible case). Assume that we have <span class="arithmatex">\(p\)</span> unknown parameters <span class="arithmatex">\(\theta_{1}, \ldots, \theta_{p}\)</span>; we take <span class="arithmatex">\(r\)</span> independent observations on each of them, and as an overall check we take one observation <span class="arithmatex">\(y_{n}\)</span> of</p>
<div class="arithmatex">\[
\sqrt{\frac{r}{n-p}}\left(\theta_{1}+\cdots+\theta_{p}\right)
\]</div>
<p>Here, <span class="arithmatex">\(n=r p+1\)</span> is the total number of observations, and the corresponding hat matrix happens to be balanced, that is, all its diagonal elements <span class="arithmatex">\(h_{i}\)</span> are equal to <span class="arithmatex">\(p / n\)</span>.</p>
<p>It is intuitively obvious that any robust regression estimate of <span class="arithmatex">\(\left(\theta_{1}, \ldots, \theta_{p}\right)\)</span>, for all practical purposes, is equivalent to estimating the <span class="arithmatex">\(p\)</span> parameters separately from <span class="arithmatex">\(\sum_{1}^{r} \psi\left(y_{i}-\hat{\theta}_{1}\right)=0\)</span>, and so on, since the single observation <span class="arithmatex">\(y_{n}\)</span> of the scaled sum should have only a negligible influence. So the predicted value of this last observation is</p>
<div class="arithmatex">\[
\hat{\alpha}_{n}=\sqrt{\frac{r}{n-p}}\left(\hat{\theta}_{1}+\cdots+\hat{\theta}_{p}\right)
\]</div>
<p>where the <span class="arithmatex">\(\hat{\theta}_{i}\)</span> have been estimated from the <span class="arithmatex">\(r\)</span> observations of each separately. [The definition of <span class="arithmatex">\(g\)</span> in Huber (1973a), p. 810, should read <span class="arithmatex">\(g^{2}=r /\)</span> <span class="arithmatex">\((n-p)\)</span>.] But the distributions of the <span class="arithmatex">\(\hat{\theta}_{i}\)</span> are slightly asymmetric and not quite centered at their "true" values, and if we work things out in detail, we find that <span class="arithmatex">\(\hat{\alpha}_{n}\)</span> is affected by a bias of the order <span class="arithmatex">\(p^{3 / 2} / n\)</span>. Note that the</p>
<p>asymptotic variance of <span class="arithmatex">\(\hat{\alpha}_{n}\)</span> is of the order <span class="arithmatex">\(p / n\)</span>, so that the bias measured in units of the standard deviation is <span class="arithmatex">\(p / n^{1 / 2}\)</span>. The asymptotic behavior of the fitted value <span class="arithmatex">\(\hat{y}_{n}\)</span> is the same as that of <span class="arithmatex">\(\hat{\alpha}_{n}\)</span>, of course.</p>
<p>In other words, if <span class="arithmatex">\(h=p / n \rightarrow 0\)</span>, but <span class="arithmatex">\(p^{3 / 2} / n \rightarrow \infty\)</span>, it can happen that the residual <span class="arithmatex">\(r_{n}=y_{n}-\hat{y}_{n}\)</span> tends to infinity, not because of a gross error in <span class="arithmatex">\(y_{n}\)</span>, but because the small biases in the <span class="arithmatex">\(\hat{\theta}_{i}\)</span> have added up to a large bias in <span class="arithmatex">\(\hat{y}_{n}\)</span> ! However, we should hasten to add that this bias of the order <span class="arithmatex">\(\sqrt{p} p / n\)</span> is asymptotically negligible against the bias</p>
<div class="arithmatex">\[
\sqrt{\frac{r}{n-p}} p \delta \approx \sqrt{p} \delta
\]</div>
<p>caused by a systematic error <span class="arithmatex">\(+\delta\)</span> in all the observations.
Moreover, the quantitative aspects are such that it is far from easy to verify the effect by Monte Carlo simulation; with <span class="arithmatex">\(p / n=\frac{1}{2}\)</span> we need <span class="arithmatex">\(p \cong 100\)</span> to make the bias of <span class="arithmatex">\(\hat{y}_{n}\)</span> approximately equal to <span class="arithmatex">\(\left(\operatorname{var} \hat{y}_{n}\right)^{1 / 2}\)</span>, and this with highly asymmetric error distributions ( <span class="arithmatex">\(x^{2}\)</span> with two to four degrees of freedom).</p>
<p>From these remarks we derive the following practical conclusions:
(1) The biases caused by asymmetric error distributions exist and can cause havoc within the asymptotic theory but, for most practical purposes, they will be so small that they can be neglected.
(2) The biases are largest in situations that should also be avoided for another reason (robustness of design), namely, situations where the estimand is interpolated between observations that are widely separated in the design space-as in our example where <span class="arithmatex">\(\alpha=\Sigma \theta_{i}\)</span> is estimated from observed values for the individual <span class="arithmatex">\(\theta_{i}\)</span>. In such cases relatively minor deviations from the linear model may cause large deviations in the fitted values.</p>
<h1 id="76-asymptotic-covariances-and-their-estimation">7.6 ASYMPTOTIC COVARIANCES AND THEIR ESTIMATION</h1>
<p>The covariance matrix of the classical least squares estimate <span class="arithmatex">\(\boldsymbol{\theta}_{\mathrm{LS}}\)</span> is traditionally estimated by</p>
<div class="arithmatex">\[
\operatorname{cov}\left(\hat{\boldsymbol{\theta}}_{\mathrm{LS}}\right) \approx \frac{1}{n-p}\left(\sum r_{i}^{2}\right)\left(X^{T} X\right)^{-1}
\]</div>
<p>By what should this be replaced in the robustized case?</p>
<p>The limiting expression for the covariance of the robust estimate, derived from Proposition 4.1, is</p>
<div class="arithmatex">\[
\operatorname{cov}(\hat{\boldsymbol{\theta}})=\frac{E(\psi)^{2}}{\left(E \psi^{\prime}\right)^{2}}\left(X^{T} X\right)^{-1}
\]</div>
<p>which can be translated straightforwardly into the estimate</p>
<div class="arithmatex">\[
\operatorname{cov}(\hat{\boldsymbol{\theta}}) \approx \frac{(1 / n) \sum \psi\left(r_{i}\right)^{2}}{\left[(1 / n) \sum \psi^{\prime}\left(r_{i}\right)\right]^{2}}\left(X^{T} X\right)^{-1}
\]</div>
<p>If we want to recapture the classical formula (6.1) in the classical case <span class="arithmatex">\([\psi(x)=x]\)</span>, we should multiply the right-hand side of (6.3) by <span class="arithmatex">\(n /(n-p)\)</span>, and perhaps some other corrections of the order <span class="arithmatex">\(h=p / n\)</span> are needed. Also the matrix <span class="arithmatex">\(X^{T} X\)</span> should perhaps be replaced by something like the matrix</p>
<div class="arithmatex">\[
W_{j k}=\sum \psi^{\prime}\left(r_{i}\right) x_{i j} x_{i k}
\]</div>
<p>The second, and perhaps even more important, goal of the asymptotic expansions mentioned in the preceding sections is to find proposals for correction terms of the order <span class="arithmatex">\(h\)</span>.</p>
<p>The general expressions are extremely unwieldy, but in the balanced case (i.e., <span class="arithmatex">\(h_{i}=h=p / n\)</span> ), with symmetric error distributions and skew symmetric <span class="arithmatex">\(\psi\)</span>, assuming that <span class="arithmatex">\(1 \ll p \ll n\)</span>, and if we neglect terms of the orders <span class="arithmatex">\(h^{2}=(p / n)^{2}\)</span> or <span class="arithmatex">\(1 / n\)</span>, the following three expressions all are unbiased estimates of <span class="arithmatex">\(\operatorname{cov}(\hat{\boldsymbol{\theta}})\)</span> :</p>
<div class="arithmatex">\[
\begin{gathered}
K^{2} \frac{[1 /(n-p)] \sum \psi\left(r_{i}\right)^{2}}{\left[(1 / n) \sum \psi^{\prime}\left(r_{i}\right)\right]^{2}}\left(X^{T} X\right)^{-1} \\
K \frac{[1 /(n-p)] \sum \psi\left(r_{i}\right)^{2}}{(1 / n) \sum \psi^{\prime}\left(r_{i}\right)} W^{-1} \\
K^{-1} \frac{1}{n-p} \sum \psi\left(r_{i}\right)^{2} W^{-1}\left(X^{T} X\right) W^{-1}
\end{gathered}
\]</div>
<p>The correction factors are expressed in terms of</p>
<div class="arithmatex">\[
K=1+\frac{p}{n} \frac{\operatorname{var}\left(\psi^{\prime}\right)}{\left(E \psi^{\prime}\right)^{2}}
\]</div>
<p>In practice <span class="arithmatex">\(E\left(\psi^{\prime}\right)\)</span> and <span class="arithmatex">\(\operatorname{var}\left(\psi^{\prime}\right)\)</span> are unknown and will be estimated by</p>
<div class="arithmatex">\[
\begin{gathered}
E\left(\psi^{\prime}\right) \approx m=\frac{1}{n} \sum \psi^{\prime}\left(r_{i}\right) \\
\operatorname{var}\left(\psi^{\prime}\right) \approx \frac{1}{n} \sum\left[\psi^{\prime}\left(r_{i}\right)-m\right]^{2}
\end{gathered}
\]</div>
<p>In the special case</p>
<div class="arithmatex">\[
\psi(x)=\min [c, \max (-c, x)]
\]</div>
<p>(6.8) simplifies to</p>
<div class="arithmatex">\[
K=1+\frac{p}{n} \frac{1-m}{m}
\]</div>
<p>where <span class="arithmatex">\(m\)</span> is the relative frequency of the residuals satisfying <span class="arithmatex">\(-c&lt;r_{i}&lt;c\)</span>.
Note that, in the classical case, all three expressions (6.5), (6.6), and (6.7) reduce to (6.1).</p>
<p>In the simple location case ( <span class="arithmatex">\(p=1, x_{i j}=1\)</span> ), the three expressions agree exactly if we put <span class="arithmatex">\(K=1\)</span> (the derivation of <span class="arithmatex">\(K\)</span> neglected terms of the order <span class="arithmatex">\(1 / n\)</span> anyhow).</p>
<p>For details and a comparison with Monte Carlo results, see Huber (1973a). (For normal errors, the agreement between the expansions and the Monte Carlo results was excellent up to <span class="arithmatex">\(p / n=\frac{1}{4}\)</span>; for Cauchy errors excellent up to <span class="arithmatex">\(p / n=\frac{1}{16}\)</span>, and still tolerable for <span class="arithmatex">\(p / n=\frac{1}{8}\)</span>.)</p>
<p>NOTE Since <span class="arithmatex">\(\hat{\boldsymbol{\theta}}\)</span> can also be characterized formally as the solution of the weighted least squares problem</p>
<div class="arithmatex">\[
\sum_{i} w_{i} r_{i} x_{i j}=0, \quad j=1, \ldots, p
\]</div>
<p>with weights <span class="arithmatex">\(w_{i}=\psi\left(r_{i}\right) / r_{i}\)</span> depending on the sample, a further variant to <span class="arithmatex">\(X^{T} X\)</span> and (6.4), namely,</p>
<div class="arithmatex">\[
\sum w_{i} x_{i j} x_{i k}
\]</div>
<p>looks superficially attractive, together with</p>
<div class="arithmatex">\[
\frac{1}{n-p} \sum w_{i} r_{i}^{2}
\]</div>
<p>in place of</p>
<div class="arithmatex">\[
\frac{1}{n-p} \sum \psi\left(r_{i}\right)^{2}
\]</div>
<p>However, (6.14) is not robust in general [ <span class="arithmatex">\(w_{i} r_{i}^{2}=\psi\left(r_{i}\right) r_{i}\)</span> is unbounded unless <span class="arithmatex">\(\psi\)</span> is redescending] and is not a consistent estimate of <span class="arithmatex">\(E\left(\psi^{2}\right)\)</span>. So we should be strongly advised against the use of (6.14).</p>
<p>It would be feasible to use the suitably scaled matrix (6.13), namely</p>
<div class="arithmatex">\[
\frac{\sum w_{i} x_{i j} x_{i k}}{(1 / n) \sum w_{i}}
\]</div>
<p>in place of <span class="arithmatex">\(X^{T} X\)</span>, just as we did with <span class="arithmatex">\(W\)</span> in (6.6) and (6.7), but the bias correction factors then seem to become discouragingly complicated.</p>
<h1 id="77-concomitant-scale-estimates">7.7 CONCOMITANT SCALE ESTIMATES</h1>
<p>For the sake of simplicity, we have so far assumed that scale was known and fixed. In practice we would have to estimate also a scale parameter <span class="arithmatex">\(\sigma\)</span>, and we would have to solve</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{y_{i}-\sum x_{i j} \theta_{j}}{\sigma}\right) x_{i j}=0, \quad j=1, \ldots, p
\]</div>
<p>in place of (3.2).
This introduces some technical complications similar to those in Chapter 6 , but does not change the asymptotic results. The reason is that, if we have some estimate for which the fitted values <span class="arithmatex">\(\hat{y}_{i}\)</span> are consistent, we can estimate scale <span class="arithmatex">\(\hat{\sigma}\)</span> consistently from the corresponding residuals <span class="arithmatex">\(r_{i}=y_{i}-\hat{y}_{i}\)</span>, and then use this <span class="arithmatex">\(\hat{\sigma}\)</span> in (7.1) for calculating the final estimate <span class="arithmatex">\(\hat{\theta}\)</span>.</p>
<p>In practice we calculate the estimates <span class="arithmatex">\(\hat{\boldsymbol{\theta}}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> by simultaneous iterations (which may cause difficulties with the convergence proofs).</p>
<p>Which scale estimate should we use? In the simple location case the unequivocal answer is given by the results of the Princeton study (Andrews et al., 1972); the estimates using the median absolute deviation, that is</p>
<div class="arithmatex">\[
\hat{\sigma}=\operatorname{med}\left\{\left|r_{i}\right|\right\}
\]</div>
<p>when expressed in terms of residuals relative to the sample median, fared best. This result is theoretically underpinned by the facts that the median</p>
<p>absolute deviation (1) is minimax with respect to bias (Section 5.7), and (2) has the highest possible breakdown point <span class="arithmatex">\(\left(\varepsilon^{*}=\frac{1}{2}\right)\)</span>.</p>
<p>In regression the case for the median absolute residual (7.2) is less well founded. First, it is not feasible to calculate it beforehand (the analogue to the sample median, the <span class="arithmatex">\(L_{1}\)</span>-estimate, may take more time to calculate than our intended estimate <span class="arithmatex">\(\hat{\boldsymbol{\theta}}\)</span> ). Second, we still lack a convergence proof for procedures simultaneously iterating (7.1) and (7.2) (the empirical evidence is, however, good).</p>
<p>For the following we assume, somewhat more generally, that <span class="arithmatex">\(\hat{\theta}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span> are estimated by solving the simultaneous equations</p>
<div class="arithmatex">\[
\begin{gathered}
\sum \psi\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right) \frac{\partial f_{i}(\boldsymbol{\theta})}{\partial \theta_{j}}=0, \quad j=1, \ldots, p \\
\sum \chi\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right)=0
\end{gathered}
\]</div>
<p>for <span class="arithmatex">\(\boldsymbol{\theta}\)</span> and <span class="arithmatex">\(\sigma\)</span>; the functions <span class="arithmatex">\(f_{i}\)</span> are not necessarily linear.
Note that this contains, in particular:
(1) Maximum likelihood estimation. Assume that the observations have a probability density of the form</p>
<div class="arithmatex">\[
\frac{1}{\sigma} g\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right)
\]</div>
<p>then (7.3) and (7.4) give the maximum likelihood estimates if</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi(x)=-\frac{g^{\prime}(x)}{g(x)} \\
&amp; \chi(x)=x \psi(x)-1
\end{aligned}
\]</div>
<p>(2) Median absolute residuals as the scale estimate, if</p>
<div class="arithmatex">\[
\chi(x)=\operatorname{sign}(|x|-1)
\]</div>
<p>Some problems with existence and convergence proofs arise when <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are totally unrelated. For purely technical reasons we therefore introduce the following minimum problem:</p>
<div class="arithmatex">\[
Q(\boldsymbol{\theta}, \sigma)=\frac{1}{n} \sum \rho\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right) \sigma=\min !
\]</div>
<p>where <span class="arithmatex">\(\rho\)</span> is a convex function that has a strictly positive minimum at 0 . If we take partial derivatives of (7.9) with respect to <span class="arithmatex">\(\theta_{j}\)</span> and <span class="arithmatex">\(\sigma\)</span>, we obtain the following characterization of the minimum:</p>
<div class="arithmatex">\[
\begin{aligned}
\sum \psi\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right) \frac{\partial f_{i}}{\partial \theta_{j}} &amp; =0 \\
\sum \chi\left(\frac{y_{j}-f_{j}(\boldsymbol{\theta})}{\sigma}\right) &amp; =0
\end{aligned}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi(x)=\rho^{\prime}(x) \\
&amp; \chi(x)=x \psi(x)-\rho(x)
\end{aligned}
\]</div>
<p>Note that <span class="arithmatex">\(\chi^{\prime}(x)=x \psi^{\prime}(x)\)</span> then is negative for <span class="arithmatex">\(x \leqslant 0\)</span> and positive for <span class="arithmatex">\(x \geqslant 0\)</span>; hence <span class="arithmatex">\(\chi\)</span> has an absolute minimum at <span class="arithmatex">\(x=0\)</span>, namely, <span class="arithmatex">\(\chi(0)=-\rho(0)&lt;0\)</span>.</p>
<p>In particular, with</p>
<div class="arithmatex">\[
\begin{aligned}
\rho(x) &amp; =\frac{1}{2} x^{2}+\frac{1}{2} \beta, &amp; &amp; \text { for }|x|&lt;c \\
&amp; =c\left|x \left\lvert\,-\frac{1}{2} c^{2}+\frac{1}{2} \beta\right.,\right. &amp; &amp; \text { for }|x| \geqslant c
\end{aligned}
\]</div>
<p>we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
\psi(x) &amp; =-c, &amp; &amp; \text { for } x \leqslant-c \\
&amp; =x, &amp; &amp; \text { for }-c&lt;x&lt;c \\
&amp; =c, &amp; &amp; \text { for } x \geqslant c
\end{aligned}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\chi(x)=\frac{1}{2}\left[\psi(x)^{2}-\beta\right]
\]</div>
<p>Note that this is a <span class="arithmatex">\(\psi, \chi\)</span> pair suggested by minimax considerations both for location and for scale (cf. Example 6.4.1), and that both <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are bounded [whereas, with the maximum likelihood approach, the <span class="arithmatex">\(\chi\)</span> corresponding to a monotone <span class="arithmatex">\(\psi\)</span> would always be unbounded; cf. (7.7)].</p>
<p>If the <span class="arithmatex">\(f_{i}\)</span> are linear, then <span class="arithmatex">\(Q(\boldsymbol{\theta}, \sigma)\)</span> in fact is a convex function not only of <span class="arithmatex">\(\boldsymbol{\theta}\)</span>, but of <span class="arithmatex">\((\boldsymbol{\theta}, \sigma)\)</span>. In order to demonstrate this, we assume that <span class="arithmatex">\((\boldsymbol{\theta}, \sigma)\)</span></p>
<p>depends linearly on some real parameter <span class="arithmatex">\(t\)</span> and calculate the second derivative with respect to <span class="arithmatex">\(t\)</span> of the summands of (7.9):</p>
<div class="arithmatex">\[
q_{i}(t)=\rho\left(\frac{y_{i}-f_{i}(\theta)}{\sigma}\right) \sigma
\]</div>
<p>Denote differentiation with respect to <span class="arithmatex">\(t\)</span> by a superscript dot, then (omitting the index <span class="arithmatex">\(i\)</span> )</p>
<div class="arithmatex">\[
\dot{q}=\rho\left(\frac{y-f}{\sigma}\right) \dot{\sigma}+\rho^{\prime}\left(\frac{y-f}{\sigma}\right)\left(-\frac{y-f}{\sigma} \dot{\sigma}-\dot{f}\right)
\]</div>
<p>and</p>
<div class="arithmatex">\[
\ddot{q}=\rho^{\prime \prime}\left(\frac{y-f}{\sigma}\right)\left(\frac{y-f}{\sigma} \dot{\sigma}+\dot{f}\right)^{2} \frac{1}{\sigma} \geqslant 0
\]</div>
<p>Thus <span class="arithmatex">\(Q\)</span> is convex. If <span class="arithmatex">\(\rho\)</span> is not twice differentiable, the result still holds (prove this by approximating <span class="arithmatex">\(\rho\)</span> differentiably).</p>
<p>Assume now that</p>
<div class="arithmatex">\[
0&lt;\lim _{|x| \rightarrow \infty} \frac{\rho(x)}{|x|}=c \leqslant \infty
\]</div>
<p>If <span class="arithmatex">\(c&lt;\infty, Q\)</span> can be extended by continuity:</p>
<div class="arithmatex">\[
Q(\boldsymbol{\theta}, 0)=c \frac{1}{n} \sum\left|y_{i}-f_{i}(\boldsymbol{\theta})\right|
\]</div>
<p>Hence the limiting case <span class="arithmatex">\(\sigma=0\)</span> corresponds to <span class="arithmatex">\(L_{1}\)</span>-estimation. Of course, on the boundary <span class="arithmatex">\(\sigma=0\)</span>, the characterization of the minimum by (7.10) and (7.11) breaks down, but in any case, the set of solutions <span class="arithmatex">\((\boldsymbol{\theta}, \sigma)\)</span> of (7.9) is a convex subset of <span class="arithmatex">\((p+1)\)</span>-space. Often it reduces to a single point. For this it suffices, for instance, that <span class="arithmatex">\(\rho\)</span> is strictly convex, that the <span class="arithmatex">\(f_{i}\)</span> are linear, and that the columns of the design matrix <span class="arithmatex">\(x_{i, j}=\partial f_{i} / \partial \theta_{j}\)</span> and the residual vector <span class="arithmatex">\(x_{i}-f_{i}\)</span> are linearly independent (that is, the design matrix has full rank, and there is no exact solution with vanishing residuals). Then also <span class="arithmatex">\(Q\)</span> is strictly convex [cf. (7.19)], and the solution <span class="arithmatex">\((\boldsymbol{\theta}, \sigma)\)</span> is necessarily unique.</p>
<p>Even if <span class="arithmatex">\(\rho\)</span> is not strictly convex everywhere, but contains a strictly convex piece, the solution is usually unique when <span class="arithmatex">\(n / p\)</span> is large (because then enough residuals will fall into the strictly convex region of <span class="arithmatex">\(\rho\)</span> for the above argument to carry through).</p>
<h1 id="78-computation-of-regression-m-estimates">7.8 COMPUTATION OF REGRESSION M-ESTIMATES</h1>
<p>We now describe some simple algorithms. They alternate between improving trial values for <span class="arithmatex">\(\hat{\boldsymbol{\theta}}\)</span> and <span class="arithmatex">\(\hat{\sigma}\)</span>, and they decrease (7.9). We prefer to write the latter expression in the form</p>
<div class="arithmatex">\[
Q(\boldsymbol{\theta}, \sigma)=\frac{1}{n} \sum\left[\rho_{0}\left(\frac{y_{i}-f_{i}(\boldsymbol{\theta})}{\sigma}\right)+a\right] \sigma
\]</div>
<p>where <span class="arithmatex">\(\rho_{0}(0)=0\)</span> and <span class="arithmatex">\(a&gt;0\)</span>. The equations (7.10) and (7.11) can then be written</p>
<div class="arithmatex">\[
\begin{gathered}
\frac{1}{n} \sum \psi_{0}\left(\frac{r_{i}}{\sigma}\right) \frac{\partial f_{i}}{\partial \theta_{j}}=0 \\
\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma}\right)=a
\end{gathered}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi_{0}(x)=\rho_{0}^{\prime}(x) \\
&amp; \chi_{0}(x)=x \psi_{0}(x)-\rho_{0}(x)
\end{aligned}
\]</div>
<p>Note that <span class="arithmatex">\(\chi_{0}\)</span> has an absolute minimum at <span class="arithmatex">\(x=0\)</span>, namely, <span class="arithmatex">\(\chi_{0}(0)=0\)</span>. We assume throughout that <span class="arithmatex">\(\psi_{0}\)</span> and <span class="arithmatex">\(\chi_{0}\)</span> are continuous.</p>
<p>In order to obtain consistency of the scale estimate at the normal model and to recapture the classical estimates for the classical choice <span class="arithmatex">\(\rho_{0}(x)=\frac{1}{2} x^{2}\)</span>, we propose to take</p>
<div class="arithmatex">\[
a=\frac{n-p}{n} E_{\theta}\left(\chi_{0}\right)
\]</div>
<h2 id="the-scale-step">The Scale Step</h2>
<p>Let <span class="arithmatex">\(\boldsymbol{\theta}^{(m)}\)</span> and <span class="arithmatex">\(\sigma^{(m)}\)</span> be trial values for <span class="arithmatex">\(\boldsymbol{\theta}\)</span> and <span class="arithmatex">\(\sigma\)</span>, and put <span class="arithmatex">\(r_{i}=y_{i}-f_{i}\left(\boldsymbol{\theta}^{(m)}\right)\)</span>. Define</p>
<div class="arithmatex">\[
\left(\sigma^{(m+1)}\right)^{2}=\frac{1}{n a} \sum \chi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right)\left(\sigma^{(m)}\right)^{2}
\]</div>
<p>Remarks For the classical choice <span class="arithmatex">\(\rho_{0}(x)=\frac{1}{2} x^{2}\)</span>, with <span class="arithmatex">\(a\)</span> as in (8.6), we obtain</p>
<div class="arithmatex">\[
\left(\sigma^{(m+1)}\right)^{2}=\frac{1}{n-p} \sum r_{i}^{2}
\]</div>
<p>For the choice (7.14) we obtain</p>
<div class="arithmatex">\[
\left(\sigma^{(m+1)}\right)^{2}=\frac{1}{(n-p) \beta} \sum \psi\left(\frac{r_{i}}{\sigma^{(m)}}\right)^{2}\left(\sigma^{(m)}\right)^{2}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\beta=E_{\Phi}\left(\psi^{2}\right)
\]</div>
<p>In the latter case we may say that <span class="arithmatex">\(\sigma^{(m+1)}\)</span> is an ordinary variance estimate (8.8), but calculated from metrically Winsorized residuals</p>
<div class="arithmatex">\[
\begin{aligned}
r_{i}^{w}=\psi\left(\frac{r_{i}}{\sigma^{(m)}}\right) \sigma^{(m)} &amp; =-c \sigma^{(m)}, &amp; &amp; \text { for } r_{i}&lt;-c \sigma^{(m)} \\
=r_{i}, &amp; &amp; \text { for }\left|r_{i}\right| \leqslant c \sigma^{(m)} \\
=c \sigma^{(m)}, &amp; &amp; \text { for } r_{i}&gt;c \sigma^{(m)}
\end{aligned}
\]</div>
<p>and corrected for bias by the factor <span class="arithmatex">\(\beta\)</span>.
LEMMA 8.1 Assume that <span class="arithmatex">\(\rho_{0} \geqslant 0\)</span> is convex, that <span class="arithmatex">\(\rho_{0}(0)=0\)</span>, and that <span class="arithmatex">\(\rho_{0}(x) / x\)</span> is convex for <span class="arithmatex">\(x&lt;0\)</span>, concave for <span class="arithmatex">\(x&gt;0\)</span>. Then</p>
<div class="arithmatex">\[
Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)-Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m+1)}\right) \geqslant \frac{a\left(\sigma^{(m+1)}-\sigma^{(m)}\right)^{2}}{\sigma^{(m)}}
\]</div>
<p>In particular, unless (8.3) is already satisfied, <span class="arithmatex">\(Q\)</span> is strictly decreased.
Proof The idea is to construct a simple "comparison function" <span class="arithmatex">\(U(\sigma)\)</span> that agrees with <span class="arithmatex">\(Q\left(\boldsymbol{\theta}^{(m)}, \sigma\right)\)</span> at <span class="arithmatex">\(\sigma=\sigma^{(m)}\)</span>, that lies wholly above <span class="arithmatex">\(Q\left(\boldsymbol{\theta}^{(m)}, \cdot\right)\)</span>, and that reaches its minimum at <span class="arithmatex">\(\sigma^{(m+1)}\)</span>, namely,</p>
<div class="arithmatex">\[
U(\sigma)=Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)+a\left(\sigma-\sigma^{(m)}\right)+\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right)\left[\frac{\left(\sigma^{(m)}\right)^{2}}{\sigma}-\sigma^{(m)}\right]
\]</div>
<p>Obviously, <span class="arithmatex">\(U\left(\sigma^{(m)}\right)=Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span>. The derivatives with respect to <span class="arithmatex">\(\sigma\)</span> are</p>
<div class="arithmatex">\[
\begin{aligned}
U^{\prime}(\sigma) &amp; =-\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right)\left(\frac{\sigma^{(m)}}{\sigma}\right)^{2}+a \\
Q^{\prime}\left(\boldsymbol{\theta}^{(m)}, \sigma\right) &amp; =-\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma}\right)+a
\end{aligned}
\]</div>
<p>hence they agree at <span class="arithmatex">\(\sigma=\sigma^{(m)}\)</span>. Define</p>
<div class="arithmatex">\[
f(z)=U\left(\frac{1}{z}\right)-Q\left(\boldsymbol{\theta}^{(m)}, \frac{1}{z}\right), \quad z&gt;0
\]</div>
<p>This function is convex, since it can be written</p>
<div class="arithmatex">\[
f(z)=-\frac{1}{n} \sum \frac{\rho_{0}\left(z r_{i}\right)}{z}+b_{0}+b_{1} z
\]</div>
<p>with some constants <span class="arithmatex">\(b_{0}\)</span> and <span class="arithmatex">\(b_{1}\)</span>; it has a horizontal tangent at <span class="arithmatex">\(z=1 / \sigma^{(m)}\)</span>, and it vanishes there. It follows that <span class="arithmatex">\(f(z) \geqslant 0\)</span> for all <span class="arithmatex">\(z&gt;0\)</span>; hence</p>
<div class="arithmatex">\[
U(\sigma) \geqslant Q\left(\boldsymbol{\theta}^{(m)}, \sigma\right)
\]</div>
<p>for all <span class="arithmatex">\(\sigma&gt;0\)</span>. Note that <span class="arithmatex">\(U\)</span> reaches its minimum at <span class="arithmatex">\(\sigma^{(m+1)}\)</span>. A simple calculation, using (8.7) to eliminate <span class="arithmatex">\(\Sigma \chi_{0}\)</span>, gives</p>
<div class="arithmatex">\[
\begin{aligned}
U\left(\sigma^{(m+1)}\right) &amp; =Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)+a\left(\sigma^{(m+1)}-\sigma^{(m)}\right)+a\left(\frac{\sigma^{(m+1)}}{\sigma^{(m)}}\right)^{2}\left[\frac{\left(\sigma^{(m)}\right)^{2}}{\sigma^{(m+1)}}-\sigma^{(m)}\right] \\
&amp; =Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)-a \frac{\left(\sigma^{(m+1)}-\sigma^{(m)}\right)^{2}}{\sigma^{(m)}}
\end{aligned}
\]</div>
<p>The assertion of the lemma now follows from (8.18).
For the location step, we have two variants: one modifies the residuals, the other the weights.</p>
<h1 id="the-location-step-with-modified-residuals">The Location Step with Modified Residuals</h1>
<p>Let <span class="arithmatex">\(\boldsymbol{\theta}^{(m)}\)</span> and <span class="arithmatex">\(\sigma^{(m)}\)</span> be trial values for <span class="arithmatex">\(\boldsymbol{\theta}\)</span> and <span class="arithmatex">\(\sigma\)</span>. Put</p>
<div class="arithmatex">\[
\begin{aligned}
r_{i} &amp; =y_{i}-f_{i}\left(\boldsymbol{\theta}^{(m)}\right) \\
r_{i}^{*} &amp; =\psi\left(\frac{r_{i}}{\sigma^{(m)}}\right) \sigma^{(m)} \\
x_{i k} &amp; =\frac{\partial}{\partial \theta_{k}} f_{i}\left(\boldsymbol{\theta}^{(m)}\right)
\end{aligned}
\]</div>
<p>Solve</p>
<div class="arithmatex">\[
\sum\left(r_{i}^{*}-\sum_{k} x_{i k} \tau_{k}\right)^{2}=\min !
\]</div>
<p>for <span class="arithmatex">\(\tau\)</span>, that is, determine the solution <span class="arithmatex">\(\tau=\hat{\tau}\)</span> of</p>
<div class="arithmatex">\[
X^{T} X \tau=X^{T} \mathbf{r}^{*}
\]</div>
<p>Put</p>
<div class="arithmatex">\[
\theta^{(m+1)}=\theta^{(m)}+q \hat{\tau}
\]</div>
<p>where <span class="arithmatex">\(0&lt;q&lt;2\)</span> is an arbitrary relaxation factor.
Remark Except that the residuals <span class="arithmatex">\(r_{i}\)</span> have been replaced by their metrically Winsorized versions <span class="arithmatex">\(r_{i}^{*}\)</span>, this is just the ordinary iterative GaussNewton step one uses to solve nonlinear least squares problems (if the <span class="arithmatex">\(f_{i}\)</span> are linear, it gives the least squares solution in one step).</p>
<p>LEMMA 8.2 Assume that <span class="arithmatex">\(\rho_{0} \geqslant 0, \rho_{0}(0)=0,0 \leqslant \rho_{0}^{\prime \prime} \leqslant 1\)</span>, and that the <span class="arithmatex">\(f_{i}\)</span> are linear. Without loss of generality choose the coordinate system such that <span class="arithmatex">\(X^{T} X=I\)</span>. Then</p>
<div class="arithmatex">\[
\begin{aligned}
Q\left(\theta^{(m)}, \sigma^{(m)}\right)-Q\left(\theta^{(m+1)}, \sigma^{(m)}\right) &amp; \geqslant \frac{q(2-q)}{2 \sigma^{(m)} n} \sum_{j}\left(\sum_{i} r_{i}^{*} x_{i j}\right)^{2} \\
&amp; =\frac{q(2-q)}{2 \sigma^{(m)} n}\|\hat{\tau}\|^{2} \\
&amp; =\frac{2-q}{2 \sigma^{(m)} n q}\left\|\theta^{(m+1)}-\theta^{(m)}\right\|^{2}
\end{aligned}
\]</div>
<p>In particular, unless (8.2) is already satisfied, <span class="arithmatex">\(Q\)</span> is strictly decreased.
Proof As in the scale step, we use a comparison function that agrees with <span class="arithmatex">\(Q\)</span> at <span class="arithmatex">\(\theta^{(m)}\)</span>, that lies wholly above <span class="arithmatex">\(Q\)</span>, and that reaches its minimum at <span class="arithmatex">\(\theta^{(m+1)}\)</span>. Put</p>
<div class="arithmatex">\[
W(\tau)=Q\left(\theta^{(m)}, \sigma^{(m)}\right)+\frac{1}{2 \sigma^{(m)} n} \sum\left[\left(r_{i}^{*}-\sum_{k} x_{i k} \tau_{k}\right)^{2}-\left(r_{i}^{*}\right)^{2}\right]
\]</div>
<p>The functions <span class="arithmatex">\(W(\tau)\)</span> and <span class="arithmatex">\(Q\left(\boldsymbol{\theta}^{(m)}+\tau, \sigma^{(m)}\right)\)</span> then have the same value and the same first derivative at <span class="arithmatex">\(\tau=0\)</span>, as we can easily check. The matrix of second order derivatives of the difference,</p>
<div class="arithmatex">\[
\frac{\partial^{2}}{\partial \tau_{j} \partial \tau_{k}}\left[W(\tau)-Q\left(\boldsymbol{\theta}^{(m)}+\tau, \sigma^{(m)}\right)\right]=\frac{1}{\sigma^{(m)} n} \sum_{i}\left[1-\psi^{\prime}\left(\frac{r_{i}-\Sigma x_{i j} \tau_{i}}{\sigma^{(m)}}\right)\right] x_{i j} x_{i k}
\]</div>
<p>is positive semidefinite; hence</p>
<div class="arithmatex">\[
W(\tau) \geqslant Q\left(\boldsymbol{\theta}^{(m)}+\tau, \sigma^{(m)}\right)
\]</div>
<p>for all <span class="arithmatex">\(\tau\)</span>. The minimum of <span class="arithmatex">\(W(\tau)\)</span> occurs at <span class="arithmatex">\(\hat{\tau}=X^{T} \tau^{*}\)</span>, and we easily check that it has the value</p>
<div class="arithmatex">\[
W(\hat{\tau})=Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)-\frac{1}{2 \sigma^{(m)} n}\|\hat{\tau}\|^{2}
\]</div>
<p>As a function of <span class="arithmatex">\(q\)</span>,</p>
<div class="arithmatex">\[
W(q \hat{\tau})-Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)
\]</div>
<p>is quadratic, vanishes at <span class="arithmatex">\(q=0\)</span>, has a minimum at <span class="arithmatex">\(q=1\)</span>, and for reasons of symmetry must vanish again at <span class="arithmatex">\(q=2\)</span>. Hence we obtain, by quadratic interpolation,</p>
<div class="arithmatex">\[
W(q \hat{\tau})-Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)=-\frac{q(2-q)}{2 \sigma^{(m)} n}\|\hat{\tau}\|
\]</div>
<p>and the assertion of the lemma now follows from (8.28).
Remark The relaxation factor <span class="arithmatex">\(q\)</span> had originally been introduced because theoretical considerations had indicated that <span class="arithmatex">\(q \approx 1 / E \psi^{\prime} \geqslant 1\)</span> should give faster convergence than <span class="arithmatex">\(q=1\)</span>. The empirical experience shows hardly any difference.</p>
<h1 id="the-location-step-with-modified-weights">The Location Step with Modified Weights</h1>
<p>Instead of (8.2) we can equivalently write</p>
<div class="arithmatex">\[
\sum w_{i} r_{i} \frac{\partial f_{i}}{\partial \theta_{j}}=0, \quad j=1, \ldots, p
\]</div>
<p>with weights depending on the current residuals <span class="arithmatex">\(r_{i}\)</span>, determined by</p>
<div class="arithmatex">\[
w_{i}=\frac{\psi\left(r_{i} / \sigma^{(m)}\right)}{r_{i} / \sigma^{(m)}}
\]</div>
<p>Let <span class="arithmatex">\(\boldsymbol{\theta}^{(m)}\)</span> and <span class="arithmatex">\(\sigma^{(m)}\)</span> be trial values, then find <span class="arithmatex">\(\boldsymbol{\theta}^{(m+1)}\)</span> by solving the weighted least squares problem (8.31), that is, find the solution <span class="arithmatex">\(\tau=\hat{\tau}\)</span> of</p>
<div class="arithmatex">\[
X^{T} W X \tau=X^{T} W \tau
\]</div>
<p>where <span class="arithmatex">\(W\)</span> is the diagonal matrix with diagonal elements <span class="arithmatex">\(w_{i}\)</span>, and put</p>
<div class="arithmatex">\[
\boldsymbol{\theta}^{(m+1)}=\boldsymbol{\theta}^{(m)}+\hat{\tau}
\]</div>
<p>LEMMA 8.3 (Dutter 1975) Assume that <span class="arithmatex">\(\rho_{0}\)</span> is convex and symmetric, that <span class="arithmatex">\(\psi(x) / x\)</span> is bounded and monotone decreasing for <span class="arithmatex">\(x&gt;0\)</span>, and that the <span class="arithmatex">\(f_{i}\)</span> are linear. Then, for <span class="arithmatex">\(\sigma&gt;0\)</span>, we have <span class="arithmatex">\(Q\left(\theta^{(m+1)}, \sigma^{(m)}\right)&lt;Q\left(\theta^{(m)}, \sigma^{(m)}\right)\)</span>, unless <span class="arithmatex">\(\theta^{(m)}\)</span> already minimizes <span class="arithmatex">\(Q\left(\cdot, \sigma^{(m)}\right)\)</span>. The decrease in <span class="arithmatex">\(Q\)</span> exceeds that of the corresponding modified residuals step.
Proof To simplify notation assume <span class="arithmatex">\(\sigma^{(m)}=1\)</span>. We also use a comparison function <span class="arithmatex">\(U\)</span> here, and we define it as follows:</p>
<div class="arithmatex">\[
U(\boldsymbol{\theta})=\sum_{i} U_{i}\left(y_{i}-f_{i}(\boldsymbol{\theta})\right)
\]</div>
<p>where each <span class="arithmatex">\(U_{i}\)</span> is a quadratic function</p>
<div class="arithmatex">\[
U_{i}(x)=a_{i}+\frac{1}{2} b_{i} x^{2}
\]</div>
<p>with <span class="arithmatex">\(a_{i}\)</span> and <span class="arithmatex">\(b_{i}\)</span> determined such that</p>
<div class="arithmatex">\[
U_{i}(x) \geqslant \rho_{0}(x), \quad \text { for all } x
\]</div>
<p>and</p>
<div class="arithmatex">\[
U_{i}\left(r_{i}\right)=\rho_{0}\left(r_{i}\right)
\]</div>
<p>with <span class="arithmatex">\(r_{i}=y_{i}-f_{i}\left(\boldsymbol{\theta}^{(m)}\right)\)</span>; see Exhibit 7.8.1.
These conditions imply that <span class="arithmatex">\(U_{i}\)</span> and <span class="arithmatex">\(\rho\)</span> have a common tangent at <span class="arithmatex">\(r_{i}\)</span> :</p>
<div class="arithmatex">\[
U_{i}^{\prime \prime}\left(r_{i}\right)=b_{i} r_{i}=\psi_{0}\left(r_{i}\right)
\]</div>
<p><img alt="img-9.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 7.8.1
hence</p>
<div class="arithmatex">\[
b_{i}=\frac{\psi\left(r_{i}\right)}{r_{i}}=w_{i}
\]</div>
<p>and</p>
<div class="arithmatex">\[
a_{i}=\rho_{0}\left(r_{i}\right)-\frac{1}{2} r_{i} \psi\left(r_{i}\right)
\]</div>
<p>We have to check that (8.37) holds. Write <span class="arithmatex">\(r\)</span> instead of <span class="arithmatex">\(r_{i}\)</span>. The difference</p>
<div class="arithmatex">\[
\begin{aligned}
z(x) &amp; =U_{i}(x)-\rho_{0}(x) \\
&amp; =\rho_{0}(r)-\frac{1}{2} r \psi_{0}(r)+\frac{1}{2} \frac{\psi_{0}(r)}{r} x^{2}-\rho_{0}(x)
\end{aligned}
\]</div>
<p>satisfies</p>
<div class="arithmatex">\[
\begin{aligned}
z(r) &amp; =z(-r)=0 \\
z^{\prime}(r) &amp; =z^{\prime}(-r)=0
\end{aligned}
\]</div>
<p>and</p>
<div class="arithmatex">\[
z^{\prime}(x)=\frac{\psi(r)}{r} x-\psi(x)
\]</div>
<p>Since <span class="arithmatex">\(\psi(x) / x\)</span> is decreasing for <span class="arithmatex">\(x&gt;0\)</span>, this implies that</p>
<div class="arithmatex">\[
\begin{aligned}
z^{\prime}(x) &amp; &lt;0, &amp; &amp; \text { for } 0&lt;x \leqslant r \\
&amp; \geqslant 0, &amp; &amp; \text { for } x \geqslant r
\end{aligned}
\]</div>
<p>hence <span class="arithmatex">\(z(x) \geqslant z(r)=0\)</span> for <span class="arithmatex">\(x \geqslant 0\)</span>, and the same holds for <span class="arithmatex">\(x \leqslant 0\)</span> because of symmetry.</p>
<p>In view of (8.40) we have</p>
<div class="arithmatex">\[
U(\boldsymbol{\theta})=\frac{1}{2} \sum w_{i}\left[y_{i}-f_{i}(\boldsymbol{\theta})\right]^{2}+\text { const. }
\]</div>
<p>and this is, of course, minimized by <span class="arithmatex">\(\boldsymbol{\theta}^{(m+1)}\)</span>. This proves the first part of the lemma. The second part follows from the remark that, if we had used comparison functions of the form</p>
<div class="arithmatex">\[
U_{i}^{*}(x)=a_{i}+c_{i} x+\frac{1}{2} x^{2}
\]</div>
<p>instead of (8.36), we would have recaptured the proof of Lemma 8.2, and that</p>
<div class="arithmatex">\[
U_{i}^{*}(x) \geqslant U_{i}(x), \quad \text { for all } x
\]</div>
<p>provided <span class="arithmatex">\(0 \leqslant \rho^{\prime \prime} \leqslant 1\)</span> (if necessary rescale <span class="arithmatex">\(\psi\)</span> to achieve this). Hence</p>
<div class="arithmatex">\[
W(\tau) \geqslant U\left(\boldsymbol{\theta}^{(m)}+\tau\right) \geqslant \rho\left(\boldsymbol{\theta}^{(m)}+\tau\right)
\]</div>
<p>In fact the same argument shows that <span class="arithmatex">\(U\)</span> is the best possible quadratic comparison function.</p>
<p>Remark 1 If we omit the convexity assumption and only assume that <span class="arithmatex">\(\rho(x)\)</span> increases for <span class="arithmatex">\(x&gt;0\)</span>, the above proof still goes through and shows that the modified weights algorithm converges to a (local) minimum if the scale is kept fixed.</p>
<p>Remark 2 The second part of Lemma 8.3 implies that the modified weights approach should give a faster convergence than the modified residuals approach. However the empirically observed convergence rates show only small differences. Since the modified residuals approach (for</p>
<p>linear <span class="arithmatex">\(f_{i}\)</span> ) can use the same matrices over all iterations, it even seems to have a slight advantage in total computing costs [cf. Dutter (1977a, b)].</p>
<p>If we alternate between location and scale steps (using either of the two versions for the location step), we obtain a sequence <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span>, which is guaranteed to decrease <span class="arithmatex">\(Q\)</span> at each step. We now want to prove that the sequence converges toward a solution of (8.2) and (8.3).</p>
<h1 id="theorem-84">THEOREM 8.4</h1>
<p>(1) The sequence <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span> has at least one accumulation point <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span>.
(2) Every accumulation point <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span> with <span class="arithmatex">\(\hat{\sigma}&gt;0\)</span> is a solution of (8.2) and (8.3) and minimizes (8.1).</p>
<p>Proof The sets of the form</p>
<div class="arithmatex">\[
A_{b}=\{(\boldsymbol{\theta}, \sigma) \mid \sigma \geqslant 0, Q(\boldsymbol{\theta}, \sigma) \leqslant b\}
\]</div>
<p>are compact. First, they are obviously closed, since <span class="arithmatex">\(Q\)</span> is continuous. We have <span class="arithmatex">\(\sigma \leqslant b / a\)</span> on <span class="arithmatex">\(A_{b}\)</span>. Since the <span class="arithmatex">\(f_{i}\)</span> are linear and the matrix of the <span class="arithmatex">\(x_{i j}=\partial f_{i} / \partial \theta_{j}\)</span> is assumed to have full rank, <span class="arithmatex">\(\|\boldsymbol{\theta}\|\)</span> must also be bounded (otherwise at least one of the <span class="arithmatex">\(f_{i}(\theta)\)</span> would be unbounded on <span class="arithmatex">\(A_{b}\)</span>; hence <span class="arithmatex">\(\sigma \rho\left\{\left[y_{i}-f_{i}(\theta)\right] / \sigma\right\}\)</span> would be unbounded). Compactness of the sets <span class="arithmatex">\(A_{b}\)</span> obviously implies (1). To prove (2), assume <span class="arithmatex">\(\hat{\sigma}&gt;0\)</span> and let <span class="arithmatex">\(\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}\right)}\right)\)</span> be a subsequence converging toward <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span>. Then</p>
<div class="arithmatex">\[
Q\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}\right)}\right) \geqslant Q\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}+1\right)}\right) \geqslant Q\left(\boldsymbol{\theta}^{\left(m_{i+1}\right)}, \sigma^{\left(m_{i+1}\right)}\right)
\]</div>
<p>(see Lemma 8.1); the two outer members of this inequality tend to <span class="arithmatex">\(Q(\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span>; hence (see Lemmas 8.2 and 8.3)</p>
<div class="arithmatex">\[
Q\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}\right)}\right)-Q\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}+1\right)}\right) \geqslant a \frac{\left(\sigma^{\left(m_{i}+1\right)}-\sigma^{\left(m_{i}\right)}\right)^{2}}{\sigma^{\left(m_{i}\right)}}
\]</div>
<p>converges to 0 . In particular, it follows that</p>
<div class="arithmatex">\[
\left(\frac{\sigma^{\left(m_{i}+1\right)}}{\sigma^{\left(m_{i}\right)}}\right)^{2}=\frac{1}{n a} \sum \chi_{0}\left(\frac{y_{i}-f_{i}\left(\boldsymbol{\theta}^{\left(m_{i}\right)}\right)}{\sigma^{\left(m_{i}\right)}}\right)
\]</div>
<p>converges to 1 ; hence in the limit</p>
<div class="arithmatex">\[
\frac{1}{n} \sum \chi_{0}\left(\frac{y_{i}-f_{i}(\hat{\theta})}{\hat{\sigma}}\right)=a
\]</div>
<p>Thus (8.3) is satisfied.
In the same way, we obtain from Lemma 8.2 that</p>
<div class="arithmatex">\[
Q\left(\boldsymbol{\theta}^{\left(m_{i}\right)}, \sigma^{\left(m_{i}\right)}\right)-Q\left(\theta^{\left(m_{i}+1\right)}, \sigma^{\left(m_{i}\right)}\right) \geqslant \frac{q(2-q)}{2 \sigma^{\left(m_{i}\right)} n} \sum_{j}\left(\sum_{i} r_{i}^{*} x_{i j}\right)^{2}
\]</div>
<p>tends to 0 ; in particular</p>
<div class="arithmatex">\[
\sum_{i} r_{i}^{*} x_{i j}=\sigma^{\left(m_{i}\right)} \sum_{i} \psi\left(\frac{y_{i}-f_{i}\left(\theta^{\left(m_{i}\right)}\right)}{\sigma^{\left(m_{i}\right)}}\right) x_{i j} \rightarrow 0
\]</div>
<p>Hence in the limit</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{y_{i}-f_{i}(\hat{\theta})}{\hat{\sigma}}\right) x_{i j}=0
\]</div>
<p>and thus (8.2) also holds. In view of the convexity of <span class="arithmatex">\(Q\)</span>, every solution of (8.2) and (8.3) minimizes (8.1).</p>
<p>We now intend to give conditions sufficient for there to be no accumulation points with <span class="arithmatex">\(\hat{\sigma}=0\)</span>. The main condition is one ensuring that the maximum number <span class="arithmatex">\(p^{\prime}\)</span> of residuals that can be made simultaneously 0 is not too big; assume that <span class="arithmatex">\(\chi_{0}\)</span> is symmetric and bounded, and that</p>
<div class="arithmatex">\[
n-p^{\prime}&gt;(n-p) \frac{E_{\Phi}\left(\chi_{0}\right)}{\chi_{0}(\infty)}
\]</div>
<p>Note that <span class="arithmatex">\(p^{\prime}=p\)</span> with probability 1 if the error distribution is absolutely continuous with respect to Lebesgue measure, so (8.51) is then automatically satisfied, since <span class="arithmatex">\(E_{\Phi}\left(\chi_{0}\right)&lt;\max \left(\chi_{0}\right)=\chi_{0}(\infty)\)</span>.</p>
<p>We assume that the iteration is started with <span class="arithmatex">\(\left(\theta^{(0)}, \sigma^{(0)}\right)\)</span> where <span class="arithmatex">\(\sigma^{(0)}&gt;0\)</span>. Then <span class="arithmatex">\(\sigma^{(m)}&gt;0\)</span> for all finite <span class="arithmatex">\(m\)</span>. Moreover, we note that, for all <span class="arithmatex">\(m,\left(\theta^{(m)}, \sigma^{(m)}\right)\)</span> then is contained in the compact set <span class="arithmatex">\(A_{b}\)</span>, with <span class="arithmatex">\(b=Q\left(\theta^{(0)}, \sigma^{(0)}\right)\)</span>. Hence it suffices to restrict <span class="arithmatex">\((\boldsymbol{\theta}, \sigma)\)</span> to <span class="arithmatex">\(A_{b}\)</span> for all the following arguments.</p>
<p>Clearly, (8.51) is equivalent to the following: for sufficiently small <span class="arithmatex">\(\sigma\)</span> we have</p>
<div class="arithmatex">\[
\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma}\right)&gt;a=\frac{n-p}{n} E_{\Phi}\left(\chi_{0}\right)
\]</div>
<p>This is strengthened in the following lemma.
LEMMA 8.5 Assume that (8.51) holds. Then there is a <span class="arithmatex">\(\sigma_{0}&gt;0\)</span> and a <span class="arithmatex">\(d&gt;1\)</span> such that for all <span class="arithmatex">\((\boldsymbol{\theta}, \sigma) \in A_{b}\)</span> with <span class="arithmatex">\(\sigma \leqslant \sigma_{0}\)</span></p>
<div class="arithmatex">\[
\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma}\right) \geqslant d^{2} a
\]</div>
<p>Proof For each <span class="arithmatex">\(\boldsymbol{\theta}\)</span> order the corresponding residuals according to increasing absolute magnitude, and let <span class="arithmatex">\(h(\boldsymbol{\theta})=\left|r_{\left(p^{\prime}+1\right)}\right|\)</span> be the <span class="arithmatex">\(\left(p^{\prime}+1\right)\)</span> st smallest. Then <span class="arithmatex">\(h(\boldsymbol{\theta})\)</span> is a continuous (in fact piecewise linear) strictly positive function. Since <span class="arithmatex">\(A_{b}\)</span> is compact, the minimum <span class="arithmatex">\(h_{0}\)</span> of <span class="arithmatex">\(h(\boldsymbol{\theta})\)</span> is attained and hence must be strictly positive. It follows that</p>
<div class="arithmatex">\[
\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma}\right) \geqslant \frac{n-p^{\prime}}{n} \chi_{0}\left(\frac{h_{0}}{\sigma}\right)
\]</div>
<p>In the limit <span class="arithmatex">\(\sigma \rightarrow 0\)</span> the right-hand side becomes</p>
<div class="arithmatex">\[
\frac{n-p^{\prime}}{n} \chi_{0}(\infty)&gt;\frac{n-p}{n} E_{\Phi}\left(\chi_{0}\right)=a
\]</div>
<p>in view of (8.51). Clearly strict inequality must already hold for some nonzero <span class="arithmatex">\(\sigma_{0}\)</span>, and the assertion of the lemma follows.</p>
<p>PROPOSITION 8.6 Assume (8.51), that <span class="arithmatex">\(\chi_{0}\)</span> is symmetric and bounded, and that <span class="arithmatex">\(\sigma^{(0)}&gt;0\)</span>. Then the sequence <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right.\)</span> ) cannot have an accumulation point on the boundary <span class="arithmatex">\(\sigma=0\)</span>.
Proof Lemma 8.5 implies that <span class="arithmatex">\(\sigma^{(m+1)} \geqslant d \sigma^{(m)}\)</span>. It follows that the sequence <span class="arithmatex">\(\sigma^{(m)}\)</span> cannot indefinitely stay below <span class="arithmatex">\(\sigma_{0}\)</span> and that there must be infinitely many <span class="arithmatex">\(m\)</span> for which <span class="arithmatex">\(\sigma^{(m)}&gt;\sigma_{0}\)</span>. Hence <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span> has an accumulation point <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span> with <span class="arithmatex">\(\hat{\sigma}&gt;0\)</span>, and, by Theorem 8.4, <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span> minimizes <span class="arithmatex">\(Q(\boldsymbol{\theta}, \sigma)\)</span>. It follows from (8.51) that, on the boundary, <span class="arithmatex">\(Q(\boldsymbol{\theta}, 0)&gt;Q(\hat{\boldsymbol{\theta}}, \hat{\sigma})=b_{0}\)</span>. Furthermore <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span> ultimately stays in <span class="arithmatex">\(A_{b_{0}+\varepsilon}\)</span> for every <span class="arithmatex">\(\varepsilon&gt;0\)</span>, and, for sufficiently small <span class="arithmatex">\(\varepsilon, A_{b_{0}+\varepsilon}\)</span> does not intersect the boundary.</p>
<p>THEOREM 8.7 Assume (8.51). Then, with the location step using modified residuals, the sequence <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right.\)</span> ) always converges to some solution of (8.2) and (8.3).</p>
<p>Proof If the solution <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span> of the minimum problem (8.1), or of the simultaneous equations (8.2) and (8.3), is unique, then Theorem 8.4 and Proposition 8.6 together imply that <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span> must be the unique accumulation point of the sequence, and there is nothing to prove. Assume now that the (necessarily convex) solution set <span class="arithmatex">\(S\)</span> contains more than one point.</p>
<p>A look at Exhibit 7.8.2 helps us to understand the following arguments; the diagram shows <span class="arithmatex">\(S\)</span> and some of the surfaces <span class="arithmatex">\(Q(\boldsymbol{\theta}, \sigma)=\)</span> const.</p>
<p>Clearly, for <span class="arithmatex">\(m \rightarrow \infty, Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right) \rightarrow \inf Q(\boldsymbol{\theta}, \sigma)\)</span>, that is, <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span> converge to the set <span class="arithmatex">\(S\)</span>. The idea is to demonstrate that the iteration steps succeeding <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span> will have to stay inside an approximately conical region (the shaded region in the picture). With increasing <span class="arithmatex">\(m\)</span> the base of the respective cone will get smaller and smaller, and since each cone is contained in the preceding one, this will imply convergence. The details of the proof are messy; we only sketch the main idea.</p>
<p>We standardize the coordinate system such that <span class="arithmatex">\(X^{T} X=2 a n I\)</span>. Then</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \Delta \theta_{j}=\frac{1}{2 a n} \sum \psi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right) x_{i j} \sigma^{(m)} \\
&amp; \Delta \sigma \cong \frac{1}{2} \sigma^{(m)}\left[\left(\frac{\sigma^{(m+1)}}{\sigma^{(m)}}\right)^{2}-1\right]=\frac{\sigma^{(m)}}{2 a}\left[\frac{1}{n} \sum x_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right)-a\right]
\end{aligned}
\]</div>
<p><img alt="img-10.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhlbit 7.8.2</p>
<p>whereas the gradient of <span class="arithmatex">\(Q\)</span> is given by</p>
<div class="arithmatex">\[
\begin{aligned}
g_{j} &amp; =\frac{\partial}{\partial \theta_{j}} Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)=-\frac{1}{2} \sum \psi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right) x_{i j}, \quad j=1, \ldots, p \\
g_{p+1} &amp; =\frac{\partial}{\partial \sigma} Q\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)=-\frac{1}{n} \sum \chi_{0}\left(\frac{r_{i}}{\sigma^{(m)}}\right)-a
\end{aligned}
\]</div>
<p>In other words in this particular coordinate system, the step</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \Delta \theta_{j}=-\frac{\sigma^{(m)}}{2 a} g_{j} \\
&amp; \Delta \sigma=-\frac{\sigma^{(m)}}{2 a} g_{p+1}
\end{aligned}
\]</div>
<p>is in the direction of the negative gradient at the point <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(m)}, \sigma^{(m)}\right)\)</span>.
It is not known to me whether this theorem remains true with the location step with modified weights.</p>
<p>Of course, the algorithms described so far have to be supplemented with a stopping rule, for example, stop iterations when the shift of every linear combination <span class="arithmatex">\(\alpha=\mathbf{a}^{T} \boldsymbol{\theta}\)</span> is smaller than <span class="arithmatex">\(\varepsilon\)</span> times its own estimated standard deviation [using (6.5)], with <span class="arithmatex">\(\varepsilon=0.001\)</span> or the like. Our experience is that on the average this will need about 10 iterations [for <span class="arithmatex">\(\rho\)</span> as in (7.14), with <span class="arithmatex">\(c=1.5\)</span> ], with relatively little dependence on <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(n\)</span>.</p>
<p>If <span class="arithmatex">\(\psi\)</span> is piecewise linear, it is possible to devise algorithms that reach the exact solution in a finite (and usually small, mostly under 10) number of iterations, if they converge at all: partition the residuals according to the linear piece of <span class="arithmatex">\(\psi\)</span> on which they sit and determine the algebraically exact solution under the assumption that the partitioning of the residuals stays the same for the new parameter values. If this assumption turns out to be true, we have found the exact solution <span class="arithmatex">\((\hat{\boldsymbol{\theta}}, \hat{\sigma})\)</span>; otherwise iterate. In the one-dimensional location case, this procedure seems to converge without fail; in the general regression case, some elaborate safeguards against singular matrices and other mishaps are needed. See Huber (1973a) and Dutter (1975, 1977a, b).</p>
<p>As starting values <span class="arithmatex">\(\left(\boldsymbol{\theta}^{(0)}, \sigma^{(0)}\right)\)</span> we usually take the ordinary least squares estimate, despite its known poor properties [cf. Andrews et al. (1972), for the simple location case].</p>
<p>Descending <span class="arithmatex">\(\psi\)</span>-functions are tricky, especially when the starting values for the iterations are nonrobust. Residuals that are accidentally large because of the poor starting parameters then may stay large forever</p>
<p>because they exert zero pull. It is therefore preferable to start with a monotone <span class="arithmatex">\(\psi\)</span>, iterate to death, and then append a few ( 1 or 2 ) iterations with the nonmonotone <span class="arithmatex">\(\psi\)</span>.</p>
<h1 id="79-moderate-leverage-points">7.9 MODERATE LEVERAGE POINTS</h1>
<p>We now return to the example of Section 7.1 and to the formulas derived in Section 7.2. In particular, we recall that in the classical least squares case, with <span class="arithmatex">\(\operatorname{var}\left(y_{i}\right)=\sigma^{2}\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{var}\left(\hat{y}_{i}\right) &amp; =h_{i} \sigma^{2} \\
\operatorname{var}\left(y_{i}-\hat{y}_{i}\right) &amp; =\left(1-h_{i}\right) \sigma^{2} \\
\operatorname{var}\left(\hat{\alpha}_{i}\right) &amp; =\frac{h_{i}}{1-h_{i}} \sigma^{2} \\
y_{i}-\hat{y}_{i} &amp; =\left(1-h_{i}\right)\left(y_{i}-\hat{\alpha}_{i}\right) \\
\operatorname{var}\left(y_{i}-\hat{\alpha}_{i}\right) &amp; =\frac{1}{1-h_{i}} \sigma^{2}
\end{aligned}
\]</div>
<p>Here <span class="arithmatex">\(\hat{y}_{i}\)</span> denotes the fitted value, and <span class="arithmatex">\(\hat{\alpha}_{i}\)</span> the "interpolated" value, estimated without using <span class="arithmatex">\(y_{i}\)</span>.</p>
<p>If we robustize least squares by using (7.1), that is,</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{y_{i}-\hat{y}_{i}}{\sigma}\right) x_{i j}=0, \quad j=1, \ldots, p
\]</div>
<p>with <span class="arithmatex">\(\psi\)</span> as in (7.15), for instance, and if point <span class="arithmatex">\(i\)</span> happens to be a leverage point with a high <span class="arithmatex">\(h_{i}\)</span>, then <span class="arithmatex">\(y_{i}\)</span> can be grossly aberrant, but <span class="arithmatex">\(\left(y_{i}-\hat{y}_{i}\right) / \sigma\)</span> will still remain on the linear part of <span class="arithmatex">\(\psi\)</span>. This is, of course, undesirable.</p>
<p>We can try to correct this by cutting down the overall influence of observation <span class="arithmatex">\(i\)</span> by introducing a weight factor <span class="arithmatex">\(\gamma\)</span>; we can shorten the linear part of <span class="arithmatex">\(\psi\)</span> by cutting down scale by a factor <span class="arithmatex">\(\delta\)</span>; and we can do both ( <span class="arithmatex">\(\gamma\)</span> and <span class="arithmatex">\(\delta\)</span>, of course, depend on <span class="arithmatex">\(h_{i}\)</span> and possibly other variables). This means that we replace the term <span class="arithmatex">\(\psi\left[\left(y_{i}-\hat{y}_{i}\right) / \sigma\right]\)</span> in (9.6) by</p>
<div class="arithmatex">\[
\gamma \psi\left(\frac{y_{i}-\hat{y}_{i}}{\delta \sigma}\right)
\]</div>
<p>We claim there are strong heuristic arguments in favor of choosing <span class="arithmatex">\(\gamma=\delta\)</span>, and somewhat weaker ones suggest choosing</p>
<div class="arithmatex">\[
\gamma=\delta=\sqrt{1-h_{i}}
\]</div>
<p>These arguments run as follows. Assume first that <span class="arithmatex">\(y_{i}\)</span> and the interpolated value <span class="arithmatex">\(\hat{\alpha}_{i}\)</span> differ only slightly, so that the residual sits on the linear part of <span class="arithmatex">\(\psi\)</span>. Then (9.7) means, essentially, that the <span class="arithmatex">\(i\)</span> th observation is treated with weight <span class="arithmatex">\(\gamma / \delta\)</span>. Clearly, if <span class="arithmatex">\(h_{i}\)</span> is small, we should have <span class="arithmatex">\(\gamma \approx \delta \approx 1\)</span>. On the other hand if <span class="arithmatex">\(h_{i}\)</span> is large, say <span class="arithmatex">\(h_{i}&gt;\frac{1}{2}\)</span>, then according to (9.3) a "good" observation <span class="arithmatex">\(y_{i}\)</span> is more accurate than <span class="arithmatex">\(\hat{\alpha}_{i}\)</span>. If the underlying distribution is a moderately contaminated normal one ( <span class="arithmatex">\(\varepsilon=1\)</span> to <span class="arithmatex">\(10 \%\)</span> ), then the likelihood is quite high that <span class="arithmatex">\(y_{i}\)</span> is a "good" observation if it does not deviate too much from <span class="arithmatex">\(\hat{\alpha}_{i}\)</span>. But then we would not want the extrapolated value <span class="arithmatex">\(\hat{\alpha}_{i}\)</span> to take precedence over <span class="arithmatex">\(y_{i}\)</span>, that is, we would not want to downweight <span class="arithmatex">\(y_{i}\)</span>. [Note that <span class="arithmatex">\(\hat{\alpha}_{i}\)</span> is more influential than <span class="arithmatex">\(y_{i}\)</span> anyway, cf. (2.36).] Thus we are induced to put <span class="arithmatex">\(\gamma=\delta\)</span>.</p>
<p>Now imagine that, for most observations, the residuals sit on the linear part of <span class="arithmatex">\(\psi\)</span>, so that, essentially, the parameters are determined by ordinary least squares. Move one observation <span class="arithmatex">\(y_{i}\)</span> from <span class="arithmatex">\(-\infty\)</span> to <span class="arithmatex">\(+\infty\)</span>, and, for each value of <span class="arithmatex">\(y_{i}\)</span>, let <span class="arithmatex">\(y_{i}^{*}\)</span> be the corresponding observational value for which the least squares solution would agree with the robustized version based on (9.7). Using (9.4) we find that</p>
<div class="arithmatex">\[
\begin{aligned}
y_{i}^{*} &amp; =y_{i}, &amp; &amp; \text { for }\left|y_{i}-\hat{\alpha}_{i}\right| \leqslant \frac{\delta}{1-h_{i}} c \sigma \\
&amp; =\hat{\alpha}_{i} \pm \frac{\delta}{1-h_{i}} c \sigma, &amp; &amp; \text { for }\left|y_{i}-\hat{\alpha}_{i}\right| \geqslant \frac{\delta}{1-h_{i}} c \sigma
\end{aligned}
\]</div>
<p>In view of (9.5) it would seem natural to choose <span class="arithmatex">\(\delta=\sqrt{1-h_{i}}\)</span>, so that the changeover in (9.9) would be related to a natural measure of scale of <span class="arithmatex">\(\left|y_{i}-\hat{\alpha}_{i}\right|\)</span>.</p>
<p>In other words we propose to modify (9.6) to</p>
<div class="arithmatex">\[
\sum_{i} \sigma \sqrt{1-h_{i}} \psi\left\{\frac{y_{i}-\hat{y}_{i}}{\sigma \sqrt{1-h_{i}}}\right\} x_{i j}=0
\]</div>
<p>with scale <span class="arithmatex">\(\sigma\)</span> determined simultaneously from</p>
<div class="arithmatex">\[
\sum_{i}\left[\sqrt{1-h_{i}} \psi\left\{\frac{y_{i}-\hat{y_{i}}}{\sigma \sqrt{1-h_{i}}}\right\}\right]^{2}=(n-p) E_{\Phi} \psi^{2}
\]</div>
<p>Equivalently, this corresponds to minimizing, simultaneously with respect to <span class="arithmatex">\(\boldsymbol{\theta}\)</span> and <span class="arithmatex">\(\sigma\)</span>, the expression</p>
<div class="arithmatex">\[
\sum \rho\left\{\frac{y_{i}-\hat{y_{i}}}{\sigma \sqrt{1-h_{i}}}\right\}\left(1-h_{i}\right) \sigma
\]</div>
<p>with <span class="arithmatex">\(\rho\)</span> as in (7.14) and <span class="arithmatex">\(\beta=E_{\Phi} \psi^{2}\)</span>.
Computationally, this does not introduce any new problems; instead of modifying the residual <span class="arithmatex">\(r_{i}=y_{i}-\hat{y_{i}}\)</span> to <span class="arithmatex">\(r_{i}^{*}= \pm c \sigma\)</span> whenever <span class="arithmatex">\(\left|r_{i}\right|&gt;c \sigma\)</span>, we now modify it to <span class="arithmatex">\(r_{i}^{*}= \pm \sqrt{1-h_{i}} c \sigma\)</span> whenever <span class="arithmatex">\(\left|r_{i}\right|&gt;\sqrt{1-h_{i}} c \sigma\)</span> (cf. the location step with modified residuals).</p>
<p>If we look at these matters quantitatively, then it is clear that, for <span class="arithmatex">\(h_{i} \leqslant 0.2\)</span>, the change from (9.6) to (9.10) is hardly noticeable (and the effort hardly worthwhile); on the other hand, for <span class="arithmatex">\(h_{i} \geqslant 0.8\)</span>, it may not give a good enough protection from the ill effects of outliers.</p>
<p>Therefore, several researchers have proposed more drastic downweighting of leverage points in order to bound, simultaneously for all possible positions in the design space, the influence of any observational value toward any estimable quantity. This is an outgrowth of Hampel's approach (cf. Section 11.1). Much of the material is unpublished; the most systematic treatment so far, together with a comprehensive account of earlier work done by Hampel, Mallows, Schweppe, and others, can be found in Krasker and Welsch (1980). The last-named authors find estimates that are asymptotically efficient at the model, subject to an overall bound on the gross-error sensitivity, both with regard to value and position.</p>
<p>However, some basic difficulties remain unresolved. The most fundamental one probably is that we are confronted with a small sample problem - the fitted value at a high leverage point is essentially determined by a single observation. Therefore, we cannot really rely on tools derived from asymptotic considerations, like the influence function, and we should check everything against insights gained from finite sample theory (cf. Chapter 10). Some preliminary explorations along these lines seem to suggest that the Krasker-Welsch approach may be overly pessimistic with regard to outliers at leverage points, but not pessimistic enough with regard</p>
<p>to small systematic errors at nonleverage points, and, somewhat obnoxiously, the first effect becomes particularly severe when there are no real leverage points (i.e., when max <span class="arithmatex">\(h_{i}\)</span> is small, but large against <span class="arithmatex">\(p / n\)</span> ). Clearly, much work still remains to be done in this area.</p>
<p>To avoid possible misunderstandings, we should add that the preceding discussion has little to do with robustness relative to outliers among the independent variables (the rows of <span class="arithmatex">\(X\)</span> ). Although several studies have been devoted to this important problem in the past few years, it does not seem that an adequate conceptual penetration has been achieved. In particular, unless we have an (approximate) model underlying the generation of the rows of <span class="arithmatex">\(X\)</span>, the concept of robustness would seem to be ill defined. In some cases a treatment via robust covariance/correlation matrices would seem to make more sense than the regression approach.</p>
<h1 id="710-analysis-of-variance">7.10 ANALYSIS OF VARIANCE</h1>
<p>Geometrically speaking, analysis of variance is concerned with nested models, say a larger <span class="arithmatex">\(p\)</span>-parameter model and a smaller <span class="arithmatex">\(q\)</span>-parameter model, <span class="arithmatex">\(q&lt;p\)</span>, and with orthogonal projections of the observational vector <span class="arithmatex">\(y\)</span> into the linear subspaces <span class="arithmatex">\(V_{q} \subset V_{p}\)</span> spanned by the columns of the respective design matrices; see Exhibit 7.10.1. Let <span class="arithmatex">\(\hat{y}_{(p)}\)</span> and <span class="arithmatex">\(\hat{y}_{(q)}\)</span> be the fitted values.
<img alt="img-11.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 7.10.1</p>
<p>If the experimental errors are independent normal with (say) unit variance, then the differences squared,</p>
<div class="arithmatex">\[
\left\|\mathbf{y}-\hat{\mathbf{y}}_{(q)}\right\|^{2}, \quad\left\|\mathbf{y}-\hat{\mathbf{y}}_{(p)}\right\|^{2}, \quad\left\|\hat{\mathbf{y}}_{(p)}-\hat{\mathbf{y}}_{(q)}\right\|^{2}
\]</div>
<p>are <span class="arithmatex">\(\chi^{2}\)</span>-distributed with <span class="arithmatex">\(n-q, n-p, p-q\)</span> degrees of freedom, and the latter two are independent, so that</p>
<div class="arithmatex">\[
\frac{1 /(p-q)\left\|\hat{y}_{(p)}-\hat{y}_{(q)}\right\|^{2}}{1 /(n-p)\left\|\mathbf{y}-\hat{y}_{(p)}\right\|^{2}}
\]</div>
<p>has an <span class="arithmatex">\(F\)</span>-distribution, on which we can then base a test of the adequacy of the smaller model.</p>
<p>What of this can be salvaged if the errors are no longer normal? Of course, the distributional assumptions behind (10.1) are then violated, and worse, the power of the tests may be severely impaired.</p>
<p>If we try to improve by estimating <span class="arithmatex">\(\hat{y}_{(p)}\)</span> and <span class="arithmatex">\(\hat{y}_{(q)}\)</span> robustly, then these two quantities at least will be asymptotically normal under fairly general assumptions (cf. Sections 7.4 and 7.5). Since the projections are no longer orthogonal, but defined in a somewhat complicated nonlinear fashion, we do not obtain the same result by first projecting to <span class="arithmatex">\(V_{p}\)</span>, then to <span class="arithmatex">\(V_{q}\)</span> as by directly projecting to <span class="arithmatex">\(V_{q}\)</span> (even though the two results are asymptotically equivalent). For the sake of internal consistency, when more than two nested models are concerned, the former variant (project via <span class="arithmatex">\(V_{p}\)</span> ) is preferable.</p>
<p>It follows from Proposition 4.1 that, under suitable regularity conditions, <span class="arithmatex">\(\left\|\hat{y}_{(p)}-\hat{y}_{(q)}\right\|^{2}\)</span> for the robust estimates still is asymptotically <span class="arithmatex">\(\chi^{2}\)</span>, when suitably scaled, with <span class="arithmatex">\(p-q\)</span> degrees of freedom. The denominator of (10.1), however, is nonrobust and useless as it stands. We must replace it by something that is a robust and consistent estimate of the expected value of the numerator. The obvious choice for the denominator, suggested by (6.5), is of course</p>
<div class="arithmatex">\[
\frac{1}{n-p} \frac{K^{2} \sum \psi\left(r_{i} / \sigma\right)^{2} \sigma^{2}}{\left[(1 / n) \sum \psi^{\prime}\left(r_{i} / \sigma\right)\right]^{2}}
\]</div>
<p>where</p>
<div class="arithmatex">\[
r_{i}=y_{i}-f_{i}\left(\hat{\boldsymbol{\theta}}_{(p)}\right)
\]</div>
<p>Since the asymptotic approximations will not work very well unless <span class="arithmatex">\(p / n\)</span> is</p>
<p>reasonably small (say <span class="arithmatex">\(p / n \leqslant 0.2\)</span> ), and since <span class="arithmatex">\(p \geqslant 2, n-p\)</span> will be much larger than <span class="arithmatex">\(p-q\)</span>, and the numerator</p>
<div class="arithmatex">\[
\frac{1}{p-q}\left\|\hat{y}_{(p)}-\hat{y}_{(q)}\right\|^{2}
\]</div>
<p>will always be much more variable than (10.2). Thus the quotient of (10.3) divided by (10.2),</p>
<div class="arithmatex">\[
\frac{\frac{1}{p-q}\left\|\hat{y}_{(p)}-\hat{y}_{(q)}\right\|^{2}}{\frac{1}{n-p} \frac{K^{2} \sum \psi\left(r_{i} / \sigma\right)^{2} \sigma^{2}}{\left[(1 / n) \sum \psi^{\prime}\left(r_{i} / \sigma\right)\right]^{2}}}
\]</div>
<p>will be approximated quite well by a <span class="arithmatex">\(\chi^{2}\)</span>-variable with <span class="arithmatex">\(p-q\)</span> degrees of freedom, divided by <span class="arithmatex">\(p-q\)</span>, and presumably even better by an <span class="arithmatex">\(F\)</span>-distribution with <span class="arithmatex">\(p-q\)</span> degrees of freedom in the numerator and <span class="arithmatex">\(n-p\)</span> degrees in the denominator. We might argue that the latter value-but not the factor <span class="arithmatex">\(n-p\)</span> occurring in (10.4)-should be lowered somewhat; however, since the exact amount depends on the underlying distribution and is not known anyway, we may just as well stick to the classical value <span class="arithmatex">\(n-p\)</span>.</p>
<p>Thus we end up with the following proposal for doing analysis of variance. Unfortunately, it is only applicable when there is a considerable excess of observations over parameters, say <span class="arithmatex">\(p / n \leqslant 0.2\)</span>. First, fit the largest model under consideration, giving <span class="arithmatex">\(\hat{y}_{(p)}\)</span>. Make sure that there are no leverage points (an erroneous observation at a leverage point of the larger model may cause an erroneous rejection of the smaller model), or at least, be aware of the danger. Then estimate the dispersion of the "unit weight" fitted value by (10.2). Estimate the parameters of smaller models using <span class="arithmatex">\(\hat{y}_{(p)}\)</span> (not y ) by ordinary least squares. Then proceed in the classical fashion [but replace <span class="arithmatex">\([1 /(n-p)]\left\|\mathrm{y}-\mathrm{y}_{(p)}\right\|^{2}\)</span> by (10.2)].</p>
<p>Incidentally, the above procedure can also be described as follows. Let</p>
<div class="arithmatex">\[
r_{k}^{*}=\frac{K \psi\left(r_{k} / \sigma\right) \sigma}{\frac{1}{n} \sum \psi^{\prime}\left(r_{i} / \sigma\right)}
\]</div>
<p>Put</p>
<div class="arithmatex">\[
\mathbf{y}^{*}=\hat{y}_{(p)}+\mathbf{r}^{*}
\]</div>
<p>Then proceed classically, using the pseudo-observations of <span class="arithmatex">\(\mathbf{y}^{*}\)</span> instead of <span class="arithmatex">\(y\)</span>.</p>
<p>At first sight the following approach also might look attractive. First, fit the largest model, yielding <span class="arithmatex">\(\hat{\mathbf{y}}_{(p)}\)</span>. This amounts to an ordinary weighted least squares fit with modified weights (8.32). Now freeze the weights <span class="arithmatex">\(w_{i}\)</span> and proceed in the classical fashion, using <span class="arithmatex">\(y_{i}\)</span> and the same weights <span class="arithmatex">\(w_{i}\)</span> for all models. However, this gives improper (inconsistent) values for the denominator of (10.1), and for monotone <span class="arithmatex">\(\psi\)</span>-functions it is not even outlier resistant.</p>
<h1 id="chapter-8">CHAPTER 8</h1>
<h2 id="robust-covariance-and-correlation-matrices">Robust Covariance and Correlation Matrices</h2>
<h3 id="81-general-remarks">8.1 GENERAL REMARKS</h3>
<p>The classical covariance and correlation matrices are used for a variety of different purposes. We mention just a few:</p>
<ul>
<li>They (or better: the associated ellipsoids) give a simple description of the overall shape of a pointcloud in <span class="arithmatex">\(p\)</span>-space. This is an important aspect with regard to discriminant analysis as well as principal component and factor analysis.</li>
<li>They allow us to calculate variances in arbitrary directions: <span class="arithmatex">\(\operatorname{var}\left(\mathbf{a}^{\boldsymbol{T}} \mathbf{x}\right)\)</span> <span class="arithmatex">\(=\mathbf{a}^{T} \operatorname{cov}(\mathbf{x}) \mathbf{a}\)</span>.</li>
<li>For a multivariate Gaussian distribution, the sample covariance matrix, together with the sample mean, is a sufficient statistic.</li>
<li>They can be used for tests of independence.</li>
</ul>
<p>Unfortunately, sample covariance matrices are excessively sensitive to outliers. All too often a principal component or factor analysis "explains" a structure that, on closer scrutiny, has been created by a mere one or two outliers (cf. Exhibit 8.1.1).</p>
<p>The robust alternative approaches can be roughly classified into the following three categories:
(1) Robust estimation of the individual matrix elements of the covariance/correlation matrix.
(2) Robust estimation of variances in sufficiently many selected directions (to which a quadratic form is then fitted).
(3) Direct (maximum likelihood) estimation of the shape matrix of some elliptical distribution.</p>
<p>The third of these approaches is affinely invariant; the first one certainly is not. The second one is somewhere in between, depending on how the</p>
<p><img alt="img-12.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 8.1.1 From Devlin, Gnanadesikan, and Kettenring (1979); see also Chen, H., Gnanadesikan, R., and Kettenring, J. R. (1974), with permission of the authors.
directions are selected. For example, we can choose them in relation to the coordinate axes and determine the matrix elements as in (1), or we can mimic an eigenvector/eigenvalue determination and find the direction with the smallest or largest robust variance, leading to an orthogonally invariant approach.</p>
<p>The coordinate dependent approaches are more germane to the estimation of correlation matrices (which are coordinate dependent anyway); the affinely invariant ones are better matched to covariance matrices.</p>
<p>Exhibits 8.1.1 and 8.1.2 illustrate the severity of the effects.
Exhibit 8.1.1 shows a principal component analysis of 14 economic characteristics of 29 chemical companies, namely the projection of the data on the plane of the first 2 components. The sample correlation between the two principal components is zero, as it should be, but there is a maverick company in the bottom right-hand corner, invalidating the analysis.</p>
<p>Exhibit 8.1.2 compares the influence of outliers on classical and on robust covariance estimates. The solid lines show ellipses derived from the classical sample covariance, theoretically containing <span class="arithmatex">\(80 \%\)</span> of the total normal mass; the dotted lines derive from the maximum likelihood estimate based on (10.26) with <span class="arithmatex">\(\kappa=2\)</span> and correspond to the ellipse <span class="arithmatex">\(|\mathbf{y}|=b=2\)</span>,</p>
<p><img alt="img-13.jpeg" src="data:image/jpeg;base64,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" />
(a)
<img alt="img-14.jpeg" src="data:image/jpeg;base64,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" />
(b)</p>
<p>Exhibit 8.1.2</p>
<p>which, asymptotically, also contains about <span class="arithmatex">\(80 \%\)</span> of the total mass, if the underlying distribution is normal. The observations in Exhibit 8.1.2a are a random sample of size 18 from a bivariate normal distribution with covariance matrix</p>
<div class="arithmatex">\[
\left(\begin{array}{cc}
1 &amp; 0.9 \\
0.9 &amp; 1
\end{array}\right)
\]</div>
<p>In Exhibit 8.1.2b, two contaminating observations with covariance matrix</p>
<div class="arithmatex">\[
\left(\begin{array}{cc}
4 &amp; -3.6 \\
-3.6 &amp; 4
\end{array}\right)
\]</div>
<p>were added to the sample.</p>
<h1 id="82-estimation-of-matrix-elements-through-robust-variances">8.2 ESTIMATION OF MATRIX ELEMENTS THROUGH ROBUST VARIANCES</h1>
<p>This approach is based on the following identity, valid for square integrable random variables <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> :</p>
<div class="arithmatex">\[
\operatorname{cov}(X, Y)=\frac{1}{4 a b}[\operatorname{var}(a X+b Y)-\operatorname{var}(a X-b Y)]
\]</div>
<p>It has been utilized by Gnanadesikan and Kettenring (1972).
Assume that <span class="arithmatex">\(S\)</span> is a robust scale functional; we write for short <span class="arithmatex">\(S(X)=\)</span> <span class="arithmatex">\(S\left(F_{X}\right)\)</span> and assume that</p>
<div class="arithmatex">\[
S(a X+b)=|a| S(X)
\]</div>
<p>If we replace <span class="arithmatex">\(\operatorname{var}(\cdot)\)</span> by <span class="arithmatex">\(S(\cdot)^{2}\)</span>, then (2.1) is turned into the definition of a robust alternative <span class="arithmatex">\(C(X, Y)\)</span> to the covariance between <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> :</p>
<div class="arithmatex">\[
C(X, Y)=\frac{1}{4 a b}\left[S(a X+b Y)^{2}-S(a X-b Y)^{2}\right]
\]</div>
<p>The constants <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> can be chosen arbitrarily, but (2.3) will have awkward and unstable properties if <span class="arithmatex">\(a X\)</span> and <span class="arithmatex">\(b Y\)</span> are on an entirely different scale. Gnanadesikan and Kettenring therefore recommend to take, for <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span>, the inverses of some robust scale estimates for <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, respectively; for example, take</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; a=\frac{1}{S(X)} \\
&amp; b=\frac{1}{S(Y)}
\end{aligned}
\]</div>
<p>Then</p>
<div class="arithmatex">\[
\frac{1}{4}\left[S(a X+b Y)^{2}-S(a X-b Y)^{2}\right]
\]</div>
<p>becomes a kind of robust correlation. However, it is not necessarily confined to the interval <span class="arithmatex">\([-1,+1]\)</span>, and the expression</p>
<div class="arithmatex">\[
R^{*}(X, Y)=\frac{S(a X+b Y)^{2}-S(a X-b Y)^{2}}{S(a X+b Y)^{2}+S(a X-b Y)^{2}}
\]</div>
<p>will therefore be preferable to (2.5) as a definition of a robust correlation coefficient. "Covariances" then can be reconstructed as</p>
<div class="arithmatex">\[
C^{*}(X, Y)=R^{*}(X, Y) S(X) S(Y)
\]</div>
<p>It is convenient to standardize <span class="arithmatex">\(S\)</span> such that <span class="arithmatex">\(S(X)=1\)</span> if <span class="arithmatex">\(X\)</span> is normal <span class="arithmatex">\(\mathfrak{R}(0,1)\)</span>. Then if the joint distribution of <span class="arithmatex">\((X, Y)\)</span> is bivariate normal, we have</p>
<div class="arithmatex">\[
C(X, Y)=C^{*}(X, Y)=\operatorname{cov}(X, Y)
\]</div>
<p>Proof (2.8) Note that <span class="arithmatex">\(a X \pm b Y\)</span> is normal with variance</p>
<div class="arithmatex">\[
a^{2} \operatorname{var}(X) \pm 2 a b \operatorname{cov}(X, Y)+b^{2} \operatorname{var}(Y)
\]</div>
<p>Now (2.8) follows from (2.2).
If <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> are independent, but not necessarily normal, and if the distribution of either <span class="arithmatex">\(X\)</span> or <span class="arithmatex">\(Y\)</span> is symmetric, then, clearly, <span class="arithmatex">\(C(X, Y)=\)</span> <span class="arithmatex">\(C^{*}(X, Y)=0\)</span>.</p>
<p>Now let <span class="arithmatex">\(S_{n}(X)\)</span> and <span class="arithmatex">\(C_{n}(X, Y)\)</span> be the finite sample versions based on <span class="arithmatex">\(\left(x_{1}, y_{1}\right), \ldots,\left(x_{n}, y_{n}\right)\)</span>. We can expect that the asymptotic distribution of <span class="arithmatex">\(\sqrt{n}\left[C_{n}(X, Y)-C(X, Y)\right]\)</span> will be normal, but already for a normal parent distribution we obtain some quite complicated expressions. For a nonnormal parent the situation seems to become almost intractably messy.</p>
<p>This approach has another and even more serious drawback: when it is applied to the components of a <span class="arithmatex">\(p\)</span>-vector <span class="arithmatex">\(\mathbf{X}=\left(X_{1}, \ldots, X_{p}\right)\)</span>, it does not automatically produce a positive definite robust correlation or covariance matrix <span class="arithmatex">\(\left[C\left(X_{i}, X_{j}\right)\right]\)</span> and thus these matrices may cause both computational and conceptual trouble (the shape ellipsoid may be a hyperboloid!). The schemes proposed by Devlin et al. (1975) to enforce positive definiteness would seem to be very difficult to analyze theoretically.</p>
<p>There is an intriguing and, as far as I know, not yet explored variant of this approach, that avoids this drawback. It directly determines the eigenvalues <span class="arithmatex">\(\lambda_{i}\)</span> and eigenvectors <span class="arithmatex">\(\mathbf{u}_{i}\)</span> of a robust covariance matrix; namely find</p>
<p>that unit vector <span class="arithmatex">\(\mathbf{u}_{1}\)</span> for which <span class="arithmatex">\(\lambda_{1}=S\left(\mathbf{u}_{1}^{T} \mathbf{X}\right)^{2}\)</span> is maximal (or minimal), then do the same for unit vectors <span class="arithmatex">\(\mathbf{u}_{2}\)</span> orthogonal to <span class="arithmatex">\(\mathbf{u}_{1}\)</span>, and so on. This will automatically give a positive definite matrix.</p>
<h1 id="83-estimation-of-matrix-elements-through-robust-correlation">8.3 ESTIMATION OF MATRIX ELEMENTS THROUGH ROBUST CORRELATION</h1>
<p>This approach is based on a remarkable distribution-free property of the ordinary sample correlation coefficient</p>
<div class="arithmatex">\[
r_{n}(\mathbf{x}, \mathbf{y})=\frac{\sum\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\left[\sum\left(x_{i}-\bar{x}\right)^{2} \cdot \sum\left(y_{i}-\bar{y}\right)^{2}\right]^{1 / 2}}
\]</div>
<p>THEOREM 3.1 If the two vectors <span class="arithmatex">\(\mathbf{x}^{T}=\left(x_{1}, \ldots, x_{n}\right)\)</span> and <span class="arithmatex">\(\mathbf{y}^{T}=\left(y_{1}, \ldots, y_{n}\right)\)</span> are independent, and either the distribution of <span class="arithmatex">\(\mathbf{y}\)</span> or the distribution of <span class="arithmatex">\(\mathbf{x}\)</span> is invariant under permutation of the components, then</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; E\left(r_{n}\right)=0 \\
&amp; E\left(r_{n}^{2}\right)=\frac{1}{n-1}
\end{aligned}
\]</div>
<p>Proof It suffices to calculate the above expectations conditionally, <span class="arithmatex">\(\mathbf{x}\)</span> given, and <span class="arithmatex">\(\mathbf{y}\)</span> given up to a random permutation.</p>
<p>Despite this distribution-free result, <span class="arithmatex">\(r_{n}\)</span> obviously is not robust-one single, sufficiently bad outlying pair ( <span class="arithmatex">\(x_{i}, y_{i}\)</span> ) can shift <span class="arithmatex">\(r_{n}\)</span> to any value in <span class="arithmatex">\((-1,+1)\)</span>.</p>
<p>But the following is a remedy. Replace <span class="arithmatex">\(r_{n}(\mathbf{x}, \mathbf{y})\)</span> by <span class="arithmatex">\(r_{n}(\mathbf{u}, \mathbf{v})\)</span>, where <span class="arithmatex">\(\mathbf{u}\)</span> and <span class="arithmatex">\(\mathbf{v}\)</span> are computed from <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{y}\)</span>, respectively, according to certain quite general rules given below. The first two of the following five requirements are essential; the others add some convenience:
(1) <span class="arithmatex">\(\mathbf{u}\)</span> is computed from <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{v}\)</span> from <span class="arithmatex">\(\mathbf{y}: \mathbf{u}=\Psi(\mathbf{x}), \mathbf{v}=\Xi(\mathbf{y})\)</span>.
(2) <span class="arithmatex">\(\Psi\)</span> and <span class="arithmatex">\(\Xi\)</span> commute with permutations of the components of <span class="arithmatex">\(\mathbf{x}, \mathbf{u}\)</span> and <span class="arithmatex">\(\mathbf{y}, \mathbf{v}\)</span>.
(3) <span class="arithmatex">\(\Psi\)</span> and <span class="arithmatex">\(\Xi\)</span> preserve a monotone ordering of the components of <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{y}\)</span>.
(4) <span class="arithmatex">\(\Psi=\Xi\)</span>.
(5) <span class="arithmatex">\(\forall a&gt;0, \forall b, \exists a_{1}&gt;0, \exists b_{1}, \forall \mathbf{x} \Psi(a \mathbf{x}+b)=a_{1} \Psi(\mathbf{x})+b_{1}\)</span>.</p>
<p>Of these requirements, (1) and (2) ensure that <span class="arithmatex">\(\mathbf{u}\)</span> and <span class="arithmatex">\(\mathbf{v}\)</span> still satisfy the assumptions of Theorem 3.1 if <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{y}\)</span> do. If (3) holds, then perfect rank correlations are preserved. Finally (4) and (5) together imply that correla-</p>
<p>tions <span class="arithmatex">\(\pm 1\)</span> are preserved. In the following two examples, all five requirements hold.</p>
<p>Example 3.1 Let</p>
<div class="arithmatex">\[
u_{i}=a\left(R_{i}\right)
\]</div>
<p>where <span class="arithmatex">\(R_{i}\)</span> is the rank of <span class="arithmatex">\(x_{i}\)</span> in <span class="arithmatex">\(\left(x_{1}, \ldots, x_{n}\right)\)</span> and <span class="arithmatex">\(a(\cdot)\)</span> is some monotone scores function. The choice <span class="arithmatex">\(a(i)=i\)</span> gives the classical Spearman rank correlation between <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{y}\)</span>.</p>
<p>Example 3.2 Let <span class="arithmatex">\(T\)</span> and <span class="arithmatex">\(S\)</span> be arbitrary estimates of location and scale satisfying</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; T(a \mathbf{x}+b)=a T(\mathbf{x})+b \\
&amp; S(a \mathbf{x}+b)=|a| S(\mathbf{x})
\end{aligned}
\]</div>
<p>let <span class="arithmatex">\(\psi\)</span> be a monotone function, and put</p>
<div class="arithmatex">\[
u_{i}=\psi\left(\frac{x_{i}-T}{S}\right)
\]</div>
<p>For example, <span class="arithmatex">\(S\)</span> could be the median absolute deviation, and <span class="arithmatex">\(T\)</span> the <span class="arithmatex">\(M\)</span>-estimate determined by</p>
<div class="arithmatex">\[
\sum \psi\left(\frac{x_{i}-T}{S}\right)=0
\]</div>
<p>The choice <span class="arithmatex">\(\psi(x)=\operatorname{sign}(x)\)</span> and <span class="arithmatex">\(T=\operatorname{med}\left\{x_{i}\right\}\)</span> gives the so-called quadrant correlation.</p>
<h1 id="some-properties-of-such-modified-correlations">Some Properties of Such Modified Correlations</h1>
<h2 id="minimax-bias">Minimax Bias</h2>
<p>Let <span class="arithmatex">\(G\)</span> and <span class="arithmatex">\(H\)</span> be centrosymmetric distributions in <span class="arithmatex">\(\mathbb{R}^{2}\)</span>, and assume that <span class="arithmatex">\((X, Y)\)</span> is distributed according to the mixture</p>
<div class="arithmatex">\[
F=(1-\varepsilon) G+\varepsilon H
\]</div>
<p>Then the (ordinary) correlation coefficient <span class="arithmatex">\(\rho_{F}\)</span> of <span class="arithmatex">\(\psi(X)\)</span> and <span class="arithmatex">\(\psi(Y)\)</span> satisfies</p>
<div class="arithmatex">\[
(1-\eta) \rho_{G}-\eta \leqslant \rho_{F} \leqslant(1-\eta) \rho_{G}+\eta
\]</div>
<p>The bounds are sharp, with</p>
<div class="arithmatex">\[
\frac{\eta}{1-\eta}=\frac{\varepsilon}{1-\varepsilon} \cdot \frac{\sup \psi^{2}}{E_{G}\left(\psi^{2}\right)}
\]</div>
<p>Thus <span class="arithmatex">\(\eta\)</span> is made smallest if <span class="arithmatex">\(\psi(x)=\operatorname{sign}(x)\)</span>; in other words the quadrant correlation is asymptotically minimax with respect to bias. This is analogous to the minimax property of the sample median (Section 4.2).</p>
<h1 id="tests-for-independence">Tests for Independence</h1>
<p>Take the following test problem. Hypothesis: the probability law behind <span class="arithmatex">\(\left(X^{*}, Y^{*}\right)\)</span> is</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; X^{*}=X+\delta \cdot Z \\
&amp; Y^{*}=Y+\delta \cdot Z_{1}
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(X, Y, Z\)</span>, and <span class="arithmatex">\(Z_{1}\)</span> are independent symmetric random variables, with <span class="arithmatex">\(Z\)</span> and <span class="arithmatex">\(Z_{1}\)</span> being bounded and having the same distribution. Assume <span class="arithmatex">\(\operatorname{var}(Z)=\operatorname{var}\left(Z_{1}\right)=1 ; \delta\)</span> is a small number.</p>
<p>The alternative is the same, except that <span class="arithmatex">\(Z=Z_{1}\)</span>.
According to the Neyman-Pearson lemma, the most powerful tests are based on the test statistic</p>
<div class="arithmatex">\[
\prod_{i} \frac{h_{A}\left(x_{i}, y_{i}\right)}{h_{H}\left(x_{i}, y_{i}\right)}
\]</div>
<p>where <span class="arithmatex">\(h_{H}\)</span> and <span class="arithmatex">\(h_{A}\)</span> are the densities of <span class="arithmatex">\(\left(X^{*}, Y^{*}\right)\)</span> under the hypothesis and the alternative, respectively. If <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> are the densities of <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, respectively, we have</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; h_{H}(x, y)=E\left[f(x-\delta Z) g\left(y-\delta Z_{1}\right)\right] \\
&amp; h_{A}(x, y)=E[f(x-\delta Z) g(y-\delta Z)]
\end{aligned}
\]</div>
<p>and thus</p>
<div class="arithmatex">\[
\frac{h_{A}(x, y)}{h_{H}(x, y)}=1+\frac{\operatorname{cov}[f(x-\delta Z), g(y-\delta Z)]}{E[f(x-\delta Z)] E[g(y-\delta Z)]}
\]</div>
<p>If <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> can be expanded into a Taylor series</p>
<div class="arithmatex">\[
f(x-\delta Z)=f(x)-\delta Z f^{\prime}(x)+\frac{1}{2} \delta^{2} Z^{2} f^{\prime \prime}(x)-\cdots
\]</div>
<p>we obtain that</p>
<div class="arithmatex">\[
\frac{h_{A}(x, y)}{h_{H}(x, y)}=1+\delta^{2} \frac{f^{\prime}(x)}{f(x)} \frac{g^{\prime}(y)}{g(y)}+O\left(\delta^{4}\right)
\]</div>
<p>so, asymptotically for <span class="arithmatex">\(\delta \rightarrow 0\)</span>, the most powerful test will be based on the test statistic</p>
<div class="arithmatex">\[
T_{n}=\sum \psi\left(x_{i}\right) \chi\left(y_{i}\right)
\]</div>
<p>where</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi(x)=\frac{f^{\prime}(x)}{f(x)} \\
&amp; \chi(x)=\frac{g^{\prime}(x)}{g(x)}
\end{aligned}
\]</div>
<p>If we standardize (3.15) by dividing it by its (estimated) standard deviation, then we obtain a robust correlation of the form suggested in Example 3.2.</p>
<p>Under the hypothesis the test statistic (3.15) has expectation 0 and variance</p>
<div class="arithmatex">\[
E_{H}\left(T_{n}^{2}\right)=n E\left(\psi^{2}\right) E\left(\chi^{2}\right)
\]</div>
<p>Under the alternative the expectation is</p>
<div class="arithmatex">\[
E_{A}\left(T_{n}\right)=\delta^{2} n E\left(\psi^{\prime}\right) E\left(\chi^{\prime}\right)
\]</div>
<p>while the variance stays the same (neglecting higher order terms in <span class="arithmatex">\(\delta\)</span> ). It follows that the asymptotic power of the test can be measured by the variance ratio</p>
<div class="arithmatex">\[
\frac{\left[E_{A}\left(T_{n}\right)\right]^{2}}{\operatorname{var}_{A}\left(T_{n}\right)} \approx n \delta^{4} \frac{\left[E\left(\psi^{\prime}\right)\right]^{2}\left[E\left(\chi^{\prime}\right)\right]^{2}}{E\left(\psi^{2}\right) E\left(\chi^{2}\right)}
\]</div>
<p>This holds also if <span class="arithmatex">\(\psi\)</span> and <span class="arithmatex">\(\chi\)</span> are not related to <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> by (3.16) and (3.17). [For a rigorous treatment of such problems under less stringent regularity conditions, see Hájek and Šidák (1967), p. 75ff.].</p>
<p>A glance at (3.20) shows that there is a close formal analogy to problems in estimation of location. For instance, if the distributions of <span class="arithmatex">\(X^{*}\)</span> and <span class="arithmatex">\(Y^{*}\)</span></p>
<p>vary over some sets and we would like to maximize the minimum asymptotic power of a test for independence, we have to find the distributions <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> minimizing Fisher information for location (!).</p>
<p>Of course, this also bears directly on correlation estimates, since in most cases it will be desirable to optimize the estimates so that they are best for nearly independent variables.</p>
<h1 id="a-particular-choice-for-psi">A Particular Choice for <span class="arithmatex">\(\psi\)</span></h1>
<p>Let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \psi_{c}(x)=2 \Phi\left(\frac{x}{c}\right)-1, \quad \text { for } c&gt;0 \\
&amp; \psi_{0}(x)=\operatorname{sign}(x)
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(\Phi\)</span> is the standard normal cumulative.
PROPOSITION 3.2 If <span class="arithmatex">\((X, Y)\)</span> is bivariate normal with mean 0 and covariance matrix</p>
<div class="arithmatex">\[
\left(\begin{array}{cc}
1 &amp; \beta \\
\beta &amp; 1
\end{array}\right)
\]</div>
<p>then</p>
<div class="arithmatex">\[
E\left[\psi_{c}(X) \psi_{c}(Y)\right]=\frac{2}{\pi} \arcsin \left(\frac{\beta}{1+c^{2}}\right)
\]</div>
<p>Proof We first treat the special case <span class="arithmatex">\(c=0\)</span>. We may represent <span class="arithmatex">\(Y\)</span> as <span class="arithmatex">\(Y=\beta X-\sqrt{1-\beta^{2}} Z\)</span> where <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Z\)</span> are independent standard normal. We have</p>
<div class="arithmatex">\[
E\left[\psi_{0}(X) \psi_{0}(Y)\right]=4 P\{X&gt;0, Y&gt;0\}-1
\]</div>
<p>Now</p>
<div class="arithmatex">\[
\begin{aligned}
P\{X&gt;0, Y&gt;0\} &amp; =P\left\{X&gt;0, \beta X-\sqrt{1-\beta^{2}} Z&gt;0\right\} \\
&amp; =\int_{\beta x-\sqrt{1-\beta^{2}} z&gt;0} \frac{1}{2 \pi} e^{-\left(x^{2}+z^{2}\right) / 2} d x d z
\end{aligned}
\]</div>
<p><img alt="img-15.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhibit 8.3.1
is the integral of the bivariate normal density over the shaded sector in Exhibit 8.3.1. The slope of the boundary line is <span class="arithmatex">\(\beta / \sqrt{1-\beta^{2}}\)</span>; thus</p>
<div class="arithmatex">\[
\varphi=\arcsin \beta
\]</div>
<p>and it follows that</p>
<div class="arithmatex">\[
P(X&gt;0, Y&gt;0)=\frac{1}{4}+\frac{1}{2 \pi} \arcsin \beta
\]</div>
<p>Thus the special case is proved.
With regard to the general case, we first note that</p>
<div class="arithmatex">\[
E\left[\psi_{c}(X) \psi_{c}(Y)\right]=4 E\left[\Phi\left(\frac{X}{c}\right) \Phi\left(\frac{Y}{c}\right)\right]-1
\]</div>
<p>If we introduce two auxiliary random variables <span class="arithmatex">\(Z_{1}\)</span> and <span class="arithmatex">\(Z_{2}\)</span> that are standard normal and independent of <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, we can write</p>
<div class="arithmatex">\[
\begin{aligned}
E\left[\Phi\left(\frac{X}{c}\right) \Phi\left(\frac{Y}{c}\right)\right] &amp; =E\left[P^{X}\left(X-c Z_{1}&gt;0\right) P^{Y}\left(Y-c Z_{2}&gt;0\right)\right] \\
&amp; =P\left\{X-c Z_{1}&gt;0, Y-c Z_{2}&gt;0\right\}
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(P^{X}\)</span> and <span class="arithmatex">\(P^{Y}\)</span> denote conditional probabilities, given <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>, respectively. But since the correlation of <span class="arithmatex">\(X-c Z_{1}\)</span> and <span class="arithmatex">\(Y-c Z_{2}\)</span> is <span class="arithmatex">\(\beta /\left(1+c^{2}\right)\)</span>, the general case now follows from the special one.</p>
<p>NOTE 1 This theorem exhibits a choice of <span class="arithmatex">\(\psi\)</span> for which we can recapture the original correlation of <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span> from that of <span class="arithmatex">\(\psi(X)\)</span> and <span class="arithmatex">\(\psi(Y)\)</span> in a particularly simple way. However, if this transformation is applied to the elements of a sample covariance/correlation matrix, it in general destroys positive definiteness. So we may prefer to work with the covariances of <span class="arithmatex">\(\psi(X)\)</span> and <span class="arithmatex">\(\psi(Y)\)</span>, even though they are biased.</p>
<p>NOTE 2 If <span class="arithmatex">\(T_{X, n}\)</span> and <span class="arithmatex">\(T_{Y, n}\)</span> are the location estimates determined through</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \sum \psi\left(x_{i}-T_{X}\right)=0 \\
&amp; \sum \psi\left(y_{i}-T_{Y}\right)=0
\end{aligned}
\]</div>
<p>then the correlation <span class="arithmatex">\(\rho(\psi(X), \psi(Y))\)</span> can be interpreted as the (asymptotic) correlation between the two location estimates <span class="arithmatex">\(T_{X, n}\)</span> and <span class="arithmatex">\(T_{Y, n}\)</span>. (Heuristic argument: use the influence function to write</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; T_{X, n} \cong \frac{1}{n} \sum \frac{\psi\left(x_{i}\right)}{E\left(\psi^{\prime}\right)} \\
&amp; T_{Y, n} \cong \frac{1}{n} \sum \frac{\psi\left(y_{i}\right)}{E\left(\psi^{\prime}\right)}
\end{aligned}
\]</div>
<p>assuming without loss of generality that the limiting values of <span class="arithmatex">\(T_{X, n}\)</span> and <span class="arithmatex">\(T_{Y, n}\)</span> are 0 . Thus</p>
<div class="arithmatex">\[
\operatorname{cov}\left(T_{X, n}, T_{Y, n}\right) \cong \frac{1}{n} \frac{E[\psi(X) \psi(Y)]}{\left[E\left(\psi^{\prime}\right)\right]^{2}}
\]</div>
<p>The (relative) efficiency of these covariance/correlation estimates is the square of that of the corresponding location estimates, so the efficiency loss may be quite severe. For instance, assume that the correlation <span class="arithmatex">\(\rho\)</span> in Proposition 3.2 is small. Then</p>
<div class="arithmatex">\[
\rho\left(\psi_{c}(X), \psi_{c}(Y)\right) \approx \beta \frac{1}{\left(1+c^{2}\right) \arcsin \left[1 /\left(1+c^{2}\right)\right]}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\rho\left(\psi_{0}(X), \psi_{0}(Y)\right) \approx \beta \cdot \frac{2}{\pi}
\]</div>
<p>Thus if we are testing <span class="arithmatex">\(\rho(X, Y)=0\)</span> against <span class="arithmatex">\(\rho(X, Y)=\beta=\beta_{0} / \sqrt{n}\)</span>, for sample size <span class="arithmatex">\(n\)</span>, then the asymptotic efficiency of <span class="arithmatex">\(r_{n}\left(\psi_{c}(X), \psi_{c}(Y)\right)\)</span> relative to <span class="arithmatex">\(r_{n}(X, Y)\)</span> is</p>
<div class="arithmatex">\[
\left[\left(1+c^{2}\right) \arcsin \left(\frac{1}{1+c^{2}}\right)\right]^{-2}
\]</div>
<p>For <span class="arithmatex">\(c=0\)</span> this amounts to <span class="arithmatex">\(4 / \pi^{2} \approx 0.41\)</span>.</p>
<h1 id="84-an-affinely-invariant-approach">8.4 AN AFFINELY INVARIANT APPROACH</h1>
<h2 id="maximum-likelihood-estimates">Maximum Likelihood Estimates</h2>
<p>Let <span class="arithmatex">\(f(\mathbf{x})=f(|\mathbf{x}|)\)</span> be a spherically symmetric probability density in <span class="arithmatex">\(\mathbb{R}^{p}\)</span>. We apply general nondegenerate affine transformations <span class="arithmatex">\(\mathbf{x} \rightarrow V(\mathbf{x}-\mathbf{t})\)</span> to obtain a <span class="arithmatex">\(p\)</span>-dimensional location and scale family of "elliptic" densities</p>
<div class="arithmatex">\[
f(\mathbf{x} ; \mathbf{t}, V)=|\operatorname{det} V| f(|V(\mathbf{x}-\mathbf{t})|)
\]</div>
<p>The problem is to estimate the vector <span class="arithmatex">\(\mathbf{t}\)</span> and the matrix <span class="arithmatex">\(V\)</span> from <span class="arithmatex">\(n\)</span> observations of <span class="arithmatex">\(\mathbf{x}\)</span>.</p>
<p>Evidently, <span class="arithmatex">\(V\)</span> is not uniquely identifiable (it can be multiplied by an arbitrary orthogonal matrix from the left), but <span class="arithmatex">\(V^{T} V\)</span> is. We can enforce uniqueness of <span class="arithmatex">\(V\)</span> by suitable side conditions, for example by requiring that it be positive definite symmetric, or that it be lower triangular with a positive diagonal. Mostly, we adopt the latter convention; it is the most convenient one for numerical calculations, but the other is more convenient for some proofs.</p>
<p>The maximum likelihood estimate of <span class="arithmatex">\((\mathbf{t}, V)\)</span> is obtained by maximizing</p>
<div class="arithmatex">\[
\log (\operatorname{det} V)+\operatorname{ave}\{\log f(|V(\mathbf{x}-\mathbf{t})|)\}
\]</div>
<p>where ave <span class="arithmatex">\(\{\cdot\}\)</span> denotes the average taken over the sample. A necessary condition for a maximum is that (4.2) remain stationary under infinitesimal variations of <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span>. So we let <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> depend differentiably on a dummy parameter and take the derivative (denoted by a superscribed dot). We obtain the condition</p>
<div class="arithmatex">\[
\operatorname{tr}(S)+\operatorname{ave}\left\{\frac{f^{\prime}(|\mathbf{y}|)}{f(|\mathbf{y}|)} \cdot \frac{\mathbf{y}^{T} S \mathbf{y}}{|\mathbf{y}|}\right\}-\operatorname{ave}\left\{\frac{f^{\prime}(|\mathbf{y}|)}{f(|\mathbf{y}|)} \frac{\mathbf{t}^{T} V^{T} \mathbf{y}}{|\mathbf{y}|}\right\}=0
\]</div>
<p>with the abbreviations</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \mathbf{y}=V(\mathbf{x}-\mathbf{t}) \\
&amp; S=\dot{V} V^{-1}
\end{aligned}
\]</div>
<p>Since this should hold for arbitrary infinitesimal variations <span class="arithmatex">\(\dot{\mathbf{t}}\)</span> and <span class="arithmatex">\(\dot{V}\)</span>, (4.3) can be rewritten into the set of simultaneous matrix equations</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{ave}\{w(|y|) y\} &amp; =0 \\
\operatorname{ave}\left\{w(|y|) y y^{T}-I\right\} &amp; =0
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(I\)</span> is the <span class="arithmatex">\(p \times p\)</span> identity matrix, and</p>
<div class="arithmatex">\[
w(|y|)=-\frac{f^{\prime}(|y|)}{|y| f(|y|)}
\]</div>
<p>Example 4.1 Let</p>
<div class="arithmatex">\[
f(|x|)=(2 \pi)^{-p / 2} \exp \left(\frac{-|\mathbf{x}|^{2}}{2}\right)
\]</div>
<p>be the standard normal density. Then <span class="arithmatex">\(w \equiv 1\)</span>, and (4.6) and (4.7) can equivalently be written as</p>
<div class="arithmatex">\[
\begin{aligned}
\mathbf{t} &amp; =\operatorname{ave}\{\mathbf{x}\} \\
\left(V^{T} V\right)^{-1} &amp; =\operatorname{ave}\left\{(\mathbf{x}-\mathbf{t})(\mathbf{x}-\mathbf{t})^{T}\right\}
\end{aligned}
\]</div>
<p>In this case <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span> is the ordinary covariance matrix of <span class="arithmatex">\(\mathbf{x}\)</span> (the sample one if the average is taken over the sample, the true one if the average is taken over the distribution).</p>
<p>More generally, we call <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span> a pseudo-covariance matrix of <span class="arithmatex">\(\mathbf{x}\)</span>, if <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> are determined from any set of equations</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{ave}\{w(|y|) y\} &amp; =0 \\
\operatorname{ave}\left\{u(|y|) \frac{y y^{T}}{|y|^{2}}-v(|y|) I\right\} &amp; =0
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(\mathbf{y}=V(\mathbf{x}-\mathbf{t})\)</span>, and where <span class="arithmatex">\(u, v\)</span> and <span class="arithmatex">\(w\)</span> are arbitrary functions.</p>
<p>Note that (4.11) determines location <span class="arithmatex">\(t\)</span> as a weighted mean</p>
<div class="arithmatex">\[
\mathbf{t}=\frac{\operatorname{ave}\{w(|\mathbf{y}|) \mathbf{x}\}}{\operatorname{ave}\{w(|\mathbf{y}|)\}}
\]</div>
<p>with weights <span class="arithmatex">\(w(|\mathbf{y}|)\)</span> depending on the sample.
Similarly, the pseudo-covariance can be written as a kind of scaled weighted covariance</p>
<div class="arithmatex">\[
\left(V^{T} V\right)^{-1}=\frac{\operatorname{ave}\left\{s(|\mathbf{y}|)(\mathbf{x}-\mathbf{t})(\mathbf{x}-\mathbf{t})^{T}\right\}}{\operatorname{ave}\{s(|\mathbf{y}|)\}} \cdot \frac{\operatorname{ave}\{s(|\mathbf{y}|)\}}{\operatorname{ave}\{v(|\mathbf{y}|)\}}
\]</div>
<p>with weights</p>
<div class="arithmatex">\[
s(|\mathbf{y}|)=\frac{u(|\mathbf{y}|)}{|\mathbf{y}|^{2}}
\]</div>
<p>depending on the sample. The choice <span class="arithmatex">\(v=s\)</span> then looks particularly attractive, since it make the scale factor in (4.14) disappear.</p>
<h1 id="85-estimates-determined-by-implicit-equations">8.5 ESTIMATES DETERMINED BY IMPLICIT EQUATIONS</h1>
<p>This section shows that (4.12), with arbitrary functions <span class="arithmatex">\(u\)</span> and <span class="arithmatex">\(v\)</span>, is in some sense the most general form of an implicit equation determining <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span>.</p>
<p>In order to simplify the discussion, we assume that location is known and fixed to be <span class="arithmatex">\(\mathbf{t}=0\)</span>. Then we can write (4.12) in the form</p>
<div class="arithmatex">\[
\operatorname{ave}\{\Psi(V \mathbf{x})\}=0
\]</div>
<p>with</p>
<div class="arithmatex">\[
\Psi(\mathbf{x})=s(|\mathbf{x}|) \mathbf{x} \mathbf{x}^{T}-v(|\mathbf{x}|) I
\]</div>
<p>where <span class="arithmatex">\(s\)</span> is as in (4.15). Is this the most general form of <span class="arithmatex">\(\Psi\)</span> ?
Let us take a sufficiently smooth, but otherwise arbitrary function <span class="arithmatex">\(\Psi\)</span> from <span class="arithmatex">\(\mathbb{R}^{p}\)</span> into the space of symmetric <span class="arithmatex">\(p \times p\)</span> matrices. This gives us the proper number of equations for the <span class="arithmatex">\(p(p+1) / 2\)</span> unique components of <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span>.</p>
<p>We determine a matrix <span class="arithmatex">\(V\)</span> such that</p>
<div class="arithmatex">\[
\operatorname{ave}\{\Psi(V \mathbf{x})\}=0
\]</div>
<p>where the average is taken with respect to a fixed (true or sample) distribution of <span class="arithmatex">\(\mathbf{x}\)</span>.</p>
<p>Let us assume that <span class="arithmatex">\(\Psi\)</span> and the distribution of <span class="arithmatex">\(\mathbf{x}\)</span> are such that (5.3) has at least one solution <span class="arithmatex">\(V\)</span>, that if <span class="arithmatex">\(S\)</span> is an arbitrary orthogonal matrix, <span class="arithmatex">\(S V\)</span> is also a solution, and that all solutions lead to the same pseudo-covariance matrix</p>
<div class="arithmatex">\[
C_{\mathbf{x}}=\left(V^{T} V\right)^{-1}
\]</div>
<p>This uniqueness assumption implies at once that <span class="arithmatex">\(C_{\mathbf{x}}\)</span> transforms in the same way under linear transformations <span class="arithmatex">\(B\)</span> as the classical covariance matrix</p>
<div class="arithmatex">\[
C_{B \mathbf{x}}=B C_{\mathbf{x}} B^{T}
\]</div>
<p>Now let <span class="arithmatex">\(S\)</span> be an arbitrary orthogonal transformation and define</p>
<div class="arithmatex">\[
\Psi_{S}(\mathbf{x})=S^{T} \Psi(S \mathbf{x}) S
\]</div>
<p>The transformed function <span class="arithmatex">\(\Psi_{S}\)</span> determines a new pseudo-covariance <span class="arithmatex">\(\left(W^{T} W\right)^{-1}\)</span> through the solution <span class="arithmatex">\(W\)</span> of</p>
<div class="arithmatex">\[
\operatorname{ave}\left\{\Psi_{S}(W \mathbf{x})\right\}=\operatorname{ave}\left\{S^{T} \Psi(S W \mathbf{x}) S\right\}=0
\]</div>
<p>Evidently, this is solved by <span class="arithmatex">\(W=S^{T} V\)</span>, where <span class="arithmatex">\(V\)</span> is any solution of (5.3), and thus</p>
<div class="arithmatex">\[
W^{T} W=V^{T} S S^{T} V=V^{T} V
\]</div>
<p>It follows that <span class="arithmatex">\(\Psi\)</span> and <span class="arithmatex">\(\Psi_{S}\)</span> determine the same pseudo-covariances.
We now form</p>
<div class="arithmatex">\[
\bar{\Psi}(\mathbf{x})=\underset{S}{\operatorname{ave}}\left\{\Psi_{S}(\mathbf{x})\right\}
\]</div>
<p>by averaging over <span class="arithmatex">\(S\)</span> (using the invariant measure on the orthogonal group). Evidently, every solution of (5.3) still solves <span class="arithmatex">\(\operatorname{ave}\{\bar{\Psi}(V \mathbf{x})\}=0\)</span>, but, of course, the uniqueness postulated in (5.4) may have been destroyed by the averaging process.</p>
<p>Clearly, <span class="arithmatex">\(\bar{\Psi}\)</span> is invariant under orthogonal transformations in the sense that</p>
<div class="arithmatex">\[
\bar{\Psi}_{S}(\mathbf{x})=S^{T} \bar{\Psi}(S \mathbf{x}) S=\bar{\Psi}(\mathbf{x})
\]</div>
<p>or equivalently,</p>
<div class="arithmatex">\[
\bar{\Psi}(S \mathbf{x}) S=S \bar{\Psi}(\mathbf{x})
\]</div>
<p>Now let <span class="arithmatex">\(\mathbf{x} \neq 0\)</span> be an arbitrary fixed vector, then (5.9) shows that the matrix <span class="arithmatex">\(\widetilde{\Psi}(\mathbf{x})\)</span> commutes with all orthogonal matrices <span class="arithmatex">\(S\)</span> that keep <span class="arithmatex">\(\mathbf{x}\)</span> fixed. This implies that the restriction of <span class="arithmatex">\(\widetilde{\Psi}(\mathbf{x})\)</span> to the subspace of <span class="arithmatex">\(\mathbb{R}^{p}\)</span> orthogonal to <span class="arithmatex">\(\mathbf{x}\)</span> must be a multiple of the identity. Moreover, for every <span class="arithmatex">\(S\)</span> that keeps <span class="arithmatex">\(\mathbf{x}\)</span> fixed, we have</p>
<div class="arithmatex">\[
S \widetilde{\Psi}(\mathbf{x}) \mathbf{x}=\widetilde{\Psi}(\mathbf{x}) \mathbf{x}
\]</div>
<p>hence <span class="arithmatex">\(S\)</span> also keeps <span class="arithmatex">\(\widetilde{\Psi}(\mathbf{x}) \mathbf{x}\)</span> fixed, which therefore must be a multiple of <span class="arithmatex">\(\mathbf{x}\)</span>. It follows that <span class="arithmatex">\(\widetilde{\Psi}(\mathbf{x})\)</span> can be written in the form</p>
<div class="arithmatex">\[
\widetilde{\Psi}(\mathbf{x})=s(\mathbf{x}) \mathbf{x} \mathbf{x}^{T}-v(\mathbf{x}) I
\]</div>
<p>with some scalar-valued functions <span class="arithmatex">\(s\)</span> and <span class="arithmatex">\(v\)</span>. Because of (5.8) <span class="arithmatex">\(s\)</span> and <span class="arithmatex">\(v\)</span> depend on <span class="arithmatex">\(\mathbf{x}\)</span> only through <span class="arithmatex">\(|\mathbf{x}|\)</span>, and we conclude that <span class="arithmatex">\(\widetilde{\Psi}\)</span> is of the form (5.2).</p>
<p>Global uniqueness, as postulated in (5.4), is a rather severe requirement. The arguments carry through in all essential respects with the much weaker local uniqueness requirement that there be a neighborhood of <span class="arithmatex">\(C_{\mathbf{x}}\)</span> that contains no other solutions besides <span class="arithmatex">\(C_{\mathbf{x}}\)</span>. For the symmetrized version (5.2) a set of sufficient conditions for local uniqueness is outlined at the end of Section 8.7.</p>
<h1 id="86-existence-and-uniqueness-of-solutions">8.6 EXISTENCE AND UNIQUENESS OF SOLUTIONS</h1>
<p>The following existence and uniqueness results are due to Maronna (1976) and Schönholzer (1979). The results are not entirely satisfactory with regard to joint estimation of <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span>.</p>
<h2 id="the-scatter-estimate-v">The Scatter Estimate <span class="arithmatex">\(V\)</span></h2>
<p>Assume first that location is fixed <span class="arithmatex">\(\mathbf{t}=0\)</span>. Existence is proved constructively by defining an iterative process converging to a solution <span class="arithmatex">\(V\)</span> of (4.12). The iteration step from <span class="arithmatex">\(V_{m}\)</span> to <span class="arithmatex">\(V_{m+1}=h\left(V_{m}\right)\)</span> is defined as follows:</p>
<div class="arithmatex">\[
\left(V_{m+1}^{T} V_{m+1}\right)^{-1}=\frac{\operatorname{ave}\left\{s\left(\left|V_{m} \mathbf{x}\right|\right) \mathbf{x} \mathbf{x}^{T}\right\}}{\operatorname{ave}\left\{v\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}
\]</div>
<p>If the process converges, then the limit <span class="arithmatex">\(V\)</span> satisfies (4.14) and hence solves (4.12). If (6.1) is used for actual computation, then it is convenient to assume that the matrices <span class="arithmatex">\(V_{m}\)</span> are lower triangular with a positive diagonal; for the proofs below, it is more convenient to take them as positive definite</p>
<p>symmetric. Clearly, the choice does not matter-both sides of (6.1) are unchanged if <span class="arithmatex">\(V_{m}\)</span> and <span class="arithmatex">\(V_{m+1}\)</span> are multiplied by arbitrary orthogonal matrices from the left.</p>
<h1 id="assumptions_4">ASSUMPTIONS</h1>
<p>(E-1) The function <span class="arithmatex">\(s(r)\)</span> is monotone decreasing and <span class="arithmatex">\(s(r)&gt;0\)</span> for <span class="arithmatex">\(r&gt;0\)</span>.
(E-2) The function <span class="arithmatex">\(v(r)\)</span> is monotone increasing, and <span class="arithmatex">\(v(r)&gt;0\)</span> for <span class="arithmatex">\(r \geqslant 0\)</span>.
(E-3) <span class="arithmatex">\(u(r)=r^{2} s(r)\)</span>, and <span class="arithmatex">\(v(r)\)</span> are bounded and continuous.
(E-4) <span class="arithmatex">\(u(0) / v(0)&lt;p\)</span>.
For any hyperplane <span class="arithmatex">\(H\)</span> in the sample space (i.e., <span class="arithmatex">\(\operatorname{dim}(H)=p-1\)</span> ), let</p>
<div class="arithmatex">\[
P(H)=\operatorname{ave}\left\{1_{[\mathbf{x} \in H]}\right\}
\]</div>
<p>be the probability of <span class="arithmatex">\(H\)</span>, or the fraction of observations lying in <span class="arithmatex">\(H\)</span>, respectively (depending on whether we work with the true or with the sample distribution).
(E-5) (i) For all hyperplanes <span class="arithmatex">\(H, P(H)&lt;1-p v(\infty) / u(\infty)\)</span>.
(ii) For all hyperplanes <span class="arithmatex">\(H, P(H) \leqslant 1 / p\)</span>.</p>
<p>LEMMA 6.1 If (E-1), (E-2), (E-3), and (E-5)(i) are satisfied, and if there is an <span class="arithmatex">\(r_{0}&gt;0\)</span> such that</p>
<div class="arithmatex">\[
\frac{\operatorname{ave}\left\{u\left(r_{0}|\mathbf{x}|\right)\right\}}{\operatorname{ave}\left\{v\left(r_{0}|\mathbf{x}|\right)\right\}}&lt;1
\]</div>
<p>then <span class="arithmatex">\(h\)</span> has a fixed point <span class="arithmatex">\(V\)</span>.</p>
<p>Proof Let <span class="arithmatex">\(\mathbf{z}\)</span> be an arbitrary vector. Then with <span class="arithmatex">\(V_{0}=r_{0} I\)</span> we obtain, from (6.1) and (6.2),</p>
<div class="arithmatex">\[
\begin{aligned}
\mathbf{z}^{T}\left(V_{1}^{T} V_{1}\right)^{-1} \mathbf{z} &amp; =\frac{\operatorname{ave}\left\{s\left(r_{0}|\mathbf{x}|\right)\left(\mathbf{z}^{T} \mathbf{x}\right)^{2}\right\}}{\operatorname{ave}\left\{v\left(r_{0}|\mathbf{x}|\right)\right\}} \\
&amp; \leqslant \frac{|\mathbf{z}|^{2}}{r_{0}^{2}} \frac{\operatorname{ave}\left\{u\left(r_{0}|\mathbf{x}|\right)\right\}}{\operatorname{ave}\left\{v\left(r_{0}|\mathbf{x}|\right)\right\}} \leqslant \frac{|\mathbf{z}|^{2}}{r_{0}^{2}}
\end{aligned}
\]</div>
<p>Hence</p>
<div class="arithmatex">\[
\left(V_{1}^{T} V_{1}\right)^{-1}&lt;\frac{1}{r_{0}^{2}} I
\]</div>
<p>(where <span class="arithmatex">\(A&lt;B\)</span> means that <span class="arithmatex">\(B-A\)</span> is positive semidefinite). Thus</p>
<div class="arithmatex">\[
r_{0} I&lt;V_{1}=h\left(r_{0} I\right)
\]</div>
<p>It follows from (E-1) and (E-2) that <span class="arithmatex">\(V_{m+1}=h\left(V_{m}\right)\)</span> defines an increasing sequence</p>
<div class="arithmatex">\[
r_{0} I=V_{0}&lt;V_{1}&lt;V_{2}&lt;\cdots
\]</div>
<p>So it suffices to show that the sequence <span class="arithmatex">\(V_{m}\)</span> is bounded from above in order to prove convergence <span class="arithmatex">\(V_{m} \rightarrow V\)</span>. Continuity (E-3) then implies that <span class="arithmatex">\(V\)</span> satisfies (4.14).</p>
<p>Let</p>
<div class="arithmatex">\[
H=\left\{\mathbf{z}|\lim | V_{m} \mathbf{z} \mid&lt;\infty\right\}
\]</div>
<p><span class="arithmatex">\(H\)</span> is a vector space. Assume first that <span class="arithmatex">\(H\)</span> is a proper subspace of <span class="arithmatex">\(\mathbb{R}^{p}\)</span>.
Since <span class="arithmatex">\(V_{m}&lt;V_{m+1}\)</span>, we have</p>
<div class="arithmatex">\[
I&gt;V_{m} V_{m+1}^{-2} V_{m}=\frac{\operatorname{ave}\left\{s\left(\left|V_{m} \mathbf{x}\right|\right)\left(V_{m} \mathbf{x}\right)\left(V_{m} \mathbf{x}\right)^{T}\right\}}{\operatorname{ave}\left\{v\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}
\]</div>
<p>Taking the trace on both sides gives</p>
<div class="arithmatex">\[
p \geqslant \frac{\operatorname{ave}\left\{u\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}{\operatorname{ave}\left\{v\left(\left|V_{m} \mathbf{x}\right|\right)\right\}} \geqslant \frac{\operatorname{ave}\left\{u\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}{v(\infty)}
\]</div>
<p>Since <span class="arithmatex">\(\left|V_{m} \mathbf{x}\right| \uparrow \infty\)</span> for all <span class="arithmatex">\(\mathbf{x} \notin H\)</span>, we obtain from the monotone convergence theorem</p>
<div class="arithmatex">\[
p \geqslant[1-P(H)] \frac{u(\infty)}{v(\infty)}
\]</div>
<p>which contradicts (E-5)(i).
Hence <span class="arithmatex">\(H=\mathbb{R}^{p}\)</span>, but this is only possible if <span class="arithmatex">\(V_{m}\)</span> stays bounded (note that the trace must converge).</p>
<p>Remark Assumption (6.2) serves to guarantee the existence of a starting matrix <span class="arithmatex">\(V_{0}\)</span>, such that <span class="arithmatex">\(h\left(V_{0}\right)&gt;V_{0}\)</span>. Assume, for instance, that <span class="arithmatex">\(s(0)&gt;0\)</span>, then (6.2) is satisfied for all sufficiently small <span class="arithmatex">\(r_{0}\)</span>. In the limit <span class="arithmatex">\(r_{0} \rightarrow 0\)</span>, we obtain that <span class="arithmatex">\(\left(V_{1}^{T} V_{1}\right)^{-1}\)</span> then is a multiple of the ordinary covariance matrix.</p>
<p>PROPOSITION 6.2 Assume (E-1) to (E-5). Then <span class="arithmatex">\(h\)</span> has a fixed point <span class="arithmatex">\(V\)</span>.
Proof If <span class="arithmatex">\(s\)</span> is bounded, the existence of a fixed point follows from Lemma 6.1. If <span class="arithmatex">\(s\)</span> is unbounded, we choose an <span class="arithmatex">\(r_{1}&gt;0\)</span> and replace <span class="arithmatex">\(s\)</span> by <span class="arithmatex">\(\tilde{s}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
\tilde{s}(r) &amp; =s\left(r_{1}\right), &amp; &amp; \text { for } r&lt;r_{1} \\
&amp; =s(r), &amp; &amp; \text { for } r \geqslant r_{1}
\end{aligned}
\]</div>
<p>Let <span class="arithmatex">\(\tilde{h}\)</span> be the function defined by (6.1) with <span class="arithmatex">\(\tilde{s}\)</span> in place of <span class="arithmatex">\(s\)</span>. Lemma 6.1 then implies that <span class="arithmatex">\(\tilde{h}\)</span> has a fixed point <span class="arithmatex">\(\tilde{V}\)</span>. Since <span class="arithmatex">\(s \geqslant \tilde{s}\)</span>, it follows that, for all <span class="arithmatex">\(V\)</span>, <span class="arithmatex">\(h(V)&lt;\tilde{h}(V)\)</span>. Hence <span class="arithmatex">\(h(\tilde{V})&lt;\tilde{h}(\tilde{V})=\tilde{V}\)</span>, and it follows from (E-1) and (E-2) that <span class="arithmatex">\(V_{m+1}=h\left(V_{m}\right)\)</span> defines a decreasing sequence</p>
<div class="arithmatex">\[
\tilde{V}=V_{0}&gt;V_{1}&gt;V_{2}&gt;\cdots
\]</div>
<p>So it suffices to show that <span class="arithmatex">\(V=\lim V_{m}\)</span> is nonsingular in order to prove that it is a fixed point of <span class="arithmatex">\(h\)</span>.</p>
<p>As in the proof of Lemma 6.1, we find</p>
<div class="arithmatex">\[
I&lt;\frac{\operatorname{ave}\left\{s\left(\left|V_{m} \mathbf{x}\right|\right)\left(V_{m} \mathbf{x}\right)\left(V_{m} \mathbf{x}\right)^{T}\right\}}{\operatorname{ave}\left\{v\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}
\]</div>
<p>and, taking the trace,</p>
<div class="arithmatex">\[
p \leqslant \frac{\operatorname{ave}\left\{u\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}{\operatorname{ave}\left\{v\left(\left|V_{m} \mathbf{x}\right|\right)\right\}} \leqslant \frac{\operatorname{ave}\left\{u\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}{v(0)}
\]</div>
<p>We conclude that not all eigenvalues of <span class="arithmatex">\(V_{m}\)</span> can converge to 0 , because otherwise</p>
<div class="arithmatex">\[
p \leqslant \frac{\lim \operatorname{ave}\left\{u\left(\left|V_{m} \mathbf{x}\right|\right)\right\}}{v(0)}=\frac{u(0)}{v(0)}
\]</div>
<p>by the monotone convergence theorem, which would contradict (E-4).
Now assume that <span class="arithmatex">\(\mathbf{q}_{m}\)</span> and <span class="arithmatex">\(\mathbf{z}_{m}\)</span> are unit-length eigenvectors of <span class="arithmatex">\(V_{m}\)</span> belonging to the largest and smallest eigenvalues <span class="arithmatex">\(\lambda_{m}\)</span> and <span class="arithmatex">\(\mu_{m}\)</span> of <span class="arithmatex">\(V_{m}\)</span>, respectively. If</p>
<p>we multiply (6.5) from the left and right with <span class="arithmatex">\(\mathbf{z}_{m}^{T}\)</span> and <span class="arithmatex">\(\mathbf{z}_{m}\)</span>, respectively, we obtain</p>
<div class="arithmatex">\[
1 \leqslant \frac{\operatorname{ave}\left\{s\left(\left|V_{m} \mathbf{x}\right|\right) \mu_{m}^{2}\left(\mathbf{z}_{m}^{T} \mathbf{x}\right)^{2}\right\}}{\operatorname{ave} v\left(\left|V_{m} \mathbf{x}\right|\right)}
\]</div>
<p>Since the largest eigenvalues converge monotonely <span class="arithmatex">\(\lambda_{m} \downarrow \lambda&gt;0\)</span>, we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
G_{m, r} &amp; =\left\{\mathbf{x} \| V_{m} \mathbf{x} \mid \leqslant r\right\} \subset\left\{\mathbf{x} \mid \lambda_{m}\left|\mathbf{h}_{m}^{T} \mathbf{x}\right| \leqslant r\right\} \\
&amp; \subset\left\{\mathbf{x}\left\|\mathbf{h}_{m}^{T} \mathbf{x}\right| \leqslant \frac{r}{\lambda}\right\}=H_{m, r}
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(G_{m, r}\)</span> and <span class="arithmatex">\(H_{m, r}\)</span> defined by (6.8).
Assumption (E-5)(ii) implies that, for each <span class="arithmatex">\(\varepsilon&gt;0\)</span>, there is a <span class="arithmatex">\(r_{1}&gt;0\)</span> such that</p>
<div class="arithmatex">\[
P\left\{H_{m, r}\right\} \leqslant \frac{1}{p}+\varepsilon, \quad \text { for } r \leqslant r_{1}
\]</div>
<p>Furthermore (E-4) implies that we can choose <span class="arithmatex">\(b&gt;0\)</span> and <span class="arithmatex">\(\varepsilon&gt;0\)</span> such that</p>
<div class="arithmatex">\[
\frac{u(0)+b}{v(0)}\left(\frac{1}{p}+\varepsilon\right)&lt;1
\]</div>
<p>If <span class="arithmatex">\(r_{0}&lt;r_{1}\)</span> is chosen such that <span class="arithmatex">\(u(r) \leqslant u(0)+b\)</span> for <span class="arithmatex">\(r \leqslant r_{0}\)</span>, then (6.7) to (6.9) imply</p>
<div class="arithmatex">\[
\begin{aligned}
1 &amp; \leqslant \frac{1}{v(0)}\left[\operatorname{ave}\left\{1_{G_{m, r}}(\mathbf{x}) u\left(\left|V_{m} \mathbf{x}\right|\right)+1_{G_{m, r}^{T}}(\mathbf{x}) s\left(\left|V_{m} \mathbf{x}\right|\right) \mu_{m}^{2}\left(\mathbf{z}_{m}^{T} \mathbf{x}\right)^{2}\right\}\right] \\
&amp; \leqslant \frac{1}{v(0)}[u(0)+b]\left(\frac{1}{p}+\varepsilon\right)+\operatorname{ave}\left\{\frac{1}{v(0)} \min \left[s\left(r_{0}\right) \mu_{m}^{2}|\mathbf{x}|^{2}, u(\infty)\right]\right\}
\end{aligned}
\]</div>
<p>If <span class="arithmatex">\(\lim \mu_{m}=0\)</span>, then the last summand tends to 0 by the dominated convergence theorem; this leads to a contradiction in view of (6.10). Hence <span class="arithmatex">\(\lim \mu_{m}&gt;0\)</span> and the proposition is proved.</p>
<p>Uniqueness of the fixed point can be proved under the following assumptions.</p>
<h1 id="assumptions_5">ASSUMPTIONS</h1>
<p>(U-1) <span class="arithmatex">\(s(r)\)</span> is decreasing.
(U-2) <span class="arithmatex">\(u(r)=r^{2} s(r)\)</span> is continuous and increasing, and <span class="arithmatex">\(u(r)&gt;0\)</span> for <span class="arithmatex">\(r&gt;0\)</span>.</p>
<p>(U-3) <span class="arithmatex">\(v(r)\)</span> is continuous and decreasing, and <span class="arithmatex">\(v(r) \geqslant 0, v(r)&gt;0\)</span> for <span class="arithmatex">\(0 \leqslant r&lt;r_{0}\)</span>.
(U-4) For all hyperplanes <span class="arithmatex">\(H \subset \mathbb{R}^{p}, P(H)&lt;\frac{1}{2}\)</span>.
Remark In view of (E-3), we can prove simultaneous existence and uniqueness only if <span class="arithmatex">\(v=\)</span> constant (as in the ML case).</p>
<p>PROPOSITION 6.3 Assume ( <span class="arithmatex">\(\mathrm{U}-1\)</span> ) to ( <span class="arithmatex">\(\mathrm{U}-4\)</span> ). If <span class="arithmatex">\(V\)</span> and <span class="arithmatex">\(V_{1}\)</span> are two fixed points of <span class="arithmatex">\(h\)</span>, then there is a real number <span class="arithmatex">\(\lambda\)</span> such that <span class="arithmatex">\(V_{1}=\lambda V\)</span>, and</p>
<div class="arithmatex">\[
u(|V \mathbf{x}|)=u(\lambda|V \mathbf{x}|), \quad v(|V \mathbf{x}|)=v(\lambda|V \mathbf{x}|)
\]</div>
<p>for almost all <span class="arithmatex">\(\mathbf{x}\)</span>. In particular, <span class="arithmatex">\(\lambda=1\)</span> if either <span class="arithmatex">\(u\)</span> or <span class="arithmatex">\(v\)</span> is strictly monotone.
We first prove a special case:
LEMMA 6.4 Proposition 6.3 holds if either <span class="arithmatex">\(V&gt;V_{1}\)</span> or <span class="arithmatex">\(V&lt;V_{1}\)</span>.
Proof of the Lemma We may assume without loss of generality that <span class="arithmatex">\(V_{1}=I\)</span>. Assume <span class="arithmatex">\(V&gt;I\)</span> (the case <span class="arithmatex">\(V&lt;I\)</span> is proved in the same way). Then</p>
<div class="arithmatex">\[
\underbrace{\operatorname{ave}\left\{u(|V \mathbf{x}|) \frac{(V \mathbf{x})(V \mathbf{x})^{T}}{|V \mathbf{x}|^{2}}\right\}}_{\operatorname{ave}\{v(|V \mathbf{x}|)\}}=\frac{\operatorname{ave}\left\{u(|\mathbf{x}|) \frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}\right\}}{\operatorname{ave}\{v(|\mathbf{x}|)\}}=I
\]</div>
<p>If we take the trace, we obtain</p>
<div class="arithmatex">\[
\frac{\operatorname{ave}\{u(|V \mathbf{x}|)\}}{\operatorname{ave}\{v(|V \mathbf{x}|)\}}=\frac{\operatorname{ave}\{u(|\mathbf{x}|)\}}{\operatorname{ave}\{v(|\mathbf{x}|)\}}=p
\]</div>
<p>In view of (U-2) and (U-3), we must have</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{ave}\{u(|V \mathbf{x}|)\}=\operatorname{ave}\{u(|\mathbf{x}|)\} \\
&amp; \operatorname{ave}\{v(|V \mathbf{x}|)\}=\operatorname{ave}\{v(|\mathbf{x}|)\}
\end{aligned}
\]</div>
<p>Because of <span class="arithmatex">\(V&gt;I\)</span> this implies</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; u(|V \mathbf{x}|)=u(|\mathbf{x}|) \\
&amp; v(|V \mathbf{x}|)=v(|\mathbf{x}|)
\end{aligned}
\]</div>
<p>for almost all <span class="arithmatex">\(\mathbf{x}\)</span>.</p>
<p>If either <span class="arithmatex">\(u\)</span> or <span class="arithmatex">\(v\)</span> is strictly monotone, this already forces <span class="arithmatex">\(V=I\)</span>.
In view of (6.14) it follows from (6.11) that</p>
<div class="arithmatex">\[
\operatorname{ave}\left\{u(|\mathbf{x}|)\left[\frac{(V \mathbf{x})(V \mathbf{x})^{T}}{|V \mathbf{x}|^{2}}-\frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}\right]\right\}=0
\]</div>
<p>Now let <span class="arithmatex">\(\mathbf{z}\)</span> be an eigenvector belonging to the largest eigenvalue <span class="arithmatex">\(\lambda\)</span> of <span class="arithmatex">\(V\)</span>. Then (6.15) implies</p>
<div class="arithmatex">\[
\operatorname{ave}\left\{u(|\mathbf{x}|)\left(\frac{\lambda^{2}}{|V \mathbf{x}|^{2}}-\frac{1}{|\mathbf{x}|^{2}}\right)\left(\mathbf{z}^{T} \mathbf{x}\right)^{2}\right\}=0
\]</div>
<p>The expression inside the curly parentheses of (6.16) is <span class="arithmatex">\(&gt;0\)</span> unless either: (1) <span class="arithmatex">\(\mathbf{x}\)</span> is an eigenvector of <span class="arithmatex">\(V\)</span>, to the eigenvalue <span class="arithmatex">\(\lambda\)</span>; or (2) <span class="arithmatex">\(\mathbf{x}\)</span> is orthogonal to <span class="arithmatex">\(\mathbf{z}\)</span>.</p>
<p>If <span class="arithmatex">\(V=\lambda I\)</span>, the lemma is proved. If <span class="arithmatex">\(V \neq \lambda I\)</span>, then (U-4) implies that the union of the <span class="arithmatex">\(\mathbf{x}\)</span>-sets (1) and (2) has a total mass less than 1 , which leads to a contradiction.</p>
<p>Proof of the Proposition Assume the fixed points are <span class="arithmatex">\(V\)</span> and <span class="arithmatex">\(I\)</span>, and neither <span class="arithmatex">\(V&lt;I\)</span> nor <span class="arithmatex">\(V&gt;I\)</span>. Choose <span class="arithmatex">\(0&lt;r&lt;1\)</span> so that <span class="arithmatex">\(r I&lt;V\)</span>. Because of (U-2) and (U-3) we have</p>
<div class="arithmatex">\[
\begin{aligned}
h(r I)^{-2} &amp; =\frac{\operatorname{ave}\left\{u(r|\mathbf{x}|) \frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}\right\}}{\operatorname{ave}\{v(r|\mathbf{x}|)\}} \cdot \frac{1}{r^{2}} \\
&amp; &lt;\frac{\operatorname{ave}\left\{u(|\mathbf{x}|) \frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}\right\}}{\operatorname{ave}\{v(|\mathbf{x}|)\}} \cdot \frac{1}{r^{2}}=\frac{1}{r^{2}} I
\end{aligned}
\]</div>
<p>or</p>
<div class="arithmatex">\[
r I&lt;h(r I)
\]</div>
<p>It follows from <span class="arithmatex">\(r I&lt;I\)</span> and <span class="arithmatex">\(r I&lt;V\)</span> that <span class="arithmatex">\(V_{1}=\lim h^{m}(r I)\)</span> is a fixed point with <span class="arithmatex">\(V_{1}&lt;I\)</span> and <span class="arithmatex">\(V_{1}&lt;V\)</span>. Then both pairs <span class="arithmatex">\(V_{1}, I\)</span> and <span class="arithmatex">\(V_{1}, V\)</span> satisfy the assumptions of Lemma 6.4, so <span class="arithmatex">\(V_{1}, I\)</span>, and <span class="arithmatex">\(V\)</span> are scalar multiples of each others. This contradicts the assumption that neither <span class="arithmatex">\(V&lt;I\)</span> nor <span class="arithmatex">\(V&gt;I\)</span>, and the proposition is proved.</p>
<h1 id="the-location-estimate-mathbft">The Location Estimate <span class="arithmatex">\(\mathbf{t}\)</span></h1>
<p>If <span class="arithmatex">\(V\)</span> is kept fixed, say <span class="arithmatex">\(V=I\)</span>, existence and uniqueness of the location estimate <span class="arithmatex">\(\mathbf{t}\)</span> are easy to establish, provided <span class="arithmatex">\(\psi(r)=w(r) r\)</span> is monotone increasing for positive <span class="arithmatex">\(r\)</span>. Then there is a convex function</p>
<div class="arithmatex">\[
\rho(\mathbf{x})=\rho(|\mathbf{x}|)=\int_{0}^{|\mathbf{x}|} \psi(r) d r
\]</div>
<p>such that <span class="arithmatex">\(\mathbf{t}\)</span> can equivalently be defined as minimizing</p>
<div class="arithmatex">\[
Q(\mathbf{t})=\operatorname{ave}\{\rho(|\mathbf{x}-\mathbf{t}|)\}
\]</div>
<p>We only treat the sample case, so we do not have to worry about the possible nonexistence of the distribution average. Thus the set of solutions <span class="arithmatex">\(\mathbf{t}\)</span> is nonempty and convex, and if there is at least one observation <span class="arithmatex">\(\mathbf{x}\)</span> such that <span class="arithmatex">\(\rho^{\prime \prime}(|\mathbf{x}-\mathbf{t}|)&gt;0\)</span>, the solution is in fact unique.</p>
<p>Proof We shall show that <span class="arithmatex">\(Q\)</span> is strictly convex. Assume that <span class="arithmatex">\(\mathbf{z} \in \mathbb{R}^{p}\)</span> depends linearly on a parameter <span class="arithmatex">\(s\)</span>, and take derivatives with respect to <span class="arithmatex">\(s\)</span> (denoted by a superscript dot). Then</p>
<div class="arithmatex">\[
\rho(|\mathbf{z}|)^{`}=\frac{\rho^{\prime}(|\mathbf{z}|)}{|\mathbf{z}|} \mathbf{z}^{T} \dot{\mathbf{z}}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\rho(|\mathbf{z}|)^{`}=\frac{\rho^{\prime \prime}(|\mathbf{z}|)}{|\mathbf{z}|^{2}}\left(\mathbf{z}^{T} \dot{\mathbf{z}}\right)^{2}+\frac{\rho^{\prime}(|\mathbf{z}|)}{|\mathbf{z}|^{3}}\left[\left(\mathbf{z}^{T} \mathbf{z}\right)\left(\dot{\mathbf{z}}^{T} \dot{\mathbf{z}}\right)-\left(\mathbf{z}^{T} \dot{\mathbf{z}}\right)^{2}\right] \geqslant 0
\]</div>
<p>since <span class="arithmatex">\(\rho^{\prime} \geqslant 0,\left(\mathbf{z}^{T} \dot{\mathbf{z}}\right)^{2} \leqslant\left(\mathbf{z}^{T} \mathbf{z}\right)\left(\dot{\mathbf{z}}^{T} \dot{\mathbf{z}}\right)\)</span>, and <span class="arithmatex">\(\rho^{\prime \prime}(r)=\psi^{\prime}(r) \geqslant 0\)</span>. Hence <span class="arithmatex">\(\rho(|\mathbf{z}|)\)</span> is convex as a function of <span class="arithmatex">\(\mathbf{z}\)</span>. Moreover, if <span class="arithmatex">\(\rho^{\prime \prime}(|\mathbf{z}|)&gt;0\)</span> and <span class="arithmatex">\(\rho^{\prime}(|\mathbf{z}|)&gt;0\)</span>, then <span class="arithmatex">\(\rho\)</span> is strictly convex at the point <span class="arithmatex">\(\mathbf{z}\)</span> : if the variation <span class="arithmatex">\(\dot{\mathbf{z}}\)</span> is orthogonal to <span class="arithmatex">\(\mathbf{z}\)</span>, then</p>
<div class="arithmatex">\[
\rho(|\mathbf{z}|)^{`}=\frac{\rho^{\prime}(|\mathbf{z}|)}{|\mathbf{z}|}\left(\dot{\mathbf{z}}^{T} \dot{\mathbf{z}}\right)&gt;0
\]</div>
<p>and otherwise</p>
<div class="arithmatex">\[
\rho(|\mathbf{z}|)^{`} \geqslant \frac{\rho^{\prime \prime}(|\mathbf{z}|)}{|\mathbf{z}|^{2}}\left(\mathbf{z}^{T} \dot{\mathbf{z}}\right)^{2}&gt;0
\]</div>
<p>In fact <span class="arithmatex">\(\rho^{\prime \prime}(r)&gt;0, \rho^{\prime}(r)=0\)</span> can only happen at <span class="arithmatex">\(r=0\)</span>, and <span class="arithmatex">\(\mathbf{z}=0\)</span> is a point of strict convexity, as we verify easily by a separate argument. Hence <span class="arithmatex">\(Q\)</span> is strictly convex, which implies uniqueness.</p>
<h1 id="joint-estimation-of-mathbft-and-v">Joint Estimation of <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span></h1>
<p>Joint existence of solutions <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> is then also easy to establish, if we do not mind somewhat restrictive regularity conditions. Assume that, for each fixed <span class="arithmatex">\(\mathbf{t}\)</span>, there is a unique solution <span class="arithmatex">\(V_{t}\)</span> of (4.12), which depends continuously on <span class="arithmatex">\(\mathbf{t}\)</span>, and that for each fixed <span class="arithmatex">\(V\)</span> there is a unique solution <span class="arithmatex">\(\mathbf{t}(V)\)</span> of (4.11), which depends continuously on <span class="arithmatex">\(V\)</span>. It follows from (4.13) that <span class="arithmatex">\(\mathbf{t}(V)\)</span> is always contained in the convex hull <span class="arithmatex">\(H\)</span> of the observations. Thus the continuous function <span class="arithmatex">\(\mathbf{t} \rightarrow \mathbf{t}\left(V_{t}\right)\)</span> maps <span class="arithmatex">\(H\)</span> into itself and hence has a fixed point by Brouwer's theorem. The corresponding pair ( <span class="arithmatex">\(\mathbf{t}, V_{t}\)</span> ) obviously solves (4.11) and (4.12). Uniqueness of the fixed point so far has been proved only under the assumption that the distribution of the <span class="arithmatex">\(\mathbf{x}\)</span> has a center of symmetry; in the sample distribution case this is of course very unrealistic [cf. Maronna (1976)].</p>
<h3 id="87-influence-functions-and-qualitative-robustness">8.7 INFLUENCE FUNCTIONS AND QUALITATIVE ROBUSTNESS</h3>
<p>Our estimates <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span>, defined through (4.11) and (4.12) with the help of averages over the sample distribution, clearly can be regarded as functionals <span class="arithmatex">\(\mathbf{t}(F)\)</span> and <span class="arithmatex">\(V(F)\)</span> of some underlying distribution <span class="arithmatex">\(F\)</span>. The estimates are vector and matrix valued; the influence functions, measuring changes of <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> under infinitesimal changes of <span class="arithmatex">\(F\)</span>, clearly are vector and matrix valued too.</p>
<p>Without loss of generality we can choose the coordinate system such that <span class="arithmatex">\(\mathbf{t}(F)=0\)</span> and <span class="arithmatex">\(V(F)=I\)</span>. We assume that <span class="arithmatex">\(F\)</span> is (at least) centrosymmetric. In order to find the influence functions, we have to insert <span class="arithmatex">\(F_{s}=(1-s) F+s \delta_{\mathbf{x}}\)</span> into the defining equations and take the derivative with respect to <span class="arithmatex">\(s\)</span> at <span class="arithmatex">\(s=0\)</span>; we denote it by a superscript dot.</p>
<p>We first take (4.11). The procedure just outlined gives</p>
<div class="arithmatex">\[
\begin{gathered}
-\operatorname{ave}_{F}\left\{\frac{w^{\prime}(|\mathbf{y}|)}{|\mathbf{y}|}\left(\mathbf{y}^{T} \dot{\mathbf{t}}\right) \mathbf{y}+w(|\mathbf{y}|) \dot{\mathbf{t}}\right\} \\
+\operatorname{ave}_{F}\left\{\frac{w^{\prime}(|\mathbf{y}|)}{|\mathbf{y}|}\left(\mathbf{y}^{T} \dot{V} \mathbf{y}\right) \mathbf{y}+w(|\mathbf{y}|) \dot{V} \mathbf{y}\right\}+w(|\mathbf{x}|) \mathbf{x}=0
\end{gathered}
\]</div>
<p>The second term (involving <span class="arithmatex">\(\dot{V}\)</span> ) averages to 0 if <span class="arithmatex">\(F\)</span> is centrosymmetric. There is a considerable further simplification if <span class="arithmatex">\(F\)</span> is spherically symmetric [or, at least, if the conditional covariance matrix of <span class="arithmatex">\(\mathbf{y} /|\mathbf{y}|\)</span>, given <span class="arithmatex">\(|\mathbf{y}|\)</span>, equals <span class="arithmatex">\((1 / p) I\)</span> for all <span class="arithmatex">\(|y|]\)</span>, since then <span class="arithmatex">\(E\left\{\left(\mathbf{y}^{T} \mathbf{i}\right) \mathbf{y}| | \mathbf{y} \mid\right\}=(1 / p)|\mathbf{y}|^{2} \mathbf{i}\)</span>. So (7.1) becomes</p>
<div class="arithmatex">\[
-\operatorname{ave}_{F}\left\{\frac{1}{p} w^{\prime}(|\mathbf{y}|)|\mathbf{y}|+w(|\mathbf{y}|)\right\} \mathbf{i}+w(|\mathbf{x}|) \mathbf{x}=0
\]</div>
<p>Hence the influence function for location is</p>
<div class="arithmatex">\[
I C(\mathbf{x} ; F, \mathbf{t})=\frac{w(|\mathbf{x}|) \mathbf{x}}{\operatorname{ave}_{F}\left\{w(|\mathbf{y}|)+\frac{1}{p} w^{\prime}(|\mathbf{y}|)|\mathbf{y}| \right\}}
\]</div>
<p>Similarly, differentiation of (4.12) gives,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{ave}_{F}\left\{\frac{u^{\prime}(|\mathbf{y}|)|\mathbf{y}|-2 u(|\mathbf{y}|)}{|\mathbf{y}|^{4}}\left(\mathbf{y}^{T} \dot{V} \mathbf{y}\right)\left(\mathbf{y} \mathbf{y}^{T}\right)+\frac{u(|\mathbf{y}|)}{|\mathbf{y}|^{2}}\left(\dot{V} \mathbf{y} \mathbf{y}^{T}+\mathbf{y} \mathbf{y}^{T} \dot{V}^{T}\right)\right. \\
&amp; \left.-\frac{v^{\prime}(|\mathbf{y}|)}{|\mathbf{y}|}\left(\mathbf{y}^{T} \dot{V} \mathbf{y}\right) I\right\} \\
&amp; -\operatorname{ave}_{F}\left\{\frac{u^{\prime}(|\mathbf{y}|)|\mathbf{y}|-2 u(|\mathbf{y}|)}{|\mathbf{y}|^{4}}\left(\mathbf{y}^{T} \mathbf{i}\right)\left(\mathbf{y} \mathbf{y}^{T}\right)+\frac{u(|\mathbf{y}|)}{|\mathbf{y}|^{2}}\left(\mathbf{i} \mathbf{y}^{T}+\mathbf{y} \mathbf{i}^{T}\right)\right. \\
&amp; \left.-\frac{v^{\prime}(|\mathbf{y}|)}{|\mathbf{y}|}\left(\mathbf{y}^{T} \mathbf{i}\right) I\right\}+\left\{u(|\mathbf{x}|) \frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}-v(|\mathbf{x}|) I\right\}=0
\end{aligned}
\]</div>
<p>The second term (involving <span class="arithmatex">\(\dot{\mathbf{i}}\)</span> ) averages to 0 if <span class="arithmatex">\(F\)</span> is centrosymmetric.
It is convenient to split (7.3) into two equations. We first take the trace of (7.3) and divide it by <span class="arithmatex">\(p\)</span>. This gives</p>
<div class="arithmatex">\[
\operatorname{ave}_{F}\left\{\left[\frac{1}{p} u^{\prime}(|\mathbf{y}|)-v^{\prime}(|\mathbf{y}|)\right] \frac{\mathbf{y}^{T} \dot{V} \mathbf{y}}{|\mathbf{y}|}\right\}+\left\{\frac{1}{p} u(|\mathbf{x}|)-v(|\mathbf{x}|)\right\}=0
\]</div>
<p>If we now subtract (7.4) from the diagonal of (7.3), we obtain</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{ave}_{F}\left\{\frac{u^{\prime}(|\mathbf{y}|)}{|\mathbf{y}|}\left[\frac{\mathbf{y y}^{T}}{|\mathbf{y}|^{2}}-\frac{1}{p} I\right]\left(\mathbf{y}^{T} \dot{V} \mathbf{y}\right)\right. \\
&amp; \left.\quad+\frac{u(|\mathbf{y}|)}{|\mathbf{y}|^{4}}\left[|\mathbf{y}|^{2}\left(\dot{V} \mathbf{y} \mathbf{y}^{T}+\mathbf{y} \mathbf{y}^{T} \dot{V}^{T}\right)-2\left(\mathbf{y}^{T} \dot{V} \mathbf{y}\right) \mathbf{y} \mathbf{y}^{T}\right]\right\} \\
&amp; +u(|\mathbf{x}|)\left(\frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}-\frac{1}{p} I\right)=0
\end{aligned}
\]</div>
<p>If <span class="arithmatex">\(F\)</span> is spherically symmetric, the averaging process can be carried one step further. From (7.4) we then obtain [with <span class="arithmatex">\(\dot{W}=\frac{1}{2}\left(\dot{V}+\dot{V}^{T}\right)\)</span> ]</p>
<div class="arithmatex">\[
\operatorname{ave}_{F}\left\{\left[\frac{1}{p} u^{\prime}(|\mathbf{y}|)-v^{\prime}(|\mathbf{y}|)\right]|\mathbf{y}|\right\} \frac{1}{p} \operatorname{tr}(\dot{W})+\left[\frac{1}{p} u(|\mathbf{x}|)-v(|\mathbf{x}|)\right]=0
\]</div>
<p>and from <span class="arithmatex">\((7.5)\)</span></p>
<div class="arithmatex">\[
\begin{gathered}
\frac{2}{p+2} \operatorname{ave}_{F}\left\{u(|\mathbf{y}|)+\frac{1}{p} u^{\prime}(|\mathbf{y}|)|\mathbf{y}|\right\}\left[\dot{W}-\frac{1}{p} \operatorname{tr}(\dot{W})\right] \\
+u(|\mathbf{x}|)\left(\frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}-\frac{1}{p} I\right)=0
\end{gathered}
\]</div>
<p>[Cf. Section 8.10, after (10.15), for this averaging process.] Clearly, only the symmetric part <span class="arithmatex">\(\dot{W}\)</span> of the influence function <span class="arithmatex">\(\dot{V}=I C(\mathbf{x} ; F, V)\)</span> matters and is determinable. We obtain it in explicit form from (7.6) and (7.7) as</p>
<div class="arithmatex">\[
\begin{gathered}
\frac{1}{p} \operatorname{tr}(\dot{W})=-\frac{\frac{1}{p} u(|\mathbf{x}|)-v(|\mathbf{x}|)}{\operatorname{ave}_{F}\left\{\left[\frac{1}{p} u^{\prime}(|\mathbf{y}|)-v^{\prime}(|\mathbf{y}|)\right]|\mathbf{y}|\right\}} \\
\dot{W}-\frac{1}{p} \operatorname{tr}(\dot{W}) I=-\frac{p+2}{2} \frac{u(|\mathbf{x}|)\left(\frac{\mathbf{x} \mathbf{x}^{T}}{|\mathbf{x}|^{2}}-\frac{1}{p}\right)}{\operatorname{ave}_{F}\left\{u(|\mathbf{y}|)+\frac{1}{p} u^{\prime}(|\mathbf{y}|)|\mathbf{y}|\right\}}
\end{gathered}
\]</div>
<p>The influence function of the pseudo-covariance is, clearly,</p>
<div class="arithmatex">\[
I C\left(\mathbf{x} ; F,\left(V^{T} V\right)^{-1}\right)=-2 \dot{W}
\]</div>
<p>(assuming throughout that the coordinate system is matched so that <span class="arithmatex">\(V=I\)</span> ).
It can be seen from (7.2) and (7.8) that the influence functions are bounded if and only if the functions <span class="arithmatex">\(w(r) r, u(r)\)</span>, and <span class="arithmatex">\(v(r)\)</span> are bounded [and the denominators of (7.2) and (7.8) are not equal to 0 ].</p>
<p>Qualitative robustness, that is, essentially the continuity of the functionals <span class="arithmatex">\(\mathbf{t}(F)\)</span> and <span class="arithmatex">\(V(F)\)</span>, is difficult to discuss for the simple reason that we do not yet know for which <span class="arithmatex">\(F\)</span> these functionals are uniquely defined. However, they are so for elliptical distributions of the type (4.1), and by the implicit function theorem we can then conclude that the solutions are still well defined in some neighborhood. This involves a careful discussion of the influence functions, not only at the model distribution (which is spherically symmetric by assumption), but also in some neighborhood of it. That is, we have to argue directly with (7.1) and (7.3), instead of the simpler (7.2) and (7.8).</p>
<p>Thus we are in good shape if the denominators in (7.2) and (7.8) are strictly positive and if <span class="arithmatex">\(w, w r, w^{\prime} r, w^{\prime} r^{2}, u, u / r, u^{\prime}, u^{\prime} r, v, v^{\prime}\)</span>, and <span class="arithmatex">\(v^{\prime} r\)</span> are bounded and continuous, because then the influence function is stable at the model distribution, and we can use (2.5.8) to conclude that a small change in <span class="arithmatex">\(F\)</span> induces only a small change in the values of the functionals.</p>
<h1 id="88-consistency-and-asymptotic-normality">8.8 CONSISTENCY AND ASYMPTOTIC NORMALITY</h1>
<p>The estimates <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> are consistent and asymptotically normal under relatively mild assumptions, and proofs can be found along the lines of Sections 6.2 and 6.3. While the consistency proof is complicated [the main problem being caused by the fact that we have a simultaneous location-scale problem, where assumptions (A-5) or (B-4) fail], asymptotic normality can be proved straightforwardly by verifying assumptions ( <span class="arithmatex">\(\mathrm{N}-1\)</span> ) to ( <span class="arithmatex">\(\mathrm{N}-4\)</span> ). Of course, this imposes some regularity conditions on <span class="arithmatex">\(w, u\)</span>, and <span class="arithmatex">\(v\)</span> and the underlying distribution. Note in particular that there will be trouble if <span class="arithmatex">\(u(r) / r\)</span> is unbounded and there is a pointmass at the origin. For details see Maronna (1976) and Schönholzer (1979).</p>
<p>The asymptotic variances and covariances of the estimates coincide with those of their influence functions, and thus can easily be derived from (7.2) and (7.8). For symmetry reasons location and covariance estimates are asymptotically uncorrelated, and hence asymptotically independent.</p>
<p>The location components <span class="arithmatex">\(\hat{t}_{j}\)</span> are asymptotically independent, with asymptotic variance</p>
<div class="arithmatex">\[
n \operatorname{var}\left(\hat{t}_{j}\right)=\frac{p^{-1} E[w(|\mathbf{x}|)|\mathbf{x}|]^{2}}{\left\{E\left[w(|\mathbf{x}|)+p^{-1} w^{\prime}(|\mathbf{x}|)|\mathbf{x}|]\right\}^{2}}
\]</div>
<p>The asymptotic variances and covariances of the components of <span class="arithmatex">\(\hat{V}\)</span> can be described as follows (we assume that <span class="arithmatex">\(V\)</span> is lower triangular):</p>
<div class="arithmatex">\[
\begin{gathered}
n \operatorname{var}\left(\frac{1}{p} \operatorname{tr} \hat{V}\right)=\frac{E\left\{\left[p^{-1} u(|\mathbf{x}|)-v(|\mathbf{x}|)\right]^{2}\right\}}{\left\{E\left[p^{-1} u^{\prime}(|\mathbf{x}|)|\mathbf{x}|-v^{\prime}(|\mathbf{x}|)|\mathbf{x}|]\right\}^{2}} \\
n \operatorname{var}\left(\hat{V}_{j j}-p^{-1} \operatorname{tr} \hat{V}\right)=\frac{(p-1)(p-2)}{2 p^{2}} \lambda \\
n E\left[\left(\hat{V}_{j j}-p^{-1} \operatorname{tr} \hat{V}\right)\left(\hat{V}_{k k}-p^{-1} \operatorname{tr} \hat{V}\right)\right]=\frac{p+2}{2 p^{2}} \lambda, \quad \text { for } j \neq k \\
n \operatorname{var}\left(\hat{V}_{j k}\right)=\frac{p+2}{p} \lambda, \quad \text { for } j&gt;k
\end{gathered}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\lambda=\frac{E\left[u(|\mathbf{x}|)^{2}\right]}{\left\{E\left[(1 / p) u^{\prime}(|\mathbf{x}|)|\mathbf{x}|+u(|\mathbf{x}|)\right]\right\}^{2}}
\]</div>
<p>All other asymptotic covariances between <span class="arithmatex">\(p^{-1} \operatorname{tr}(\hat{V}), \hat{V}_{j j}-p^{-1} \operatorname{tr} \hat{V}\)</span>, and <span class="arithmatex">\(\hat{V}_{j k}\)</span> are 0 .</p>
<h1 id="89-breakdown-point">8.9 BREAKDOWN POINT</h1>
<p>Let us agree that breakdown occurs when at least one solution of (4.12) misbehaves. Then the breakdown point (with regard to centrosymmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination) is always</p>
<div class="arithmatex">\[
\varepsilon^{*}&lt;\frac{1}{p}
\]</div>
<p>This bound is conjectured to be sharp [if we allow asymmetric contamination, then the sharp bound is conjectured to be <span class="arithmatex">\(1 /(p+1)]\)</span>.</p>
<p>The demonstration follows an idea of W. Stahel (personal communication). Let <span class="arithmatex">\(G\)</span> and <span class="arithmatex">\(H\)</span> be centrosymmetric, but not spherically symmetric, distributions in <span class="arithmatex">\(\mathbb{R}^{p}\)</span>, centered at 0 , and put</p>
<div class="arithmatex">\[
F=(1-\varepsilon) G+\varepsilon H
\]</div>
<p>Assume that <span class="arithmatex">\(|\mathbf{x}|\)</span> has the same distribution under <span class="arithmatex">\(G\)</span> and <span class="arithmatex">\(H\)</span>, hence also under <span class="arithmatex">\(F\)</span>.</p>
<p>We assume that the conditional covariance matrix of <span class="arithmatex">\(\mathbf{x} /|\mathbf{x}|\)</span>, given <span class="arithmatex">\(|\mathbf{x}|\)</span>, is diagonal under both <span class="arithmatex">\(G\)</span> and <span class="arithmatex">\(H\)</span>, namely, with diagonal vector</p>
<div class="arithmatex">\[
\left(0, \frac{1}{p-1}, \ldots, \frac{1}{p-1}\right)
\]</div>
<p>under <span class="arithmatex">\(G\)</span>, with diagonal vector <span class="arithmatex">\((1,0,0, \ldots, 0)\)</span> under <span class="arithmatex">\(H\)</span>. For instance, we may take <span class="arithmatex">\(G\)</span> to be the distribution of <span class="arithmatex">\(\left(0, z_{2}, \ldots, z_{p}\right)\)</span>, where <span class="arithmatex">\(z_{2}, \ldots, z_{p}\)</span> are independent standard normal, and <span class="arithmatex">\(H\)</span> to be the distribution of <span class="arithmatex">\(\left(z_{1}, 0, \ldots, 0\right)\)</span>, where <span class="arithmatex">\(z_{1}\)</span> has a <span class="arithmatex">\(\chi\)</span>-distribution with <span class="arithmatex">\(p-1\)</span> degrees of freedom. For <span class="arithmatex">\(\varepsilon=1 / p\)</span>, the conditional covariance matrix of <span class="arithmatex">\(\mathbf{x} /|\mathbf{x}|\)</span>, given <span class="arithmatex">\(|\mathbf{x}|\)</span>, under <span class="arithmatex">\(F\)</span> is diagonal with diagonal vector <span class="arithmatex">\((1 / p, \ldots, 1 / p)\)</span>.</p>
<p>Now let <span class="arithmatex">\(\bar{F}\)</span> be the spherically symmetric distribution obtained by averaging <span class="arithmatex">\(F\)</span> over the orthogonal group. For both <span class="arithmatex">\(F\)</span> and <span class="arithmatex">\(\bar{F}\)</span>, the radial distribution (i.e. the distribution of <span class="arithmatex">\(|\mathbf{x}|\)</span> ) then is a <span class="arithmatex">\(\chi\)</span>-distribution with <span class="arithmatex">\(p-1\)</span> degrees of freedom. Clearly, any covariance estimate defined by a relation of the form (4.12), viewed as a functional, then will be the same for <span class="arithmatex">\(F\)</span> and for <span class="arithmatex">\(\bar{F}\)</span>, namely a certain multiple of the identity matrix.</p>
<p>We interpret this result that a symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination on the <span class="arithmatex">\(x_{1}\)</span>-axis, with <span class="arithmatex">\(\varepsilon=1 / p\)</span>, can cause breakdown.</p>
<p>A breakdown point <span class="arithmatex">\(\varepsilon^{*} \leqslant 1 / p\)</span> is disappointingly low in high dimension. A possible way out may be the following. Estimate first some location <span class="arithmatex">\(\mathbf{t}\)</span> and pseudo-covariance <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span>. Then make a search for outliers in the space of <span class="arithmatex">\(y\)</span>-vectors <span class="arithmatex">\([\mathbf{y}=V(\mathbf{x}-\mathbf{t})]\)</span>. If the type of breakdown encountered in this section is at all typical (and there is little doubt that it is), the "good" points <span class="arithmatex">\(\mathbf{y}\)</span> will form a flat disk, while the "bad" points that have caused breakdown will stick out roughly in the axial direction of the disk. A univariate robust scale estimate (e.g., the median absolute deviation) should therefore show a well defined minimum in this direction.</p>
<h1 id="810-least-informative-distributions">8.10 LEAST INFORMATIVE DISTRIBUTIONS</h1>
<h2 id="location">Location</h2>
<p>Consider the family of distributions</p>
<div class="arithmatex">\[
f(\mathbf{x} ; \mathbf{t}, I)=f(|\mathbf{x}-\mathbf{t}|), \quad \mathbf{x}, \mathbf{t} \in \mathbb{R}^{p}
\]</div>
<p>where <span class="arithmatex">\(f\)</span> belongs to some convex set <span class="arithmatex">\(\mathscr{F}\)</span> of densities. Assume that <span class="arithmatex">\(\mathbf{t}\)</span> depends differentiably on some real parameter <span class="arithmatex">\(\theta\)</span>. Then Fisher information with respect to <span class="arithmatex">\(\theta\)</span> is</p>
<div class="arithmatex">\[
\begin{aligned}
I(f) &amp; =E_{\mathbf{t}}\left\{\left[\frac{\partial}{\partial \theta} \log f(|\mathbf{x}-\mathbf{t}|)\right]^{2}\right\} \\
&amp; =E\left\{\left[\frac{f^{\prime}(|\mathbf{x}|)}{f(|\mathbf{x}|)} \frac{\mathbf{i}^{T} \mathbf{x}}{|\mathbf{x}|}\right]^{2}\right\} \\
&amp; =E\left\{\left[\frac{f^{\prime}(|\mathbf{x}|)}{f(|\mathbf{x}|)}\right]^{2}\right\} \cdot \frac{|\mathbf{t}|^{2}}{p}
\end{aligned}
\]</div>
<p>We now intend to find a <span class="arithmatex">\(f_{0} \in \mathscr{F}\)</span> minimizing <span class="arithmatex">\(I(f)\)</span>. Clearly, this is done by minimizing</p>
<div class="arithmatex">\[
E\left\{\left[\frac{f^{\prime}(|\mathbf{x}|)}{f(|\mathbf{x}|)}\right]^{2}\right\}=C_{p} \int_{0}^{\infty}\left[\frac{f^{\prime}(r)}{f(r)}\right]^{2} f r^{p-1} d r
\]</div>
<p>where <span class="arithmatex">\(C_{p}\)</span> denotes the surface area of the unit sphere in <span class="arithmatex">\(\mathbb{R}^{p}\)</span>. This immediately leads to the variational condition</p>
<div class="arithmatex">\[
\int_{0}^{\infty}\left[-\left(\frac{f^{\prime}}{f}\right)^{2} r^{p-1}-2\left(\frac{f^{\prime}}{f} r^{p-1}\right)^{\prime}\right] \delta f d r \geqslant 0
\]</div>
<p>subject to the side condition</p>
<div class="arithmatex">\[
\int r^{p-1} \delta f d r=0
\]</div>
<p>or, with some Lagrange multiplier <span class="arithmatex">\(\gamma\)</span>,</p>
<div class="arithmatex">\[
4 \gamma r^{p-1}-\left(\frac{f^{\prime}}{f}\right)^{2} r^{p-1}-2\left(\frac{f^{\prime}}{f} r^{p-1}\right)^{\prime}=0
\]</div>
<p>on the set of <span class="arithmatex">\(r\)</span>-values where <span class="arithmatex">\(f\)</span> can be varied freely; the equality sign should be replaced by <span class="arithmatex">\(\geqslant 0\)</span> on the set where <span class="arithmatex">\(\delta f \geqslant 0\)</span>.</p>
<p>With <span class="arithmatex">\(u=\sqrt{f}\)</span> we obtain the linear differential equation</p>
<div class="arithmatex">\[
u^{\prime \prime}+\frac{p-1}{r} u^{\prime}-\gamma u=0
\]</div>
<p>valid on the set where <span class="arithmatex">\(f\)</span> can be freely varied.
Example 10.1 Let <span class="arithmatex">\(\mathscr{F}\)</span> be the set of spherically symmetric <span class="arithmatex">\(\varepsilon\)</span>-contaminated normal distributions in <span class="arithmatex">\(\mathbb{R}^{3}\)</span>. Then (10.7) has the particular solution</p>
<div class="arithmatex">\[
u(r)=\frac{e^{-\sqrt{\gamma} r}}{r}
\]</div>
<p>Since <span class="arithmatex">\(f_{0}\)</span> and <span class="arithmatex">\(f_{0}^{\prime} / f_{0}\)</span> should be continuous, we obtain after some calculations</p>
<div class="arithmatex">\[
\begin{aligned}
f_{0}(r) &amp; =a e^{-r^{2} / 2}, &amp; &amp; \text { for } r \leqslant r_{0} \\
&amp; =b \frac{e^{-c r}}{r^{2}}, &amp; &amp; \text { for } r \geqslant r_{0}
\end{aligned}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; a=(1-\varepsilon)(2 \pi)^{-3 / 2} \\
&amp; b=(1-\varepsilon)(2 \pi)^{-3 / 2} r_{0}^{2} e^{\left(r_{0}^{2} / 2\right)-2} \\
&amp; c=2 \sqrt{\gamma}=r_{0}-\frac{2}{r_{0}}
\end{aligned}
\]</div>
<p>and thus</p>
<div class="arithmatex">\[
\begin{aligned}
-\frac{f_{0}^{\prime}(r)}{f_{0}(r)} &amp; =r, &amp; &amp; \text { for } r \leqslant r_{0} \\
&amp; =c+\frac{2}{r}, &amp; &amp; \text { for } r \geqslant r_{0}
\end{aligned}
\]</div>
<p>The constants <span class="arithmatex">\(r_{0}\)</span> and <span class="arithmatex">\(\varepsilon\)</span> are related by the requirement that <span class="arithmatex">\(f_{0}\)</span> be a probability density:</p>
<div class="arithmatex">\[
C_{p} \int f_{0}(r) r^{p-1} d r=1
\]</div>
<p>In particular, we must have <span class="arithmatex">\(c&gt;0\)</span>, and hence <span class="arithmatex">\(r_{0}&gt;\sqrt{2}\)</span>; the limiting case <span class="arithmatex">\(c=0\)</span> corresponds to <span class="arithmatex">\(r_{0}=\sqrt{2}\)</span> and <span class="arithmatex">\(\varepsilon=1\)</span>.</p>
<p>It can be seen from the nonmonotonicity of (10.11) that <span class="arithmatex">\(-\log f_{0}(|x|)\)</span> is not a convex function of <span class="arithmatex">\(\mathbf{x}\)</span>. Hence, in general, the maximum likelihood estimate of location need not be unique, and there are some troubles with consistency proofs when <span class="arithmatex">\(\varepsilon\)</span> is large.</p>
<p>For our present purposes location is but a nuisance parameter, and it is hardly worthwhile to bother with complicated estimates of location. We therefore prefer to work with a simple monotone approximation to (10.11), of the form</p>
<div class="arithmatex">\[
\begin{aligned}
w(r) r &amp; =r, &amp; &amp; \text { for } r&lt;r_{0} \\
&amp; =r_{0}, &amp; &amp; \text { for } r \geqslant r_{0}
\end{aligned}
\]</div>
<p>compare (4.6).</p>
<h1 id="covariance">Covariance</h1>
<p>We now consider the family of distributions</p>
<div class="arithmatex">\[
f(\mathbf{x} ; 0, V)=|\operatorname{det} V| f(|V \mathbf{x}|), \quad \mathbf{x} \in \mathbb{R}^{p}
\]</div>
<p>We assume that <span class="arithmatex">\(V\)</span> depends differentiably on some real parameter <span class="arithmatex">\(\theta\)</span>. Then Fisher information with respect to <span class="arithmatex">\(\theta\)</span> at <span class="arithmatex">\(V=V_{0}=I\)</span> is</p>
<div class="arithmatex">\[
\begin{aligned}
I(f) &amp; =E\left\{\left[\frac{\partial}{\partial \theta} \log f(\mathbf{x} ; 0, V)\right]^{2}\right\} \\
&amp; =E\left\{\left[\operatorname{tr} \dot{V}+\frac{f^{\prime}(|\mathbf{x}|)}{f(|\mathbf{x}|)} \frac{\mathbf{x}^{T} \dot{V} \mathbf{x}}{|\mathbf{x}|}\right]^{2}\right\}
\end{aligned}
\]</div>
<p>Because of symmetry it suffices to treat this special case.
In order to simplify (10.15) we first take the conditional expectation, given <span class="arithmatex">\(|\mathbf{x}|\)</span>, that is we average over the uniform distribution on the spheres <span class="arithmatex">\(|\mathbf{x}|=\)</span> const. The conditional averages of <span class="arithmatex">\(\mathbf{x}^{T} \dot{V} \mathbf{x}\)</span> and <span class="arithmatex">\(\left(\mathbf{x}^{T} \dot{V} \mathbf{x}\right)^{2}\)</span> are <span class="arithmatex">\(\beta|\mathbf{x}|^{2}\)</span> and <span class="arithmatex">\(\gamma|\mathbf{x}|^{4}\)</span>, respectively, with <span class="arithmatex">\(\beta=(1 / p) \operatorname{tr} \dot{V}\)</span> and</p>
<div class="arithmatex">\[
\gamma=\frac{1}{p(p+2)}\left[(\operatorname{tr} \dot{V})^{2}+2 \sum_{j, k} \dot{V}_{j k}^{2}\right]
\]</div>
<p>if we assume (without loss of generality) that <span class="arithmatex">\(\dot{V}\)</span> is symmetric. The easiest</p>
<p>way to prove this is to show that, for reasons of symmetry and homogeneity, the averages must be proportional to <span class="arithmatex">\(|\mathbf{x}|^{2}\)</span> and <span class="arithmatex">\(|\mathbf{x}|^{4}\)</span>, respectively, and then to determine the proportionality constants in the special case where <span class="arithmatex">\(\mathbf{x}\)</span> is <span class="arithmatex">\(p\)</span>-variate standard normal and <span class="arithmatex">\(V\)</span> is diagonal. Thus if we put</p>
<div class="arithmatex">\[
u(r)=-\frac{f^{\prime}(r)}{f(r)} r
\]</div>
<p>we have</p>
<div class="arithmatex">\[
\begin{aligned}
I(f) &amp; =E\left\{\left[u(|\mathbf{x}|) \frac{\mathbf{x}^{T} \dot{V} \mathbf{x}}{|\mathbf{x}|^{2}}-p \beta\right]^{2}\right\} \\
&amp; =E\left[\gamma u(|\mathbf{x}|)^{2}-2 p \beta u(|\mathbf{x}|)+p^{2} \beta^{2}\right] \\
&amp; =\gamma E\left[u(|\mathbf{x}|)^{2}\right]-p^{2} \beta^{2}
\end{aligned}
\]</div>
<p>Hence in order to minimize <span class="arithmatex">\(I(f)\)</span> over <span class="arithmatex">\(\mathscr{F}\)</span>, it suffices to minimize</p>
<div class="arithmatex">\[
\begin{aligned}
J(f) &amp; =E\left[u(|\mathbf{x}|)^{2}\right]=C_{p} \int_{0}^{\infty} u(r)^{2} r^{p-1} f d r \\
&amp; =C_{p} \int_{0}^{\infty} \frac{f^{\prime}(r)^{2}}{f(r)} r^{p+1} d r
\end{aligned}
\]</div>
<p>A standard variational argument gives</p>
<div class="arithmatex">\[
\delta J(f)=C_{p} \int_{0}^{\infty}\left(-u^{2}+2 p u+2 r u^{\prime}\right) r^{p-1} \delta f d r
\]</div>
<p>Together with the side condition <span class="arithmatex">\(C_{p} \int r^{p-1} \delta f d r=0\)</span>, we obtain that the <span class="arithmatex">\(u\)</span> corresponding to the minimizing <span class="arithmatex">\(f_{0}\)</span> should satisfy</p>
<div class="arithmatex">\[
2 r u^{\prime}+2 p u-u^{2}=c
\]</div>
<p>for those <span class="arithmatex">\(r\)</span> where <span class="arithmatex">\(f_{0}\)</span> can be varied freely, or</p>
<div class="arithmatex">\[
-2 r u^{\prime}+(u-p)^{2}=p^{2}-c=\kappa^{2}
\]</div>
<p>for some constant <span class="arithmatex">\(\kappa\)</span>.</p>
<p>For our purposes we only need the constant solutions corresponding to <span class="arithmatex">\(u^{\prime}=0\)</span>. Thus</p>
<div class="arithmatex">\[
u=p \pm \kappa
\]</div>
<p>In particular, let</p>
<div class="arithmatex">\[
\mathscr{G}=\left\{f \mid f(r)=(1-\varepsilon) \varphi(r)+\varepsilon h(r), h \in \mathscr{M}_{\tau}\right\}
\]</div>
<p>be the set of all spherically symmetric contaminated normal densities, with</p>
<div class="arithmatex">\[
\varphi(r)=(2 \pi)^{-p / 2} e^{-r^{2} / 2}
\]</div>
<p>and <span class="arithmatex">\(\mathscr{M}_{\tau}\)</span> being the set of all spherically symmetric probability densities in <span class="arithmatex">\(\mathbb{R}^{p}\)</span>.</p>
<p>Then we verify easily that <span class="arithmatex">\(J(f)\)</span>, and thus <span class="arithmatex">\(I(f)\)</span>, are minimized by choosing</p>
<div class="arithmatex">\[
\begin{aligned}
u(r)=-\frac{f_{0}^{\prime}(r)}{f_{0}(r)} r &amp; =a^{2}, &amp; &amp; \text { for } 0 \leqslant r \leqslant a \\
&amp; =r^{2}, &amp; &amp; \text { for } a \leqslant r \leqslant b \\
&amp; =b^{2}, &amp; &amp; \text { for } b \leqslant r
\end{aligned}
\]</div>
<p>and thus</p>
<div class="arithmatex">\[
\begin{array}{rlr}
f_{0}(r) &amp; =(1-\varepsilon) \varphi(a)\left(\frac{a}{r}\right)^{a^{2}}, &amp; &amp; \text { for } 0 \leqslant r \leqslant a \\
&amp; =(1-\varepsilon) \varphi(r), &amp; &amp; \text { for } a \leqslant r \leqslant b \\
&amp; =(1-\varepsilon) \varphi(b)\left(\frac{b}{r}\right)^{b^{2}} &amp; &amp; \text { for } b \leqslant r .
\end{array}
\]</div>
<p>The constants <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> satisfy</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; a=\sqrt{(p-\kappa)^{+}} \\
&amp; b=\sqrt{p+\kappa}
\end{aligned}
\]</div>
<p>and <span class="arithmatex">\(\kappa&gt;0\)</span> has to be determined such that the total mass of <span class="arithmatex">\(f_{0}\)</span> is 1 , or</p>
<p>equivalently, that</p>
<div class="arithmatex">\[
\begin{aligned}
C_{p} &amp; {\left[\varphi(a) \int_{0}^{a}\left(\frac{a}{r}\right)^{a^{2}} r^{p-1} d r+\int_{a}^{b} \varphi(r) r^{p-1} d r+\varphi(b) \int_{b}^{\infty}\left(\frac{b}{r}\right)^{b^{2}} r^{p-1} d r\right] } \\
&amp; =\frac{1}{1-\varepsilon}
\end{aligned}
\]</div>
<p>The maximum likelihood estimate of pseudo-covariance for <span class="arithmatex">\(f_{0}\)</span> can be described by (4.12), with <span class="arithmatex">\(u\)</span> as in (10.25), and <span class="arithmatex">\(v \equiv 1\)</span>. It has the following minimax property. Let <span class="arithmatex">\(\mathscr{T}_{\varepsilon} \subset \mathscr{T}\)</span> be that subset for which it is a consistent estimate of the identity matrix. Then it minimizes the supremum over <span class="arithmatex">\(\mathscr{T}_{\varepsilon}\)</span> of the asymptotic variances (8.2) to (8.6).</p>
<p>If <span class="arithmatex">\(\kappa&lt;p\)</span> and hence <span class="arithmatex">\(a&gt;0\)</span>, the least informative density <span class="arithmatex">\(f_{0}\)</span> is highly unrealistic in view of its singularity at the origin. In other words the corresponding minimax estimate appears to protect against an unlikely contingency. Moreover, if the underlying distribution happens to put a pointmass at the origin (or, if in the course of a computation, a sample point happens to coincide with the current trial value <span class="arithmatex">\(\mathbf{t}\)</span> ), (4.12) or (4.14) is not well defined.</p>
<p>If we separate the scale aspects (information contained in <span class="arithmatex">\(|\mathbf{y}|\)</span> ) from the directional aspects (information contained in <span class="arithmatex">\(\mathbf{y} /|\mathbf{y}|\)</span> ), then it appears that values <span class="arithmatex">\(a&gt;0\)</span> are beneficial with regard to the former aspects only-they help to prevent breakdown by "implosion," caused by inliers. The limiting scale estimate for <span class="arithmatex">\(\kappa \rightarrow 0\)</span> is, essentially, the median absolute deviation <span class="arithmatex">\(\operatorname{med}\{|\mathbf{x}|\}\)</span>, and we have already commented upon its good robustness properties in the one-dimensional case. Also the indeterminacy of (4.12) at <span class="arithmatex">\(\mathbf{y}=0\)</span> only affects the directional, but not the scale aspects.</p>
<p>With regard to the directional aspects, a value <span class="arithmatex">\(u(0) \neq 0\)</span> is distinctly awkward. To give some intuitive insight into what is going on, we note that, for the maximum likelihood estimates <span class="arithmatex">\(\hat{\mathbf{t}}\)</span> and <span class="arithmatex">\(\hat{\mathbf{V}}\)</span>, the linearly transformed quantities <span class="arithmatex">\(\mathbf{y}=\hat{V}(\mathbf{x}-\hat{\mathbf{t}})\)</span> possess the following property (cf. Exhibit 8.10.1): if the sample points with <span class="arithmatex">\(|\mathbf{y}|&lt;a\)</span> and those with <span class="arithmatex">\(|\mathbf{y}|&gt;b\)</span> are moved radially outward and inward to the spheres <span class="arithmatex">\(|\mathbf{y}|=a\)</span> and <span class="arithmatex">\(|\mathbf{y}|=b\)</span>, respectively, while the points with <span class="arithmatex">\(a \leqslant|\mathbf{y}| \leqslant b\)</span> are left where they are, then the sample thus modified has the (ordinary) covariance matrix <span class="arithmatex">\(I\)</span>.</p>
<p>A value <span class="arithmatex">\(\mathbf{y}\)</span> very close to the origin clearly does not give any directional information; in fact <span class="arithmatex">\(\mathbf{y} /|\mathbf{y}|\)</span> changes randomly under small random changes of <span class="arithmatex">\(\mathbf{t}\)</span>. We should therefore refrain from moving points to the sphere with radius <span class="arithmatex">\(a\)</span> when they are close to the origin, but we should like to retain the scale information contained in them. This can be achieved by letting <span class="arithmatex">\(u\)</span> decrease to 0 as <span class="arithmatex">\(r \rightarrow 0\)</span>, and simultaneously changing <span class="arithmatex">\(v\)</span> so that the trace of</p>
<p><img alt="img-16.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhlbit 8.10.1 From Huber (1977a), with permission of the publisher.
(4.12) is unchanged. For instance, we might change (10.25) by putting</p>
<div class="arithmatex">\[
u(r)=\frac{a^{2}}{r_{0}} r, \quad \text { for } r \leqslant r_{0}&lt;a
\]</div>
<p>and</p>
<div class="arithmatex">\[
\begin{aligned}
v(r) &amp; =\left(1-\frac{a^{2}}{p}\right)+\frac{a^{2}}{p r_{0}} r, &amp; &amp; \text { for } r \leqslant r_{0} \\
&amp; =1, &amp; &amp; \text { for } r \geqslant r_{0}
\end{aligned}
\]</div>
<p>Unfortunately, this will destroy the uniqueness proofs of Section 8.6.
It usually is desirable to standardize the scale part of these estimates such that we obtain the correct asymptotic values at normal distributions. This is best done by applying a correction factor <span class="arithmatex">\(\tau\)</span> at the very end, as follows.</p>
<p>Example 10.2 With the <span class="arithmatex">\(u\)</span> defined in (10.25) we have, for standard normal observations <span class="arithmatex">\(\mathbf{x}\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
E[u(\tau \mid \mathbf{x} \mid)]= &amp; a^{2} \chi^{2}\left(p, \frac{a^{2}}{\tau^{2}}\right)+b^{2}\left[1-\chi^{2}\left(p, \frac{b^{2}}{\tau^{2}}\right)\right] \\
&amp; +\tau^{2} p\left[\chi^{2}\left(p+2, \frac{b^{2}}{\tau^{2}}\right)-\chi^{2}\left(p+2, \frac{a^{2}}{\tau^{2}}\right)\right]
\end{aligned}
\]</div>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Mass of <span class="arithmatex">\(F_{0}\)</span></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Below <span class="arithmatex">\(a\)</span></td>
<td style="text-align: center;">Above <span class="arithmatex">\(b\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\varepsilon\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(p\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\kappa\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(a=\sqrt{(p-\kappa)^{+}}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(b=\sqrt{p+\kappa}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\tau^{2}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4.1350</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.0332</td>
<td style="text-align: center;">1.0504</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5.2573</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.0363</td>
<td style="text-align: center;">1.0305</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">6.0763</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.0380</td>
<td style="text-align: center;">1.0230</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">7.3433</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.0401</td>
<td style="text-align: center;">1.0164</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">9.6307</td>
<td style="text-align: center;">0.0000</td>
<td style="text-align: center;">0.0426</td>
<td style="text-align: center;">1.0105</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">12.9066</td>
<td style="text-align: center;">0.0038</td>
<td style="text-align: center;">0.0440</td>
<td style="text-align: center;">1.0066</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">19.7896</td>
<td style="text-align: center;">0.0133</td>
<td style="text-align: center;">0.0419</td>
<td style="text-align: center;">1.0030</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">27.7370</td>
<td style="text-align: center;">0.0187</td>
<td style="text-align: center;">0.0395</td>
<td style="text-align: center;">1.0016</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2.2834</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1165</td>
<td style="text-align: center;">1.1980</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3.0469</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1262</td>
<td style="text-align: center;">1.1165</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3.6045</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1313</td>
<td style="text-align: center;">1.0873</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4.4751</td>
<td style="text-align: center;">0.0087</td>
<td style="text-align: center;">0.1367</td>
<td style="text-align: center;">1.0612</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">6.2416</td>
<td style="text-align: center;">0.0454</td>
<td style="text-align: center;">0.1332</td>
<td style="text-align: center;">1.0328</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">8.8237</td>
<td style="text-align: center;">0.0659</td>
<td style="text-align: center;">0.1263</td>
<td style="text-align: center;">1.0166</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">13.9670</td>
<td style="text-align: center;">0.0810</td>
<td style="text-align: center;">0.1185</td>
<td style="text-align: center;">1.0067</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">19.7634</td>
<td style="text-align: center;">0.0877</td>
<td style="text-align: center;">0.1141</td>
<td style="text-align: center;">1.0033</td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1.6086</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1957</td>
<td style="text-align: center;">1.3812</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2.2020</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.2101</td>
<td style="text-align: center;">1.2161</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.6635</td>
<td style="text-align: center;">0.0445</td>
<td style="text-align: center;">0.2141</td>
<td style="text-align: center;">1.1539</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">3.4835</td>
<td style="text-align: center;">0.0912</td>
<td style="text-align: center;">0.2072</td>
<td style="text-align: center;">1.0908</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">5.0051</td>
<td style="text-align: center;">0.1198</td>
<td style="text-align: center;">0.1965</td>
<td style="text-align: center;">1.0441</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">7.1425</td>
<td style="text-align: center;">0.1352</td>
<td style="text-align: center;">0.1879</td>
<td style="text-align: center;">1.0216</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">11.3576</td>
<td style="text-align: center;">0.1469</td>
<td style="text-align: center;">0.1797</td>
<td style="text-align: center;">1.0086</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">16.0931</td>
<td style="text-align: center;">0.1523</td>
<td style="text-align: center;">0.1754</td>
<td style="text-align: center;">1.0043</td>
</tr>
<tr>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.8878</td>
<td style="text-align: center;">0.2135</td>
<td style="text-align: center;">0.3604</td>
<td style="text-align: center;">1.9470</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1.3748</td>
<td style="text-align: center;">0.2495</td>
<td style="text-align: center;">0.3406</td>
<td style="text-align: center;">1.3598</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1.7428</td>
<td style="text-align: center;">0.2582</td>
<td style="text-align: center;">0.3311</td>
<td style="text-align: center;">1.2189</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2.3157</td>
<td style="text-align: center;">0.2657</td>
<td style="text-align: center;">0.3216</td>
<td style="text-align: center;">1.1220</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">3.3484</td>
<td style="text-align: center;">0.2730</td>
<td style="text-align: center;">0.3122</td>
<td style="text-align: center;">1.0577</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4.7888</td>
<td style="text-align: center;">0.2782</td>
<td style="text-align: center;">0.3059</td>
<td style="text-align: center;">1.0281</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">7.6232</td>
<td style="text-align: center;">0.2829</td>
<td style="text-align: center;">0.3004</td>
<td style="text-align: center;">1.0110</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">10.8052</td>
<td style="text-align: center;">0.2854</td>
<td style="text-align: center;">0.2977</td>
<td style="text-align: center;">1.0055</td>
</tr>
</tbody>
</table>
<p>Exhibit 8.10.2 From Huber (1977a), with permission of the publisher.</p>
<p>where <span class="arithmatex">\(\chi^{2}(p, \cdot)\)</span> is the cumulative <span class="arithmatex">\(\chi^{2}\)</span>-distribution with <span class="arithmatex">\(p\)</span> degrees of freedom. So we determine <span class="arithmatex">\(\tau\)</span> from <span class="arithmatex">\(E[u(\tau \mid \mathbf{x} \mid)]=p\)</span>, and then we multiply the pseudocovariance <span class="arithmatex">\(\left(V^{T} V\right)^{-1}\)</span> found from (4.12) by <span class="arithmatex">\(\tau^{2}\)</span>. Some numerical results are summarized in Exhibit 8.10.2.</p>
<p>Some further remarks are needed on the question of spherical symmetry. First, we should point out that the assumption of spherical symmetry is not needed when minimizing Fisher information. Note that Fisher information is a convex function of <span class="arithmatex">\(f\)</span>, so by taking averages over the orthogonal group we obtain (by Jensen's inequality)</p>
<div class="arithmatex">\[
I(\operatorname{ave}\{f\}) \leqslant \operatorname{ave}\{I(f)\}
\]</div>
<p>where ave <span class="arithmatex">\(\{f\}=\bar{f}\)</span> is a spherically symmetric density. So instead of minimizing <span class="arithmatex">\(I(f)\)</span> for spherically symmetric <span class="arithmatex">\(f\)</span>, we might minimize ave <span class="arithmatex">\(\{I(f)\}\)</span> for more general <span class="arithmatex">\(f\)</span>; the minimum will occur at a spherically symmetric <span class="arithmatex">\(f\)</span>.</p>
<p>Second, we might criticize the approach for being restricted to a framework of elliptic densities (with the exception of Section 8.9).</p>
<p>Such a symmetry assumption is reasonable if we are working with genuinely long-tailed <span class="arithmatex">\(p\)</span>-variate distributions. But, for instance, in the framework of the gross error model, typical outliers will be generated by a process distinct from that of the main family and hence will have quite a different covariance structure. For example, the main family may consist of a tight and narrow ellipsoid with only a few principal axes significantly different from zero, while there is a diffuse and roughly spherical cloud of outliers. Or it might be the outliers that show a structure and lie along some well-defined lower dimensional subspaces, and so on. Of course, in an affinely invariant framework, the two situations are not really distinguishable.</p>
<p>But we do not seem to have the means to attack such multidimensional separation problems directly, unless we possess some prior information. The estimates developed in Sections 8.4 ff . are useful just because they are able to furnish an unprejudiced estimate of the overall shape of the principal part of a pointcloud, from which a more meaningful analysis of its composition might start off.</p>
<h1 id="811-some-notes-on-computation">8.11 SOME NOTES ON COMPUTATION</h1>
<p>Unfortunately, so far we have neither a really fast, nor a demonstrably convergent, procedure for calculating simultaneous estimates of location and scatter.</p>
<p>A relatively simple and straightforward approach can be constructed from (4.13) and (4.14):
(1) Starting values For example, let</p>
<div class="arithmatex">\[
\begin{aligned}
\mathbf{t} &amp; :=\operatorname{ave}\{\mathbf{x}\} \\
\sum &amp; :=\operatorname{ave}\left\{(\mathbf{x}-\mathbf{t})(\mathbf{x}-\mathbf{t})^{T}\right\}
\end{aligned}
\]</div>
<p>be the classical estimates. Take the Choleski decomposition <span class="arithmatex">\(\Sigma=\)</span> <span class="arithmatex">\(B B^{T}\)</span>, with <span class="arithmatex">\(B\)</span> lower triangular, and put</p>
<div class="arithmatex">\[
V:=B^{-1}
\]</div>
<p>Then alternate between scatter steps and location steps, as follows.
(2) Scatter step With <span class="arithmatex">\(\mathbf{y}=V(\mathbf{x}-\mathbf{t})\)</span> let</p>
<div class="arithmatex">\[
C:=\frac{\operatorname{ave}\left\{s(|\mathbf{y}|) \mathbf{y} \mathbf{y}^{T}\right\}}{\operatorname{ave}\{v(|\mathbf{y}|)\}}
\]</div>
<p>Take the Choleski decomposition <span class="arithmatex">\(C=B B^{T}\)</span> and put</p>
<div class="arithmatex">\[
\begin{aligned}
W: &amp; =B^{-1} \\
V: &amp; =W V
\end{aligned}
\]</div>
<p>(3) Location step With <span class="arithmatex">\(\mathbf{y}=V(\mathbf{x}-\mathbf{t})\)</span> let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \mathbf{h}:=\frac{\operatorname{ave}\{w(|\mathbf{y}|)(\mathbf{x}-\mathbf{t})\}}{\operatorname{ave}\{w(|\mathbf{y}|)\}} \\
&amp; \mathbf{t}:=\mathbf{t}+\mathbf{h}
\end{aligned}
\]</div>
<p>(4) Termination rule Stop iterating when both <span class="arithmatex">\(\|W-I\|&lt;\varepsilon\)</span> and <span class="arithmatex">\(\|V \mathbf{h}\|\)</span> <span class="arithmatex">\(&lt;\delta\)</span>, for some predetermined tolerance levels, for example <span class="arithmatex">\(\varepsilon=\delta=\)</span> <span class="arithmatex">\(10^{-3}\)</span>.</p>
<p>Note that this algorithm attempts to improve the numerical properties by avoiding the possibly poorly conditioned matrix <span class="arithmatex">\(V^{T} V\)</span>.</p>
<p>If either <span class="arithmatex">\(\mathbf{t}\)</span> or <span class="arithmatex">\(V\)</span> is kept fixed, it is not difficult to show that the algorithm converges under fairly general assumptions. A convergence proof for fixed <span class="arithmatex">\(\mathbf{t}\)</span> is contained in the proof of Lemma 6.1.</p>
<p>For fixed <span class="arithmatex">\(V\)</span> convergence of the location step can easily be proved if <span class="arithmatex">\(w(r)\)</span> is monotone decreasing and <span class="arithmatex">\(w(r) r\)</span> is monotone increasing. Assume for simplicity that <span class="arithmatex">\(V=I\)</span> and let <span class="arithmatex">\(\rho(r)\)</span> be an indefinite integral of <span class="arithmatex">\(w(r) r\)</span>. Then</p>
<p><span class="arithmatex">\(\rho(|\mathbf{x}-\mathbf{t}|)\)</span> is convex as a function of <span class="arithmatex">\(\mathbf{t}\)</span>, and minimizing <span class="arithmatex">\(\operatorname{ave}\{\rho(|\mathbf{x}-\mathbf{t}|)\}\)</span> is equivalent to solving (4.11).</p>
<p>As in Section 7.8 we define comparison functions. Let <span class="arithmatex">\(r_{i}=\left|\mathbf{y}_{i}\right|=\left|\mathbf{x}_{i}-\mathbf{t}^{(m)}\right|\)</span>, where <span class="arithmatex">\(\mathbf{t}^{(m)}\)</span> is the current trial value and the index <span class="arithmatex">\(i\)</span> denotes the <span class="arithmatex">\(i\)</span> th observation. Define the comparison functions <span class="arithmatex">\(u_{i}\)</span> such that</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; u_{i}(r)=a_{i}+\frac{1}{2} b_{i} r^{2} \\
&amp; u_{i}\left(r_{i}\right)=\rho\left(r_{i}\right) \\
&amp; u_{i}^{\prime}\left(r_{i}\right)=\rho^{\prime}\left(r_{i}\right)=w\left(r_{i}\right) r_{i}
\end{aligned}
\]</div>
<p>The last condition implies <span class="arithmatex">\(b_{i}=w\left(r_{i}\right)\)</span>; hence</p>
<div class="arithmatex">\[
u_{i}(r)=\rho\left(r_{i}\right)+\frac{1}{2} w\left(r_{i}\right)\left(r^{2}-r_{i}^{2}\right)
\]</div>
<p>and, since <span class="arithmatex">\(w\)</span> is monotone decreasing, we have</p>
<div class="arithmatex">\[
\begin{aligned}
{\left[u_{i}(r)-\rho(r)\right]^{\prime}=\left[w\left(r_{i}\right)-w(r)\right] r \leqslant 0, } &amp; \text { for } r \leqslant r_{i} \\
&gt; &amp; 0, \quad \text { for } r \geqslant r_{i}
\end{aligned}
\]</div>
<p>Hence</p>
<div class="arithmatex">\[
u_{i}(r) \geqslant \rho(r), \quad \text { for all } r
\]</div>
<p>Minimizing</p>
<div class="arithmatex">\[
\operatorname{ave}\left(u_{i}\left(\left|\mathbf{x}_{i}-\mathbf{t}\right|\right)\right)
\]</div>
<p>is equivalent to performing one location step, from <span class="arithmatex">\(\mathbf{t}^{(m)}\)</span> to <span class="arithmatex">\(\mathbf{t}^{(m+1)}\)</span>; hence <span class="arithmatex">\(\operatorname{ave}\{\rho(|\mathbf{x}-\mathbf{t}|)\}\)</span> is strictly decreased, unless <span class="arithmatex">\(\mathbf{t}^{(m)}=\mathbf{t}^{(m+1)}\)</span> already is a solution, and convergence towards the minimum is now easily proved.</p>
<p>Convergence has not been proved yet when <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> are estimated simultaneously.</p>
<p>The speed of convergence of the location step is satisfactory, but not so that of the more expensive scatter step (most of the work is spent in building up the matrix <span class="arithmatex">\(C\)</span> ).</p>
<p>Some supposedly faster procedures have been proposed by Maronna (1976) and Huber (1977a). The former tried to speed up the scatter step by overrelaxation (in our notation, the Choleski decomposition would be applied to <span class="arithmatex">\(C^{2}\)</span> instead of <span class="arithmatex">\(C\)</span>, so the step is roughly doubled). The latter proposed using a modified Newton approach instead (with the Hessian</p>
<p>matrix replaced by its average over the spheres <span class="arithmatex">\(|\mathbf{y}|=\)</span> const.). But neither of these proposals performed very well in our numerical experiments (Maronna's too often led to oscillatory behavior; Huber's did not really improve the overall speed). A straightforward Newton approach is out of the question because of the high number of variables.</p>
<p>The most successful method so far (with an improvement slightly better than two in overall speed) turned out to be a variant of the conjugate gradient method, using explicit second derivatives. The idea behind it is as follows. Assume that a function <span class="arithmatex">\(f(\mathbf{z}), \mathbf{z} \in \mathbb{R}^{n}\)</span>, is to be minimized, and assume that <span class="arithmatex">\(\mathbf{z}^{(m)}:=\mathbf{z}^{(m-1)}+\mathbf{h}^{(m-1)}\)</span> was the last iteration step. If <span class="arithmatex">\(\mathbf{g}^{(m)}\)</span> is the gradient of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(\mathbf{z}^{(m)}\)</span>, then approximate the function</p>
<div class="arithmatex">\[
F\left(t_{1}, t_{2}\right)=f\left(\mathbf{z}^{(m)}+t_{1} \mathbf{g}^{(m)}+t_{2} \mathbf{h}^{(m-1)}\right)
\]</div>
<p>by a quadratic function <span class="arithmatex">\(Q\left(t_{1}, t_{2}\right)\)</span> having the same derivatives up to order two at <span class="arithmatex">\(t_{1}=t_{2}=0\)</span>, find the minimum of <span class="arithmatex">\(Q\)</span>, say at <span class="arithmatex">\(\hat{t}_{1}\)</span> and <span class="arithmatex">\(\hat{t}_{2}\)</span>, and put <span class="arithmatex">\(\mathbf{h}^{(m)}:=\hat{t}_{1} \mathbf{g}^{(m)}+\hat{t}_{2} \mathbf{h}^{(m-1)}\)</span> and <span class="arithmatex">\(\mathbf{z}^{(m+1)}:=\mathbf{z}^{(m)}+\mathbf{h}^{(m)}\)</span>. The first and second derivatives of <span class="arithmatex">\(F\)</span> should be determined analytically.</p>
<p>If <span class="arithmatex">\(f\)</span> itself is quadratic, the procedure is algebraically equivalent to the standard descriptions of the conjugate gradient method and reaches the true minimum in <span class="arithmatex">\(n\)</span> steps (where <span class="arithmatex">\(n\)</span> is the dimension of <span class="arithmatex">\(\mathbf{z}\)</span> ). Its advantage over the more customary versions that determine <span class="arithmatex">\(\mathbf{h}^{(m)}\)</span> recursively (FletcherPowell, etc.) is that it avoids instabilities due to accumulation of errors caused by (1) deviation of <span class="arithmatex">\(f\)</span> from a quadratic function, and (2) rounding (in essence the usual recursive determination of <span class="arithmatex">\(\mathbf{h}^{(m)}\)</span> amounts to numerical differentiation).</p>
<p>In our case we start from the maximum likelihood problem (4.2) and assume that we have to minimize</p>
<div class="arithmatex">\[
Q=-\log (\operatorname{det} V)-\operatorname{ave}\{\log f(|V(\mathbf{x}-\mathbf{t})|\}
\]</div>
<p>We write <span class="arithmatex">\(V(\mathbf{x}-\mathbf{t})=W \mathbf{y}\)</span> with <span class="arithmatex">\(\mathbf{y}=V_{0}(\mathbf{x}-\mathbf{t}) ; \mathbf{t}\)</span> and <span class="arithmatex">\(V_{0}\)</span> will correspond to the current trial values. We assume that <span class="arithmatex">\(W\)</span> is lower triangular and depends linearly on two real parameters <span class="arithmatex">\(s_{1}\)</span> and <span class="arithmatex">\(s_{2}\)</span> :</p>
<div class="arithmatex">\[
W=I+s_{1} U_{1}+s_{2} U_{2}
\]</div>
<p>where <span class="arithmatex">\(U_{1}\)</span> and <span class="arithmatex">\(U_{2}\)</span> are lower triangular matrices. If</p>
<div class="arithmatex">\[
Q(W)=-\log (\operatorname{det} W)-\log \left(\operatorname{det} V_{0}\right)-\operatorname{ave}\{\log f(|W \mathbf{y}|)\}
\]</div>
<p>is differentiated with respect to a linear parameter in <span class="arithmatex">\(W\)</span>, we obtain</p>
<div class="arithmatex">\[
\dot{Q}(W)=-\operatorname{tr}\left(\dot{W} W^{-1}\right)+\operatorname{ave}\left\{s(|W y|)(W y)^{T}(\dot{W} y)\right\}
\]</div>
<p>with</p>
<div class="arithmatex">\[
s(r)=-\frac{f^{\prime}(r)}{r f(r)}
\]</div>
<p>At <span class="arithmatex">\(s_{1}=s_{2}=0\)</span> this gives</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \dot{Q}(I)=\operatorname{ave}\left\{s(|y|) y^{T} \dot{W} y\right\}-\operatorname{tr}(\dot{W}) \\
&amp; \dot{Q}(I)=\operatorname{ave}\left\{\frac{s^{\prime}(|y|)}{|y|}\left(y^{T} \dot{W} y\right)\left(y^{T} \dot{W} y\right)+s(|y|)(\dot{W} y)^{T}(\dot{W} y)\right\}+\operatorname{tr}(\dot{W} \dot{W})
\end{aligned}
\]</div>
<p>In particular, if we calculate the partial derivatives of <span class="arithmatex">\(Q\)</span> with respect to the <span class="arithmatex">\(p(p+1) / 2\)</span> elements of <span class="arithmatex">\(W\)</span>, we obtain from the above that the gradient <span class="arithmatex">\(U_{1}\)</span> can be naturally identified with the lower triangle of</p>
<div class="arithmatex">\[
U_{1}=\operatorname{ave}\left\{s(|y|) y y^{T}\right\}-I
\]</div>
<p>The idea outlined before is now implemented as follows, in such a way that we can always work near the identity matrix and take advantage of the corresponding simpler formulas and better conditioned matrices.</p>
<h1 id="cg-iteration-step-for-scatter">CG-Iteration Step for Scatter</h1>
<p>Let <span class="arithmatex">\(\mathbf{t}\)</span> and <span class="arithmatex">\(V\)</span> be the current trial values and write <span class="arithmatex">\(\mathbf{y}=V(\mathbf{x}-\mathbf{t})\)</span>. Let <span class="arithmatex">\(U_{1}\)</span> be lower triangular such that</p>
<div class="arithmatex">\[
U_{1}:=\operatorname{ave}\left\{s(|y|) y y^{T}\right\}-I
\]</div>
<p>(ignoring the upper triangle of the right-hand side).
In the first iteration step let <span class="arithmatex">\(j=k=1\)</span>; in all following steps let <span class="arithmatex">\(j\)</span> and <span class="arithmatex">\(k\)</span> take the values 1 and 2 ; let</p>
<div class="arithmatex">\[
\begin{aligned}
a_{j k} &amp; =\operatorname{tr}\left(U_{j} U_{k}\right)+\operatorname{ave}\left\{\frac{s^{\prime}(|y|)}{|y|}\left(y^{T} U_{j} y\right)\left(y^{T} U_{k} y\right)+s(|y|)\left(U_{j} y\right)^{T}\left(U_{k} y\right)\right\} \\
b_{j} &amp; =-\operatorname{tr}\left(U_{j}\right)+\operatorname{ave}\left\{s(|y|)\left(y^{T} U_{j} y\right)\right\}
\end{aligned}
\]</div>
<p>[then <span class="arithmatex">\(Q(W) \cong Q(I)+\sum b_{j} s_{j}+\frac{1}{2} \sum a_{j k} s_{j} s_{k}\)</span> ]. Solve</p>
<div class="arithmatex">\[
\sum_{k} a_{j k} s_{k}+b_{j}=0
\]</div>
<p>for <span class="arithmatex">\(s_{1}\)</span> and <span class="arithmatex">\(s_{2}\left(s_{2}=0\right.\)</span> in the first step). Put</p>
<div class="arithmatex">\[
U_{2}:=s_{1} U_{1}+s_{2} U_{2}
\]</div>
<p>Cut <span class="arithmatex">\(U_{2}\)</span> down by a fudge factor if <span class="arithmatex">\(U_{2}\)</span> is too large; for example, let <span class="arithmatex">\(U_{2}:=c U_{2}\)</span>, with</p>
<div class="arithmatex">\[
c=\frac{1}{\max (1,2 d)}
\]</div>
<p>where <span class="arithmatex">\(d\)</span> is the maximal absolute diagonal element of <span class="arithmatex">\(U_{2}\)</span>. Put</p>
<div class="arithmatex">\[
\begin{aligned}
W: &amp; =I+U_{2} \\
V: &amp; =W V
\end{aligned}
\]</div>
<p>Empirically, with <span class="arithmatex">\(p\)</span> up to 20 [i.e., up to <span class="arithmatex">\(p=20\)</span> parameters for location and <span class="arithmatex">\(p(p+1) / 2=210\)</span> parameters for scatter] the procedure showed a smooth convergence down to essentially machine accuracy.</p>
<h1 id="chapter-9">CHAPTER 9</h1>
<h2 id="robustness-of-design">Robustness of Design</h2>
<h3 id="91-general-remarks">9.1 GENERAL REMARKS</h3>
<p>We already have encountered two design-related problems. The first was concerned with leverage points (Sections 7.1 and 7.2), the second with subtle questions of bias (Section 7.5). In both cases we had single observations sitting at isolated points in the design space, and the difficulty was, essentially, that these observations were not cross-checkable.</p>
<p>There are many considerations entering into a design. From the point of view of robustness, the most important requirement is to have enough redundancy so that everything can be cross-checked. In this little chapter we give another example of this sort; it illuminates the surprising fact that deviations from linearity that are too small to be detected are already large enough to tip the balance away from the "optimal" designs, which assume exact linearity and put the observations on the extreme points of the observable range, toward the "naive" ones, which distribute the observations more or less evenly over the entire design space (and thus allow us to check for linearity).</p>
<p>One simple example should suffice to illustrate the point; it is taken from Huber (1975). See Sacks and Ylvisaker (1978), as well as Bickel and Herzberg (1979), for interesting further developments.</p>
<h3 id="92-minimax-global-fit">9.2 MINIMAX GLOBAL FIT</h3>
<p>Assume that <span class="arithmatex">\(f\)</span> is an approximately linear function defined in the interval <span class="arithmatex">\(I=\left[-\frac{1}{2}, \frac{1}{2}\right]\)</span>. It should be approximated by a linear function as accurately as possible; we choose mean square error as our measure of disagreement:</p>
<div class="arithmatex">\[
\int[f(x)-\alpha-\beta x]^{2} d x
\]</div>
<p>All integrals are over the interval <span class="arithmatex">\(I\)</span>. Clearly, (2.1) is minimized for</p>
<div class="arithmatex">\[
\alpha_{0}=\int f(x) d x, \quad \beta_{0}=\frac{\int x f(x) d x}{\int x^{2} d x}
\]</div>
<p>and the minimum value of (2.1) is denoted by</p>
<div class="arithmatex">\[
Q_{f}=\int\left[f(x)-\alpha_{0}-\beta_{0} x\right]^{2} d x
\]</div>
<p>Assume now that the values of <span class="arithmatex">\(f\)</span> are only observable with some measurement errors. Assume that we can observe <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(n\)</span> freely chosen points <span class="arithmatex">\(x_{1}, \ldots, x_{n}\)</span> in the interval <span class="arithmatex">\(I\)</span>, and that the observed values are</p>
<div class="arithmatex">\[
y_{i}=f\left(x_{i}\right)+u_{i}
\]</div>
<p>where the <span class="arithmatex">\(u_{i}\)</span> are independent normal <span class="arithmatex">\(\mathfrak{R}\left(0, \sigma^{2}\right)\)</span>.
Our original problem is thus turned into the following: find estimates <span class="arithmatex">\(\hat{\alpha}\)</span> and <span class="arithmatex">\(\hat{\beta}\)</span> for the coefficients of a linear function, based on the <span class="arithmatex">\(y_{i}\)</span>, such that the expected mean square error</p>
<div class="arithmatex">\[
Q=E\left\{\int\left[f(x)-\hat{\alpha}-\hat{\beta} x\right]^{2} d x\right\}
\]</div>
<p>is least possible. <span class="arithmatex">\(Q\)</span> can be decomposed into a constant part, a bias part, and a variance part:</p>
<div class="arithmatex">\[
Q=Q_{f}+Q_{b}+Q_{v}
\]</div>
<p>where <span class="arithmatex">\(Q_{f}\)</span> depends on <span class="arithmatex">\(f\)</span> alone [see (2.3)], where</p>
<div class="arithmatex">\[
Q_{b}=\left(\alpha_{1}-\alpha_{0}\right)^{2}+\frac{\left(\beta_{1}-\beta_{0}\right)^{2}}{12}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\alpha_{1}=E(\hat{\alpha}), \quad \beta_{1}=E(\hat{\beta})
\]</div>
<p>and where</p>
<div class="arithmatex">\[
Q_{v}=\operatorname{var}(\hat{\alpha})+\frac{\operatorname{var}(\hat{\beta})}{12}
\]</div>
<p>It is convenient to characterize the design by the design measure</p>
<div class="arithmatex">\[
\xi=\frac{1}{n} \sum \delta_{x_{i}}
\]</div>
<p>where <span class="arithmatex">\(\delta_{x}\)</span> denotes the pointmass 1 at <span class="arithmatex">\(x\)</span>. We allow arbitrary probability measures for <span class="arithmatex">\(\xi\)</span> [in practice they have to be approximated by a measure of the form (2.10)].</p>
<p>For the sake of simplicity we consider only the traditional linear estimates</p>
<div class="arithmatex">\[
\hat{\alpha}=\frac{1}{n} \sum y_{i}, \quad \hat{\beta}=\frac{\sum x_{i} y_{i}}{\sum x_{i}^{2}}
\]</div>
<p>based on a symmetric design <span class="arithmatex">\(x_{1}, \ldots, x_{n}\)</span>. For fixed <span class="arithmatex">\(x_{1}, \ldots, x_{n}\)</span> and a linear <span class="arithmatex">\(f\)</span>, these are, of course, the optimal estimates. The restriction to symmetric designs is inessential and can be removed at the cost of some complications; the restriction to linear estimates is more serious and certainly awkward from a point of view of theoretical purity.</p>
<p>Then we obtain the following explicit representation of (2.5):</p>
<div class="arithmatex">\[
\begin{aligned}
Q(f, \xi) &amp; =E\left\{\int\left[f(x)-\hat{\alpha}-\hat{\beta} x\right]^{2} d x\right\}=Q_{f}+Q_{b}+Q_{v} \\
&amp; =Q_{f}+\left[\left(\alpha_{1}-\alpha_{0}\right)^{2}+\frac{\left(\beta_{1}-\beta_{0}\right)^{2}}{12}\right]+\frac{\sigma^{2}}{n}\left(1+\frac{1}{12 \gamma}\right)
\end{aligned}
\]</div>
<p>with</p>
<div class="arithmatex">\[
\begin{gathered}
\alpha_{1}=E(\hat{\alpha})=\int f(x) d \xi \\
\beta_{1}=E(\hat{\beta})=\frac{\int x f(x) d \xi}{\int x^{2} d \xi} \\
\gamma=\int x^{2} d \xi
\end{gathered}
\]</div>
<p>If <span class="arithmatex">\(f\)</span> is exactly linear, then <span class="arithmatex">\(Q_{f}=Q_{b}=0\)</span>, and (2.12) is minimized by maximizing <span class="arithmatex">\(\gamma\)</span>, that is, by putting all mass of <span class="arithmatex">\(\xi\)</span> on the extreme points <span class="arithmatex">\(\pm \frac{1}{2}\)</span>. Note that the uniform design (where <span class="arithmatex">\(\xi\)</span> has the density <span class="arithmatex">\(m \equiv 1\)</span> ) corresponds to <span class="arithmatex">\(\gamma=\int x^{2} d x=\frac{1}{12}\)</span>, whereas the "optimal" design (all mass on <span class="arithmatex">\(\pm \frac{1}{2}\)</span> ), has <span class="arithmatex">\(\gamma=\frac{1}{4}\)</span>.</p>
<p>Assume now that the response curve <span class="arithmatex">\(f\)</span> is only approximately linear, say <span class="arithmatex">\(Q_{f} \leqslant \eta\)</span>, where <span class="arithmatex">\(\eta&gt;0\)</span> is a small number, and assume that the Statistician plays a game against Nature, with loss function <span class="arithmatex">\(Q(f, \xi)\)</span>.</p>
<p>THEOREM 2.1 The game with loss function <span class="arithmatex">\(Q(f, \xi), f \in \mathscr{F}_{\eta}=\left\{f \mid Q_{f} \leqslant \eta\right\}\)</span>, has a saddlepoint <span class="arithmatex">\(\left(f_{0}, \xi_{0}\right)\)</span> :</p>
<div class="arithmatex">\[
Q\left(f, \xi_{0}\right) \leqslant Q\left(f_{0}, \xi_{0}\right) \leqslant Q\left(f_{0}, \xi\right)
\]</div>
<p>The design measure <span class="arithmatex">\(\xi_{0}\)</span> has a density of the form <span class="arithmatex">\(m_{0}(x)=\left(a x^{2}+b\right)^{+}\)</span>, and <span class="arithmatex">\(f_{0}\)</span> is proportional to <span class="arithmatex">\(m_{0}\)</span> (except that an arbitrary linear function can be added to it).</p>
<p>The dependence of <span class="arithmatex">\(\left(f_{0}, \xi_{0}\right)\)</span> on <span class="arithmatex">\(\eta\)</span> can be described in parametric form, with everything depending on the parameter <span class="arithmatex">\(\gamma\)</span>. If <span class="arithmatex">\(\frac{1}{12} \leqslant \gamma \leqslant \frac{3}{20}\)</span>, then <span class="arithmatex">\(\xi_{0}\)</span> has the density</p>
<div class="arithmatex">\[
m_{0}(x)=1+\frac{5}{4}(12 \gamma-1)\left(12 x^{2}-1\right)
\]</div>
<p>and</p>
<div class="arithmatex">\[
f_{0}(x)=\left(12 x^{2}-1\right) \varepsilon
\]</div>
<p>with</p>
<div class="arithmatex">\[
\varepsilon^{2}=\frac{\sigma^{2}}{n} \cdot \frac{1}{2(12 \gamma)^{2}(12 \gamma-1)}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\eta=\frac{4}{5} \varepsilon^{2}
\]</div>
<p>If <span class="arithmatex">\(\frac{3}{20} \leqslant \gamma \leqslant \frac{1}{4}\)</span>, the solution is much more complicated, and we better change the parameter to <span class="arithmatex">\(c \in[0,1)\)</span>, with no direct interpretation of <span class="arithmatex">\(c\)</span>. Then</p>
<div class="arithmatex">\[
\begin{aligned}
m_{0}(x) &amp; =\frac{3}{(1+2 c)(1-c)^{2}}\left(4 x^{2}-c^{2}\right)^{+} \\
\gamma &amp; =\frac{3+6 c+4 c^{2}+2 c^{3}}{20(1+2 c)} \\
f_{0}(x) &amp; =\left[m_{0}(x)-1\right] \varepsilon \\
\varepsilon^{2} &amp; =\frac{125(1-c)^{3}(1+2 c)^{5}}{72\left(3+6 c+4 c^{2}+2 c^{3}\right)^{2}\left(1+3 c+6 c^{2}+5 c^{3}\right)} \\
\eta &amp; =\frac{25(1-c)^{2}(1+2 c)^{3}}{18\left(3+6 c+4 c^{2}+2 c^{3}\right)^{2}}
\end{aligned}
\]</div>
<p>In the limit <span class="arithmatex">\(\gamma=\frac{1}{4}, c=1\)</span>, the solution degenerates and <span class="arithmatex">\(m_{0}\)</span> puts pointmasses <span class="arithmatex">\(\frac{1}{2}\)</span> at each of the points <span class="arithmatex">\(\pm \frac{1}{2}\)</span>.</p>
<p>Proof We first keep <span class="arithmatex">\(\xi\)</span> fixed and assume it has a density <span class="arithmatex">\(m\)</span>. Then <span class="arithmatex">\(Q(f, \xi)\)</span> is maximized by maximizing the bias term</p>
<div class="arithmatex">\[
Q_{b}=\left(\alpha_{1}-\alpha_{0}\right)^{2}+\frac{\left(\beta_{1}-\beta_{0}\right)^{2}}{12}
\]</div>
<p>Without loss of generality we normalize <span class="arithmatex">\(f\)</span> such that <span class="arithmatex">\(\alpha_{0}=\beta_{0}=0\)</span>. Thus we have to maximize</p>
<div class="arithmatex">\[
Q_{b}=\left(\int f m d x\right)^{2}+\frac{\left(\int x f m d x\right)^{2}}{12 \gamma^{2}}
\]</div>
<p>under the side conditions</p>
<div class="arithmatex">\[
\begin{aligned}
\int f d x &amp; =0 \\
\int x f d x &amp; =0 \\
\int f^{2} d x &amp; =\eta
\end{aligned}
\]</div>
<p>A standard variational argument now shows that the maximizing <span class="arithmatex">\(f\)</span> must be of the form</p>
<div class="arithmatex">\[
f=A \cdot(m-1)+B \cdot(m-12 \gamma) x
\]</div>
<p>for some Lagrange multipliers <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(B\)</span>. The multipliers have already been adjusted such that this <span class="arithmatex">\(f\)</span> satisfies the side conditions (2.26) and (2.27). If we insert <span class="arithmatex">\(f\)</span> into (2.25) and (2.28), we find that we have to maximize</p>
<div class="arithmatex">\[
Q_{b}=A^{2}\left[\int(m-1)^{2} d x\right]^{2}+B^{2} \frac{\left[\int(m-12 \gamma)^{2} x^{2} d x\right]^{2}}{12 \gamma^{2}}
\]</div>
<p>under the side condition</p>
<div class="arithmatex">\[
A^{2} \int(m-1)^{2} d x+B^{2} \int(m-12 \gamma)^{2} x^{2} d x=\eta
\]</div>
<p>This is a linear programming problem (linear in <span class="arithmatex">\(A^{2}\)</span> and <span class="arithmatex">\(B^{2}\)</span> ), and the maximum is clearly reached on the boundary <span class="arithmatex">\(A^{2}=0\)</span> or <span class="arithmatex">\(B^{2}=0\)</span>. According as the upper or the lower inequality holds in</p>
<div class="arithmatex">\[
\int(m-1)^{2} d x \leqq \frac{1}{12 \gamma^{2}} \int(m-12 \gamma)^{2} x^{2} d x
\]</div>
<p>either <span class="arithmatex">\(B\)</span> or <span class="arithmatex">\(A\)</span> is zero; it turns out that in all interesting cases the upper inequality applies, so <span class="arithmatex">\(B=\beta_{1}=0\)</span> (this verification is left to the reader). Thus if we solve for <span class="arithmatex">\(A^{2}\)</span> in (2.31) and insert the solution into (2.30), we obtain an explicit expression for <span class="arithmatex">\(\sup Q_{b}\)</span> and hence</p>
<div class="arithmatex">\[
\sup _{f} Q(f, \xi)=\eta+\eta \int(m-1)^{2} d x+\frac{\sigma^{2}}{n}\left(1+\frac{1}{12 \gamma}\right)
\]</div>
<p>We now minimize this under the side conditions</p>
<div class="arithmatex">\[
\begin{gathered}
\int m d x=1 \\
\int x^{2} m d x=\gamma
\end{gathered}
\]</div>
<p>and obtain that</p>
<div class="arithmatex">\[
m_{0}(x)=\left(a x^{2}+b\right)^{+}
\]</div>
<p>for some Lagrange multipliers <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span>. We verify easily that, for <span class="arithmatex">\(\frac{1}{12}&lt;\gamma&lt;\frac{3}{20}\)</span>, both <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> are <span class="arithmatex">\(\geqslant 0\)</span>. For <span class="arithmatex">\(\frac{3}{20}&lt;\gamma&lt;\frac{1}{4}\)</span> we have <span class="arithmatex">\(b&lt;0\)</span>. Finally, we minimize over <span class="arithmatex">\(\gamma\)</span>, which leads to (2.16) to (2.24).</p>
<p>These results need some interpretation and discussion. First, with any minimax procedure there is the question of whether it is too pessimistic and perhaps safeguards only against some very unlikely contingency. This is not the case here; an approximately quadratic disturbance in <span class="arithmatex">\(f\)</span> is perhaps the one most likely to occur, so (2.17) makes very good sense. But perhaps <span class="arithmatex">\(f_{0}\)</span> corresponds to such a glaring nonlinearity that nobody in his right mind would want to fit a straight line anyway?</p>
<p>To answer this in an objective fashion, we have to construct a most powerful test for distinguishing <span class="arithmatex">\(f_{0}\)</span> from a straight line.</p>
<p>If <span class="arithmatex">\(\xi\)</span> is an arbitrary fixed symmetric design, then the most powerful test is based on the test statistic</p>
<div class="arithmatex">\[
Z=\sum y_{i}\left[f_{0}\left(x_{i}\right)-\bar{f}_{0}\right]
\]</div>
<p>where</p>
<div class="arithmatex">\[
\bar{f}_{0}=\frac{1}{n} \sum f_{0}\left(x_{i}\right)
\]</div>
<p>with <span class="arithmatex">\(f_{0}\)</span> as in (2.17). Under the hypothesis, <span class="arithmatex">\(E(Z)=0 ; \operatorname{var}(Z)\)</span> is the same under the hypothesis and the alternative. We then obtain the signal-to-noise or variance ratio</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\frac{1}{\sigma^{2}} \sum\left[f_{0}\left(x_{i}\right)-\bar{f}_{0}\right]^{2}=\frac{n}{\sigma^{2}} \int\left[f_{0}(x)-\alpha_{1}\right]^{2} d \xi
\]</div>
<p>Proof (2.37) We test the hypothesis that <span class="arithmatex">\(f(x) \equiv \overline{f_{0}}\)</span> against the alternative that <span class="arithmatex">\(f(x)=f_{0}(x)\)</span>. The most powerful test is given by the Neyman-Pearson lemma; the logarithm of the likelihood ratio <span class="arithmatex">\(\Pi\left[p_{1}\left(x_{i}\right) / p_{0}\left(x_{i}\right)\right]\)</span> is</p>
<div class="arithmatex">\[
\begin{aligned}
-\frac{1}{2} \sum\left[\frac{y_{i}-f_{0}\left(x_{i}\right)}{\sigma}\right]^{2} &amp; +\frac{1}{2} \sum\left(\frac{y_{i}-\bar{f}_{0}}{\sigma}\right)^{2} \\
&amp; =\frac{1}{\sigma^{2}}\left\{\sum y_{i}\left[f_{0}\left(x_{i}\right)-\bar{f}_{0}\right]-\frac{1}{2} \sum\left[f_{0}\left(x_{i}\right)-\bar{f}_{0}\right]^{2}\right\}
\end{aligned}
\]</div>
<p>In particular, the best design for such a test, giving the highest variance ratio, puts one-half of the observations at <span class="arithmatex">\(x=0\)</span>, and one-quarter at each of the endpoints <span class="arithmatex">\(x= \pm \frac{1}{2}\)</span>. The variance ratio is then</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\frac{9}{4} \frac{n \varepsilon^{2}}{\sigma^{2}}
\]</div>
<p>The uniform design <span class="arithmatex">\((m \equiv 1)\)</span> gives a variance ratio</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\frac{4}{5} \frac{n \varepsilon^{2}}{\sigma^{2}}
\]</div>
<p>and, finally, the minimax design <span class="arithmatex">\(\xi_{0}\)</span> yields</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\left[\frac{4}{5}+\frac{4}{7}(12 \gamma-1)-(12 \gamma-1)^{2}\right] \frac{n \varepsilon^{2}}{\sigma^{2}}
\]</div>
<p>Exhibit 9.2.1 gives some numerical values for these variance ratios. Note that: (1) according to (2.18), <span class="arithmatex">\(n \varepsilon^{2} / \sigma^{2}\)</span> is a function of <span class="arithmatex">\(\gamma\)</span> alone; and (2) the</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Variance Ratios</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="arithmatex">\(\gamma\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\frac{n \varepsilon^{2}}{\sigma^{2}}\)</span></td>
<td style="text-align: center;">"Best" <br> (2.40)</td>
<td style="text-align: center;">"Uniform" <br> (2.41)</td>
<td style="text-align: center;">"Minimax <span class="arithmatex">\(\xi_{0}\)</span> " <br> (2.42)</td>
<td style="text-align: center;">Quotient <br> (2.42)/(2.41)</td>
<td style="text-align: center;"><span class="arithmatex">\(m_{0}(0)\)</span></td>
</tr>
<tr>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">24.029</td>
<td style="text-align: center;">54.066</td>
<td style="text-align: center;">19.223</td>
<td style="text-align: center;">19.488</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr>
<td style="text-align: center;">0.090</td>
<td style="text-align: center;">5.358</td>
<td style="text-align: center;">12.056</td>
<td style="text-align: center;">4.287</td>
<td style="text-align: center;">4.497</td>
<td style="text-align: center;">1.049</td>
<td style="text-align: center;">0.900</td>
</tr>
<tr>
<td style="text-align: center;">0.095</td>
<td style="text-align: center;">2.748</td>
<td style="text-align: center;">6.183</td>
<td style="text-align: center;">2.198</td>
<td style="text-align: center;">2.364</td>
<td style="text-align: center;">1.076</td>
<td style="text-align: center;">0.825</td>
</tr>
<tr>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">1.736</td>
<td style="text-align: center;">3.906</td>
<td style="text-align: center;">1.389</td>
<td style="text-align: center;">1.518</td>
<td style="text-align: center;">1.093</td>
<td style="text-align: center;">0.750</td>
</tr>
<tr>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">1.211</td>
<td style="text-align: center;">2.725</td>
<td style="text-align: center;">0.969</td>
<td style="text-align: center;">1.067</td>
<td style="text-align: center;">1.101</td>
<td style="text-align: center;">0.675</td>
</tr>
<tr>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.897</td>
<td style="text-align: center;">2.018</td>
<td style="text-align: center;">0.717</td>
<td style="text-align: center;">0.790</td>
<td style="text-align: center;">1.101</td>
<td style="text-align: center;">0.600</td>
</tr>
<tr>
<td style="text-align: center;">0.115</td>
<td style="text-align: center;">0.691</td>
<td style="text-align: center;">1.555</td>
<td style="text-align: center;">0.553</td>
<td style="text-align: center;">0.603</td>
<td style="text-align: center;">1.091</td>
<td style="text-align: center;">0.525</td>
</tr>
<tr>
<td style="text-align: center;">0.120</td>
<td style="text-align: center;">0.548</td>
<td style="text-align: center;">1.233</td>
<td style="text-align: center;">0.438</td>
<td style="text-align: center;">0.470</td>
<td style="text-align: center;">1.072</td>
<td style="text-align: center;">0.450</td>
</tr>
<tr>
<td style="text-align: center;">0.125</td>
<td style="text-align: center;">0.444</td>
<td style="text-align: center;">1.000</td>
<td style="text-align: center;">0.356</td>
<td style="text-align: center;">0.371</td>
<td style="text-align: center;">1.045</td>
<td style="text-align: center;">0.375</td>
</tr>
<tr>
<td style="text-align: center;">0.130</td>
<td style="text-align: center;">0.367</td>
<td style="text-align: center;">0.825</td>
<td style="text-align: center;">0.294</td>
<td style="text-align: center;">0.296</td>
<td style="text-align: center;">1.008</td>
<td style="text-align: center;">0.300</td>
</tr>
<tr>
<td style="text-align: center;">0.135</td>
<td style="text-align: center;">0.307</td>
<td style="text-align: center;">0.691</td>
<td style="text-align: center;">0.246</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.225</td>
</tr>
<tr>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.261</td>
<td style="text-align: center;">0.586</td>
<td style="text-align: center;">0.208</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.908</td>
<td style="text-align: center;">0.150</td>
</tr>
<tr>
<td style="text-align: center;">0.145</td>
<td style="text-align: center;">0.223</td>
<td style="text-align: center;">0.502</td>
<td style="text-align: center;">0.179</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">0.844</td>
<td style="text-align: center;">0.075</td>
</tr>
<tr>
<td style="text-align: center;">0.150</td>
<td style="text-align: center;">0.193</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">0.154</td>
<td style="text-align: center;">0.119</td>
<td style="text-align: center;">0.771</td>
<td style="text-align: center;">0.</td>
</tr>
</tbody>
</table>
<p>Exhihit 9.2.1 Variance ratios for tests of linearity against a quadratic alternative.
minimax and the uniform design have very similar variance ratios. To give an idea of the shape of the minimax design, its minimal density <span class="arithmatex">\(m_{0}(0)\)</span> is also shown.</p>
<p>From this exhibit we can, for instance, infer that, if <span class="arithmatex">\(\gamma \geqslant 0.095\)</span> and if we use either the uniform or the minimax design, we are not able to see the nonlinearity of <span class="arithmatex">\(f_{0}\)</span> with any degree of certainty, since the two-sided Neyman -Pearson test with level <span class="arithmatex">\(10 \%\)</span> does not even achieve <span class="arithmatex">\(50 \%\)</span> power (see Exhibit 9.2.2).</p>
<p>To give another illustration let us now take that value of <span class="arithmatex">\(\varepsilon\)</span> for which the uniform design ( <span class="arithmatex">\(m \equiv 1\)</span> ), minimizing the bias term <span class="arithmatex">\(Q_{b}\)</span>, and the "optimal" design, minimizing the variance term <span class="arithmatex">\(Q_{v}\)</span> by putting all mass on the extreme points of <span class="arithmatex">\(I\)</span>, have the same efficiency. As</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; Q\left(f_{0}, \text { uni }\right)=\int f_{0}^{2} d x+2 \frac{\sigma^{2}}{n} \\
&amp; Q\left(f_{0}, \text { opt }\right)=\int f_{0}^{2} d x+(2 \varepsilon)^{2}+\frac{4}{3} \frac{\sigma^{2}}{n}
\end{aligned}
\]</div>
<p>we obtain equality for</p>
<div class="arithmatex">\[
\varepsilon^{2}=\frac{1}{6} \frac{\sigma^{2}}{n}
\]</div>
<p>and the variance ratio (2.41) then is</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\frac{2}{15}
\]</div>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Variance Ratio</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Level <span class="arithmatex">\(\alpha\)</span></td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">5.0</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">9.0</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.058</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.199</td>
<td style="text-align: center;">0.282</td>
<td style="text-align: center;">0.367</td>
<td style="text-align: center;">0.450</td>
<td style="text-align: center;">0.664</td>
</tr>
<tr>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.181</td>
<td style="text-align: center;">0.276</td>
<td style="text-align: center;">0.372</td>
<td style="text-align: center;">0.464</td>
<td style="text-align: center;">0.549</td>
<td style="text-align: center;">0.750</td>
</tr>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.170</td>
<td style="text-align: center;">0.293</td>
<td style="text-align: center;">0.410</td>
<td style="text-align: center;">0.516</td>
<td style="text-align: center;">0.609</td>
<td style="text-align: center;">0.688</td>
<td style="text-align: center;">0.851</td>
</tr>
<tr>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.264</td>
<td style="text-align: center;">0.410</td>
<td style="text-align: center;">0.535</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.723</td>
<td style="text-align: center;">0.790</td>
<td style="text-align: center;">0.912</td>
</tr>
<tr>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0.400</td>
<td style="text-align: center;">0.556</td>
<td style="text-align: center;">0.675</td>
<td style="text-align: center;">0.764</td>
<td style="text-align: center;">0.830</td>
<td style="text-align: center;">0.879</td>
<td style="text-align: center;">0.957</td>
</tr>
</tbody>
</table>
<p>Exhlbit 9.2.2 Power of two-sided tests, in function of the level and the variance ratio.</p>
<p>A variance ratio of about 4 is needed to obtain approximate power <span class="arithmatex">\(50 \%\)</span> with a <span class="arithmatex">\(5 \%\)</span> test (see Exhibit 9.2.2). Hence (2.46) can be interpreted as follows. Even if the pooled evidence of up to 30 experiments similar to the one under consideration suggests that <span class="arithmatex">\(f_{0}\)</span> is linear, the uniform design may still be better than the "optimal" one and may lead to a smaller expected mean square error!</p>
<h1 id="93-minimax-slope">9.3 MINIMAX SLOPE</h1>
<p>Conceivably, the situation might be different when we are only interested in estimating the slope <span class="arithmatex">\(\beta\)</span>. The expected square error in this case is</p>
<div class="arithmatex">\[
\begin{aligned}
Q(f, \xi) &amp; =E\left(\hat{\beta}-\beta_{0}\right)^{2}=\left(\beta_{1}-\beta_{0}\right)^{2}+\operatorname{var}(\hat{\beta}) \\
&amp; =\left(\frac{\int x f(x) d x}{\gamma}\right)^{2}+\frac{1}{\gamma} \frac{\sigma^{2}}{n}
\end{aligned}
\]</div>
<p>if we standardize <span class="arithmatex">\(f\)</span> such that <span class="arithmatex">\(\alpha_{0}=\beta_{0}=0\)</span> (using the notation of the preceding section).</p>
<p>The game with loss function (3.1) is easy to solve by variational methods similar to those used in the preceding section. For the Statistician the minimax design <span class="arithmatex">\(\xi_{0}\)</span> has density</p>
<div class="arithmatex">\[
m_{0}(x)=\frac{1}{(1-2 a)^{2}}\left(1-\frac{a^{2}}{x^{2}}\right)^{+}
\]</div>
<p>for some <span class="arithmatex">\(0&lt;a&lt;\frac{1}{2}\)</span>, and for Nature the minimax strategy is</p>
<div class="arithmatex">\[
f_{0}(x) \sim\left[m_{0}(x)-12 \gamma\right] x
\]</div>
<p>We do not work out the details, but we note that <span class="arithmatex">\(f_{0}\)</span> is crudely similar to a cubic function.</p>
<p>For the following heuristics we therefore use a more manageable, and perhaps even more realistic, cubic <span class="arithmatex">\(f\)</span> :</p>
<div class="arithmatex">\[
f(x)=\left(20 x^{3}-3 x\right) \varepsilon
\]</div>
<p>This <span class="arithmatex">\(f\)</span> satisfies <span class="arithmatex">\(\int f d x=\int x f d x=0\)</span> and</p>
<div class="arithmatex">\[
\int f(x)^{2} d x=\frac{1}{3} \varepsilon^{2}
\]</div>
<p>We now repeat the argumentation used in the last paragraphs of Section 9.2.</p>
<p>How large should <span class="arithmatex">\(\varepsilon\)</span> be in order that the uniform design and the "optimal" design are equally efficient in terms of the risk function (3.1)? As</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; Q(f, \text { uni })=12 \frac{\sigma^{2}}{n} \\
&amp; Q(f, \text { opt })=(4 \varepsilon)^{2}+4 \frac{\sigma^{2}}{n}
\end{aligned}
\]</div>
<p>we obtain equality if</p>
<div class="arithmatex">\[
\varepsilon^{2}=\frac{\sigma^{2}}{2 n}
\]</div>
<p>The most powerful test between a linear <span class="arithmatex">\(f\)</span> and (3.4) has the variance ratio</p>
<div class="arithmatex">\[
\frac{(E Z)^{2}}{\operatorname{var}(Z)}=\frac{1}{7} \frac{n \varepsilon^{2}}{\sigma^{2}}
\]</div>
<p>If we insert (3.8) this becomes equal to <span class="arithmatex">\(\frac{1}{14}\)</span>. Thus the situation is even worse than at the end of Section 9.2: even if the pooled evidence of up to 50 experiments similar to the one under consideration suggests that <span class="arithmatex">\(f_{0}\)</span> is linear, the uniform design (which minimizes bias for a not necessarily linear <span class="arithmatex">\(f\)</span> ) may still be better than the "optimal" design (which minimizes variance, assuming that <span class="arithmatex">\(f\)</span> is exactly linear)!</p>
<p>We conclude from these examples that the so-called optimum design theory (minimizing variance, assuming that the model is exactly correct) is meaningless in a robustness context; we should try rather to minimize bias, assuming that the model is only approximately correct. This had already been recognized by Box and Draper (1959), p. 622: "The optimal design in typical situations in which both variance and bias occur is very nearly the same as would be obtained if variance were ignored completely and the experiment designed so as to minimize bias alone."</p>
<h1 id="chapter-10">CHAPTER 10</h1>
<h2 id="exact-finite-sample-results">Exact Finite Sample Results</h2>
<h3 id="101-general-remarks">10.1 GENERAL REMARKS</h3>
<p>Assume that our data contain <span class="arithmatex">\(1 \%\)</span> gross errors. Then it makes a tremendous conceptual difference whether the sample size is 1000 or 5 . In the former case each sample will contain around 10 grossly erroneous values, while in the latter, 19 out of 20 samples are good. In particular, it is not at all clear whether conclusions derived from an asymptotic theory remain valid for small samples. Many people are willing to take a <span class="arithmatex">\(5 \%\)</span> risk (remember the customary levels of statistical tests and confidence intervals!), and possibly, if we are applying a nonrobust optimal procedure, the gains on the good samples might more than offset the losses caused by an occasional bad sample, especially if we are using a realistic (i.e., bounded) loss function.</p>
<p>The main purpose of this chapter is to show that this is not so. We shall find exact, finite sample minimax estimates of location, which, surprisingly, have the same structure as the asymptotically minimax <span class="arithmatex">\(M\)</span>-estimates found in Chapter 4, and they are even quantitatively comparable.</p>
<p>These estimates are derived from minimax robust tests, and thus we have to develop a theory of robust tests.</p>
<p>We begin with a discussion of the structure of some of the neighborhoods used to describe approximately specified probabilities; the goal would be to ultimately develop a kind of interval arithmetics for probability measures (e.g., in Bayesian framework, how we step from an approximate prior to an approximate posterior distribution). It appears that alternating capacities of order two, and occasionally of infinite order, are the appropriate tools in these contexts.</p>
<p>If (and essentially only if) the inaccuracies can be formulated in terms of alternating capacities of order two, the minimax tests have a very simple structure.</p>
<h1 id="102-lower-and-upper-probabilities-and-capacities">10.2 LOWER AND UPPER PROBABILITIES AND CAPACITIES</h1>
<p>Let <span class="arithmatex">\(\mathscr{N}\)</span> be the set of all probability measures on some measurable space <span class="arithmatex">\((\Omega, \mathscr{E})\)</span>. We single out four classes of subsets <span class="arithmatex">\(\mathscr{P} \subset \mathscr{N}\)</span> : those representable through (1) upper expectations, (2) upper probabilities, (3) alternating capacities of order two, (4) alternating capacities of infinite order. Each class contains the following one.</p>
<p>Formally, our treatment is restricted to finite sets <span class="arithmatex">\(\Omega\)</span>, even though all the concepts and a majority of the results are valid for much more general spaces. But if we consider the more general spaces, the important conceptual aspects are buried under a mass of technical complications of a measure theoretic and topological nature.</p>
<p>Let <span class="arithmatex">\(\mathscr{P} \subset \mathscr{N}\)</span> be an arbitrary nonempty subset. We define the lower and the upper expectation induced by <span class="arithmatex">\(\mathscr{P}\)</span> as</p>
<div class="arithmatex">\[
E_{*}(X)=\inf _{\mathscr{P}} \int X d P, \quad E^{*}(X)=\sup _{\mathscr{P}} \int X d P
\]</div>
<p>and similarly, the lower and the upper probability induced by <span class="arithmatex">\(\mathscr{P}\)</span> as</p>
<div class="arithmatex">\[
v_{*}(A)=\inf _{\mathscr{P}} P(A), \quad v^{*}(A)=\sup _{\mathscr{P}} P(A)
\]</div>
<p><span class="arithmatex">\(E_{*}\)</span> and <span class="arithmatex">\(E^{*}\)</span> are nonlinear functionals conjugate to each other in the sense that</p>
<div class="arithmatex">\[
E_{*}(X)=-E^{*}(-X)
\]</div>
<p>and</p>
<div class="arithmatex">\[
v_{*}(A)=1-v^{*}\left(A^{c}\right)
\]</div>
<p>Conversely, we may start with an arbitrary pair of conjugate functionals ( <span class="arithmatex">\(E_{*}, E^{*}\)</span> ) or set functions ( <span class="arithmatex">\(v_{*}, v^{*}\)</span> ) satisfying (2.3) or (2.4), respectively, and define sets <span class="arithmatex">\(\mathscr{P}\)</span> by</p>
<div class="arithmatex">\[
\begin{aligned}
\mathscr{P} &amp; =\left\{P \in \mathscr{N} \mid \int X d P \geqslant E_{*}(X) \text { for all } X\right\} \\
&amp; =\left\{P \in \mathscr{N} \mid \int X d P \leqslant E^{*}(X) \text { for all } X\right\}
\end{aligned}
\]</div>
<p>or</p>
<div class="arithmatex">\[
\begin{aligned}
\mathscr{P} &amp; =\left\{P \in \mathscr{M} \mid P(A) \geqslant v_{*}(A) \text { for all } A\right\} \\
&amp; =\left\{P \in \mathscr{M} \mid P(A) \leqslant v^{*}(A) \text { for all } A\right\}
\end{aligned}
\]</div>
<p>respectively.
We note that (2.1), followed by (2.5), does not in general restore <span class="arithmatex">\(\mathscr{P}\)</span>; nor does (2.5), followed by (2.1), restore ( <span class="arithmatex">\(E_{*}, E^{*}\)</span> ). But from the second round on, matters stabilize. We say that <span class="arithmatex">\(\mathscr{P}\)</span> and ( <span class="arithmatex">\(E_{*}, E^{*}\)</span> ) represent each other if they mutually induce each other through (2.1) and (2.5).</p>
<p>Similarly, we say that <span class="arithmatex">\(\mathscr{P}\)</span> and ( <span class="arithmatex">\(v_{*}, v^{*}\)</span> ) represent each other if they mutually induce each other through (2.2) and (2.6).</p>
<p>Obviously, it suffices to look at one member of the respective pairs <span class="arithmatex">\(\left(E_{*}, E^{*}\right)\)</span> and <span class="arithmatex">\(\left(v_{*}, v^{*}\right)\)</span>, say <span class="arithmatex">\(E^{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span>.</p>
<p>These notions immediately provoke a few questions:
(1) What conditions must ( <span class="arithmatex">\(E_{*}, E^{*}\)</span> ) satisfy so that it is representable by some <span class="arithmatex">\(\mathscr{P}\)</span> ? What conditions must <span class="arithmatex">\(\mathscr{P}\)</span> satisfy so that it is representable by some <span class="arithmatex">\(\left(E_{*}, E^{*}\right)\)</span> ?
(2) What conditions must ( <span class="arithmatex">\(v_{*}, v^{*}\)</span> ) satisfy so that it is representable by some <span class="arithmatex">\(\mathscr{P}\)</span> ? What conditions must <span class="arithmatex">\(\mathscr{P}\)</span> satisfy so that it is representable by some <span class="arithmatex">\(\left(v_{*}, v^{*}\right)\)</span> ?
The answer to (1) is very simple. We first note that every representable <span class="arithmatex">\(\mathscr{P}\)</span> is closed and convex (since we are working with finite sets <span class="arithmatex">\(\Omega, \mathscr{P}\)</span> can be identified with a subset of the simplex <span class="arithmatex">\(\left\{\left(p_{1}, \ldots, p_{n}\right) \mid \sum p_{i}=1, p_{i} \geqslant 0\right\}\)</span>, so there is a unique natural topology). On the other hand every representable <span class="arithmatex">\(E^{*}\)</span> is monotone,</p>
<div class="arithmatex">\[
X \leqslant Y \Rightarrow E^{*}(X) \leqslant E^{*}(Y)
\]</div>
<p>positively affinely homogeneous,</p>
<div class="arithmatex">\[
E^{*}(a X+b)=a E^{*}(X)+b, \quad a, b \in \mathbf{R}, \quad a \geqslant 0
\]</div>
<p>and subadditive,</p>
<div class="arithmatex">\[
E^{*}(X+Y) \leqslant E^{*}(X)+E^{*}(Y)
\]</div>
<p><span class="arithmatex">\(E_{*}\)</span> satisfies the same conditions (2.7) and (2.8), but is superadditive,</p>
<div class="arithmatex">\[
E_{*}(X+Y) \geqslant E_{*}(X)+E_{*}(Y)
\]</div>
<p>PROPOSITION 2.1 <span class="arithmatex">\(\mathscr{P}\)</span> is representable by an upper expectation <span class="arithmatex">\(E^{*}\)</span> iff it is closed and convex. Conversely, (2.7), (2.8) and (2.9) are necessary and sufficient for representability of <span class="arithmatex">\(E^{*}\)</span>.</p>
<p>Proof Assume that <span class="arithmatex">\(\mathscr{P}\)</span> is convex and closed, and define <span class="arithmatex">\(E^{*}\)</span> by (2.1). <span class="arithmatex">\(E^{*}\)</span> represents <span class="arithmatex">\(\mathscr{P}\)</span> if we can show that, for every <span class="arithmatex">\(Q \notin \mathscr{P}\)</span>, there is an <span class="arithmatex">\(X\)</span> and a real number <span class="arithmatex">\(c\)</span> such that, for all <span class="arithmatex">\(P \in \mathscr{P}, \int X d P \leqslant c&lt;f X d Q\)</span>; their existence is in fact guaranteed by one of the well-known separation theorems for convex sets.</p>
<p>Now assume that <span class="arithmatex">\(E^{*}\)</span> is monotone, positively affinely homogeneous, and subadditive. It suffices to show that for every <span class="arithmatex">\(X_{0}\)</span> there is a probability measure <span class="arithmatex">\(P\)</span> such that, for all <span class="arithmatex">\(X, \int X d P \leqslant E^{*}(X)\)</span>, and <span class="arithmatex">\(\int X_{0} d P=E^{*}\left(X_{0}\right)\)</span>. Because of (2.8) we can assume without any loss of generality that <span class="arithmatex">\(E^{*}\left(X_{0}\right)=1\)</span>. Let <span class="arithmatex">\(U=\left\{X \mid E^{*}(X)&lt;1\right\}\)</span>. It follows from (2.7) and (2.8) that <span class="arithmatex">\(U\)</span> is open: with <span class="arithmatex">\(X\)</span> it also contains all <span class="arithmatex">\(Y\)</span> such that <span class="arithmatex">\(Y&lt;X+\varepsilon\)</span>, for <span class="arithmatex">\(\varepsilon=1-E^{*}(X)\)</span>. Moreover, (2.9) implies that <span class="arithmatex">\(U\)</span> is convex. Since <span class="arithmatex">\(X_{0} \notin U\)</span>, there is a linear functional <span class="arithmatex">\(\lambda\)</span> separating <span class="arithmatex">\(X_{0}\)</span> from <span class="arithmatex">\(U\)</span> :</p>
<div class="arithmatex">\[
\lambda(X)&lt;\lambda\left(X_{0}\right), \quad \text { for all } X \in U
\]</div>
<p>With <span class="arithmatex">\(X=0\)</span> this implies in particular that <span class="arithmatex">\(\lambda\left(X_{0}\right)\)</span> is strictly positive, and we may normalize <span class="arithmatex">\(\lambda\)</span> such that <span class="arithmatex">\(\lambda\left(X_{0}\right)=1=E^{*}\left(X_{0}\right)\)</span>. Thus we may write (2.11) as</p>
<div class="arithmatex">\[
E^{*}(X)&lt;1 \Rightarrow \lambda(X)&lt;1
\]</div>
<p>In view of (2.7) and (2.8), we have</p>
<div class="arithmatex">\[
X \leqslant 0 \Rightarrow E^{*}(X) \leqslant E^{*}(0)=0
\]</div>
<p>hence (2.12) implies that, for all <span class="arithmatex">\(c&gt;0, X \geqslant 0\)</span>, we have</p>
<div class="arithmatex">\[
c \lambda(X)=-\lambda(-c X)&gt;-1
\]</div>
<p>thus <span class="arithmatex">\(\lambda(X) \geqslant-1 / c\)</span>. Hence <span class="arithmatex">\(\lambda\)</span> is a positive functional. Moreover, we claim that <span class="arithmatex">\(\lambda(1)=1\)</span>. First, it follows from (2.12) that <span class="arithmatex">\(\lambda(c)&lt;1\)</span> for <span class="arithmatex">\(c&lt;1\)</span>; hence <span class="arithmatex">\(\lambda(1) \leqslant 1\)</span>. On the other hand with <span class="arithmatex">\(c&gt;1\)</span> we have <span class="arithmatex">\(E^{*}\left(2 X_{0}-c\right)=2-c&lt;1\)</span>; hence <span class="arithmatex">\(\lambda\left(2 X_{0}-c\right)=2-c \lambda(1)&lt;1\)</span>, or <span class="arithmatex">\(\lambda(1)&gt;1 / c\)</span> for all <span class="arithmatex">\(c&gt;1\)</span>; hence <span class="arithmatex">\(\lambda(1)=1\)</span>. It follows now from (2.8) and (2.12) that, for all <span class="arithmatex">\(c\)</span>,</p>
<div class="arithmatex">\[
E^{*}(X)&lt;c \Rightarrow \lambda(X)&lt;c
\]</div>
<p>hence <span class="arithmatex">\(\lambda(X) \leqslant E^{*}(X)\)</span> for all <span class="arithmatex">\(X\)</span>, and the probability measure <span class="arithmatex">\(P(A)=\lambda\left(1_{A}\right)\)</span> is the one we are looking for.</p>
<p>Question (2) is trickier. We note first that every representable ( <span class="arithmatex">\(v_{*}, v^{*}\)</span> ) will satisfy</p>
<div class="arithmatex">\[
\begin{gathered}
v_{*}(\phi)=v^{*}(\phi)=0, \quad v_{*}(\Omega)=v^{*}(\Omega)=1 \\
A \subset B \Rightarrow v_{*}(A) \leqslant v_{*}(B), \quad v^{*}(A) \leqslant v^{*}(B) \\
v_{*}(A \cup B) \geqslant v_{*}(A)+v_{*}(B), \quad \text { for } A \cap B=\phi \\
v^{*}(A \cup B) \leqslant v^{*}(A)+v^{*}(B)
\end{gathered}
\]</div>
<p>But these conditions are not sufficient for ( <span class="arithmatex">\(v_{*}, v^{*}\)</span> ) to be representable, as the following counterexample shows.</p>
<p>Example 2.1 Let <span class="arithmatex">\(\Omega\)</span> have cardinality <span class="arithmatex">\(|\Omega|=4\)</span>, and assume that <span class="arithmatex">\(v_{*}(A)\)</span> and <span class="arithmatex">\(v^{*}(A)\)</span> depend only on the cardinality of <span class="arithmatex">\(A\)</span>, according to the following table:</p>
<table>
<thead>
<tr>
<th style="text-align: left;"><span class="arithmatex">\(A\)</span></th>
<th style="text-align: left;">0</th>
<th style="text-align: left;">1</th>
<th style="text-align: left;">2</th>
<th style="text-align: left;">3</th>
<th style="text-align: left;">4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(v_{*}\)</span></td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;"><span class="arithmatex">\(\frac{1}{2}\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(\frac{1}{2}\)</span></td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;"><span class="arithmatex">\(v^{*}\)</span></td>
<td style="text-align: left;">0</td>
<td style="text-align: left;"><span class="arithmatex">\(\frac{1}{2}\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(\frac{1}{2}\)</span></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p>Then <span class="arithmatex">\(\left(v_{*}, v^{*}\right)\)</span> satisfies the above necessary conditions, but there is only a single additive set function between <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span>, namely <span class="arithmatex">\(P(A)=|A| / 4\)</span>; hence <span class="arithmatex">\(\left(v_{*}, v^{*}\right)\)</span> is not representable.</p>
<p>Let <span class="arithmatex">\(\mathscr{P}\)</span> be any collection of subsets of <span class="arithmatex">\(\Omega\)</span>, and let <span class="arithmatex">\(v_{*}: \mathscr{D} \rightarrow \mathbb{R}_{+}\)</span>be an arbitrary nonnegative set function. Let</p>
<div class="arithmatex">\[
\mathscr{P}=\left\{P \in \mathscr{M} \mid P(A) \geqslant v_{*}(A) \text { for all } A \in \mathscr{P}\right\}
\]</div>
<p>Dually, <span class="arithmatex">\(\mathscr{P}\)</span> can also be characterized as</p>
<div class="arithmatex">\[
\mathscr{P}=\left\{P \in \mathscr{M} \mid P(B) \leqslant v^{*}(B) \text { for all } B \text { with } B^{c} \in \mathscr{P}\right\}
\]</div>
<p>where <span class="arithmatex">\(v^{*}(B)=1-v_{*}\left(B^{c}\right)\)</span>.
LEMMA 2.2 The set <span class="arithmatex">\(\mathscr{P}\)</span> of (2.17) is not empty iff the following condition holds: whenever</p>
<div class="arithmatex">\[
\sum a_{i} 1_{A_{i}} \leqslant 1, \quad a_{i} \geqslant 0, A_{i} \in \mathscr{P}
\]</div>
<p>then</p>
<div class="arithmatex">\[
\sum a_{i} v_{*}\left(A_{i}\right) \leqslant 1
\]</div>
<p>Proof The necessity of the condition is obvious. The sufficiency follows from the next lemma.</p>
<p>We define functionals</p>
<div class="arithmatex">\[
E_{*}(X)=\sup \left\{\sum a_{i} v_{*}\left(A_{i}\right)-a \mid \sum a_{i} 1_{A_{i}}-a \leqslant X, a_{i} \geqslant 0, A_{i} \in \mathscr{D}\right\}
\]</div>
<p>and <span class="arithmatex">\(E^{*}(X)=-E_{*}(-X)\)</span>, or</p>
<div class="arithmatex">\[
E^{*}(X)=\inf \left\{\sum b_{i} v^{*}\left(B_{i}\right)-b \mid \sum b_{i} 1_{B_{i}}-b \geqslant X, b_{i} \geqslant 0, B_{i}^{c} \in \mathscr{D}\right\}
\]</div>
<p>Put</p>
<div class="arithmatex">\[
\begin{array}{ll}
v_{* 0}(A)=E_{*}\left(1_{A}\right), &amp; \text { for } A \subset \Omega \\
v^{* 0}(A)=E^{*}\left(1_{A}\right), &amp; \text { for } A \subset \Omega
\end{array}
\]</div>
<p>Clearly, <span class="arithmatex">\(v_{*} \leqslant v_{* 0}\)</span> and <span class="arithmatex">\(v^{* 0} \leqslant v^{*}\)</span>; we verify easily that we obtain the same functionals <span class="arithmatex">\(E_{*}\)</span> and <span class="arithmatex">\(E^{*}\)</span> if we replace <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span> by <span class="arithmatex">\(v_{* 0}\)</span> and <span class="arithmatex">\(v^{* 0}\)</span> and <span class="arithmatex">\(\mathscr{D}\)</span> by <span class="arithmatex">\(2^{\Omega}\)</span> in (2.19) and (2.20).</p>
<p>LEMMA 2.3 Let <span class="arithmatex">\(\mathscr{P}\)</span> be given by (2.17). If <span class="arithmatex">\(\mathscr{P}\)</span> is empty, then <span class="arithmatex">\(E_{*}(X)=\infty\)</span> and <span class="arithmatex">\(E^{*}(X)=-\infty\)</span> identically for all <span class="arithmatex">\(X\)</span>. Otherwise <span class="arithmatex">\(E_{*}\)</span> and <span class="arithmatex">\(E^{*}\)</span> coincide with the lower/upper expectations (2.1) defined by <span class="arithmatex">\(\mathscr{P}\)</span>, and <span class="arithmatex">\(v_{* 0}\)</span> and <span class="arithmatex">\(v^{* 0}\)</span> with the lower/upper probabilities (2.2).</p>
<p>Proof We note first that <span class="arithmatex">\(E_{*}(X) \geqslant 0\)</span> if <span class="arithmatex">\(X \geqslant 0\)</span>, and that either <span class="arithmatex">\(E_{*}(0)=0\)</span>, or else <span class="arithmatex">\(E_{*}(X)=\infty\)</span> for all <span class="arithmatex">\(X\)</span>. In the latter case <span class="arithmatex">\(\mathscr{P}\)</span> is empty (this follows from the necessity part of Lemma 2.2 which has already been proved). In the former case we verify easily that <span class="arithmatex">\(E_{*}\left(E^{*}\right)\)</span> is monotone, positively affinely homogeneous, and superadditive (subadditive, respectively). The definitions imply at once that <span class="arithmatex">\(\mathscr{P}\)</span> is contained in the nonempty set <span class="arithmatex">\(\tilde{\mathscr{P}}\)</span> induced by <span class="arithmatex">\(\left(E_{*}, E^{*}\right):\)</span></p>
<div class="arithmatex">\[
\mathscr{P} \subset \tilde{\mathscr{P}}=\left\{P \in \mathscr{M} \mid E_{*}(X) \leqslant \int X d P \leqslant E^{*}(X) \text { for all } X\right\}
\]</div>
<p>But on the other hand it follows from <span class="arithmatex">\(v_{*}(A) \leqslant v_{* 0}(A)\)</span> and <span class="arithmatex">\(v^{* 0}(A) \leqslant v^{*}(A)\)</span> that <span class="arithmatex">\(\mathscr{P} \supset \tilde{\mathscr{P}}\)</span>; hence <span class="arithmatex">\(\mathscr{P}=\tilde{\mathscr{P}}\)</span>. The assertion of the lemma follows.</p>
<p>The sufficiency of the condition in Lemma 2.2 follows at once from the remark that it is equivalent to <span class="arithmatex">\(E_{*}(0) \leqslant 0\)</span>.</p>
<p>PROPOSITION 2.4 (Wolf 1977) A set function <span class="arithmatex">\(v^{*}\)</span> on <span class="arithmatex">\(\oplus=2^{\Omega}\)</span> is representable by some <span class="arithmatex">\(\mathscr{P}\)</span> iff it has the following property: whenever</p>
<div class="arithmatex">\[
1_{A} \leqslant \sum a_{i} 1_{A_{i}}-a, \quad \text { with } a_{i} \geqslant 0
\]</div>
<p>then</p>
<div class="arithmatex">\[
v^{*}(A) \leqslant \sum a_{i} v^{*}\left(A_{i}\right)-a
\]</div>
<p>The following weaker set of conditions is in fact sufficient: <span class="arithmatex">\(v^{*}\)</span> is monotone <span class="arithmatex">\(v^{*}(\phi)=0, v^{*}(\Omega)=1\)</span>, and (2.24) holds for all decompositions</p>
<div class="arithmatex">\[
1_{A}=\sum a_{i} 1_{A_{i}}
\]</div>
<p>where <span class="arithmatex">\(a_{i}&gt;0\)</span> when <span class="arithmatex">\(A_{i} \neq \Omega\)</span>, and where <span class="arithmatex">\(\left(1_{A_{1}}, \ldots, 1_{A_{k}}\right)\)</span> is linearly independent.
Proof If <span class="arithmatex">\(\oplus=2^{\Omega}\)</span>, then <span class="arithmatex">\(v^{*}=v^{* 0}\)</span> is a necessary and sufficient condition for <span class="arithmatex">\(v^{*}\)</span> to be representable; this follows immediately from Lemma 2.3. If we spell this out, we obtain (2.23) and (2.24). As (2.23) involves an uncountable infinity of conditions, it is not easy to verify; in the second version (2.25) the number of conditions is still uncomfortably large, but finite [the <span class="arithmatex">\(a_{i}\)</span> are uniquely determined if the system <span class="arithmatex">\(\left(1_{A_{1}}, \ldots, 1_{A_{k}}\right)\)</span> is linearly independent].</p>
<p>To prove the sufficiency of the second set of conditions, assume to the contrary that (2.24) holds for all decompositions (2.25), but fails for some (2.23). We may assume that we have equality in (2.23)-if not, we can achieve it by decreasing some <span class="arithmatex">\(a_{i}\)</span> or <span class="arithmatex">\(A_{i}\)</span>, or increasing <span class="arithmatex">\(a\)</span>, on the right-hand side of (2.23). We thus can write (2.23) in the form (2.25), but <span class="arithmatex">\(\left(1_{A_{1}}, \ldots, 1_{A_{k}}\right)\)</span> then must be linearly dependent. Let <span class="arithmatex">\(k\)</span> be least possible; then all <span class="arithmatex">\(a_{i} \neq 0\)</span>, <span class="arithmatex">\(A_{i} \neq \phi\)</span>, and <span class="arithmatex">\(a_{i}&gt;0\)</span> if <span class="arithmatex">\(A_{i} \neq \Omega\)</span>. Assume that <span class="arithmatex">\(\sum c_{i} 1_{A_{i}}=0\)</span>, not all <span class="arithmatex">\(c_{i}=0\)</span>; then <span class="arithmatex">\(1_{A}=\sum\left(a_{i}+\lambda c_{i}\right) A_{i}\)</span>, for all <span class="arithmatex">\(\lambda\)</span>. Let <span class="arithmatex">\(\left[\lambda_{0}, \lambda_{1}\right]\)</span> be the interval of <span class="arithmatex">\(\lambda\)</span>-values for which <span class="arithmatex">\(a_{i}+\lambda c_{i} \geqslant 0\)</span> for all <span class="arithmatex">\(A_{i} \neq \Omega\)</span>; clearly, it contains 0 in its interior. Evidently <span class="arithmatex">\(\sum\left(a_{i}+\lambda c_{i}\right) v^{*}\left(A_{i}\right)\)</span> is a linear function of <span class="arithmatex">\(\lambda\)</span>, and thus reaches its minimum at one of the endpoints <span class="arithmatex">\(\lambda_{0}\)</span> or <span class="arithmatex">\(\lambda_{1}\)</span>. There, (2.24) is also violated, but <span class="arithmatex">\(k\)</span> is decreased by at least one. But <span class="arithmatex">\(k\)</span> was minimal, which leads to a contradiction.</p>
<p>This proposition gives at least a partial answer to question (2). Note that, in general, several distinct closed convex sets <span class="arithmatex">\(\mathscr{P}\)</span> induce the same <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span>. The set given by (2.6) is the largest among them. Correspondingly, there will be several upper expectations <span class="arithmatex">\(E^{*}\)</span> inducing <span class="arithmatex">\(v^{*}\)</span> through <span class="arithmatex">\(v^{*}(A)=E^{*}\left(1_{A}\right)\)</span>; (2.20) is the largest one of them, and (2.19) is the smallest lower expectation inducing <span class="arithmatex">\(v_{*}\)</span>.</p>
<p>For a given <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span>, there is no simple way to construct the corresponding (extremal) pair <span class="arithmatex">\(E_{*}\)</span> and <span class="arithmatex">\(E^{*}\)</span>; we can do it either through (2.6) and (2.1) or through (2.19) and (2.20), but either way some awkward suprema and infima are involved.</p>
<h1 id="2-monotone-and-2-alternating-capacities">2-Monotone and 2-Alternating Capacities</h1>
<p>The situation is simplified if <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span> are a monotone capacity of order two and an alternating capacity of order two, respectively (or short: 2-monotone, 2-alternating), that is, if <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span>, apart from the obvious conditions</p>
<div class="arithmatex">\[
\begin{gathered}
v_{*}(\phi)=v^{*}(\phi)=0, \quad v_{*}(\Omega)=v^{*}(\Omega)=1 \\
A \subset B \Rightarrow v_{*}(A) \leqslant v_{*}(B), \quad v^{*}(A) \leqslant v^{*}(B)
\end{gathered}
\]</div>
<p>satisfy</p>
<div class="arithmatex">\[
\begin{gathered}
v_{*}(A \cup B)+v_{*}(A \cap B) \geqslant v_{*}(A)+v_{*}(B) \\
v^{*}(A \cup B)+v^{*}(A \cap B) \leqslant v^{*}(A)+v^{*}(B)
\end{gathered}
\]</div>
<p>This seemingly slight strengthening of the assumptions (2.13) to (2.16) has dramatic effects.</p>
<p>Assume <span class="arithmatex">\(v^{*}\)</span> satisfies (2.26) and (2.27), and define a functional <span class="arithmatex">\(E^{*}\)</span> through</p>
<div class="arithmatex">\[
E^{*}(X)=\int_{0}^{\infty} v^{*}\{X&gt;t\} d t, \quad \text { for } X \geqslant 0
\]</div>
<p>Then <span class="arithmatex">\(E^{*}\)</span> is monotone and positively affinely homogeneous, as we verify easily; with the help of (2.8) it can be extended to all <span class="arithmatex">\(X\)</span>. [Note that, if the construction (2.30) is applied to a probability measure, we obtain the expectation:</p>
<div class="arithmatex">\[
\int_{0}^{\infty} P\{X&gt;t\} d t=\int X d P, \quad \text { for } X \geqslant 0 .]
\]</div>
<p>Similarly, define <span class="arithmatex">\(E_{*}\)</span>, with <span class="arithmatex">\(v_{*}\)</span> in place of <span class="arithmatex">\(v^{*}\)</span>.
PROPOSITION 2.5 The functional <span class="arithmatex">\(E^{*}\)</span>, defined by (2.30), is subadditive iff <span class="arithmatex">\(v^{*}\)</span> satisfies (2.29). [Similarly, <span class="arithmatex">\(E_{*}\)</span> is superadditive iff <span class="arithmatex">\(v_{*}\)</span> satisfies (2.28)].</p>
<p>Proof Assume that <span class="arithmatex">\(E^{*}\)</span> is subadditive, then</p>
<div class="arithmatex">\[
E^{*}\left(1_{A}+1_{B}\right)=v^{*}(A \cup B)+v^{*}(A \cap B)
\]</div>
<p>and</p>
<div class="arithmatex">\[
E^{*}\left(1_{A}\right)+E^{*}\left(1_{B}\right)=v^{*}(A)+v^{*}(B)
\]</div>
<p>Hence if <span class="arithmatex">\(E^{*}\)</span> is subadditive, (2.29) holds. The other direction is more difficult to establish. We first note that (2.29) is equivalent to</p>
<div class="arithmatex">\[
E^{*}(X \vee Y)+E^{*}(X \wedge Y) \leqslant E^{*}(X)+E^{*}(Y), \quad \text { for } X, Y \geqslant 0
\]</div>
<p>where <span class="arithmatex">\(X \vee Y\)</span> and <span class="arithmatex">\(X \wedge Y\)</span> stand for the pointwise supremum and infimum of the two functions <span class="arithmatex">\(X\)</span> and <span class="arithmatex">\(Y\)</span>. This follows at once from</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \{X&gt;t\} \cup\{Y&gt;t\}=\{X \vee Y&gt;t\} \\
&amp; \{X&gt;t\} \cap\{Y&gt;t\}=\{X \wedge Y&gt;t\}
\end{aligned}
\]</div>
<p>Since <span class="arithmatex">\(\Omega\)</span> is a finite set, <span class="arithmatex">\(X\)</span> is a vector <span class="arithmatex">\(\mathbf{x}=\left(x_{1}, \ldots, x_{n}\right)\)</span>, and <span class="arithmatex">\(E^{*}\)</span> is a function of <span class="arithmatex">\(n\)</span> real variables. The proposition now follows from the following lemma.</p>
<p>LEMMA 2.6 (Choquet) If <span class="arithmatex">\(f\)</span> is a positively homogeneous function on <span class="arithmatex">\(\mathbb{R}_{+}^{n}\)</span></p>
<div class="arithmatex">\[
f(c \mathbf{x})=c f(\mathbf{x}), \quad \text { for } c \geqslant 0
\]</div>
<p>satisfying</p>
<div class="arithmatex">\[
f(\mathbf{x} \vee \mathbf{y})+f(\mathbf{x} \wedge \mathbf{y}) \leqslant f(\mathbf{x})+f(\mathbf{y})
\]</div>
<p>then <span class="arithmatex">\(f\)</span> is subadditive:</p>
<div class="arithmatex">\[
f(\mathbf{x}+\mathbf{y}) \leqslant f(\mathbf{x})+f(\mathbf{y})
\]</div>
<p>Proof Assume that <span class="arithmatex">\(f\)</span> is twice continuously differentiable for <span class="arithmatex">\(\mathbf{x} \neq 0\)</span>. Let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \mathbf{a}=\left(x_{1}+h_{1}, x_{2}, \ldots, x_{n}\right) \\
&amp; \mathbf{b}=\left(x_{1}, x_{2}+h_{2}, \ldots, x_{n}+h_{n}\right)
\end{aligned}
\]</div>
<p>with <span class="arithmatex">\(h_{i} \geqslant 0\)</span>; then <span class="arithmatex">\(\mathbf{a} \vee \mathbf{b}=\mathbf{x}+\mathbf{h}, \mathbf{a} \wedge \mathbf{b}=\mathbf{x}\)</span>. If we expand (2.33) into a power series in the <span class="arithmatex">\(h_{i}\)</span>, we find that the second order terms must satisfy</p>
<div class="arithmatex">\[
\sum_{j \neq 1} f_{x_{i} x_{j}} h_{1} h_{j} \leqslant 0
\]</div>
<p>hence</p>
<div class="arithmatex">\[
f_{x_{1} x_{j}} \leqslant 0, \quad \text { for } \quad j \neq 1
\]</div>
<p>and more generally</p>
<div class="arithmatex">\[
f_{x_{i} x_{j}} \leqslant 0, \quad \text { for } \quad i \neq j
\]</div>
<p>Differentiate (2.32) with respect to <span class="arithmatex">\(x_{j}\)</span> :</p>
<div class="arithmatex">\[
c f_{x_{i}}(c \mathbf{x})=c f_{x_{j}}(\mathbf{x})
\]</div>
<p>divide by <span class="arithmatex">\(c\)</span>, and then differentiate with respect to <span class="arithmatex">\(c\)</span> :</p>
<div class="arithmatex">\[
\sum_{i} x_{i} f_{x_{i} x_{j}}=0
\]</div>
<p>If <span class="arithmatex">\(F\)</span> denotes the sum of the second order terms in the Taylor expansion of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(\mathbf{x}\)</span>, we obtain thus</p>
<div class="arithmatex">\[
2 F=-\sum_{i \neq j} x_{i} x_{j} f_{x_{i} x_{j}}\left(\frac{d x_{i}}{x_{i}}-\frac{d x_{j}}{x_{j}}\right)^{2} \geqslant 0
\]</div>
<p>It follows that <span class="arithmatex">\(f\)</span> is convex, and because of (2.32), this is equivalent with being subadditive.</p>
<p>If <span class="arithmatex">\(f\)</span> is not twice continuously differentiable, we must approximate it in a suitable fashion.</p>
<p>In view of Proposition 2.1, we thus obtain that <span class="arithmatex">\(E^{*}\)</span> is the upper expectation induced by the set</p>
<div class="arithmatex">\[
\begin{aligned}
\mathscr{P} &amp; =\left\{P \in \mathscr{M} \mid \int X d P \leqslant E^{*}(X) \text { for all } X\right\} \\
&amp; =\left\{P \in \mathscr{M} \mid P(A) \leqslant v^{*}(A) \text { for all } A\right\}
\end{aligned}
\]</div>
<p>Hence every 2-alternating <span class="arithmatex">\(v^{*}\)</span> is representable, and the corresponding maximal upper expectation is given by (2.30). In particular, (2.30) implies that, for any monotone sequence <span class="arithmatex">\(A_{1} \subset A_{2} \subset \cdots \subset A_{k}\)</span>, it is possible to find a probability <span class="arithmatex">\(Q \leqslant v^{*}\)</span> such that, for all <span class="arithmatex">\(i\)</span>, simultaneously <span class="arithmatex">\(Q\left(A_{i}\right)=v^{*}\left(A_{i}\right)\)</span>.</p>
<h1 id="monotone-and-alternating-capacities-of-infinite-order">Monotone and Alternating Capacities of Infinite Order</h1>
<p>Consider the following generalized gross error model: let ( <span class="arithmatex">\(\Omega^{\prime}, \mathscr{Q}^{\prime}, P^{\prime}\)</span> ) be some probability space, assign to each <span class="arithmatex">\(\omega^{\prime} \in \Omega^{\prime}\)</span> a nonempty subset <span class="arithmatex">\(T\left(\omega^{\prime}\right) \subset \Omega\)</span>,</p>
<p>and put</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; v_{*}(A)=P^{\prime}\left\{\omega^{\prime} \mid T\left(\omega^{\prime}\right) \subset A\right\} \\
&amp; v^{*}(A)=P^{\prime}\left\{\omega^{\prime} \mid T\left(\omega^{\prime}\right) \cap A \neq \phi\right\}
\end{aligned}
\]</div>
<p>We can easily check that <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span> are conjugate set functions. The interpretation is that, instead of the ideal but unobservable outcome <span class="arithmatex">\(\omega^{\prime}\)</span> of the random experiment, the statistician is shown an arbitrary (not necessarily randomly chosen) element of <span class="arithmatex">\(T\left(\omega^{\prime}\right)\)</span>. Clearly, <span class="arithmatex">\(v_{*}(A)\)</span> and <span class="arithmatex">\(v^{*}(A)\)</span> are lower and upper bounds for the probability that the statistician is shown an element of <span class="arithmatex">\(A\)</span>.</p>
<p>It is intuitively clear that <span class="arithmatex">\(v_{*}\)</span> and <span class="arithmatex">\(v^{*}\)</span> are representable; it is easy to check that they are 2 -monotone and 2 -alternating, respectively. In fact a much stronger statement is true: they are monotone (alternating) of infinite order. We do not define this notion here, but refer the reader to Choquet's fundamental paper (1953/54); by a theorem of Choquet, a capacity is monotone/alternating of infinite order iff it can be generated in the forms (2.35) and (2.36), respectively.</p>
<p>Example 2.2 Let <span class="arithmatex">\(Y\)</span> and <span class="arithmatex">\(U\)</span> be two independent real random variables; the first has the idealized distribution <span class="arithmatex">\(P_{0}\)</span>, and the second takes two values <span class="arithmatex">\(\delta \geqslant 0\)</span> and <span class="arithmatex">\(+\infty\)</span> with probability <span class="arithmatex">\(1-\varepsilon\)</span> and <span class="arithmatex">\(\varepsilon\)</span>, respectively. Let <span class="arithmatex">\(T\)</span> be the intervalvalued set function defined by</p>
<div class="arithmatex">\[
T\left(\omega^{\prime}\right)=\left[Y\left(\omega^{\prime}\right)-U\left(\omega^{\prime}\right), Y\left(\omega^{\prime}\right)+U\left(\omega^{\prime}\right)\right]
\]</div>
<p>Then with probability <span class="arithmatex">\(\geqslant 1-\varepsilon\)</span>, the statistician is shown a value <span class="arithmatex">\(x\)</span> that is accurate within <span class="arithmatex">\(\delta\)</span>, that is, <span class="arithmatex">\(\left|x-Y\left(\omega^{\prime}\right)\right| \leqslant \delta\)</span>, and with probability <span class="arithmatex">\(\leqslant \varepsilon\)</span>, he is shown a value containing a gross error.</p>
<p>The generalized gross error model, using monotone and alternating set functions of infinite order, was introduced by Strassen (1964). There has been a considerable literature on set valued stochastic processes <span class="arithmatex">\(T\left(\omega^{\prime}\right)\)</span> in recent years; in particular, see Harding and Kendall (1974) and Matheron (1975). In a statistical context monotone/alternating capacities of infinite order were used by Dempster (1968) and Shafer (1976). The following example shows another application of such capacities [taken from Huber (1973b)].</p>
<p>Example 2.3 Let <span class="arithmatex">\(\alpha_{0}\)</span> be a probability distribution (the idealized prior) on a finite parameter space <span class="arithmatex">\(\Theta\)</span>. The gross error or <span class="arithmatex">\(\varepsilon\)</span>-contamination model</p>
<div class="arithmatex">\[
\mathscr{P}=\left\{\alpha \mid \alpha=(1-\varepsilon) \alpha_{0}+\varepsilon \alpha_{1}, \alpha_{1} \in \mathscr{N}\right\}
\]</div>
<p>can be described by an alternating capacity of infinite order, namely,</p>
<div class="arithmatex">\[
\begin{aligned}
\sup _{\alpha \in \mathscr{Y}} \alpha(A) &amp; =(1-\varepsilon) \alpha_{0}(A)+\varepsilon, &amp; &amp; \text { for } A \neq \phi \\
&amp; =0, &amp; &amp; \text { for } A=\phi
\end{aligned}
\]</div>
<p>Let <span class="arithmatex">\(p(x \mid \theta)\)</span> be the conditional probability of observing <span class="arithmatex">\(x\)</span>, given that <span class="arithmatex">\(\theta\)</span> is true; <span class="arithmatex">\(p(x \mid \theta)\)</span> is assumed to be accurately known. Let</p>
<div class="arithmatex">\[
\beta(\theta \mid x)=\frac{p(x \mid \theta) \alpha(\theta)}{\sum_{\theta} p(x \mid \theta) \alpha(\theta)}
\]</div>
<p>be the posterior distribution of <span class="arithmatex">\(\theta\)</span>, given that <span class="arithmatex">\(x\)</span> has been observed; let <span class="arithmatex">\(\beta_{0}(\theta \mid x)\)</span> be the posterior calculated with the prior <span class="arithmatex">\(\alpha_{0}\)</span>.</p>
<p>The inaccuracy in the prior is transmitted to the posterior:</p>
<div class="arithmatex">\[
\begin{aligned}
v^{*}(A) &amp; =\sup _{\alpha \in \mathscr{Y}} \beta(A \mid x)=\frac{\beta_{0}(A \mid x)+s(A)}{1+s(A)} \\
v_{*}(A) &amp; =\inf _{\alpha \in \mathscr{Y}} \beta(A \mid x)=\frac{\beta_{0}(A \mid x)}{1+s\left(A^{\varepsilon}\right)}
\end{aligned}
\]</div>
<p>where</p>
<div class="arithmatex">\[
\begin{aligned}
s(A) &amp; =\frac{\varepsilon}{1-\varepsilon} \frac{\sup _{\theta \in A} p(x \mid \theta)}{\sum_{\theta} p(x \mid \theta) \alpha_{0}(\theta)}, &amp; &amp; \text { for } A \neq \phi \\
&amp; =0, &amp; &amp; \text { for } A=\phi
\end{aligned}
\]</div>
<p>Then <span class="arithmatex">\(s\)</span> satisfies <span class="arithmatex">\(s(A \cup B)=\max (s(A), s(B))\)</span> and is alternating of infinite order. I do not know the exact order of <span class="arithmatex">\(v^{*}\)</span> (it is at least 2-alternating).</p>
<h1 id="103-robust-tests">10.3 ROBUST TESTS</h1>
<p>The classical probability ratio test between two simple hypotheses <span class="arithmatex">\(P_{0}\)</span> and <span class="arithmatex">\(P_{1}\)</span> is not robust: a single factor <span class="arithmatex">\(p_{1}\left(x_{i}\right) / p_{0}\left(x_{i}\right)\)</span>, equal or almost equal to 0 or <span class="arithmatex">\(\infty\)</span>, may upset the test statistic <span class="arithmatex">\(\prod_{1}^{n} p_{1}\left(x_{i}\right) / p_{0}\left(x_{i}\right)\)</span>. This danger can be averted by censoring the single factors, that is by replacing the test statistic</p>
<p>by <span class="arithmatex">\(\Pi_{1}^{n} \pi\left(x_{i}\right)\)</span>, where <span class="arithmatex">\(\pi\left(x_{i}\right)=\max \left\{c^{\prime}, \min \left[c^{\prime \prime}, p_{1}\left(x_{i}\right) / p_{0}\left(x_{i}\right)\right]\right\}\)</span>, with <span class="arithmatex">\(0&lt;c^{\prime}&lt;c^{\prime \prime}\)</span> <span class="arithmatex">\(&lt;\infty\)</span>.</p>
<p>Somewhat surprisingly, it turns out that this test possesses exact finite sample minimax properties for a wide variety of models: tests of the above structure are minimax for testing between composite hypotheses <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span>, where <span class="arithmatex">\(\mathscr{P}_{j}\)</span> is a neighborhood of <span class="arithmatex">\(P_{j}\)</span> in <span class="arithmatex">\(\varepsilon\)</span>-contamination, or total variation, and so on.</p>
<p>In principle <span class="arithmatex">\(P_{0}\)</span> and <span class="arithmatex">\(P_{1}\)</span> can be arbitrary probability measures on arbitrary measurable spaces [cf. Huber (1965)]. But in order to prepare the ground for Section 10.5, from now on we assume that they are probability distributions on the real line. In fact very little generality is lost this way, since almost everything admits a reinterpretation in terms of the real random variable <span class="arithmatex">\(p_{1}(X) / p_{0}(X)\)</span>, under various distributions of <span class="arithmatex">\(X\)</span>.</p>
<p>Let <span class="arithmatex">\(P_{0}\)</span> and <span class="arithmatex">\(P_{1}, P_{0} \neq P_{1}\)</span>, be two probability measures on the real line. Let <span class="arithmatex">\(p_{0}\)</span> and <span class="arithmatex">\(p_{1}\)</span> be their densities with respect to some measure <span class="arithmatex">\(\mu\)</span> (e.g., <span class="arithmatex">\(\mu=P_{0}+P_{1}\)</span> ), and assume that the likelihood ratio <span class="arithmatex">\(p_{1}(x) / p_{0}(x)\)</span> is almost surely (with respect to <span class="arithmatex">\(\mu\)</span> ) equal to a monotone function <span class="arithmatex">\(c(x)\)</span>.</p>
<p>Let <span class="arithmatex">\(\mathscr{O}\)</span> be the set of all probability measures on the real line, let <span class="arithmatex">\(0 \leqslant \varepsilon_{0}, \varepsilon_{1}, \delta_{0}, \delta_{1}&lt;1\)</span> be some given numbers, and let</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \mathscr{P}_{0}=\left\{Q \in \mathscr{O} \mid Q\{X&lt;x\} \geqslant\left(1-\varepsilon_{0}\right) P_{0}\{X&lt;x\}-\delta_{0} \text { for all } x\right\} \\
&amp; \mathscr{P}_{1}=\left\{Q \in \mathscr{O} \mid Q\{X&gt;x\} \geqslant\left(1-\varepsilon_{1}\right) P_{1}\{X&gt;x\}-\delta_{1} \text { for all } x\right\}
\end{aligned}
\]</div>
<p>We assume that <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span> are disjoint (i.e., that <span class="arithmatex">\(\varepsilon_{j}\)</span> and <span class="arithmatex">\(\delta_{j}\)</span> are sufficiently small).</p>
<p>It may help to visualize <span class="arithmatex">\(\mathscr{P}_{0}\)</span> as the set of distribution functions lying above the solid line <span class="arithmatex">\(\left(1-\varepsilon_{0}\right) P_{0}(x)-\delta_{0}\)</span> in Exhibit 10.3.1 and <span class="arithmatex">\(\mathscr{P}_{1}\)</span> as the set of distribution functions lying below the dotted line <span class="arithmatex">\(\left(1-\varepsilon_{1}\right) P_{1}(x)+\varepsilon_{1}+\delta_{1}\)</span>. As before <span class="arithmatex">\(P\{\cdot\}\)</span> denotes the set function, <span class="arithmatex">\(P(\cdot)\)</span> the corresponding distribution function: <span class="arithmatex">\(P(x)=P\{(-\infty, x)\}\)</span>.</p>
<p>Now let <span class="arithmatex">\(\varphi\)</span> be any (randomized) test between <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span>, rejecting <span class="arithmatex">\(\mathscr{P}_{j}\)</span> with conditional probability <span class="arithmatex">\(\varphi_{j}(\mathbf{x})\)</span> given that <span class="arithmatex">\(\mathbf{x}=\left(x_{1}, \ldots, x_{n}\right)\)</span> has been observed.
<img alt="img-17.jpeg" src="data:image/jpeg;base64,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" /></p>
<p>Exhlbit 10.3.1</p>
<p>Assume that a loss <span class="arithmatex">\(L_{j}&gt;0\)</span> is incurred if <span class="arithmatex">\(\mathscr{P}_{j}\)</span> is falsely rejected; then the expected loss, or risk, is</p>
<div class="arithmatex">\[
R\left(Q_{j}^{\prime}, \varphi\right)=L_{j} E_{Q_{j}^{\prime}}\left(\varphi_{j}\right)
\]</div>
<p>if <span class="arithmatex">\(Q_{j}^{\prime} \in \mathscr{P}_{j}\)</span> is the true underlying distribution. The problem is to find a minimax test, that is, to minimize</p>
<div class="arithmatex">\[
\max _{j=0,1} \sup _{Q_{j}^{\prime} \in \mathscr{P}_{j}^{\prime}} R\left(Q_{i}^{\prime}, \varphi\right)
\]</div>
<p>These minimax tests happen to have quite a simple structure in our case. There is a least favorable pair <span class="arithmatex">\(Q_{0} \in \mathscr{P}_{0}, Q_{1} \in \mathscr{P}_{1}\)</span>, such that, for all sample sizes, the probability ratio tests <span class="arithmatex">\(\varphi\)</span> between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> satisfy</p>
<div class="arithmatex">\[
R\left(Q_{j}^{\prime}, \varphi\right) \leqslant R\left(Q_{j}, \varphi\right), \quad \text { for } Q_{j}^{\prime} \in \mathscr{P}_{j}
\]</div>
<p>Thus in view of the Neyman-Pearson lemma, the probability ratio tests between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> form an essentially complete class of minimax tests between <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span>. The pair <span class="arithmatex">\(Q_{0}, Q_{1}\)</span> is not unique, in general, but the probability ratio <span class="arithmatex">\(d Q_{1} / d Q_{0}\)</span> is essentially unique; as already mentioned it will be a censored version of <span class="arithmatex">\(d P_{1} / d P_{0}\)</span>.</p>
<p>It is in fact quite easy to guess such a pair <span class="arithmatex">\(Q_{0}, Q_{1}\)</span>. The successful conjecture is that there are two numbers <span class="arithmatex">\(x_{0}&lt;x_{1}\)</span>, such that the <span class="arithmatex">\(Q_{j}(\cdot)\)</span> coincide with the respective boundaries between <span class="arithmatex">\(x_{0}\)</span> and <span class="arithmatex">\(x_{1}\)</span>; in particular, their densities thus will satisfy</p>
<div class="arithmatex">\[
q_{j}(x)=\left(1-\varepsilon_{j}\right) p_{j}(x), \quad \text { for } x_{0} \leqslant x \leqslant x_{1}
\]</div>
<p>On <span class="arithmatex">\(\left(-\infty, x_{0}\right)\)</span> and on <span class="arithmatex">\(\left(x_{1}, \infty\right)\)</span>, we expect the likelihood ratios to be constant, and we try densities of the form</p>
<div class="arithmatex">\[
q_{j}(x)=a p_{0}(x)+b p_{1}(x)
\]</div>
<p>The various internal consistency requirements, in particular that</p>
<div class="arithmatex">\[
\begin{array}{ll}
Q_{0}(x)=\left(1-\varepsilon_{0}\right) P_{0}(x)-\delta_{0}, &amp; \text { for } x_{0} \leqslant x \leqslant x_{1} \\
Q_{1}(x)=\left(1-\varepsilon_{1}\right) P_{1}(x)+\varepsilon_{1}+\delta_{1}, &amp; \text { for } x_{0} \leqslant x \leqslant x_{1}
\end{array}
\]</div>
<p>now lead easily to the following explicit formulas (we skip the step-by-step derivation, just stating the final results and then checking them).</p>
<p>Put</p>
<div class="arithmatex">\[
\begin{array}{ll}
v^{\prime}=\frac{\varepsilon_{1}+\delta_{1}}{1-\varepsilon_{1}}, &amp; v^{\prime \prime}=\frac{\varepsilon_{0}+\delta_{0}}{1-\varepsilon_{0}} \\
w^{\prime}=\frac{\delta_{0}}{1-\varepsilon_{0}}, &amp; w^{\prime \prime}=\frac{\delta_{1}}{1-\varepsilon_{1}}
\end{array}
\]</div>
<p>It turns out to be somewhat more convenient to characterize the middle interval between <span class="arithmatex">\(x_{0}\)</span> and <span class="arithmatex">\(x_{1}\)</span> in terms of <span class="arithmatex">\(c(x)\)</span> than in terms of the <span class="arithmatex">\(x\)</span> themselves: <span class="arithmatex">\(c^{\prime}&lt;c(x)&lt;1 / c^{\prime \prime}\)</span> for some constants <span class="arithmatex">\(c^{\prime}\)</span> and <span class="arithmatex">\(c^{\prime \prime}\)</span>, which are determined later. Since <span class="arithmatex">\(c(x)\)</span> need not be continuous or strictly monotone, the two variants are not entirely equivalent.</p>
<p>If both <span class="arithmatex">\(v^{\prime}&gt;0\)</span> and <span class="arithmatex">\(v^{\prime \prime}&gt;0\)</span>, we define <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> by their densities, as follows. Denote the three regions <span class="arithmatex">\(c(x) \leqslant c^{\prime}, c^{\prime}&lt;c(x)&lt;1 / c^{\prime \prime}\)</span>, and <span class="arithmatex">\(1 / c^{\prime \prime} \leqslant\)</span> <span class="arithmatex">\(c(x)\)</span> by <span class="arithmatex">\(I_{-}, I_{0}\)</span>, and <span class="arithmatex">\(I_{+}\)</span>, respectively. Then</p>
<div class="arithmatex">\[
\begin{aligned}
q_{0}(x) &amp; =\frac{1-\varepsilon_{0}}{v^{\prime}+w^{\prime} c^{\prime}}\left[v^{\prime} p_{0}(x)+w^{\prime} p_{1}(x)\right], &amp; &amp; \text { on } I_{-} \\
&amp; =\left(1-\varepsilon_{0}\right) p_{0}(x), &amp; &amp; \text { on } I_{0} \\
&amp; =\frac{\left(1-\varepsilon_{0}\right) c^{\prime \prime}}{v^{\prime \prime}+w^{\prime \prime} c^{\prime \prime}}\left[w^{\prime \prime} p_{0}(x)+v^{\prime \prime} p_{1}(x)\right], &amp; &amp; \text { on } I_{+} \\
q_{1}(x) &amp; =\frac{\left(1-\varepsilon_{1}\right) c^{\prime}}{v^{\prime}+w^{\prime} c^{\prime}}\left[v^{\prime} p_{0}(x)+w^{\prime} p_{1}(x)\right], &amp; &amp; \text { on } I_{-} \\
&amp; =\left(1-\varepsilon_{1}\right) p_{1}(x), &amp; &amp; \text { on } I_{0} \\
&amp; =\frac{\left(1-\varepsilon_{1}\right)}{v^{\prime \prime}+w^{\prime \prime} c^{\prime \prime}}\left[w^{\prime \prime} p_{0}(x)+v^{\prime \prime} p_{1}(x)\right], &amp; &amp; \text { on } I_{+}
\end{aligned}
\]</div>
<p>If, say, <span class="arithmatex">\(v^{\prime}=0\)</span>, then <span class="arithmatex">\(w^{\prime \prime}=0\)</span>, and the above formulas simplify to</p>
<div class="arithmatex">\[
\begin{aligned}
q_{0}(x) &amp; =\left(1-\varepsilon_{0}\right) \frac{1}{c^{\prime}} p_{1}(x), &amp; &amp; \text { on } I_{-} \\
&amp; =\left(1-\varepsilon_{0}\right) p_{0}(x), &amp; &amp; \text { on } I_{0} \\
&amp; =\left(1-\varepsilon_{0}\right) c^{\prime \prime} p_{1}(x), &amp; &amp; \text { on } I_{+} \\
q_{1}(x) &amp; =p_{1}(x), &amp; &amp; \text { for all } x
\end{aligned}
\]</div>
<p>It is evident from (3.6) [and (3.7)] that the likelihood ratio has the postulated form</p>
<div class="arithmatex">\[
\begin{aligned}
\pi(x)=\frac{q_{1}(x)}{q_{0}(x)} &amp; =\frac{1-\varepsilon_{1}}{1-\varepsilon_{0}} c^{\prime}, &amp; &amp; \text { on } I_{-} \\
&amp; =\frac{1-\varepsilon_{1}}{1-\varepsilon_{0}} c(x), &amp; &amp; \text { on } I_{0} \\
&amp; =\frac{1-\varepsilon_{1}}{1-\varepsilon_{0}} \cdot \frac{1}{c^{\prime \prime}}, &amp; &amp; \text { on } I_{+}
\end{aligned}
\]</div>
<p>Moreover, since <span class="arithmatex">\(p_{1}(x) / p_{0}(x)=c(x)\)</span> is monotone, (3.6) implies</p>
<div class="arithmatex">\[
\begin{array}{ll}
q_{0}(x) \leqslant\left(1-\varepsilon_{0}\right) p_{0}(x), &amp; \text { on } I_{-} \\
q_{0}(x) \geqslant\left(1-\varepsilon_{0}\right) p_{0}(x), &amp; \text { on } I_{+}
\end{array}
\]</div>
<p>and dual relations hold for <span class="arithmatex">\(q_{1}\)</span>.
In view of (3.9) we have <span class="arithmatex">\(Q_{j} \in \mathscr{P}_{j}\)</span>, with <span class="arithmatex">\(Q_{j}(\cdot)\)</span> touching the boundary between <span class="arithmatex">\(x_{0}\)</span> and <span class="arithmatex">\(x_{1}\)</span> if four relations hold, the first of which is</p>
<div class="arithmatex">\[
\int_{c(x)&lt;c^{\prime}}\left[\left(1-\varepsilon_{0}\right) p_{0}(x)-q_{0}(x)\right] d \mu=\delta_{0}
\]</div>
<p>The other three are obtained by interchanging left and right, and the roles of <span class="arithmatex">\(P_{0}\)</span> and <span class="arithmatex">\(P_{1}\)</span>.</p>
<p>If we insert (3.6) into (3.10), we obtain the equivalent condition</p>
<div class="arithmatex">\[
\int\left[c^{\prime} p_{0}(x)-p_{1}(x)\right]^{+} d \mu=v^{\prime}+w^{\prime} c^{\prime}
\]</div>
<p>Of the other three relations, one coincides with (3.11), the other two with</p>
<div class="arithmatex">\[
\int\left[c^{\prime \prime} p_{1}(x)-p_{0}(x)\right]^{+} d \mu=v^{\prime \prime}+w^{\prime \prime} c^{\prime \prime}
\]</div>
<p>We must now show that (3.11) and (3.12) have solutions <span class="arithmatex">\(c^{\prime}\)</span> and <span class="arithmatex">\(c^{\prime \prime}\)</span>, respectively. Evidently, it suffices to discuss (3.11).</p>
<p>If <span class="arithmatex">\(v^{\prime}=0\)</span>, we have the trivial solution <span class="arithmatex">\(c^{\prime}=0\)</span> (and perhaps also some others). Let us exclude this case and put</p>
<div class="arithmatex">\[
f(z)=\frac{\int\left(z p_{0}-p_{1}\right)^{+} d \mu}{v^{\prime}+w^{\prime} z}, \quad z \geqslant 0
\]</div>
<p>We have to find a <span class="arithmatex">\(z\)</span> such that <span class="arithmatex">\(f(z)=1\)</span>. Let <span class="arithmatex">\(\Delta \geqslant 0\)</span>, then</p>
<div class="arithmatex">\[
f(z+\Delta)-f(z)=\frac{\Delta \int_{E}\left(v^{\prime}+w^{\prime} c\right) p_{0} d \mu+\int_{E^{\prime}}\left(v^{\prime}+w z\right)(z+\Delta-c) p_{0} d \mu}{\left(v^{\prime}+w^{\prime} z\right)\left[v^{\prime}+w^{\prime}(z+\Delta)\right]}
\]</div>
<p>with</p>
<div class="arithmatex">\[
E=\{x \mid c(x) \leqslant z\}, \quad E^{\prime}=\{x \mid z&lt;c(x) \leqslant z+\Delta\}
\]</div>
<p>Hence</p>
<div class="arithmatex">\[
0 \leqslant f(z+\Delta)-f(z) \leqslant \frac{\Delta}{v^{\prime}+w^{\prime}(z+\Delta)}
\]</div>
<p>and it follows that <span class="arithmatex">\(f\)</span> is monotone increasing and continuous.
As <span class="arithmatex">\(z \rightarrow \infty, f(z) \rightarrow 1 / w^{\prime}\)</span>, and as <span class="arithmatex">\(z \rightarrow 0, f(z) \rightarrow 0\)</span>. Thus there is a solution <span class="arithmatex">\(c^{\prime}\)</span> for which <span class="arithmatex">\(f\left(c^{\prime}\right)=1\)</span>, provided <span class="arithmatex">\(w^{\prime}&lt;1\)</span>. (Note that <span class="arithmatex">\(w^{\prime} \geqslant 1\)</span> implies <span class="arithmatex">\(\mathscr{P}_{0}=\mathscr{P R}\)</span>; hence <span class="arithmatex">\(\mathscr{P}_{0} \cap \mathscr{P}_{1}=\phi\)</span> ensures <span class="arithmatex">\(\left.w^{\prime}&lt;1.\right)\)</span></p>
<p>It can be seen from (3.11) and (3.14) that <span class="arithmatex">\(f(z)\)</span> is strictly monotone for</p>
<div class="arithmatex">\[
z&gt;c_{1}=\text { ess. } \inf c(x)
\]</div>
<p>Since <span class="arithmatex">\(f(z)=0\)</span> for <span class="arithmatex">\(0 \leqslant z \leqslant c_{1}\)</span>, the solution <span class="arithmatex">\(c^{\prime}\)</span> is unique.
We can write the likelihood ratio between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> in the form</p>
<div class="arithmatex">\[
\frac{q_{1}(x)}{q_{0}(x)}=\frac{1-\varepsilon_{1}}{1-\varepsilon_{0}} \tilde{\pi}(x)
\]</div>
<p>with</p>
<div class="arithmatex">\[
\begin{aligned}
\tilde{\pi}(x) &amp; =c^{\prime}, &amp; &amp; \text { on } I_{-} \\
&amp; =c(x), &amp; &amp; \text { on } I_{0} \\
&amp; =1 / c^{\prime \prime}, &amp; &amp; \text { on } I_{+}
\end{aligned}
\]</div>
<p>(assuming that <span class="arithmatex">\(c^{\prime}&lt;1 / c^{\prime \prime}\)</span> ).</p>
<h1 id="lemma-31">LEMMA 3.1</h1>
<div class="arithmatex">\[
\begin{array}{ll}
Q_{0}^{\prime}(\tilde{\pi}&lt;t) \geqslant Q_{0}(\tilde{\pi}&lt;t), &amp; \text { for } Q_{0}^{\prime} \in \mathscr{P}_{0} \\
Q_{1}^{\prime}(\tilde{\pi}&lt;t) \leqslant Q_{1}(\tilde{\pi}&lt;t), &amp; \text { for } Q_{1}^{\prime} \in \mathscr{P}_{1}
\end{array}
\]</div>
<p>Proof These relations are trivially true for <span class="arithmatex">\(t \leqslant c^{\prime}\)</span> and for <span class="arithmatex">\(t&gt;1 / c^{\prime \prime}\)</span>. For <span class="arithmatex">\(c^{\prime}&lt;t&lt;1 / c^{\prime \prime}\)</span> they boil down to the inequalities in (3.1).</p>
<p>In other words among all distributions in <span class="arithmatex">\(\mathscr{P}_{0}, \tilde{\pi}\)</span> is stochastically largest for <span class="arithmatex">\(Q_{0}\)</span>, and among all distributions in <span class="arithmatex">\(\mathscr{P}_{1}, \tilde{\pi}\)</span> is stochastically smallest for <span class="arithmatex">\(Q_{1}\)</span>.</p>
<p>THEOREM 3.2 For any sample size <span class="arithmatex">\(n\)</span> and any level <span class="arithmatex">\(\alpha\)</span>, the NeymanPearson test of level <span class="arithmatex">\(\alpha\)</span> between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span>, namely</p>
<div class="arithmatex">\[
\begin{aligned}
\varphi(\mathbf{x}) &amp; =1, &amp; &amp; \text { for } \quad \Pi_{1}^{n} \tilde{\pi}\left(x_{i}\right)&gt;C \\
&amp; =\gamma, &amp; &amp; \text { for } \quad \Pi_{1}^{n} \tilde{\pi}\left(x_{i}\right)=C \\
&amp; =0, &amp; &amp; \text { for } \quad \Pi_{1}^{n} \tilde{\pi}\left(x_{i}\right)&lt;C
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(C\)</span> and <span class="arithmatex">\(\gamma\)</span> are chosen such that <span class="arithmatex">\(E_{Q_{0}} \varphi=\alpha\)</span>, is a minimax test between <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span>, with the same level</p>
<div class="arithmatex">\[
\sup _{\mathscr{P}_{0}} E \varphi=\alpha
\]</div>
<p>and the same minimum power</p>
<div class="arithmatex">\[
\inf _{\mathscr{P}_{1}} E \varphi=E_{Q_{1}} \varphi
\]</div>
<p>Proof This is an immediate consequence of Lemma 3.1 and of the following well-known Lemma 3.3 [putting <span class="arithmatex">\(U_{i}=\log \tilde{\pi}\left(X_{i}\right), \mathcal{E}\left(X_{i}\right)=Q\)</span>, etc.].</p>
<p>LEMMA 3.3 Let <span class="arithmatex">\(\left(U_{i}\right)\)</span> and <span class="arithmatex">\(\left(V_{i}\right), i=1,2, \ldots\)</span>, be two sequences of random variables, such that the <span class="arithmatex">\(U_{i}\)</span> are independent among themselves, the <span class="arithmatex">\(V_{i}\)</span> are independent among themselves, and <span class="arithmatex">\(U_{i}\)</span> is stochastically larger than <span class="arithmatex">\(V_{i}\)</span>, for all <span class="arithmatex">\(i\)</span>. Then, for all <span class="arithmatex">\(n, \Sigma_{1}^{n} U_{i}\)</span> is stochastically larger than <span class="arithmatex">\(\Sigma_{1}^{n} V_{i}\)</span>.
Proof Let <span class="arithmatex">\(\left(Z_{i}\right)\)</span> be a sequence of independent random variables with uniform distribution in <span class="arithmatex">\((0,1)\)</span>, and let <span class="arithmatex">\(F_{i}&lt;G_{i}\)</span> be the distribution functions of <span class="arithmatex">\(U_{i}\)</span> and <span class="arithmatex">\(V_{i}\)</span>, respectively. Then <span class="arithmatex">\(F_{i}^{-1}\left(Z_{i}\right)\)</span> has the same distribution as <span class="arithmatex">\(U_{i}\)</span>, <span class="arithmatex">\(G_{i}^{-1}\left(Z_{i}\right)\)</span> has the same distribution as <span class="arithmatex">\(V_{i}\)</span>, and the conclusion follows easily from <span class="arithmatex">\(F_{i}^{-1}\left(Z_{i}\right) \geqslant G_{i}^{-1}\left(Z_{i}\right)\)</span>.</p>
<p>For the above we have assumed that <span class="arithmatex">\(c^{\prime}&lt;1 / c^{\prime \prime}\)</span>. We now show that this is equivalent to our initial assumption that <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span> are disjoint. If <span class="arithmatex">\(c^{\prime}=1 / c^{\prime \prime}\)</span>,</p>
<p>then <span class="arithmatex">\(Q_{0}=Q_{1}\)</span>, and the sets <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span> overlap. Since the solutions <span class="arithmatex">\(c^{\prime}\)</span> and <span class="arithmatex">\(c^{\prime \prime}\)</span> of (3.11) and (3.12) are monotone increasing in the <span class="arithmatex">\(\varepsilon_{j}, \delta_{j}\)</span>, the overlap is even worse if <span class="arithmatex">\(c^{\prime}&gt;1 / c^{\prime \prime}\)</span>. On the other hand if <span class="arithmatex">\(c^{\prime}&lt;1 / c^{\prime \prime}\)</span>, then <span class="arithmatex">\(Q_{0} \neq Q_{1}\)</span>, and <span class="arithmatex">\(Q_{0}\{\tilde{\pi}&lt;t\} \geqslant Q_{1}\{\tilde{\pi}&lt;t\}\)</span> with strict inequality for some <span class="arithmatex">\(t=t_{0}\)</span> [the power of a Neyman-Pearson test exceeds its size, cf. Lehmann (1959), p. 67, Corollary 1]. In view of Lemma 3.1, then <span class="arithmatex">\(Q_{0}^{\prime}\left\{\tilde{\pi}&lt;t_{0}\right\}&gt;Q_{1}^{\prime}\left\{\tilde{\pi}&lt;t_{0}\right\}\)</span>; hence <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span> do not overlap.</p>
<p>The limiting test for the case <span class="arithmatex">\(c^{\prime}=1 / c^{\prime \prime}\)</span> is of some interest; it is a kind of sign test, based on the number of observations for which <span class="arithmatex">\(p_{1}(x) / p_{0}(x) \gtrless c^{\prime}\)</span>. Incidentally, if <span class="arithmatex">\(\varepsilon_{0}=\varepsilon_{1}\)</span>, the limiting value is <span class="arithmatex">\(c^{\prime}=1\)</span>.</p>
<h1 id="particular-cases">Particular Cases</h1>
<p>In the following we assume that either <span class="arithmatex">\(\delta_{j}=0\)</span> or <span class="arithmatex">\(\varepsilon_{j}=0\)</span>. Note that the set <span class="arithmatex">\(\mathscr{G}_{0}\)</span>, defined in (3.1), contains each of the following five sets (1) to (5), and that <span class="arithmatex">\(Q_{0}\)</span> is contained in each of them. It follows that the minimax tests of Theorem 3.2 are also minimax for testing between neighborhoods specified in terms of <span class="arithmatex">\(\varepsilon\)</span>-contamination, total variation, Prohorov distance, Kolmogorov distance, and Lévy distance, assuming only that <span class="arithmatex">\(p_{1}(x) / p_{0}(x)\)</span> is monotone for the pair of idealized model distributions.
(1) <span class="arithmatex">\(\varepsilon\)</span>-contamination With <span class="arithmatex">\(\delta_{0}=0\)</span>,</p>
<div class="arithmatex">\[
\left\{Q \in \mathscr{M} \mid Q=\left(1-\varepsilon_{0}\right) P_{0}+\varepsilon_{0} H, H \in \mathscr{M}\right\}
\]</div>
<p>(2) Total variation With <span class="arithmatex">\(\varepsilon_{0}=0\)</span>,</p>
<div class="arithmatex">\[
\left\{Q \in \mathscr{M}|\forall A| Q\{A\}-P_{0}\{A\}| \leqslant \delta_{0}\right\}
\]</div>
<p>(3) Prohorov With <span class="arithmatex">\(\varepsilon_{0}=0\)</span> and <span class="arithmatex">\(P_{0, \eta}(x)=P_{0}(x-\eta)\)</span>,</p>
<div class="arithmatex">\[
\left\{Q \in \mathscr{M} \mid \forall A Q\{A\} \leqslant P_{0, \eta}\left\{A^{\eta}\right\}+\delta_{0}\right\}
\]</div>
<p>(4) Kolmogorov With <span class="arithmatex">\(\varepsilon_{0}=0\)</span>,</p>
<div class="arithmatex">\[
\left\{Q \in \mathscr{M}|\forall x| Q(x)-P_{0}(x)| \leqslant \delta_{0}\right\}
\]</div>
<p>(5) Lévy With <span class="arithmatex">\(\varepsilon_{0}=0\)</span> and <span class="arithmatex">\(P_{0, \eta}(x)=P_{0}(x-\eta)\)</span>,</p>
<div class="arithmatex">\[
\left\{Q \in \mathscr{M} \mid P_{0, \eta}(x-\eta)-\delta_{0} \leqslant Q(x) \leqslant P_{0, \eta}(x+\eta)+\delta_{0} \text { for all } x\right\}
\]</div>
<p>Note that the gross error model (1) and the total variation model (2) make sense in arbitrary probability spaces; a closer look at the above proof</p>
<p>shows that monotonicity of <span class="arithmatex">\(p_{1}(x) / p_{0}(x)\)</span> then is not needed and that the proof carries through in arbitrary probability spaces.</p>
<p>Furthermore note that the hypothesis <span class="arithmatex">\(\mathscr{P}_{0}\)</span> of (3.1) is such that it contains with every <span class="arithmatex">\(Q\)</span> also all <span class="arithmatex">\(Q^{\prime}\)</span> stochastically smaller than <span class="arithmatex">\(Q\)</span>; similarly, <span class="arithmatex">\(\mathscr{P}_{1}\)</span> contains with every <span class="arithmatex">\(Q\)</span> also all <span class="arithmatex">\(Q^{\prime}\)</span> stochastically larger than <span class="arithmatex">\(Q\)</span>. This has the important consequence that, if <span class="arithmatex">\(\left(P_{\theta}\right)_{\theta \in \mathbf{R}}\)</span> is a monotone likelihood ratio family, that is, if <span class="arithmatex">\(p_{\theta_{1}}(x) / p_{\theta_{0}}(x)\)</span> is monotone increasing in <span class="arithmatex">\(x\)</span> if <span class="arithmatex">\(\theta_{0}&lt;\theta_{1}\)</span>, then the test of Theorem 3.2 constructed for neighborhoods <span class="arithmatex">\(\mathscr{P}_{j}\)</span> of <span class="arithmatex">\(P_{\theta_{j}}, j=0,1\)</span>, is not only a minimax test for testing <span class="arithmatex">\(\theta_{0}\)</span> against <span class="arithmatex">\(\theta_{1}\)</span>, but also for testing <span class="arithmatex">\(\theta&lt;\theta_{0}\)</span> against <span class="arithmatex">\(\theta \geqslant \theta_{1}\)</span>.</p>
<p>Example 3.1 Normal Distribution Let <span class="arithmatex">\(P_{0}\)</span> and <span class="arithmatex">\(P_{1}\)</span> be normal distributions with variance 1 and mean <span class="arithmatex">\(-a\)</span> and <span class="arithmatex">\(+a\)</span>, respectively. Then <span class="arithmatex">\(g(x)=\)</span> <span class="arithmatex">\(p_{1}(x) / p_{0}(x)=e^{2 a x}\)</span>. Assume that <span class="arithmatex">\(\varepsilon_{0}=\varepsilon_{1}=\varepsilon\)</span>, and <span class="arithmatex">\(\delta_{0}=\delta_{1}=\delta\)</span>; then for reasons of symmetry <span class="arithmatex">\(c^{\prime}=c^{\prime \prime}\)</span>. Write the common value in the form <span class="arithmatex">\(c^{\prime}=e^{-2 a k}\)</span>; then (3.11) reduces to</p>
<div class="arithmatex">\[
e^{-2 a k} \Phi(a-k)-\Phi(-a-k)=\frac{\varepsilon+\delta+\delta e^{-2 a k}}{1-\varepsilon}
\]</div>
<p>Assume that <span class="arithmatex">\(k\)</span> has been determined from this equation. Then the logarithm of the test statistic in Theorem 3.2 is, apart from a constant factor,</p>
<div class="arithmatex">\[
h(\mathbf{x})=\sum_{1}^{n} \psi\left(x_{i}\right)
\]</div>
<p>with</p>
<div class="arithmatex">\[
\psi(x)=\max (-k, \min (k, x))
\]</div>
<p>Exhibit 10.3.2 shows some numerical results. Note that the values of <span class="arithmatex">\(k\)</span> are surprisingly small: if <span class="arithmatex">\(\delta \geqslant 0.0005\)</span>, then <span class="arithmatex">\(k \leqslant 2.5\)</span>, and if <span class="arithmatex">\(\delta \geqslant 0.01\)</span>, then <span class="arithmatex">\(k \leqslant 1.5\)</span>, for all choices of <span class="arithmatex">\(a\)</span>.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"><span class="arithmatex">\(a\)</span></th>
<th style="text-align: center;"><span class="arithmatex">\(k=0\)</span></th>
<th style="text-align: center;">0.5</th>
<th style="text-align: center;">1.0</th>
<th style="text-align: center;">1.5</th>
<th style="text-align: center;">2.0</th>
<th style="text-align: center;">2.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.020</td>
<td style="text-align: center;">0.010</td>
<td style="text-align: center;">0.004</td>
<td style="text-align: center;">0.0014</td>
<td style="text-align: center;">0.0004</td>
<td style="text-align: center;">0.00010</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.040</td>
<td style="text-align: center;">0.020</td>
<td style="text-align: center;">0.008</td>
<td style="text-align: center;">0.0029</td>
<td style="text-align: center;">0.0008</td>
<td style="text-align: center;">0.00019</td>
</tr>
<tr>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.039</td>
<td style="text-align: center;">0.016</td>
<td style="text-align: center;">0.0055</td>
<td style="text-align: center;">0.0015</td>
<td style="text-align: center;">0.00035</td>
</tr>
<tr>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.191</td>
<td style="text-align: center;">0.090</td>
<td style="text-align: center;">0.034</td>
<td style="text-align: center;">0.0103</td>
<td style="text-align: center;">0.0025</td>
<td style="text-align: center;">0.00048</td>
</tr>
<tr>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.341</td>
<td style="text-align: center;">0.162</td>
<td style="text-align: center;">0.040</td>
<td style="text-align: center;">0.0087</td>
<td style="text-align: center;">0.0016</td>
<td style="text-align: center;">0.00022</td>
</tr>
<tr>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.433</td>
<td style="text-align: center;">0.135</td>
<td style="text-align: center;">0.027</td>
<td style="text-align: center;">0.0042</td>
<td style="text-align: center;">0.0005</td>
<td style="text-align: center;">0.00006</td>
</tr>
<tr>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">0.477</td>
<td style="text-align: center;">0.111</td>
<td style="text-align: center;">0.014</td>
<td style="text-align: center;">0.0015</td>
<td style="text-align: center;">0.0001</td>
<td style="text-align: center;">0.00001</td>
</tr>
</tbody>
</table>
<p>Exhibit 10.3.2 Values of <span class="arithmatex">\(\delta\)</span> in function of <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(k(\varepsilon=0)\)</span>. From Huber (1968), with permission of the publisher.</p>
<p>Example 3.2 Binomial Distributions Let <span class="arithmatex">\(\Omega=\{0,1\}\)</span>, and let <span class="arithmatex">\(b(x \mid p)=\)</span> <span class="arithmatex">\(p^{x}(1-p)^{1-x}, x=0,1\)</span>. The problem is to test between <span class="arithmatex">\(p=\pi_{0}\)</span> and <span class="arithmatex">\(p=\pi_{1}\)</span>, <span class="arithmatex">\(0 \leqslant \pi_{0}&lt;\pi_{1} \leqslant 1\)</span>, when there is uncertainty in terms of total variation. This means that</p>
<div class="arithmatex">\[
\mathscr{G}_{j}=\left\{b(\cdot \mid p) \mid 0 \leqslant p \leqslant 1, \pi_{j}-\delta_{j} \leqslant p \leqslant \pi_{j}+\delta_{j}\right\}
\]</div>
<p>It is evident that the minimax tests between <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span> coincide with the Neyman-Pearson tests of the same level between <span class="arithmatex">\(b\left(\cdot \mid \pi_{0}+\delta_{0}\right)\)</span> and <span class="arithmatex">\(b\left(\cdot \mid \pi_{1}-\right.\)</span> <span class="arithmatex">\(\delta_{1}\)</span> ), provided <span class="arithmatex">\(\pi_{0}+\delta_{0}&lt;\pi_{1}-\delta_{1}\)</span>. (This trivial example is used to construct a counterexample in the following section).</p>
<p>In general, the level and power of these robust tests are not easy to determine. It is, however, possible to attack such problems asymptotically, assuming that, simultaneously, the hypotheses approach each other at a rate <span class="arithmatex">\(\theta_{1}-\theta_{0} \sim n^{-1 / 2}\)</span>, while the neighborhood parameters <span class="arithmatex">\(\varepsilon\)</span> and <span class="arithmatex">\(\delta\)</span> shrink at the same rate. For details, see Section 11.2.</p>
<h1 id="104-sequential-tests">10.4 SEQUENTIAL TESTS</h1>
<p>Let <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span> be two composite hypotheses as in the preceding section, and let <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> be a least favorable pair with probability ratio <span class="arithmatex">\(\pi(x)=\)</span> <span class="arithmatex">\(q_{1}(x) / q_{0}(x)\)</span>. We saw that this pair is least favorable for all fixed sample sizes. What happens if we use the sequential probability ratio test (SPRT) between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> to discriminate between <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span> ?</p>
<p>Put <span class="arithmatex">\(\gamma(x)=\log \pi(x)\)</span> and let us agree that the SPRT terminates as soon as</p>
<div class="arithmatex">\[
K^{\prime}&lt;\sum_{i&lt;n} \gamma\left(x_{i}\right)&lt;K^{\prime \prime}
\]</div>
<p>is violated for the first time <span class="arithmatex">\(n=N(\mathbf{x})\)</span>, and that we decide in favor of <span class="arithmatex">\(\mathscr{G}_{0}\)</span> or <span class="arithmatex">\(\mathscr{G}_{1}\)</span>, respectively, according as the left or right inequality in (4.1) is violated, respectively. Somewhat more generally, we may allow randomization on the boundary, but we leave this to the reader.</p>
<p>Assume, for example, that <span class="arithmatex">\(Q_{0}^{\prime}\)</span> is true. We have to compare the stochastic behavior of the cumulative sums <span class="arithmatex">\(\Sigma \gamma\left(x_{i}\right)\)</span> under <span class="arithmatex">\(Q_{0}^{\prime}\)</span> and <span class="arithmatex">\(Q_{0}\)</span>. According to the proof of Lemma 3.3, there are functions <span class="arithmatex">\(f \geqslant g\)</span> and independent random variables <span class="arithmatex">\(Z_{i}\)</span> such that <span class="arithmatex">\(f\left(Z_{i}\right)\)</span> and <span class="arithmatex">\(g\left(Z_{i}\right)\)</span> have the same distribution as <span class="arithmatex">\(\gamma\left(X_{i}\right)\)</span> under <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{0}^{\prime}\)</span>, respectively. Thus if the cumulative sum <span class="arithmatex">\(\Sigma g\left(Z_{i}\right)\)</span> leaves the interval ( <span class="arithmatex">\(K^{\prime}, K^{\prime \prime}\)</span> ) first at <span class="arithmatex">\(K^{\prime \prime}, \Sigma f\left(Z_{i}\right)\)</span> will do the same, but even earlier. Therefore the probability of falsely rejecting <span class="arithmatex">\(\mathscr{G}_{0}\)</span> is at least as large under <span class="arithmatex">\(Q_{0}\)</span> as under <span class="arithmatex">\(Q_{0}^{\prime}\)</span>. A similar argument applies to the other hypothesis <span class="arithmatex">\(\mathscr{G}_{1}\)</span>, and we</p>
<p>conclude that the pair <span class="arithmatex">\(\left(Q_{0}, Q_{1}\right)\)</span> is also least favorable in the sequential case, as far as the probabilities of error are concerned.</p>
<p>It need not be least favorable for the expected sample size, as the following example shows.</p>
<p>Example 4.1 Assume that <span class="arithmatex">\(X_{1}, X_{2}, \ldots\)</span> are independent Bernoulli variables</p>
<div class="arithmatex">\[
P\left\{X_{i}=1\right\}=1-P\left\{X_{i}=0\right\}=p
\]</div>
<p>and that we are testing the hypothesis <span class="arithmatex">\(\mathscr{P}_{0}=\{p \leqslant \alpha\}\)</span> against the alternative <span class="arithmatex">\(\mathscr{P}_{1}=\left\{p \geqslant \frac{1}{2}\right\}\)</span>, where <span class="arithmatex">\(0&lt;\alpha&lt;\frac{1}{2}\)</span>. There is a least favorable pair <span class="arithmatex">\(Q_{0}, Q_{1}\)</span>, corresponding to <span class="arithmatex">\(p=\alpha\)</span> and <span class="arithmatex">\(p=\frac{1}{2}\)</span>, respectively (cf. Example 3.2). Then</p>
<div class="arithmatex">\[
\begin{aligned}
\gamma(x)=\log \frac{q_{1}(x)}{q_{0}(x)} &amp; =-\log 2(1-\alpha), &amp; &amp; \text { for } x=0 \\
&amp; =-\log 2 \alpha, &amp; &amp; \text { for } x=1
\end{aligned}
\]</div>
<p>Assume <span class="arithmatex">\(\alpha \leqslant 2^{-m-1}\)</span>, where <span class="arithmatex">\(m\)</span> is a positive integer; then</p>
<div class="arithmatex">\[
\frac{-\log 2 \alpha}{\log 2(1-\alpha)} \geqslant \frac{m \log 2}{\log 2+\log (1-\alpha)} \geqslant m
\]</div>
<p>and we verify easily that the SPRT between <span class="arithmatex">\(p=\alpha\)</span> and <span class="arithmatex">\(p=\frac{1}{2}\)</span> with boundaries</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; K^{\prime}=-m \log 2(1-\alpha) \\
&amp; K^{\prime \prime}=-\log 2 \alpha-(m-1) \log 2(1-\alpha)
\end{aligned}
\]</div>
<p>can also be described by the simple rule:
(1) Decide for <span class="arithmatex">\(\mathscr{P}_{1}\)</span> at the first appearance of a 1 .
(2) But decide for <span class="arithmatex">\(\mathscr{P}_{0}\)</span> after <span class="arithmatex">\(m\)</span> zeros in a row.</p>
<p>The probability of deciding for <span class="arithmatex">\(\mathscr{P}_{0}\)</span> is <span class="arithmatex">\((1-p)^{m}\)</span>, the probability of deciding for <span class="arithmatex">\(\mathscr{P}_{1}\)</span> is <span class="arithmatex">\(1-(1-p)^{m}\)</span>, and the expected sample size is</p>
<div class="arithmatex">\[
E_{p}(N)=\sum_{k=0}^{m-1}(1-p)^{k}=\frac{1-(1-p)^{m}}{p}
\]</div>
<p>Note that the expected sample size reaches its maximum (namely m ) for <span class="arithmatex">\(p=0\)</span>, that is, outside of the interval <span class="arithmatex">\(\left[\alpha, \frac{1}{2}\right]\)</span>. The probabilities of error of the first and of the second kind are bounded from above by <span class="arithmatex">\(1-(1-\alpha)^{m} \leqslant\)</span></p>
<p><span class="arithmatex">\(m \alpha \leqslant m 2^{-m-1}\)</span> and by <span class="arithmatex">\(2^{-m}\)</span>, respectively, and thus can be made arbitrarily small [this disproves conjecture 8(i) of Huber (1965)].</p>
<p>However, if the boundaries <span class="arithmatex">\(K^{\prime}\)</span> and <span class="arithmatex">\(K^{\prime \prime}\)</span> are so far away that the behavior of the cumulative sums is essentially determined by their nonrandom drift</p>
<div class="arithmatex">\[
\sum \gamma\left(X_{i}\right) \sim n E_{Q^{\prime}}[\gamma(X)]
\]</div>
<p>then the expected sample size is asymptotically equal to</p>
<div class="arithmatex">\[
\begin{array}{ll}
E_{Q_{0}}(N) \sim \frac{K^{\prime}}{E_{Q_{0}^{\prime}}(\gamma(X))}, &amp; \text { for } Q_{0}^{\prime} \in \mathscr{P}_{0} \\
E_{Q_{1}}(N) \sim \frac{K^{\prime \prime}}{E_{Q_{1}^{\prime}}(\gamma(X))}, &amp; \text { for } Q_{1}^{\prime} \in \mathscr{P}_{1}
\end{array}
\]</div>
<p>This heuristic argument can be made precise with the aid of the standard approximations for the expected sample sizes [cf., e.g., Lehmann (1959)]. In view of the inequalities of Theorem 3.2, it follows that the right-hand sides of (4.7) are indeed maximized for <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span>, respectively. So the pair <span class="arithmatex">\(\left(Q_{0}, Q_{1}\right)\)</span> is in a certain sense, asymptotically least favorable also for the expected sample size if <span class="arithmatex">\(K^{\prime} \rightarrow-\infty\)</span> and <span class="arithmatex">\(K^{\prime \prime} \rightarrow+\infty\)</span>.</p>
<h1 id="105-the-neyman-pearson-lemma-for-2-alternating-capacities">10.5 THE NEYMAN-PEARSON LEMMA FOR 2-ALTERNATING CAPACITIES</h1>
<p>Ordinarily, sample size <span class="arithmatex">\(n\)</span> minimax tests between two composite alternatives <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span> have a fairly complex structure. Setting aside all measure theoretic complications, they are Neyman-Pearson tests based on a likelihood ratio <span class="arithmatex">\(\bar{q}_{1}(\mathbf{x}) / \bar{q}_{0}(\mathbf{x})\)</span>, where each <span class="arithmatex">\(\bar{q}_{j}\)</span> is a mixture of product densities on <span class="arithmatex">\(\Omega^{n}:\)</span></p>
<div class="arithmatex">\[
\bar{q}_{j}(\mathbf{x})=\int \prod_{i=1}^{n} q\left(x_{i}\right) \lambda_{j}(d q)
\]</div>
<p>Here, <span class="arithmatex">\(\lambda_{j}\)</span> is a probability measure supported by the set <span class="arithmatex">\(\mathscr{P}_{j}\)</span>; in general, <span class="arithmatex">\(\lambda_{j}\)</span> depends both on the level and on the sample size.</p>
<p>The simple structure of the minimax tests found in Section 10.3 therefore was a surprise. On closer scrutiny it turned out that this had to do with the fact that all the "usual" neighborhoods <span class="arithmatex">\(\mathscr{P}\)</span> used in robustness theory could be characterized as <span class="arithmatex">\(\mathscr{P}=\mathscr{P}_{v}\)</span> with <span class="arithmatex">\(v=(\underline{v}, \bar{v})\)</span> being a pair of conjugated 2-monotone/2-alternating capacities (see Section 10.2).</p>
<p>The following summarizes the main results of Huber and Strassen (1973). Let <span class="arithmatex">\(\Omega\)</span> be a Polish space (complete, separable, metrizable), equipped with its Borel <span class="arithmatex">\(\sigma\)</span>-algebra <span class="arithmatex">\(\mathscr{Q}\)</span>, and let <span class="arithmatex">\(\mathscr{M}\)</span> be the set of all probability measures on <span class="arithmatex">\((\Omega, \mathscr{Q})\)</span>. Let <span class="arithmatex">\(\bar{v}\)</span> be a real valued set function defined on <span class="arithmatex">\(\mathscr{Q}\)</span>, such that</p>
<div class="arithmatex">\[
\begin{gathered}
\bar{v}(\phi)=0, \quad \bar{v}(\Omega)=1 \\
A \subset B \Rightarrow \bar{v}(A) \leqslant \bar{v}(B) \\
A_{n} \uparrow A \Rightarrow \bar{v}\left(A_{n}\right) \uparrow \bar{v}(A) \\
F_{n} \downarrow F, F_{n} \text { closed } \Rightarrow \bar{v}\left(F_{n}\right) \downarrow \bar{v}(F) \\
\bar{v}(A \cup B)+\bar{v}(A \cap B) \leqslant \bar{v}(A)+\bar{v}(B)
\end{gathered}
\]</div>
<p>The conjugate set function <span class="arithmatex">\(\underline{v}\)</span> is defined by</p>
<div class="arithmatex">\[
\underline{v}(A)=1-\bar{v}\left(A^{c}\right)
\]</div>
<p>A set function <span class="arithmatex">\(\bar{v}\)</span> satisfying (5.1) to (5.5) is called a 2-alternating capacity, and the conjugate function <span class="arithmatex">\(\underline{v}\)</span> shall be called a 2 -monotone capacity.</p>
<p>It can be shown that any such capacity is regular in the sense that, for every <span class="arithmatex">\(A \in \mathscr{Q}\)</span>,</p>
<div class="arithmatex">\[
\bar{v}(A)=\sup _{K} \bar{v}(K)=\inf _{G} \bar{v}(G)
\]</div>
<p>where <span class="arithmatex">\(K\)</span> ranges over the compact sets contained in <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(G\)</span> over the open sets containing <span class="arithmatex">\(A\)</span>.</p>
<p>Among these requirements (5.4) is equivalent to</p>
<div class="arithmatex">\[
\mathscr{P}_{v}=\{P \in \mathscr{M} \mid P \leqslant \bar{v}\}=\{P \in \mathscr{M} \mid P \geqslant \underline{v}\}
\]</div>
<p>being weakly compact, and (5.5) could be replaced by: for any monotone sequence of closed sets <span class="arithmatex">\(F_{1} \subset F_{2} \subset \cdots, F_{i} \subset \Omega\)</span>, there is a <span class="arithmatex">\(Q \leqslant \bar{v}\)</span> that simultaneously maximizes the probabilities of the <span class="arithmatex">\(F_{i}\)</span>, that is <span class="arithmatex">\(Q\left(F_{i}\right)=\bar{v}\left(F_{i}\right)\)</span>, for all <span class="arithmatex">\(i\)</span>.</p>
<p>Example 5.1 Let <span class="arithmatex">\(\Omega\)</span> be compact. Define <span class="arithmatex">\(\bar{v}(A)=(1-\varepsilon) P_{0}(A)+\varepsilon\)</span> for <span class="arithmatex">\(A \neq \phi\)</span>. Then <span class="arithmatex">\(\bar{v}\)</span> satisfies (5.1) to (5.5), and</p>
<div class="arithmatex">\[
\mathscr{P}_{v}=\left\{P \mid P=(1-\varepsilon) P_{0}+\varepsilon H, H \in \mathscr{M}\right\}
\]</div>
<p>is the <span class="arithmatex">\(\varepsilon\)</span>-contamination neighborhood of <span class="arithmatex">\(P_{0}\)</span>.
Example 5.2 Let <span class="arithmatex">\(\Omega\)</span> be compact metric. Define <span class="arithmatex">\(\bar{v}(A)=\min \left[P_{0}\left(A^{\delta}\right)+\varepsilon, 1\right]\)</span> for compact sets <span class="arithmatex">\(A \neq \phi\)</span>, and use (5.7) to extend <span class="arithmatex">\(v\)</span> to <span class="arithmatex">\(\mathscr{Q}\)</span>. Then <span class="arithmatex">\(v\)</span> satisfies (5.1)</p>
<p>to (5.5), and</p>
<div class="arithmatex">\[
\mathscr{P}_{v}=\left\{P \in \mathscr{M} \mid P(A) \leqslant P_{0}\left(A^{\delta}\right)+\varepsilon \text { for all } A \in \mathscr{R}\right\}
\]</div>
<p>is a Prohorov neighborhood of <span class="arithmatex">\(P_{0}\)</span>.
Now let <span class="arithmatex">\(\bar{v}_{0}\)</span> and <span class="arithmatex">\(\bar{v}_{1}\)</span> be two 2 -alternating capacities on <span class="arithmatex">\(\Omega\)</span>, and let <span class="arithmatex">\(\underline{v}_{0}\)</span> and <span class="arithmatex">\(\underline{v}_{1}\)</span> be their conjugates.</p>
<p>Let <span class="arithmatex">\(A\)</span> be a critical region for testing between <span class="arithmatex">\(\mathscr{P}_{0}=\left\{P \in \mathscr{M} \mid P \leqslant \bar{v}_{0}\right\}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}=\left\{P \in \mathscr{M} \mid P \leqslant \bar{v}_{1}\right\}\)</span>, that is, reject <span class="arithmatex">\(\mathscr{P}_{0}\)</span> if <span class="arithmatex">\(x \in A\)</span> is observed. Then the upper probability of falsely rejecting <span class="arithmatex">\(\mathscr{P}_{0}\)</span> is <span class="arithmatex">\(\bar{v}_{0}(A)\)</span>, and of falsely accepting <span class="arithmatex">\(\mathscr{P}_{0}\)</span> is <span class="arithmatex">\(\bar{v}_{1}\left(A^{c}\right)=1-\underline{v}_{1}(A)\)</span>.</p>
<p>Assume that <span class="arithmatex">\(\mathscr{P}_{0}\)</span> is true with prior probability <span class="arithmatex">\(t /(1+t), 0 \leqslant t \leqslant \infty\)</span>, then the upper Bayes risk of the critical region <span class="arithmatex">\(A\)</span> is by definition</p>
<div class="arithmatex">\[
\frac{t}{1+t} \bar{v}_{0}(A)+\frac{1}{1+t}\left[1-\underline{v}_{1}(A)\right]
\]</div>
<p>This is minimized by minimizing the 2-alternating set function</p>
<div class="arithmatex">\[
w_{t}(A)=t \bar{v}_{0}(A)-\underline{v}_{1}(A)
\]</div>
<p>through a suitable choice of <span class="arithmatex">\(A\)</span>.
It is not very difficult to show that, for each <span class="arithmatex">\(t\)</span>, there is a critical region <span class="arithmatex">\(A_{t}\)</span> minimizing (5.8). Moreover, the sets <span class="arithmatex">\(A_{t}\)</span> can be chosen decreasing, that is, <span class="arithmatex">\(A_{t}=\cup_{s&gt;t} A_{s}\)</span>.</p>
<p>Define</p>
<div class="arithmatex">\[
\pi(x)=\inf \left\{t \mid x \notin A_{t}\right\}
\]</div>
<p>If <span class="arithmatex">\(\bar{v}_{0}=\underline{v}_{0}, \bar{v}_{1}=\underline{v}_{1}\)</span> are ordinary probability measures, then <span class="arithmatex">\(\pi\)</span> is a version of the Radon-Nikodym derivative <span class="arithmatex">\(d v_{1} / d v_{0}\)</span>, so the above constitutes a natural generalization of this notion to 2-alternating capacities.</p>
<p>The crucial result now is given in the following theorem.
THEOREM 5.1 (Neyman-Pearson lemma for capacities) There exist two probabilities <span class="arithmatex">\(Q_{0} \in \mathscr{P}_{0}\)</span> and <span class="arithmatex">\(Q_{1} \in \mathscr{P}_{1}\)</span> such that, for all <span class="arithmatex">\(t\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; Q_{0}\{\pi&gt;t\}=\bar{v}_{0}\{\pi&gt;t\} \\
&amp; Q_{1}\{\pi&gt;t\}=\underline{v}_{1}\{\pi&gt;t\}
\end{aligned}
\]</div>
<p>and that <span class="arithmatex">\(\pi=d Q_{1} / d Q_{0}\)</span>.</p>
<p>Proof See Huber and Strassen (1973, with correction 1974).
In other words among all distributions in <span class="arithmatex">\(\mathscr{G}_{0}, \pi\)</span> is stochastically largest for <span class="arithmatex">\(Q_{0}\)</span>, and among all distributions in <span class="arithmatex">\(\mathscr{G}_{1}, \pi\)</span> is stochastically smallest for <span class="arithmatex">\(Q_{1}\)</span>.</p>
<p>The conclusion of Theorem 5.1 is essentially identical to that of Lemma 3.1, and we conclude, just as there, that the Neyman-Pearson tests between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span>, based on the test statistic <span class="arithmatex">\(\Pi_{i=1}^{\pi} \pi\left(x_{i}\right)\)</span>, are minimax tests between <span class="arithmatex">\(\mathscr{G}_{0}\)</span> and <span class="arithmatex">\(\mathscr{G}_{1}\)</span>, and this for arbitrary levels and sample sizes.</p>
<h1 id="106-estimates-derived-from-tests">10.6 ESTIMATES DERIVED FROM TESTS</h1>
<p>In this section we derive a rigorous correspondence between tests and interval estimates of location.</p>
<p>Let <span class="arithmatex">\(X_{1}, \ldots, X_{n}\)</span> be random variables whose joint distribution belongs to a location family, that is,</p>
<div class="arithmatex">\[
\mathscr{E}_{\theta}\left(X_{1}, \ldots, X_{n}\right)=\mathscr{E}_{0}\left(X_{1}+\theta, \ldots, X_{n}+\theta\right)
\]</div>
<p>the <span class="arithmatex">\(X_{i}\)</span> need not be independent.
Let <span class="arithmatex">\(\theta_{1}&lt;\theta_{2}\)</span>, and let <span class="arithmatex">\(\varphi\)</span> be a (randomized) test of <span class="arithmatex">\(\theta_{1}\)</span> against <span class="arithmatex">\(\theta_{2}\)</span>, of the form</p>
<div class="arithmatex">\[
\begin{aligned}
\varphi(\mathbf{x}) &amp; =0, &amp; &amp; \text { for } h(\mathbf{x})&lt;C \\
&amp; =\gamma, &amp; &amp; \text { for } h(\mathbf{x})=C \\
&amp; =1, &amp; &amp; \text { for } h(\mathbf{x})&gt;C .
\end{aligned}
\]</div>
<p>The test statistic <span class="arithmatex">\(h\)</span> is arbitrary, except that <span class="arithmatex">\(h(\mathbf{x}+\theta)=h\left(x_{1}+\theta, \ldots, x_{n}+\theta\right)\)</span> is assumed to be a monotone increasing function of <span class="arithmatex">\(\theta\)</span>. Let</p>
<div class="arithmatex">\[
\alpha=E_{\theta, \varphi}
\]</div>
<p>and</p>
<div class="arithmatex">\[
\beta=E_{\theta, \varphi}
\]</div>
<p>be the level and the power of this test.
As <span class="arithmatex">\(\alpha=E_{0} \varphi\left(\mathbf{x}+\theta_{1}\right), \beta=E_{0} \varphi\left(\mathbf{x}+\theta_{2}\right)\)</span>, and <span class="arithmatex">\(\varphi(\mathbf{x}+\theta)\)</span> is monotone increasing in <span class="arithmatex">\(\theta\)</span>, we have <span class="arithmatex">\(\alpha \leqslant \beta\)</span>.</p>
<p>We define two random variables <span class="arithmatex">\(T^{*}\)</span> and <span class="arithmatex">\(T^{* *}\)</span> by</p>
<div class="arithmatex">\[
\begin{aligned}
T^{*} &amp; =\sup \{\theta \mid h(\mathbf{x}-\theta)&gt;C\} \\
T^{* *} &amp; =\inf \{\theta \mid h(\mathbf{x}-\theta)&lt;C\}
\end{aligned}
\]</div>
<p>and put</p>
<div class="arithmatex">\[
\begin{aligned}
T^{0} &amp; =T^{*} \text { with probability } 1-\gamma \\
&amp; =T^{* *} \text { with probability } \gamma
\end{aligned}
\]</div>
<p>This randomization should be independent of <span class="arithmatex">\(\left(X_{1}, \ldots, X_{n}\right)\)</span>; for example, take a uniform <span class="arithmatex">\((0,1)\)</span> random variable <span class="arithmatex">\(U\)</span> that is independent of <span class="arithmatex">\(\left(X_{1}, \ldots, X_{n}\right)\)</span> and let <span class="arithmatex">\(T^{0}\)</span> be a deterministic function of <span class="arithmatex">\(\left(X_{1}, \ldots, X_{n}, U\right)\)</span>, defined in the obvious way: <span class="arithmatex">\(T^{0}(\mathbf{X}, U)=T^{*}\)</span> or <span class="arithmatex">\(T^{* *}\)</span> according as <span class="arithmatex">\(U \geqslant \gamma\)</span> or <span class="arithmatex">\(U&lt;\gamma\)</span>.</p>
<p>Evidently all three statistics <span class="arithmatex">\(T^{*}, T^{* *}\)</span>, and <span class="arithmatex">\(T^{0}\)</span> are translation invariant in the sense that <span class="arithmatex">\(T(\mathbf{x}+\theta)=T(\mathbf{x})+\theta\)</span>.</p>
<p>We note that <span class="arithmatex">\(T^{*} \leqslant T^{* *}\)</span> and that</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \left\{\mathbf{x} \mid T^{*}&gt;\theta\right\} \subset\{\mathbf{x} \mid h(\mathbf{x}-\theta)&gt;C\} \subset\left\{\mathbf{x} \mid T^{*} \geqslant \theta\right\} \\
&amp; \left\{\mathbf{x} \mid T^{* *}&gt;\theta\right\} \subset\{\mathbf{x} \mid h(\mathbf{x}-\theta) \geqslant C\} \subset\left\{\mathbf{x} \mid T^{* *} \geqslant \theta\right\}
\end{aligned}
\]</div>
<p>If <span class="arithmatex">\(h(\mathbf{x}-\theta)\)</span> is continuous as a function of <span class="arithmatex">\(\theta\)</span>, these relations simplify to</p>
<div class="arithmatex">\[
\begin{aligned}
\left\{T^{*}&gt;\theta\right\} &amp; =\{h(\mathbf{x}-\theta)&gt;C\} \\
\left\{T^{* *} \geqslant \theta\right\} &amp; =\{h(\mathbf{x}-\theta) \geqslant C\}
\end{aligned}
\]</div>
<p>In any case we have, for an arbitrary joint distribution of <span class="arithmatex">\(X_{1}, \ldots, X_{n}\)</span> and arbitrary <span class="arithmatex">\(\theta\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
P\left(T^{0}&gt;\theta\right) &amp; =(1-\gamma) P\left\{T^{*}&gt;\theta\right\}+\gamma P\left\{T^{* *}&gt;\theta\right\} \\
&amp; \leqslant(1-\gamma) P\{h(\mathbf{X}-\theta)&gt;C\}+\gamma P\{h(\mathbf{X}-\theta) \geqslant C\} \\
&amp; =E \varphi(\mathbf{X}-\theta)
\end{aligned}
\]</div>
<p>For <span class="arithmatex">\(T^{0} \geqslant \theta\)</span> the inequality is reversed; thus</p>
<div class="arithmatex">\[
P\left(T^{0}&gt;\theta\right) \leqslant E \varphi(\mathbf{X}-\theta) \leqslant P\left(T^{0} \geqslant \theta\right)
\]</div>
<p>For the translation family (6.1) we have, in particular,</p>
<div class="arithmatex">\[
E_{\theta \mid \varphi}(\mathbf{X})=E_{\theta} \varphi\left(\mathbf{X}+\theta_{1}\right)=\alpha
\]</div>
<p>Since <span class="arithmatex">\(T^{0}\)</span> is translation invariant, this implies</p>
<div class="arithmatex">\[
P_{\theta}\left\{T^{0}+\theta_{1}&gt;\theta\right\} \leqslant \alpha \leqslant P_{\theta}\left\{T^{0}+\theta_{1} \geqslant \theta\right\}
\]</div>
<p>and similarly,</p>
<div class="arithmatex">\[
P_{\theta}\left\{T^{0}+\theta_{2}&gt;\theta\right\} \leqslant \beta \leqslant P_{\theta}\left\{T^{0}+\theta_{2} \geqslant \theta\right\}
\]</div>
<p>We conclude that <span class="arithmatex">\(\left[T^{0}+\theta_{1}, T^{0}+\theta_{2}\right]\)</span> is a (fixed-length) confidence interval such that the true value <span class="arithmatex">\(\theta\)</span> lies to its left with probability <span class="arithmatex">\(\leqslant \alpha\)</span>, and to its right with probability <span class="arithmatex">\(\leqslant 1-\beta\)</span>. For the open interval <span class="arithmatex">\(\left(T^{0}+\theta_{1}, T^{0}+\theta_{2}\right)\)</span> the inequalities are reversed, and the probabilities of error become <span class="arithmatex">\(\geqslant \alpha\)</span> and <span class="arithmatex">\(\geqslant 1-\beta\)</span> respectively.</p>
<p>In particular, if the distribution of <span class="arithmatex">\(T^{0}\)</span> is continuous, then <span class="arithmatex">\(P_{\theta}\left\{T^{0}+\theta_{1}=\theta\right\}\)</span> <span class="arithmatex">\(=P_{\theta}\left\{T^{0}+\theta_{2}=\theta\right\}=0\)</span>; therefore we have equality in either case, and ( <span class="arithmatex">\(T^{0}+\)</span> <span class="arithmatex">\(\theta_{1}, T^{0}+\theta_{2}\)</span> ) catches the true value with probability <span class="arithmatex">\(\beta-\alpha\)</span>.</p>
<p>The following lemma gives a sufficient condition for the absolute continuity of the distribution of <span class="arithmatex">\(T^{0}\)</span>.</p>
<p>LEMMA 6.1 If the joint distribution of <span class="arithmatex">\(\mathbf{X}=\left(X_{1}, \ldots, X_{n}\right)\)</span> is absolutely continuous with respect to Lebesgue measure in <span class="arithmatex">\(\mathbb{R}^{n}\)</span>, then every translation invariant measurable estimate <span class="arithmatex">\(T\)</span> has an absolutely continuous distribution with respect to Lebesgue measure in <span class="arithmatex">\(\mathbb{R}\)</span>.</p>
<p>Proof We prove the lemma by explicitly writing down the density of <span class="arithmatex">\(T\)</span> : if the joint density of <span class="arithmatex">\(\mathbf{X}\)</span> is <span class="arithmatex">\(f(\mathbf{x})\)</span>, then the density of <span class="arithmatex">\(T\)</span> is</p>
<div class="arithmatex">\[
g(t)=\int f\left(y_{1}-T(\mathbf{y})+t, \ldots, y_{n-1}-T(\mathbf{y})+t,-T(\mathbf{y})+t\right) d y_{1} \ldots d y_{n-1}
\]</div>
<p>where <span class="arithmatex">\(\mathbf{y}\)</span> is short for <span class="arithmatex">\(\left(y_{1}, \ldots, y_{n-1}, 0\right)\)</span>. In order to prove (6.9) it suffices to verify that, for every bounded measurable function <span class="arithmatex">\(w\)</span>,</p>
<div class="arithmatex">\[
\int w(t) g(t) d t=\int w(T(\mathbf{x})) f(\mathbf{x}) d x_{1} \ldots d x_{n}
\]</div>
<p>By Fubini's theorem we can interchange the order of integrations on the left-hand side:</p>
<div class="arithmatex">\[
\int w(t) g(t) d t=\int\left\{\int w(t) f(\cdots) d t\right\} d y_{1} \ldots d y_{n-1}
\]</div>
<p>where the argument list of <span class="arithmatex">\(f(\cdots)\)</span> is the same as in (6.9). We substitute <span class="arithmatex">\(t=T(\mathbf{y})+x_{n}=T\left(\mathbf{y}+x_{n}\right)\)</span> in the inner integral and change the order of</p>
<p>integrations again:</p>
<div class="arithmatex">\[
\int w(t) g(t) d t=\int\left\{\int w\left(T\left(y+x_{n}\right)\right) f\left(y+x_{n}\right) d y_{1} \ldots d y_{n-1}\right\} d x_{n}
\]</div>
<p>Finally, we substitute <span class="arithmatex">\(x_{i}=y_{i}+x_{n}\)</span> for <span class="arithmatex">\(i=1, \ldots, n-1\)</span> and obtain the desired equivalence (6.10).</p>
<p>NOTE 1 The assertion that the distribution of a translation invariant estimate <span class="arithmatex">\(T\)</span> is continuous, provided the observations <span class="arithmatex">\(X_{i}\)</span> are independent with identical continuous distributions, is plausible but false [cf. Torgersen (1971)].</p>
<p>NOTE 2 It is possible to obtain confidence intervals with exact one-sided error probabilities <span class="arithmatex">\(\alpha\)</span> and <span class="arithmatex">\(1-\beta\)</span> also in the general discontinuous case if we are willing to choose a sometimes open, sometimes closed interval. More precisely, when <span class="arithmatex">\(U \geq \gamma\)</span> and thus <span class="arithmatex">\(T^{0}=T^{*}\)</span>, and if the set <span class="arithmatex">\(\{\theta \mid h(\mathbf{x}-\theta)&gt;C\}\)</span> is open, choose the interval <span class="arithmatex">\(\left[T^{0}+\theta_{1}, T^{0}+\theta_{2}\right)\)</span>; if it is closed, choose <span class="arithmatex">\(\left(T^{0}+\theta_{1}, T^{0}+\theta_{2}\right]\)</span>. When <span class="arithmatex">\(T^{0}=T^{* *}\)</span> and <span class="arithmatex">\(\{\theta \mid h(\mathbf{x}-\theta) \geqslant C\}\)</span> is open, take <span class="arithmatex">\(\left[T^{0}+\theta_{1}, T^{0}+\theta_{2}\right)\)</span>; if it is closed, take <span class="arithmatex">\(\left(T^{0}+\theta_{1}, T^{0}+\theta_{2}\right]\)</span>.</p>
<p>NOTE 3 The more traditional nonrandomized compromise <span class="arithmatex">\(T^{(0)}=\frac{1}{2}\left(T^{*}+\right.\)</span> <span class="arithmatex">\(T^{* *}\)</span> ) between <span class="arithmatex">\(T^{*}\)</span> and <span class="arithmatex">\(T^{* *}\)</span> in general does not satisfy the crucial relation (6.6).</p>
<p>NOTE 4 Starting from the translation invariant estimate <span class="arithmatex">\(T^{0}\)</span>, we can reconstruct a test between <span class="arithmatex">\(\theta_{1}\)</span> and <span class="arithmatex">\(\theta_{2}\)</span>, having the original level <span class="arithmatex">\(\alpha\)</span> and power <span class="arithmatex">\(\beta\)</span>, as follows. In view of (6.6)</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; P_{\theta_{1}}\left(T^{0}&gt;0\right) \leqslant \alpha \leqslant P_{\theta_{1}}\left(T^{0} \geqslant 0\right) \\
&amp; P_{\theta_{2}}\left(T^{0}&gt;0\right) \leqslant \beta \leqslant P_{\theta_{2}}\left(T^{0} \geqslant 0\right)
\end{aligned}
\]</div>
<p>Hence if <span class="arithmatex">\(T^{0}\)</span> has a continuous distribution so that <span class="arithmatex">\(P_{\theta}\left(T^{0}=0\right)=0\)</span> for all <span class="arithmatex">\(\theta\)</span>, we simply take <span class="arithmatex">\(\left(T^{0}&gt;0\right)\)</span> as the critical region. In the general case we would have to split the boundary <span class="arithmatex">\(T^{0}=0\)</span> in the manner of Note 2 (for that, the mere value of <span class="arithmatex">\(T^{0}\)</span> does not quite suffice-we also need to know on which side the confidence intervals are open and closed, respectively).</p>
<p>Rank tests are particularly attractive to derive estimates from, since they are distribution free under the null hypothesis; the sign test is so generally, and the others at least for symmetric distributions. This leads to distribu-tion-free confidence intervals-the probabilities that the true value lies to the left or the right of the interval, respectively, do not depend on the underlying distribution.</p>
<p>Example 6.1 Sign Test Assume that the <span class="arithmatex">\(X_{1}, \ldots, X_{n}\)</span> are independent, with common distribution <span class="arithmatex">\(F_{\theta}(x)=F(x-\theta)\)</span>, where <span class="arithmatex">\(F\)</span> has median 0 and is continuous at 0 . We test <span class="arithmatex">\(\theta_{1}=0\)</span> against <span class="arithmatex">\(\theta_{2}&gt;0\)</span>, using the test statistic</p>
<div class="arithmatex">\[
h(\mathbf{x})=\sum 1_{\left\{x_{i}&gt;0\right\}}
\]</div>
<p>assume that the level of the test is <span class="arithmatex">\(\alpha\)</span>. Then there will be an integer <span class="arithmatex">\(c\)</span>, independent of the special <span class="arithmatex">\(F\)</span>, such that the test rejects the hypothesis if the <span class="arithmatex">\(c\)</span> th order statistic <span class="arithmatex">\(x_{(c)}&gt;0\)</span>, accepts it if <span class="arithmatex">\(x_{(c+1)} \leqslant 0\)</span>, and randomizes it if <span class="arithmatex">\(x_{(c)} \leqslant 0&lt;x_{(c+1)}\)</span>. The corresponding estimate <span class="arithmatex">\(T^{0}\)</span> randomizes between <span class="arithmatex">\(x_{(c)}\)</span> and <span class="arithmatex">\(x_{(c+1)}\)</span>, and is a distribution-free lower confidence bound for the true median:</p>
<div class="arithmatex">\[
P_{\theta}\left\{\theta&lt;T^{0}\right\} \leqslant \alpha \leqslant P_{\theta}\left\{\theta \leqslant T^{0}\right\}
\]</div>
<p>As <span class="arithmatex">\(F\)</span> is continuous at its median, <span class="arithmatex">\(P_{\theta}\left(\theta=T^{0}\right)=P_{0}\left(0=T^{0}\right)=0\)</span>, we have in fact equality in (6.12). (The upper confidence bound <span class="arithmatex">\(T^{0}+\theta_{2}\)</span> is uninteresting, since its level depends on <span class="arithmatex">\(F\)</span>.)</p>
<p>Example 6.2 Wilcoxon and Similar Tests Assume that <span class="arithmatex">\(X_{1}, \ldots, X_{n}\)</span> are independent with common distribution <span class="arithmatex">\(F_{\theta}(x)=F(x-\theta)\)</span>, where <span class="arithmatex">\(F\)</span> is continuous and symmetric. Rank the absolute values of the observations, and let <span class="arithmatex">\(R_{i}\)</span> be the rank of <span class="arithmatex">\(\left|x_{i}\right|\)</span>. Define the test statistic</p>
<div class="arithmatex">\[
h(\mathbf{x})=\sum_{x_{i}&gt;0} a\left(R_{i}\right)
\]</div>
<p>If <span class="arithmatex">\(a(\cdot)\)</span> is an increasing function [as for the Wilcoxon test: <span class="arithmatex">\(a(i)=i\)</span> ], then <span class="arithmatex">\(h(\mathbf{x}+\theta)\)</span> is increasing in <span class="arithmatex">\(\theta\)</span>. It is easy to see that it is piecewise constant, with jumps possible at the points <span class="arithmatex">\(\theta=-\frac{1}{2}\left(x_{i}+x_{j}\right)\)</span>. It follows that <span class="arithmatex">\(T^{0}\)</span> randomizes between two (not necessarily adjacent) values of <span class="arithmatex">\(\frac{1}{2}\left(x_{i}+x_{j}\right)\)</span>.</p>
<p>It is evident from the foregoing results that there is a precise correspondence between optimality properties for tests and estimates. For instance, the theory of locally most powerful rank tests for location leads to locally most efficient <span class="arithmatex">\(R\)</span>-estimates, that is to estimates <span class="arithmatex">\(T\)</span> maximizing the probability that <span class="arithmatex">\((T-\Delta, T+\Delta)\)</span> catches the true value of the location parameter (i.e., the center of symmetry of <span class="arithmatex">\(F\)</span> ), provided <span class="arithmatex">\(\Delta\)</span> is chosen sufficiently small.</p>
<h1 id="107-minimax-interval-estimates">10.7 MINIMAX INTERVAL ESTIMATES</h1>
<p>The minimax robust tests of Section 10.3 can be translated in a straightforward fashion into location estimates possessing exact finite sample minimax properties.</p>
<p>Let <span class="arithmatex">\(G\)</span> be an absolutely continuous distribution on the real line, with a continuous density <span class="arithmatex">\(g\)</span> such that <span class="arithmatex">\(-\log g\)</span> is strictly convex on its convex support (which need not be the whole real line).</p>
<p>Let <span class="arithmatex">\(\mathscr{P}\)</span> be a "blown-up" version of <span class="arithmatex">\(G\)</span> :</p>
<div class="arithmatex">\[
\mathscr{P}=\left\{F \in \mathscr{M} \mid\left(1-\varepsilon_{0}\right) G(x)-\delta_{0} \leqslant F(x) \leqslant\left(1-\varepsilon_{1}\right) G(x)+\varepsilon_{1}+\delta_{1} \text { for all } x\right\}
\]</div>
<p>Assume that the observations <span class="arithmatex">\(X_{1}, \ldots, X_{n}\)</span> of <span class="arithmatex">\(\theta\)</span> are independent, and that the distributions <span class="arithmatex">\(F_{i}\)</span> of the observational errors <span class="arithmatex">\(X_{i}-\theta\)</span> lie in <span class="arithmatex">\(\mathscr{P}\)</span>.</p>
<p>We intend to find an estimate <span class="arithmatex">\(T\)</span> that minimizes the probability of underor overshooting the true <span class="arithmatex">\(\theta\)</span> by more than <span class="arithmatex">\(a\)</span>, where <span class="arithmatex">\(a&gt;0\)</span> is a constant fixed in advance. That is, we want to minimize</p>
<div class="arithmatex">\[
\sup _{\mathscr{P}, \theta} \max [P\{T&lt;\theta-a\}, P\{T&gt;\theta+a\}]
\]</div>
<p>We claim that this problem is essentially equivalent to finding minimax tests between <span class="arithmatex">\(\mathscr{P}_{-a}\)</span> and <span class="arithmatex">\(\mathscr{P}_{+a}\)</span>, where <span class="arithmatex">\(\mathscr{P}_{ \pm a}\)</span> are obtained by shifting the set <span class="arithmatex">\(\mathscr{P}\)</span> of distribution functions to the left and right by amounts <span class="arithmatex">\(\pm a\)</span>.</p>
<p>More precisely, define the two distribution functions <span class="arithmatex">\(G_{-a}\)</span> and <span class="arithmatex">\(G_{+a}\)</span> by their densities</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; g_{-a}(x)=g(x+a) \\
&amp; g_{+a}(x)=g(x-a)
\end{aligned}
\]</div>
<p>Then</p>
<div class="arithmatex">\[
c(x)=\frac{g(x-a)}{g(x+a)}
\]</div>
<p>is strictly monotone increasing wherever it is finite.
Expand <span class="arithmatex">\(P_{0}=G_{-a}\)</span> and <span class="arithmatex">\(P_{1}=G_{+a}\)</span> to composite hypotheses <span class="arithmatex">\(\mathscr{P}_{0}\)</span> and <span class="arithmatex">\(\mathscr{P}_{1}\)</span> according to (3.1), and determine a least favorable pair <span class="arithmatex">\(\left(Q_{0}, Q_{1}\right) \in \mathscr{P}_{0} \times \mathscr{P}_{1}\)</span>. Determine the constants <span class="arithmatex">\(C\)</span> and <span class="arithmatex">\(\gamma\)</span> of Theorem 3.2 such that errors of both kinds are equally probable under <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> :</p>
<div class="arithmatex">\[
E_{Q_{0} \varphi}=E_{Q_{1}}(1-\varphi)=\alpha
\]</div>
<p>If <span class="arithmatex">\(\mathscr{P}_{-a}\)</span> and <span class="arithmatex">\(\mathscr{P}_{+a}\)</span> are the translates of <span class="arithmatex">\(\mathscr{P}\)</span> to the left and to the right by the amount <span class="arithmatex">\(a&gt;0\)</span>, then it is easy to verify that</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; Q_{0} \in \mathscr{P}_{-a} \subset \mathscr{P}_{0} \\
&amp; Q_{1} \in \mathscr{P}_{+a} \subset \mathscr{P}_{1}
\end{aligned}
\]</div>
<p>If we now determine an estimate <span class="arithmatex">\(T^{0}\)</span> according to (6.3) and (6.4) from the test statistic</p>
<div class="arithmatex">\[
h(\mathbf{x})=\Pi_{1}^{n} \hat{\pi}\left(x_{i}\right)
\]</div>
<p>of Theorem 3.2, then (6.6) shows that</p>
<div class="arithmatex">\[
\begin{array}{ll}
Q_{0}^{\prime}\left\{T^{0}&gt;0\right\} \leqslant E_{Q_{1}^{\prime}} \varphi(\mathbf{X}) \leqslant \alpha, &amp; \text { for } Q_{0}^{\prime} \in \mathscr{P}_{0} \\
Q_{1}^{\prime}\left\{T^{0}&lt;0\right\} \leqslant E_{Q_{1}^{\prime}}(1-\varphi(\mathbf{X})) \leqslant \alpha, &amp; \text { for } Q_{1}^{\prime} \in \mathscr{P}_{1}
\end{array}
\]</div>
<p>On the other hand for any statistic <span class="arithmatex">\(T\)</span> satisfying</p>
<div class="arithmatex">\[
Q_{0}\{T=0\}=Q_{1}\{T=0\}=0
\]</div>
<p>we must have</p>
<div class="arithmatex">\[
\max \left[Q_{0}\{T&gt;0\}, Q_{1}\{T&lt;0\}\right] \geqslant \alpha
\]</div>
<p>This follows from the remark that we can view <span class="arithmatex">\(T\)</span> as a test statistic for testing between <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span>, and the minimax risk is <span class="arithmatex">\(\alpha\)</span> according to (7.5). Since <span class="arithmatex">\(Q_{0}\)</span> and <span class="arithmatex">\(Q_{1}\)</span> have densities, any translation invariant estimate, in particular <span class="arithmatex">\(T^{0}\)</span>, satisfies (7.8) (Lemma 6.1). In view of (7.6) we have proved the following theorem.</p>
<p>THEOREM 7.1 The estimate <span class="arithmatex">\(T^{0}\)</span> minimizes (7.2); more precisely, if the distributions of the errors <span class="arithmatex">\(X_{i}-\theta\)</span> are contained in <span class="arithmatex">\(\mathscr{P}\)</span>, then for all <span class="arithmatex">\(\theta\)</span>,</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; P\left\{T^{0}&lt;\theta-a\right\} \leqslant \alpha \\
&amp; P\left\{T^{0}&gt;\theta+a\right\} \leqslant \alpha
\end{aligned}
\]</div>
<p>and the bound <span class="arithmatex">\(\alpha\)</span> is the best possible for translation invariant estimates.
NOTE The restriction to translation invariant estimates can be dropped in view of the Hunt-Stein theorem [Lehmann (1959), p. 335].</p>
<p>It is useful to discuss particular cases of this theorem. Assume that <span class="arithmatex">\(G\)</span> is symmetric, and that <span class="arithmatex">\(\varepsilon_{0}=\varepsilon_{1}\)</span> and <span class="arithmatex">\(\delta_{0}=\delta_{1}\)</span>. Then for reasons of symmetry <span class="arithmatex">\(C=1\)</span> and <span class="arithmatex">\(\gamma=\frac{1}{2}\)</span>. Put</p>
<div class="arithmatex">\[
\psi(x)=\log \frac{q_{1}(x)}{q_{0}(x)}
\]</div>
<p>then</p>
<div class="arithmatex">\[
\psi(x)=\max \left\{-k, \min \left[k, \log \frac{g(x-a)}{g(x+a)}\right]\right\}
\]</div>
<p>and <span class="arithmatex">\(T^{*}\)</span> and <span class="arithmatex">\(T^{* *}\)</span> are the smallest and the largest solutions of</p>
<div class="arithmatex">\[
\sum \psi\left(x_{i}-T\right)=0
\]</div>
<p>respectively, and <span class="arithmatex">\(T^{0}\)</span> randomizes between them with equal probability. Actually, <span class="arithmatex">\(T^{*}=T^{* *}\)</span> with overwhelming probability; <span class="arithmatex">\(T^{*}&lt;T^{* *}\)</span> occurs only if the sample size <span class="arithmatex">\(n=2 m\)</span> is even and the sample has a large gap in the middle [so that all summands in (7.12) have values <span class="arithmatex">\(\pm k\)</span> ]. Although, ordinarily, the nonrandomized midpoint estimate <span class="arithmatex">\(T^{00}=\frac{1}{2}\left(T^{*}+T^{* *}\right)\)</span> seems to have slightly better properties than the randomized <span class="arithmatex">\(T^{0}\)</span>, it does not solve the minimax problem; see Huber (1968) for a counterexample.</p>
<p>In the particular case where <span class="arithmatex">\(G=\Phi\)</span> is the normal distribution, <span class="arithmatex">\(\log g(x-\)</span> a) <span class="arithmatex">\(/ g(x+a)=2 a x\)</span> is linear, and after dividing through <span class="arithmatex">\(2 a\)</span>, we obtain our old acquaintance</p>
<div class="arithmatex">\[
\psi(x)=\max \left[-k^{\prime}, \min \left(k^{\prime}, x\right)\right] \text { with } k^{\prime}=k /(2 \mathrm{a})
\]</div>
<p>Thus the <span class="arithmatex">\(M\)</span>-estimate <span class="arithmatex">\(T^{0}\)</span>, as defined by (7.12) and (7.13), has two quite different minimax robustness properties for approximately normal distributions:
(1) It minimizes the maximal asymptotic variance, for symmetric <span class="arithmatex">\(\varepsilon\)</span> contamination.
(2) It yields exact, finite sample minimax interval estimates, for not necessarily symmetric <span class="arithmatex">\(\varepsilon\)</span>-contamination (and for indeterminacy in terms of Kolmogorov distance, total variation and other models as well).</p>
<p>In retrospect it strikes us as very remarkable that the <span class="arithmatex">\(\psi\)</span> defining the finite sample minimax estimate does not depend on the sample size (only on <span class="arithmatex">\(\varepsilon, \delta\)</span>, and <span class="arithmatex">\(a\)</span> ), even though, as already mentioned, <span class="arithmatex">\(1 \%\)</span> contamination has conceptionally quite different effects for sample size 5 and for sample size 1000 .</p>
<p>The above results assume the scale to be fixed. For the more realistic case, where scale is a nuisance parameter, no exact finite sample results are known.</p>
<h1 id="chapter-11">CHAPTER 11</h1>
<h2 id="miscellaneous-topics">Miscellaneous Topics</h2>
<h3 id="111-hampels-extremal-problem">11.1 HAMPEL'S EXTREMAL PROBLEM</h3>
<p>The minimax approaches described in Chapters 4 and 10 do not generalize beyond problems possessing a high degree of symmetry. This symmetry (e.g., translation invariance) is essential in their case, since it allows us to extend the parametrization of the idealized model throughout a neighborhood.</p>
<p>Hampel (1968, 1974b) proposed an alternative approach that avoids this problem by strictly staying at the idealized model: minimize the asymptotic variance of the estimate at the model, subject to a bound on the gross error sensitivity. This works for essentially arbitrary one-parameter families (and can even be extended to multiparameter problems). The main drawback is of a conceptual nature: only "infinitesimal" deviations from the model are allowed.</p>
<p>For <span class="arithmatex">\(L\)</span> - and <span class="arithmatex">\(R\)</span>-estimates the concept of gross-error sensitivity is of questionable value (compare Examples 3.5.1 and 3.5.2). We therefore restrict our attention to <span class="arithmatex">\(M\)</span>-estimates.</p>
<p>Let <span class="arithmatex">\(f_{\theta}(x)=f(x ; \theta)\)</span> be a family of probability densities, relative to some measure <span class="arithmatex">\(\mu\)</span>, indexed by a real parameter <span class="arithmatex">\(\theta\)</span>. We intend to estimate <span class="arithmatex">\(\theta\)</span> by an <span class="arithmatex">\(M\)</span>-estimate <span class="arithmatex">\(T=T(F)\)</span>, where the functional <span class="arithmatex">\(T\)</span> is defined through an implicit equation</p>
<div class="arithmatex">\[
\int \psi(x ; T(F)) F(d x)=0
\]</div>
<p>The function <span class="arithmatex">\(\psi\)</span> is to be determined by the following extremal property.
Subject to Fisher consistency</p>
<div class="arithmatex">\[
T\left(F_{\theta}\right)=\theta
\]</div>
<p>(where <span class="arithmatex">\(d F_{\theta}=f_{\theta} d \mu\)</span> ), and subject to a prescribed bound <span class="arithmatex">\(k(\theta)\)</span> on the gross</p>
<p>error sensitivity</p>
<div class="arithmatex">\[
\left|I C\left(x ; F_{\theta}, T\right)\right| \leqslant k(\theta), \quad \text { for all } x
\]</div>
<p>the resulting estimate should minimize the asymptotic variance</p>
<div class="arithmatex">\[
\int I C\left(x ; F_{\theta}, T\right)^{2} d F_{\theta}
\]</div>
<p>Hampel showed that the solution is of the form</p>
<div class="arithmatex">\[
\psi(x ; \theta)=[g(x ; \theta)-a(\theta)]_{-b(\theta)}^{+b(\theta)}
\]</div>
<p>where</p>
<div class="arithmatex">\[
g(x ; \theta)=\frac{\partial}{\partial \theta} \log f(x ; \theta)
\]</div>
<p>and where <span class="arithmatex">\(a(\theta)\)</span> and <span class="arithmatex">\(b(\theta)&gt;0\)</span> are some functions of <span class="arithmatex">\(\theta\)</span>; we are using the notation <span class="arithmatex">\([x]_{u}^{\nu}=\max [u, \min (v, x)]\)</span>.</p>
<p>How should we choose <span class="arithmatex">\(k(\theta)\)</span> ? Hampel had left the choice open, noting that the problem fails to have a solution if <span class="arithmatex">\(k(\theta)\)</span> is too small, and pointing out that it might be preferable to start with a sensible choice for <span class="arithmatex">\(b(\theta)\)</span>, and then to determine the corresponding values of <span class="arithmatex">\(a(\theta)\)</span> and <span class="arithmatex">\(k(\theta)\)</span>. We now sketch a somewhat more systematic approach, by proposing that <span class="arithmatex">\(k(\theta)\)</span> should be an arbitrarily chosen, but fixed, multiple of the "average error sensitivity" [i.e., of the square root of the asymptotic variance (1.4)]. Thus we put</p>
<div class="arithmatex">\[
k(\theta)^{2}=k^{2} \int I C\left(x ; F_{\theta}, T\right)^{2} d F_{\theta}
\]</div>
<p>where the constant <span class="arithmatex">\(k\)</span> clearly must satisfy <span class="arithmatex">\(k \geqslant 1\)</span>, but otherwise can be chosen freely (we would tentatively recommend the range <span class="arithmatex">\(1&lt;k \leqslant 2.5\)</span> ).</p>
<p>We now discuss existence and uniqueness of <span class="arithmatex">\(a(\theta)\)</span> and <span class="arithmatex">\(b(\theta)\)</span>, when <span class="arithmatex">\(k(\theta)\)</span> is defined by (1.7).</p>
<p>The influence function of an <span class="arithmatex">\(M\)</span>-estimate (1.1) at <span class="arithmatex">\(F_{\theta}\)</span> can be written as</p>
<div class="arithmatex">\[
I C\left(x ; F_{\theta}, T\right)=\frac{\psi(x ; \theta)}{\int \psi(x ; \theta) g(x ; \theta) f(x ; \theta) d \mu}
\]</div>
<p>see (3.2.13). Here, we have used Fisher consistency and have transformed the denominator by an integration by parts.</p>
<p>The side conditions (1.2) and (1.3) now may be rewritten as</p>
<div class="arithmatex">\[
\int \psi(x ; \theta) f(x ; \theta) d \mu=0
\]</div>
<p>and</p>
<div class="arithmatex">\[
\psi(x ; \theta)^{2}&lt;k^{2} \int \psi(x ; \theta)^{2} f(x ; \theta) d \mu
\]</div>
<p>while the expression to be minimized is</p>
<div class="arithmatex">\[
\frac{\int \psi(x ; \theta)^{2} f(x ; \theta) d \mu}{\left[\int \psi(x ; \theta) g(x ; \theta) f(x ; \theta) d \mu\right]^{2}}
\]</div>
<p>This extremal problem can be solved separately for each value of <span class="arithmatex">\(\theta\)</span>. Existence of a minimizing <span class="arithmatex">\(\psi\)</span> follows in a straightforward way from the fact that <span class="arithmatex">\(\psi\)</span> is bounded (1.10) and from weak compactness of the unit ball in <span class="arithmatex">\(L_{\infty}\)</span>.</p>
<p>The explicit form of the minimizing <span class="arithmatex">\(\psi\)</span> can be found by the standard methods of the calculus of variations.</p>
<p>If we apply a small variation <span class="arithmatex">\(\delta \psi\)</span> to the <span class="arithmatex">\(\psi\)</span> in (1.9) to (1.11), we obtain as a necessary condition for the extremum</p>
<div class="arithmatex">\[
\int[\psi-\lambda g+\nu] \delta \psi f d \mu \geqslant 0
\]</div>
<p>where <span class="arithmatex">\(\lambda\)</span> and <span class="arithmatex">\(\nu\)</span> are Lagrange multipliers. Since <span class="arithmatex">\(\psi\)</span> is only determined up to a multiplicative constant, we may standardize <span class="arithmatex">\(\lambda=1\)</span>, and it follows that <span class="arithmatex">\(\psi=g-\nu\)</span> for those <span class="arithmatex">\(x\)</span> where it can be freely varied [i.e., where we have strict inequality in (1.10)]. Hence the solution must be of the form (1.5), apart from an arbitrary multiplicative constant, and excepting a limiting case to be discussed later [corresponding to <span class="arithmatex">\(b(\theta)=0\)</span> ].</p>
<p>We first show that <span class="arithmatex">\(a(\theta)\)</span> and <span class="arithmatex">\(b(\theta)\)</span> exist, and that under mild conditions they are uniquely determined by (1.9) and by the following relation derived from (1.10):</p>
<div class="arithmatex">\[
b(\theta)^{2}=k^{2} \int \psi(x ; \theta)^{2} f(x ; \theta) d \mu
\]</div>
<p>To simplify the writing we work at one fixed <span class="arithmatex">\(\theta\)</span> and drop both arguments <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(\theta\)</span> from the notation.</p>
<p>Existence and uniqueness of the solution <span class="arithmatex">\((a, b)\)</span> of (1.9) and (1.12) can be established by a method we have used already in Chapter 7. Namely, put</p>
<div class="arithmatex">\[
\begin{aligned}
\rho(z) &amp; =\frac{1}{2}\left(k^{-2}+z^{2}\right), &amp; &amp; \text { for }|z|&lt;1 \\
&amp; =\frac{1}{2}\left(k^{-2}-1\right)+|z|, &amp; &amp; \text { for }|z|&gt;1
\end{aligned}
\]</div>
<p>and let</p>
<div class="arithmatex">\[
Q(a, b)=E\left\{\rho\left(\frac{g-a}{b}\right) b-|g|\right\}
\]</div>
<p>We note that <span class="arithmatex">\(Q\)</span> is a convex function of <span class="arithmatex">\((a, b)\)</span> [this is a special case of (7.7.9)ff], and that it is minimized by the solution <span class="arithmatex">\((a, b)\)</span> of the two equations</p>
<div class="arithmatex">\[
\begin{gathered}
E\left[\rho^{\prime}\left(\frac{g-a}{b}\right)\right]=0 \\
E\left[\frac{g-a}{b} \rho^{\prime}\left(\frac{g-a}{b}\right)-\rho\left(\frac{g-a}{b}\right)\right]=0
\end{gathered}
\]</div>
<p>obtained from (1.14) by taking partial derivatives with respect to <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span>. But these two equations are equivalent to (1.9) and (1.12), respectively.</p>
<p>Note that this amounts to estimating a location parameter <span class="arithmatex">\(a\)</span> and a scale parameter <span class="arithmatex">\(b\)</span> for the random variable <span class="arithmatex">\(g\)</span> by the method of Huber (1964, "Proposal 2"); compare Example 6.4.1. In order to see this let <span class="arithmatex">\(\psi_{0}(z)=\rho^{\prime}(z)\)</span> <span class="arithmatex">\(=\max (-1, \min (1, z))\)</span>, and rewrite (1.15) and (1.16) as</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; E\left[\psi_{0}\left(\frac{g-a}{b}\right)\right]=0 \\
&amp; E\left[\psi_{0}\left(\frac{g-a}{b}\right)^{2}\right]=\frac{1}{k^{2}}
\end{aligned}
\]</div>
<p>As in Chapter 7 it is easy to show that there is always some pair ( <span class="arithmatex">\(a_{0}, b_{0}\)</span> ) with <span class="arithmatex">\(b_{0} \geqslant 0\)</span> minimizing <span class="arithmatex">\(Q(a, b)\)</span>.</p>
<p>We first take care of the limiting case <span class="arithmatex">\(b_{0}=0\)</span>. For this it is advisable to scale <span class="arithmatex">\(\psi\)</span> differently, namely to divide the right-hand side of (1.5) by <span class="arithmatex">\(b(\theta)\)</span>. In the limit <span class="arithmatex">\(b=0\)</span> this gives</p>
<div class="arithmatex">\[
\psi(x ; \theta)=\operatorname{sign}(g(x ; \theta)-a(\theta))
\]</div>
<p>The differential conditions for <span class="arithmatex">\(\left(a_{0}, 0\right)\)</span> to be a minimum of <span class="arithmatex">\(Q\)</span> now have a <span class="arithmatex">\(&lt;\)</span> sign in (1.16), since we are on the boundary, and they can be written out as</p>
<div class="arithmatex">\[
\begin{gathered}
\int \operatorname{sign}(g(x ; \theta)-a(\theta)) f(x ; \theta) d \mu=0 \\
1 \geqslant k^{2} P\{g(x ; \theta) \neq a(\theta)\}
\end{gathered}
\]</div>
<p>If <span class="arithmatex">\(k&gt;1\)</span>, and if the distribution of <span class="arithmatex">\(g\)</span> under <span class="arithmatex">\(F_{\theta}\)</span> is such that</p>
<div class="arithmatex">\[
P\{g(x ; \theta)=a\}&lt;1-k^{-2}
\]</div>
<p>for all real <span class="arithmatex">\(a\)</span>, then (1.19) clearly cannot be satisfied. It follows that (1.20) is a sufficient condition for <span class="arithmatex">\(b_{0}&gt;0\)</span>. Conversely, the choice <span class="arithmatex">\(k=1\)</span> forces <span class="arithmatex">\(b_{0}=0\)</span>. In particular, if <span class="arithmatex">\(g(x ; \theta)\)</span> has a continuous distribution under <span class="arithmatex">\(F_{\theta}, k&gt;1\)</span> is a necessary and sufficient condition for <span class="arithmatex">\(b_{0}&gt;0\)</span>.</p>
<p>Assume now that <span class="arithmatex">\(b_{0}&gt;0\)</span>. Then, in a way similar to that in Section 7.7, we find that <span class="arithmatex">\(Q\)</span> is strictly convex at <span class="arithmatex">\(\left(a_{0}, b_{0}\right)\)</span> provided the following two assumptions are true:
(1) <span class="arithmatex">\(\left|g-a_{0}\right|&lt;b_{0}\)</span> with nonzero probability.
(2) Conditionally on <span class="arithmatex">\(\left|g-a_{0}\right|&lt;b_{0}, g\)</span> is not constant.</p>
<p>It follows that then <span class="arithmatex">\(\left(a_{0}, b_{0}\right)\)</span> is unique.
In other words we now have determined a <span class="arithmatex">\(\psi\)</span> that satisfies the side conditions (1.9) and (1.10), and for which (1.11) is stationary under infinitesimal variations of <span class="arithmatex">\(\psi\)</span>, and it is the unique such <span class="arithmatex">\(\psi\)</span>. Thus we have found the unique solution to the minimum problem.</p>
<p>Unless <span class="arithmatex">\(a(\theta)\)</span> and <span class="arithmatex">\(b(\theta)\)</span> can be determined in closed form, the actual calculation of the estimate <span class="arithmatex">\(T_{n}=T\left(F_{n}\right)\)</span> through solving (1.1) may still be quite difficult. Also we may encounter the usual problems of ML estimation caused by nonuniqueness of solutions.</p>
<p>The limiting case <span class="arithmatex">\(b=0\)</span> is of special interest, since it corresponds to a generalization of the median. In detail this estimate works as follows. We first determine the median <span class="arithmatex">\(a(\theta)\)</span> of <span class="arithmatex">\(g(x ; \theta)=(\partial / \partial \theta) \log f(x ; \theta)\)</span> under the true distribution <span class="arithmatex">\(F_{\theta}\)</span>. Then we estimate <span class="arithmatex">\(\hat{\theta}_{n}\)</span> from a sample of size <span class="arithmatex">\(n\)</span> such that one-half of the sample values of <span class="arithmatex">\(g\left(x_{i} ; \hat{\theta}_{n}\right)-a\left(\hat{\theta}_{n}\right)\)</span> are positive, and the other half negative.</p>
<h1 id="112-shrinking-neighborhoods">11.2 SHRINKING NEIGHBORHOODS</h1>
<p>An interesting asymptotic approach to robust testing (and, through the methods of Section 10.6, to estimation) is obtained by letting both the</p>
<p>alternative hypotheses and the distance between them shrink with increasing sample size. This approach was first utilized by Huber-Carol (1970); recently, it has been further exploited by Rieder (1978, 1979, 1980a, b). The issues involved here deserve some discussion.</p>
<p>First, we note that the exact finite sample results of Chapter 10 are not easy to deal with; unless the sample size <span class="arithmatex">\(n\)</span> is very small, the size and minimum power are hard to calculate. This suggests the use of asymptotic approximations. Indeed for large values of <span class="arithmatex">\(n\)</span>, the test statistics, or more precisely, their logarithms (10.3.16) are approximately normal. But for increasing <span class="arithmatex">\(n\)</span>, either the size or the power of these tests, or both, tend to 0 or 1 , respectively, exponentially fast, which corresponds to a limiting theory we are interested in only very rarely. In order to get limiting sizes and powers that are bounded away from 0 and 1 , the hypotheses must approach each other at the rate <span class="arithmatex">\(n^{-1 / 2}\)</span> (at least in the nonpathological cases). If the diameters of the composite alternatives are kept constant, while they approach each other until they touch, we typically end up with a limiting sign-test. This may be a very sensible test for extremely large sample sizes (cf. Section 4.2 for a related discussion in an estimation context), but the underlying theory is relatively dull. So we shrink the hypotheses at the same rate <span class="arithmatex">\(n^{-1 / 2}\)</span>, and then we obtain nontrivial limiting tests.</p>
<p>Now two related questions pose themselves:
(1) Determine the asymptotic behavior of the sequence of exact, finite sample minimax tests.
(2) Find the properties of the limiting test; is it asymptotically equivalent to the sequence of the exact minimax tests?</p>
<p>The appeal of this approach lies in the fact that it does not make any assumptions about symmetry, and we therefore have good chances to obtain a workable theory of asymptotic robustness for tests and estimates without assuming symmetry.</p>
<p>However, there are conceptual drawbacks connected with these shrinking neighborhoods; somewhat pointedly, we may say that these tests are robust with regard to zero contamination only!</p>
<p>It appears that there is an intimate connection between limiting robust tests determined on the basis of shrinking neighborhoods and the robust estimates found through Hampel's extremal problem (Section 11.1), which share the same conceptual drawbacks.</p>
<p>This connection is now sketched very briefly; details can be found in the references mentioned at the beginning of this section; compare, in particular, Theorem 3.7 of Rieder (1978).</p>
<p>Assume that <span class="arithmatex">\(\left(P_{\theta}\right)_{\theta}\)</span> is a sufficiently regular family of probability measures, with densities <span class="arithmatex">\(p_{\theta}\)</span>, indexed by a real parameter <span class="arithmatex">\(\theta\)</span>. To fix the idea consider total variation neighborhoods <span class="arithmatex">\(\mathscr{P}_{\theta, \delta}\)</span> of <span class="arithmatex">\(P_{\theta}\)</span>, and assume that we are to test robustly between the two composite hypotheses</p>
<div class="arithmatex">\[
\mathscr{P}_{\theta \pm n^{-1 / 2} \tau, n^{-1 / 2} \delta}
\]</div>
<p>According to Chapter 10 the minimax tests between these hypotheses will be based on test statistics of the form</p>
<div class="arithmatex">\[
\sum \psi_{n}\left(X_{i}\right)
\]</div>
<p>where <span class="arithmatex">\(\psi_{n}(X)\)</span> is a censored version of</p>
<div class="arithmatex">\[
\log \left(\frac{p_{\theta+n^{-1 / 2} \tau}(X)}{p_{\theta-n^{-1 / 2} \tau}(X)}\right)
\]</div>
<p>Clearly, the limiting test will be based on</p>
<div class="arithmatex">\[
\sum \psi\left(X_{i}\right)
\]</div>
<p>where <span class="arithmatex">\(\psi(X)\)</span> is a censored version of</p>
<div class="arithmatex">\[
\frac{\partial}{\partial \theta}\left[\log p_{\theta}(X)\right]
\]</div>
<p>It can be shown under quite mild regularity conditions that the limiting test is indeed asymptotically equivalent to the sequence of exact minimax tests.</p>
<p>If we standardize <span class="arithmatex">\(\psi\)</span> by subtracting its expected value, so that</p>
<div class="arithmatex">\[
\int \psi d P_{\theta}=0
\]</div>
<p>it turns out that the censoring is symmetric:</p>
<div class="arithmatex">\[
\psi(X)=\left[\frac{\partial}{\partial \theta} \log p_{\theta}-a_{\theta}\right]_{-b_{\theta}}^{+b_{\theta}}
\]</div>
<p>Note that this is formally identical to (1.5) and (1.6). In our case the</p>
<p>constants <span class="arithmatex">\(a_{\theta}\)</span> and <span class="arithmatex">\(b_{\theta}\)</span> are determined by</p>
<div class="arithmatex">\[
\int\left(\frac{\partial}{\partial \theta} \log p_{\theta}-a_{\theta}-b_{\theta}\right)^{+} d P_{\theta}=\int\left(\frac{\partial}{\partial \theta} \log p_{\theta}-a_{\theta}+b_{\theta}\right)^{-} d P_{\theta}=\frac{\delta}{\tau}
\]</div>
<p>In the above case the relations between the exact finite sample tests and the limiting test are straightforward, and the properties of the latter are easy to interpret. In particular, (2.8) shows that it will be very nearly minimax along a whole family of total variation neighborhood alternatives with a constant ratio <span class="arithmatex">\(\delta / \tau\)</span>.</p>
<p>Trickier problems arise if such a shrinking sequence is used to describe and characterize the robustness properties of some given test. We noted earlier that some estimates get relatively less robust when the neighborhood shrinks, in the precise sense that the estimate is robust, but <span class="arithmatex">\(\lim b(\varepsilon) / \varepsilon\)</span> <span class="arithmatex">\(=\infty\)</span>; compare Section 3.5. In particular, the normal scores estimate has this property. It is therefore not surprising that the robustness properties of the normal scores test do not show up in a naive shrinking neighborhood model [cf. Rieder (1979, 1980b)].</p>
<h1 id="references">References</h1>
<p>D. F. Andrews et al. (1972), Robust Estimates of Location: Survey and Advances, Princeton University Press, Princeton N.J.
F. J. Anscombe (1960), Rejection of outliers, Technometrics, 2, pp. 123-147.
V. I. Averbukh and O. G. Smolyanov (1967), The theory of differentiation in linear topological spaces, Russian Math. Surveys, 22, pp. 201-258.
<span class="arithmatex">\(\qquad\)</span> (1968), The various definitions of the derivative in linear topological spaces, Russian Math. Surveys, 23, pp. 67-113.
R. Beran (1974), Asymptotically efficient adaptive rank estimates in location models, Ann. Statist., 2, pp. 63-74.
<span class="arithmatex">\(\qquad\)</span> (1977a), Robust location estimates, Ann. Statist., 5, pp. 431-444.
<span class="arithmatex">\(\qquad\)</span> (1977b), Minimum Hellinger distance estimates for parametric models, Ann. Statist., 5, pp. 445-463.
<span class="arithmatex">\(\qquad\)</span> (1978), An efficient and robust adaptive estimator of location, Ann. Statist., 6, pp. 292-313.
P. J. Bickel (1973), On some analogues to linear combinations of order statistics in the linear model, Ann. Statist., 1, pp. 597-616.
<span class="arithmatex">\(\qquad\)</span> (1975), One-step Huber estimates in the linear model, J. Amer. Statist. Ass., 70, pp. <span class="arithmatex">\(428-434\)</span>.
<span class="arithmatex">\(\qquad\)</span> (1976), Another look at robustness: A review of reviews and some new developments, Scand. J. Statist., 3, pp. 145-168.
P. J. Bickel and A. M. Herzberg (1979), Robustness of design against autocorrelation in time I, Ann. Statist., 7, pp. 77-95.
P. J. Bickel and J. L. Hodges (1967), The asymptotic theory of Galton's test and a related simple estimate of location, Ann. Math. Statist., 4, pp. 68-85.
P. Billingsley (1968), Convergence of Probability Measures, John Wiley, New York.
G. E. P. Box and N. R. Draper (1959), A basis for the selection of a response surface design, J. Amer. Statist. Ass., 54, pp. 622-654.
N. Bourbaki (1952), Intégration, Ch. III, Hermann, Paris.
H. Chen, R. Gnanadesikan, and J. R. Kettenring (1974), Statistical methods for grouping corporations, Sankhya, B36, pp. 1-28.
H. Chernoff, J. L. Gastwirth, and M. V. Johns (1967), Asymptotic distribution of linear combinations of functions of order statistics with applications to estimation, Ann. Math. Statist., 38, pp. 52-72.</p>
<p>G. Choquet (1953/54), Theory of capacities, Ann. Inst. Fourier, 5, pp. 131-292.
<span class="arithmatex">\(\qquad\)</span> (1959), Forme abstraite du théorème de capacitabilité, Ann. Inst. Fourier, 9, pp. 83-89.
J. R. Collins (1976), Robust estimation of a location parameter in the presence of asymmetry, Ann. Statist., 4, pp. 68-85.
C. Daniel and F. S. Wood (1971), Fitting Equations to Data, John Wiley, New York.
H. E. Daniels (1954), Saddle point approximations in statistics, Ann. Math. Statist., 25, pp. <span class="arithmatex">\(631-650\)</span>.
<span class="arithmatex">\(\qquad\)</span> (1976), Paper presented at the Grenoble Statistics Meeting, 1976.
A. P. Dempster (1967), Upper and lower probabilities induced by a multivalued mapping, Ann. Math. Statist., 38, pp. 325-339.
<span class="arithmatex">\(\qquad\)</span> (1968), A generalization of Bayesian inference, J. Roy. Statist. Soc., B30, pp. 205-247.
<span class="arithmatex">\(\qquad\)</span> (1975), A subjectivist look at robustness, Proc. 40th Session I. S. I., Warsaw, Bull. Int. Statist. Inst., 46, Book 1, pp. 349-374.
L. Denby and C. L. Mallows (1977), Two diagnostic displays for robust regression analysis, Technometrics, 19, pp. 1-13.
S. J. Devlin, R. Gnanadesikan, and J. R. Kettenring (1975), Robust estimation and outlier detection with correlation coefficients, Biometrika, 62, pp. 531-545.
<span class="arithmatex">\(\qquad\)</span> (1979), Robust estimation of dispersion matrices and principal components, submitted to J. Amer. Statist. Ass.
J. L. Doob (1953), Stochastic Processes, John Wiley, New York.
R. M. Dudley (1969), The speed of mean Glivenko-Cantelli convergence, Ann. Math. Statist., 40, pp. 40-50.
R. Dutter (1975), Robust regression: Different approaches to numerical solutions and algorithms, Res. Rep. no. 6, Fachgruppe für Statistik, Eidgen. Technische Hochschule, Zurich.
<span class="arithmatex">\(\qquad\)</span> (1976), LINWDR: Computer linear robust curve fitting program, Res. Rep. no. 10, Fachgruppe für Statistik, Eidgen. Technische Hochschule, Zurich.
<span class="arithmatex">\(\qquad\)</span> (1977a), Numerical solution of robust regression problems: Computational aspects, a comparison. J. Statist. Comput. Simul., 5, pp. 207-238.
<span class="arithmatex">\(\qquad\)</span> (1977b), Algorithms for the Huber estimator in multiple regression, Computing, 18, pp. 167-176.
<span class="arithmatex">\(\qquad\)</span> (1978), Robust regression: LINWDR and NLWDR, COMPSTAT 1978, Proc., in Computational Statistics, L. C. A. Corsten, Ed., Physica-Verlag, Vienna.
A. S. Eddington (1914), Stellar Movements and the Structure of the Universe, Macmillan, London.
W. Feller (1966), An Introduction to Probability Theory and its Applications, Vol. II, John Wiley, New York.
C. A. Field and F. R. Hampel (1980), Small sample asymptotic distributions of <span class="arithmatex">\(M\)</span>-estimates of location, submitted to Biometrika.</p>
<p>A. A. Filippova (1962), Mises' theorem of the asymptotic behavior of functionals of empirical distribution functions and its statistical applications, Theor. Prob. Appl., 7, pp. <span class="arithmatex">\(24-57\)</span>.
R. A. Fisher (1920), A mathematical examination of the methods of determining the accuracy of an observation by the mean error and the mean square error, Monthly Not. Roy. Astron. Soc., 80, pp. 758-770.
D. Gale and H. Nikaidô (1965), The Jacobian matrix and global univalence of mappings, Math. Ann., 159, pp. 81-93.
R. Gnanadesikan and J. R. Kettenring (1972), Robust estimates, residuals and outlier detection with multiresponse data, Biometrics, 28, pp. 81-124.
A. M. Gross (1977), Confidence intervals for bisquare regression estimates, <span class="arithmatex">\(J\)</span>. Amer. Statist. Ass., 72, pp. 341-354.
J. Hájek (1968), Asymptotic normality of simple linear rank statistics under alternatives, Ann. Math. Statist., 39, pp. 325-346.
J. Hájek (1972), Local asymptotic minimax and admissibility in estimation, in: Proc. Sixth Berkeley Symposium on Mathematical Statistics and Probability, Vol. 1. University of California Press, Berkeley.
J. Hájek and V. Dupač (1969), Asymptotic normality of simple linear rank statistics under alternatives, II, Ann. Math. Statist., 40, pp. 1992-2017.
J. Hájek and Z. Šidák (1967), Theory of Rank Tests, Academic, New York.
W. C. Hamilton (1970), The revolution in crystallography, Science, 169, pp. <span class="arithmatex">\(133-141\)</span>.
F. R. Hampel (1968), Contributions to the theory of robust estimation, Ph. D. Thesis, University of California, Berkeley.
<span class="arithmatex">\(\qquad\)</span> (1971), A general qualitative definition of robustness, Ann. Math. Statist., 42, pp. <span class="arithmatex">\(1887-1896\)</span>.
(1973a), Robust estimation: A condensed partial survey, Z. Wahrscheinlichkeitstheorie Verw. Gebiete, 27, pp. 87-104.
(1973b), Some small sample asymptotics, Proc. Prague Symposium on Asymptotic Statistics, Prague.
(1974a), Rejection rules and robust estimates of location: An analysis of some Monte Carlo results, Proc. European Meeting of Statisticians and 7th Prague Conference on Information Theory, Statistical Decision Functions and Random Processes, Prague, 1974.
(1974b), The influence curve and its role in robust estimation, J. Amer. Statist. Ass., 62, pp. 1179-1186.
(1975), Beyond location parameters: Robust concepts and methods, Proc. 40th Session I. S. I., Warsaw 1975, Bull. Int. Statist. Inst., 46, Book 1, pp. 375-382. (1976), On the breakdown point of some rejection rules with mean, Res. Rep. no. 11, Fachgruppe für Statistik, Eidgen. Technische Hochschule, Zurich.
E. F. Harding and D. G. Kendall (1974), Stochastic Geometry, Wiley, London.
R. W. Hill (1977), Robust regression when there are outliers in the carriers, Ph. D. Thesis, Harvard University, Cambridge, Mass.</p>
<p>R. V. Hogg (1967), Some observations on robust estimation, J. Amer. Statist. Ass., 62, pp. 1179-1186.
(1972), More light on kurtosis and related statistics, J. Amer. Statist. Ass., 67, pp. 422-424.
(1974), Adaptive robust procedures, J. Amer. Statist. Ass., 69, pp. 909-927.
D. C. Hoaglin and R. E. Welsch (1978), The hat matrix in regression and ANOVA, Amer. Statist., 32, pp. 17-22.
P. W. Holland and R. E. Welsch (1977), Robust regression using iteratively reweighted least squares, Comm. Statist., A6, pp. 813-827.
P. J. Huber (1964), Robust estimation of a location parameter, Ann. Math. Statist., 35, pp. 73-101.
(1965), A robust version of the probability ratio test, Ann. Math. Statist., 36, pp. 1753-1758.
(1966), Strict efficiency excludes superefficiency, (Abstract), Ann. Math. Statist., 37, p. 1425.
(1967), The behavior of maximum likelihood estimates under nonstandard conditions, in: Proc. Fifth Berkeley Symposium on Mathematical Statistics and Probability, Vol. 1, University of California Press, Berkeley.
(1968), Robust confidence limits, Z. Wahrscheinlichkeitstheorie Verw. Gebiete, 10, pp. 269-278.
(1969), Théorie de l'Inférence Statistique Robuste, Presses de l'Université, Montreal.
(1970), Studentizing robust estimates, in: Nonparametric Techniques in Statistical Inference, M. L. Puri, Ed., Cambridge University Press, Cambridge, England.
(1972), Robust statistics: A review, Ann. Math. Statist., 43, pp. 1041-1067.
(1973a), Robust regression: Asymptotics, conjectures and Monte Carlo, Ann. Statist., 1, pp. 799-821.
(1973b), The use of Choquet capacities in statistics, Bull. Int. Statist. Inst., Proc. 39th Session, 45, pp. 181-191.
(1975), Robustness and designs, in: A Survey of Statistical Design and Linear Models, J. N. Srivastava, Ed., North Holland, Amsterdam.
(1976), Kapazitäten statt Wahrscheinlichkeiten? Gedanken zur Grundlegung der Statistik, Jber. Deutsch. Math.-Verein., 78, H.2, pp. 81-92.
(1977a), Robust covariances, in: Statistical Decision Theory and Related Topics, II, S. S. Gupta and D. S. Moore, Eds., Academic Press, New York.
(1977b), Robust Statistical Procedures, Regional Conference Series in Applied Mathematics No. 27, Soc. Industr. Appl. Math, Philadelphia, Penn.
(1979), Robust smoothing, Proc. ARO Workshop on Robustness in Statistics, April 11-12, 1978, R. L. Launer and G. N. Wilkinson, Eds., Academic Press, New York.
P. J. Huber and R. Dutter (1974), Numerical solutions of robust regression problems, in: COMPSTAT 1974, Proc. in Computational Statistics, G. Bruckmann, Ed., Physika Verlag, Vienna.</p>
<p>P. J. Huber and V. Strassen (1973), Minimax tests and the Neyman-Pearson lemma for capacities, Ann. Statist., 1, pp. 251-263; 2, pp. 223-224.
C. Huber-Carol (1970), Etude asymptotique de tests robustes, Ph.D. Thesis, Eidgen. Technische Hochschule, Zurich.
L. A. Jaeckel (1971a), Robust estimates of location: Symmetry and asymmetric contamination, Ann. Math. Statist., 42, pp. 1020-1034.
(1971b), Some flexible estimates of location, Ann. Math. Statist., 42, pp. <span class="arithmatex">\(1540-1552\)</span>.
(1972), Estimating regression coefficients by minimizing the dispersion of the residuals, Ann. Math. Statist., 43, pp. 1449-1458.
J. Jurečková (1971), Nonparametric estimates of regression coefficients, Ann. Math. Statist., 42, pp. 1328-1338.
L. Kantorovič and G. Rubinstein (1958), On a space of completely additive functions, Vestnik, Leningrad Univ., 13, no. 7 (Ser. Mat. Astr. 2), pp. 52-59, in Russian.
J. L. Kelley (1955), General Topology, Van Nostrand, New York.
G. D. Kersting (1978), Die Geschwindigkeit der Glivenko-Cantelli-Konvergenz gemessen in der Prohorov-Metrik, Habilitationsschrift, Georg-August-Universität, Göttingen.
B. Kleiner, R. D. Martin, and D. J. Thomson (1979), Robust estimation of power spectra, J. Roy. Statist. Soc., B41, No. 3, pp. 313-351.
W. S. Krasker and R. E. Welsch (1980), Efficient bounded influence regression estimation using alternative definitions of sensitivity, unpublished.
H. W. Kuhn and A. W. Tucker (1951), Nonlinear programming, in: Proc. Second Berkeley Symposium on Mathematical Statistics and Probability, University of California Press, Berkeley.
C. L. Lawson and R. J. Hanson (1974), Solving Least Squares Problems, Prentice Hall, Englewood Cliffs, N.J.
L. LeCam (1953), On some asymptotic properties of maximum likelihood estimates and related Bayes' estimates, Univ. Calif. Publ. Statist., 1, pp. 277-330.
E. L. Lehmann (1959), Testing Statistical Hypotheses, John Wiley, New York.
R. A. Maronna (1976), Robust <span class="arithmatex">\(M\)</span>-estimators of multivariate location and scatter, Ann. Statist., 4, pp. 51-67.
G. Matheron (1975), Random Sets and Integral Geometry, John Wiley, New York.
R. Miller (1964), A trustworthy jackknife, Ann. Math. Statist., 35, pp. 1594-1605.
(1974), The jackknife-A review, Biometrika, 61, pp. 1-15.
F. Mosteller and J. W. Tukey (1977), Data Analysis and Regression, Addison-Wesley, Reading, Mass.
J. Neveu (1964), Bases Mathématiques du Calcul des Probabilités, Masson, Paris; English translation by A. Feinstein, (1965), Mathematical Foundations of the Calculus of Probability, Holden-Day, San Francisco.
Y. V. Prohorov (1956), Convergence of random processes and limit theorems in probability theory, Theor. Prob. Appl., 1, pp. 157-214.</p>
<p>M. H. Quenouille (1956), Notes on bias in estimation, Biometrika, 43, pp. 353-360.
J. A. Reeds (1976), On the definition of von Mises functionals, Ph. D. thesis, Dept. of Statistics, Harvard University, Cambridge, Mass.
D. A. Relles and W. H. Rogers (1977), Statisticians are fairly robust estimators of location, J. Amer. Statist. Ass., 72, pp. 107-111.
W. J. J. Rey (1978), Robust Statistical Methods, Lecture Notes in Mathematics, 690, Springer-Verlag, Berlin.
H. Rieder (1978), A robust asymptotic testing model, Ann. Statist., 6, pp. 1080-1094.
(1979), Robustness of one and two sample rank tests against gross errors, to appear in Ann. Statist., 9.
(1980a), On local asymptotic minimaxity and admissibility in robust estimation, unpublished.
(1980b), Qualitative robustness of rank tests, unpublished.
M. Romanowski and E. Green (1965), Practical applications of the modified normal distribution, Bull. Géodésique, 76, pp. 1-20.
J. Sacks (1975), An asymptotically efficient sequence of estimators of a location parameter, Ann. Statist., 3, pp. 285-298.
J. Sacks and D. Ylvisaker (1972), A note on Huber's robust estimation of a location parameter, Ann. Math. Statist., 43, pp. 1068-1075.
(1978) Linear estimation for approximately linear models, Ann. Statist., 6, pp. 1122-1137.
H. Schönholzer (1979), Robuste Kovarianz, Ph. D. Thesis, Eidgen. Technische Hochschule, Zurich.
F. W. Scholz (1971), Comparison of optimal location estimators, Ph. D. Thesis, Dept. of Statistics, University of California, Berkeley.
G. Shafer (1976), A Mathematical Theory of Evidence, Princeton University Press, Princeton, N.J.
G. R. Shorack (1976), Robust studentization of location estimates, Statistica Neerlandica, 30, pp. 119-141.
C. Stein (1956), Efficient nonparametric testing and estimation, in: Proc. Third Berkeley Symposium on Mathematical Statistics and Probability, Vol. 1, University of California Press, Berkeley.
S. M. Stigler (1969), Linear functions of order statistics, Ann. Math. Statist., 40, pp. <span class="arithmatex">\(770-788\)</span>.
(1973), Simon Newcomb, Percy Daniell and the history of robust estimation 1885-1920, J. Amer. Statist. Assoc., 68, pp. 872-879.
C. J. Stone (1975), Adaptive maximum likelihood estimators of a location parameter., Ann. Statist., 3, pp. 267-284.
V. Strassen (1964), Messfehler und Information, Z. Wahrscheinlichkeitstheorie Verw. Gebiete, 2, pp. 273-305.
(1965), The existence of probability measures with given marginals, Ann. Math. Statist., 36, pp. 423-439.</p>
<p>K. Takeuchi (1971), A uniformly asymptotically efficient estimator of a location parameter, J. Amer. Statist. Ass., 66, pp. 292-301.
E. N. Torgerson (1970), Comparison of experiments when the parameter space is finite, Z. Wahrscheinlichkeitstheorie Verw. Gebiete, 16, pp. 219-249.
(1971), A counterexample on translation invariant estimators, Ann. Math. Statist., 42, pp. 1450-1451.
J. W. Tukey (1958), Bias and confidence in not-quite large samples (Abstract), Ann. Math. Statist., 29, p. 614.
(1960), A survey of sampling from contaminated distributions, in: Contributions to Probability and Statistics, I. Olkin, Ed., Stanford University Press, Stanford, Calif.
(1970), Exploratory Data Analysis, mimeographed preliminary edition.
(1977), Exploratory Data Analysis, Addison-Wesley, Reading, Mass.
R. von Mises (1937), Sur les fonctions statistiques, in: Conférence de la Réunion Internationale des Mathématiciens, Gauthier-Villars, Paris; also in: Selecta R. von Mises, Vol. II, Amer. Math. Soc., Providence, R.I. 1964.
(1947), On the asymptotic distribution of differentiable statistical functions, Ann. Math. Statist., 18, pp. 309-348.
G. Wolf (1977), Obere und untere Wahrscheinlichkeiten, Ph. D. Thesis, Eidgen, Technische Hochschule, Zurich.
V. J. Yohai and R. A. Maronna (1979), Asymptotic behavior of <span class="arithmatex">\(M\)</span>-estimators for the linear model, Ann. Statist., 7, pp. 258-268.</p>
<h1 id="index">Index</h1>
<p>Adaptive estimate, vi, 7
Analysis of variance, 195-198
Andrews, D. F., 54, 101, 103, 144, 175, 191
Ansari-Bradley-Siegel-Tukey test, 115
Anscombe, F. J., 73
Asymmetric contamination, 104-105
Asymptotic approximations, 47
Asymptotic efficiency, of M-, L-, and R-
estimate, 68-72
of scale estimate, 116-118
Asymptotic expansion, 47, 170
Asymptotic minimax theory, for location, 73
Asymptotic normality, 11
of fitted value, 159
of L-estimate, 60
of M-estimate, 50
of multiparameter M-estimate, 132-135
of regression estimate, 158-159
of regression M-estimate, 170
of robust estimate of scatter matrix, 226227
via Fréchet derivative, 39
Asymptotic properties, of M-estimate, 4551
Asymptotic relative efficiency, 2-3, 5
of covariance/correlation estimate, 210211
Asymptotics, of robust regression, 164-170
Averbukh, V. I., 40
Bayes formula, robust version, 253, 263264
Bayesian robustness, vi
Beran, R., 7
Bias, 11
compared to statistical variability, 75-76
maximum, 11-12, 104
of L-estimate, 59
of M-estimate, 52
of R-estimate, 67
minimax, 74-76, 205
in regression, 243, 252
in robust regression, 171-172
of scale estimate, 107
Bickel, P. J., 164, 243
Billingsley, P., 20
Binomial distribution, minimax robust test, 273
Biweight, 101-103
Borel-sigma-algebra, 20
Bounded Lipschitz metric, 29-35, 39
Bourbaki, N., 77
Box, G. E. P., v, 252
Breakdown, by implosion, 141, 234
Breakdown point, 13, 104
of estimate of scatter matrix, 227-228
of Hodges-Lehmann estimate, 67
of joint M-estimate of location and scale, 141-144
of L-estimate, 60, 72
of median absolute deviation (MAD), 176
of M-estimate, 54
of M-estimate of scale, 110
of M-estimate with preliminary scale estimate, 144
of normal scores estimate, 67
of proposal, 2, 143-144
of R-estimate, 67
of symmetrized scale estimate, 114
of trimmed mean, 13, 104-106, 143-144
variance, 13,106
Capacity, 253-254
monotone and alternating of infinite order, 262-264
2-monotone and 2-alternating, 260-262, 276
Cauchy distribution, efficient estimate for, 71
Censoring, 264, 292</p>
<p>Chen, H., 200
Chernoff, H., 60
Choquet, G., 261, 263
Collins, J. R., 101
Comparison function, 180, 182, 184-186, 239
Computation of M-estimate, 146
with modified residuals, 146
with modified weights, 146-147
by Newton-like method, 146-148
Computation of regression M-estimate, 1719, 179-192
convergence, 187-191
with modified residuals, 181
with modified weights, 183
Computation of robust covariance estimate, 237-242
Conjugate gradient method, 240-242
Consistency, 6, 8, 11
of fitted value, 157
of L-estimate, 60
of M-estimate, 48
of multiparameter M-estimate, 127-132
of R-estimate, 68
of robust estimate of scatter matrix, 226227
Consistent estimate, 41
Contaminated normal distribution, 2
minimax estimate for, 97,99
Contamination, 110, 271
asymmetric, 104-105
Contamination neighborhood, 11, 75, 85, 276
Continuity, of L-estimate, 60
of M-estimate, 54
of R-estimate, 68
of statistical functional, 41
of trimmed mean, 60
of Winsorized mean, 60
Correlation, robust, 203-204
Correlation matrix, 199
Covariance, estimation of matrix elements through robust correlation, 204-211
estimation of matrix elements through robust variances, 202-203
robust, 202
Covariance estimation in regression, 172-175
correction factors, 173-174
Covariance matrix, 17, 199
Cramér-Rao bound, 4</p>
<p>Daniell's theorem, 24
Daniels, H. E., 47
Dempster, A. P., 263
Derivative, Fréchet, 34-40
Gâteaux, 34-40
Descending M-estimate, 100-103
enforcing uniqueness, 54
minimax, 100-102
of regression, 191-192
sensitive to wrong scale, 102-103
Design, robustness, 243
Design matrix, conditions on, 165
errors in, 163, 195
Deviation, mean absolute and mean square, 2
Deviations, from linearity, 243
Devlin, S. J., 200, 203
Differentiability, Fréchet, 35, 37
Discriminant analysis, 199
Distance, Bounded Lipschitz, see Bounded Lipschitz metric
Kolmogorov, see Kolmogorov metric
Lévy, see Lévy metric
Prohorov, see Prohorov metric
total variation, see Total variation metric
Distributional robustness, 1,4
Distribution, limiting, of M-estimate, 48
Distribution-free, distinction between robust and, 6
Distribution function, empirical, 8
Doob, J. L., 128
Draper, N. R., 252
Dudley, R. M., 40
Dupac, V., 116
Dutter, R., 184, 187, 191
Eddington, A. S., v, 2
Edgeworth expansion, 47-48
Efficiency, absolute, 5
asymptotic, of M-, L-, and R-estimate, <span class="arithmatex">\(68-72\)</span>
of scale estimate, 116-118
asymptotic relative, 2-3, 5
Efficient estimate, for Cauchy distribution, 71
for least informative distribution, 71, 99
for logistic distribution, 71
for normal distribution, 70
Ellipsoid, to describe shape of pointcloud, 199</p>
<p>Elliptic density, 211, 237
Empirical distribution function, or measure, 8
Error, gross, 3, 5, 9
Estimate, adaptive, vi, 7
consistent, 41
defined through implicit equations, 130
defined through a minimum property, <span class="arithmatex">\(128-130\)</span>
derived from rank test, see R-estimate derived from test, 278-282
Hodges-Lehmann, see Hodges-Lehmann estimate
L-, see L-estimate
of location and scale, 127
<span class="arithmatex">\(\mathrm{L}_{1}-\)</span>, see <span class="arithmatex">\(\mathrm{L}_{1}\)</span>-estimate
<span class="arithmatex">\(\mathrm{L}_{\mathrm{p}^{-}}\)</span>, see <span class="arithmatex">\(\mathrm{L}_{\mathrm{p}}\)</span>-estimate
M-, see M-estimate
maximum likelihood, 8
Maximum likelihood type, see M-estimate minimax interval, 282-285
minimax of location and scale, 137
<span class="arithmatex">\(\mathrm{R}-\)</span>, see R -estimate
randomized, 279, 281, 285
of scale, 107
Expansion, asymptotic, 47, 170
Edgeworth, 47-48
Expectation, lower and upper, 254
Factor analysis, 199
Feller, W., 51, 159
Field, C. A., 48
Filippova, A. A., 40
Finite sample, 253
minimax robustness, 265
Fisher, R. A., 2
Fisher consistency, 6, 108, 149, 286
Fisher information, 68, 77
convexity, 79
distribution minimizing, 77-82, 208, 229237
equivalent expressions for, 82
minimization by variational methods, 82 90
minimized for <span class="arithmatex">\(\epsilon\)</span>-contamination, 85
for scale, 118-122
Fisher information matrix, 133
Fitted value, asymptotic normality, 159 consistency, 157
Fréchet derivative, 34-40, 37, 39, 68</p>
<p>Fréchet differentiability, 35, 37, 68
Functional, statistical, 8,9
weakly continuous, 41
Gale, D., 139
Gâteaux derivative, 34-40, 115
Global fit, minimax, 243-251
Gnanadesikan, R., 200, 202
Green, E., 91, 94
Gross error, 3, 5, 9
Gross error model, 11
generalized, 262-263
see also Contamination neighborhood
Gross error sensitivity, 14, 17, 71, 74, 286287
of questionable value for L - and R estimate, 286
Grouping, 9
Hájek, J., 70, 116, 207
Hamilton, W. C., 164
Hampel, F. R., 10, 13-14, 17, 38, 41, 47, <span class="arithmatex">\(48,74,101-102,194,286-287\)</span>
Hampel estimate, 101-103, 146-147
Hampel's extremal problem, 286-290, 291
Hampel's theorem, 40-42
Harding, E. F., 263
Hat matrix, 156, 165
updating, 160-161
Herzberg, A. M., 243
Hodges-Lehmann estimate, 9, 63, 71, 145146
breakdown point, 67
influence function, 64
Hogg, R. V., 7
Huber-Carol, C., 291
Hunt-Stein theorem, 284
Influence curve, see Influence function
Influence function, 13, 38
and asymptotic variance, 15
of Hodges-Lehmann estimate, 64
of interquantile distance, 111
and jackknife, 16, 150-152
of joint estimate of location and scale, 136-137
of L-estimate, 56-59
of median, 57
of median absolute deviation (MAD), 137138</p>
<p>of M-estimate, 45, 287
of normal scores estimate, 65
of one-step M-estimate, 140-141
of quantile, 56
of R-estimate, 63-65
of robust estimate of scatter matrix, 223
of trimmed mean, 57-58
of trimmed standard deviation, 112
of Winsorized mean, 58
used for studentizing, 150-152
Interquantile distance, 126
influence function, 111
Interquartile distance, 12
compared to median absolute deviation (MAD), 107
Interval estimate, derived from rank test, 6 minimax, 282-285
Intuition, unreliability, 59
Iterativc reweighting, see Modified weights
Jackknife, 15-16, 149-152
Jackknifed pseudovalue, 15
Jaeckel, L. A., 98, 163
Jeffreys, H., v
Jurečková, J., 163
Kantorovic, L., 30
Kelley, J. L., 22
Kendall, D. G., 263
Kersting, G. D., 40
Kettenring, J. R., 200, 202
Kleiner, B., 19
Klotz test, 115, 118
Kolmogorov metric, 34, 86, 110, 271
Krasker, W. S., 194
Kuhn-Tucker theorem, 30
Least favorable, pair of distributions, 266
see also Least informative distribution
Least informative distribution, 71
discussion of its realism, 91
for <span class="arithmatex">\(\epsilon\)</span>-contamination, 85,87
for Kolmogorov metric, 86-90
for multivariate location, 229-231
for multivariate scatter, 231-234
for scale, 120-121
Least squares, 155
robustizing, 162-164
LeCam, L., 70
Lehmann, E. L., 52, 271, 275, 284</p>
<h2 id="index_1">INDEX</h2>
<p>L-estimate, vi, 43, 55-61, 127
asymptotically efficient, 68-72
asymptotic normality, 60
breakdown point, 60, 72
consistency, 60
continuous as a functional, 60
gross error sensitivity, 286
influence function, 56-59
for logistic, 71
maximum bias, 59
minimax properties, 97-99
quantitative and qualitative robustness, 59-61
of regression, one-step, 164
of scale, 110-114, 117
<span class="arithmatex">\(\mathrm{L}_{1}\)</span>-estimate, 176
of regression, 164, 178
<span class="arithmatex">\(\mathrm{L}_{\mathrm{p}}\)</span>-estimate, 133
Leverage point, 155, 160, 192-195, 243
Lévy metric, 25-29, 34-35, 39, 41, 110, 271
Lévy neighborhood, 11, 13, 75
Liggett, T., 79
Limiting distribution, of M-estimate, 48
Lindeberg condition, 49
Linear combinations of order statistics, see L-estimate
Linearity, deviations from, 243
Lipschitz metric, bounded, see Bounded Lipschitz metric
Location estimate, multivariate, 222
Location step, in computation of robust covariance matrix, 238
with modified residuals, 181
with modified weights, 183
Logistic distribution, efficient estimate for, 71
Lower expectation, 254
Lower probability, 254
MAD, see Median absolute deviation
Mallows, C., 194
Maronna, R. A., 170, 215, 223, 226, 239
Matheron, G., 263
Maximum bias, 11-12, 104
Maximum likelihood estimate, 8
of scatter matrix, 211-215
Maximum likelihood type estimate, see M-estimate
Maximum variance, 11-12</p>
<p>under asymmetric contamination, 104 105
Mean absolute deviation, 2
Mean square deviation, 2
Measure, empirical, 8
regular, 20-21
substochastic, 76,81
Measure with finite support, 22
Median, 54, 97, 129, 137, 290
has minimax bias, 75
influence function, 57
Median absolute deviation (MAD), 107-<span class="arithmatex">\(109,112,114,144-146,175,205\)</span>
compared to halved interquartile distance, 107
influence function, 137
as the most robust estimate of scale, 122
Median absolute residual, 175-176
M-estimate, 43-55, 127
asymptotically efficient, 68-72
asymptotically minimax, 94-97, 177
asymptotically minimax for contaminated normal, 97
asymptotic normality, 50
asymptotic normality of multiparameter, 132-135
asymptotic properties, 45-51
breakdown point, 54
computation, 146
consistency, 48, 127-132
continuous as a functional, 54
exact distribution, 47
influence function, 45, 287
maximum bias, 52
nonnormal limiting distribution, 51, 96
one-step, 140
with preliminary scale estimate, 140-141
breakdown point, 144
quantitative and qualitative robustness, 52-54
studentizing, 150
M-estimate of location, 43, 285
M-estimate of location and scale, 135-139
breakdown, 141
existence, 138
uniqueness, 138
M-estimate of regression, 162
computation, 179-192
M-estimate of scale, 109-110, 117, 125
breakdown point, 110 minimax properties, 122-124
Metric, Bounded Lipschitz, see Bounded Lipschitz metric
Kolmogorov, see Kolmogorov metric
Lévy, see Lévy metric
Prohorov, see Prohorov metric
total variation, see Total variation metric
Miller, R., 15
Minimax bias, 74-76, 205
Minimax descending M-estimate, 100-102
Minimax global fit, 243-251
Minimax interval estimate, 282-285
Minimax properties, of L-estimate, 97-99
of M-estimate, 94-97
of M-estimate of scale, 122-124
of M-estimate of scatter, 234
of R-estimate, 97-99
Minimax robustness, asymptotic, 17
finite sample, 17, 265
Minimax slope, 251
Minimax test, 264-273, 271
for binomial distribution, 273
for normal distribution, 272
Minimax theory, asymptotic, for location, 73
Minimax variance, 76
Modified residuals, in computing regression estimate, 181
Modified weights, in computing regression estimate, 183
Mood test, 115
Mosteller, F., 7
Multiparameter problems, 127
Multivariate location estimate, 222
Neighborhood, closed delta-, 26
contamination, see Contamination neighborhood
Kolmogorov, see Kolmogorov neighborhood
Lévy, see Lévy neighborhood
Prohorov, see Prohorov neighborhood
total variation, see Total variation neighborhood
Neighborhoods, shrinking, 290
Neveu, J., 20-21, 24, 50
Newcomb, S., v
Newton method, 146, 170, 239
Neyman-Pearson lemma, 270
for 2-alternating capacities, 275-278, 277</p>
<p>test statistic, 8
Nikaidú, H., 139
Nonparametric, distinction between robust and, 6
Normal distribution, contaminated, 2
efficient estimate for, 70
minimax robust test, 272
Normal scores estimate, 145
breakdown point, 67
influence function, 65, 71
One-step estimate, of regression, 170
One-step L-estimate, 164
One-step M-estimate, 140
Optimality properties, correspondence between test and estimate, 282
Order statistics, linear combinations, see L-estimate
Outlier, in regression, 4, 160
Outlier rejection, 4
comparison to robust procedures, 4-5
Outlier resistant, 4
Pointcloud, shape, 199
Polish space, 20, 25, 29
Principal component analysis, 199
Probability, lower and upper, 254
Prohorov, Y. V., 20, 24
Prohorov metric, 25-29, 27, 33-35, 34, 39, <span class="arithmatex">\(41,42,110,271\)</span>
Prohorov neighborhood, 26, 28, 277
Proposal, 2, 137, 144-145, 289
breakdown point, 143-144
Pseudo-covariance estimate, determined by implicit equations, 213
Pseudo-covariance matrix, 212
Pseudo-observations, 18, 197
Pseudo-variance, 12
Quadrant correlation, 205-206
Qualitative robustness, 7-10
of L-estimate, 59-61
of M-estimate, 52-54
of R-estimate, 65-68
and weak continuity, 8
Quantile, influence function, 56
Quantile distance, normalized, 12
Quantitative robustness, of L-estimate, 5961
of M-estimate, 52
of R-estimate, 65-68
Quenouille, M. H., 15
Rank correlation, Spearman, 205
Rank test, 281
estimate derived from, see R-estimate
interval estimate derived from, 6
Redescending, see Descending
Reeds, J. A., 37, 40
Regression, 17, 153
asymptotic normality of estimate, 158-159
L-estimate, 164
M-estimate, 162
R-estimate, 163
Regular measure, 20-21
Residuals, 160
and interpolated values, 162-164
Resistant, against outliers, 4
Resistant procedure, 7,9
R-estimate, vi, 43, 61-68, 127
asymptotically efficient, 68-72
breakdown point, 67
consistency, 68
continuity, 68
gross error sensitivity, 286
influence function, 63-65
of location, 62
minimax properties, 97-99
quantitative and qualitative robustness, 65-68
quantitative robustness, 65-68
of regression, 163
of scale, 114-116, 118
of shift, 62
Ridge regression, 155
Rieder, H., 291, 293
Robust, comparison to nonparametric and distribution-free, 6
Robust correlation, interpretation, 210
Robust covariance, affinely invariant estimate, 211-215
Robust covariance estimate, computation, 237-242
Robust estimate, computation, 17
construction, 72
standardization, 6
Robustness, 1
asymptotic minimax, 17
of design, 172, 243
distributional, 1,4</p>
<p>finite sample minimax, 17
infinitesimal, 13-16
as an insurance problem, 73
optimal, 16-17
qualitative, <span class="arithmatex">\(7-10\)</span>
qualitative, definition, 10
and weak continuity, 8
quantitative, <span class="arithmatex">\(10-13\)</span>
of validity, 6
Robust procedure, desirable features, 5
Robust regression, asymptotic normality, 170
asymptotics, <span class="arithmatex">\(164-170\)</span>
bias, 171-172
Robust test, 253, 264-273, 290-293
Romanowski, M., 91, 94
Rounding, 9
Rubinstein, G., 30
Sacks, J., 7, 90, 98, 243
Saddlepoint technique, 47
Sample median, see Median
Scale, L-estimate, 110-114
M-estimate, 109-110
R-estimate, 114-116
Scale estimate, 107
asymptotically efficient, 116-118
in regression, 163, 175-178
symmetrized version, 113
Scale functional, 202
Scale invariance, 127
Scale step, in computation of regression M-estimate, 179-180
Scatter matrix, breakdown point of estimate, 227-228
consistency and asymptotic normality, 226-227
existence of solution, 215-219
influence function of robust estimate, 223
maximum likelihood estimate, 211-215
uniqueness of solution, 219-221
Scatter step, in computation of robust covariance matrix, 238
Scholz, F. W., 138
Schönholzer, H., 215, 226
Schrödinger equation, 83
Schweppe, F. C., 194
Scores generating function, 61, 63
Sensitivity, gross error, 14, 17, 71, 74, 286-287
of classical procedures to long tails, 4
Sensitivity curve, 15
Separability, in the sense of Doob, 128, 131
Sequential test, 273-275
Shafer, G., 263
Shorack, G. R., 150
Shrinking neighborhoods, 290
Šidák, Z., 207
Sign test, 282, 291
Sine wave, of Andrews, 54, 103
Slope, minimax, 251
Smolyanov, O. G., 40
Space, Polish, 20, 25, 29
Spherical symmetry, 237
Stability principle, 1,10
Stahel, W., 228
Statistical functional, 8, 9
asymptotic normality, 11
consistency, 11
Stein, C., 7
Stein estimation, 155
Stigler, S. M., 61
Stone, C. J., 7
Strassen, V., 27, 263, 276, 278
Strassen's theorem, 27, 30, 41
Studentizing, 148-152, 197
comparison between jackknife and influence function, 150-152
an M-estimate of location, 150
a trimmed mean, 150-151
Subadditive, 255
Substochastic measure, 76, 81
Superadditive, 255
Symmetrized scale estimate, 113
breakdown point, 114
Symmetry, may be unrealistic assumption, 95</p>
<p>Takeuchi, K., 7
Test, of independence, 199, 206
minimax robust, 265, 290-293
for binomial distribution, 273
for normal distribution, 272
sequential, 273-275
Tight, 23-24
Topology, vague, 76, 79
weak, 20, 25
Torgerson, E. N., 281
Total variation, 271</p>
<p>Total variation metric, 27, 34
Trimmed mean, 9, 13, 71-72, 94, 104-106, <span class="arithmatex">\(145-146\)</span>
breakdown point, 143-144
continuity, 60
influence function, 57-58
studentizing, 150-151
Trimmed standard deviation, 94, 125
influence function, 112
Trimmed variance, 112, 122
Tukey, J. W., 1, 7, 15-16, 101
Upper expectation, 254
Upper probability, 254
Vague topology, 76, 79
Variance, estimation, 108
iteratively reweighted estimate is incon-
sistent, 175, 198
jackknifed, 152
maximum, 11-12
minimax, 76
Variance breakdown point, 13</p>
<h2 id="index_2">INDEX</h2>
<p>Variance ratio, 249-251
Volterra derivative, see Gâteaux derivative
Von Mises, R., 40
Weak continuity, 8, 9-10, 21
Weak convergence, equivalence lemma, 22
on the real line, 23
Weak-star, see Weak continuity
Weak topology, 20, 25
generated by Prohorov and Bounded
Lipschitz metric, 33
Welsch, R. E., 194
Wilcoxon test, 63, 282
Winsorized mean, continuity, 60
influence function, 58
Winsorized residuals, metrically, 180, 182
Winsorized sample, 151
Winsorized variance, 113
Winsorizing, metrically, 18, 163
Wolf, G., 259
Ylvisaker, D., 90, 98, 243
Yohai, V. J., 170</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  ページトップへ戻る
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 Tomoshige Nakamura
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.tabs", "navigation.expand", "navigation.path", "navigation.indexes", "navigation.sections", "navigation.top", "navigation.tracking", "toc.follow"], "search": "../../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.60a45f97.min.js"></script>
      
        <script src="../../../../../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>
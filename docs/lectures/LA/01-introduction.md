# 講義1: コースイントロダクション

## 1. 本日扱う内容について（概要）

- **講義の目的:** 

  - 線形代数学コース全体の概要説明  
  - 評価方法の提示  
  - 使用ツール（ChatGPT, Google Colab）の紹介  
  - 線形代数学の意義と、統計学・機械学習、医療データ、画像処理への応用事例の提示

- **講義の流れ:**  

  - 講義全体の概要および評価方法の説明  
  - 使用ツール（ChatGPTとGoogle Colab）の紹介と基本的な使い方の説明  
  - 線形代数学の意義、そして各分野（統計学・機械学習、医療データ、画像処理）への応用事例の具体例紹介


## 2. 本日の内容の説明（概要・定義・定理など）

### 2.1 線形代数学とは
  線形代数学は、ベクトル、行列、線形写像などの基本概念を用いて、データやシステムの構造を解析する数学の分野です。
  - **基本概念:**  
    - **ベクトル:** 大きさと方向を持つ量。  
    - **行列:** 数値や関数を格子状に並べたもので、複数のデータを一括して扱うためのツール。  
    - **線形写像:** ベクトル空間間の変換で、加法性とスカラー倍の性質を保つ写像。
  
  この講義は、前期の線形代数学I, 線形代数学（基礎）、後期の線形代数学IIの3つの授業で完結するように設計されている。


### 2.2 線形代数とデータサイエンスの関係

データサイエンスで解きたい課題は、大きく教師あり学習と教師なし学習に大別される。

**教師あり学習**とは、例えば、医療データにおいて、過去の診断結果や治療記録を基に患者の病状を予測するケースや、スポーツデータにおいて、試合結果や選手の成績を元に次のパフォーマンスを予測するケースのように、ラベル付きデータを用いてモデルを学習し、未知のデータに対する予測を行うことである。

**教師なし学習**とは、医療データで疾患の共通パターンを抽出したり、スポーツデータで選手のプレースタイルやチームの戦略的特徴を明らかにするために、データ自体の構造や特徴を解析する手法である。

教師あり学習の基本手法として最も広く用いられているのが**線形回帰モデル**であり、その基礎となるのは線形代数学で学ぶ**連立1次方程式**である。対して、教師なし学習の代表的手法である**主成分分析**は、**固有値・固有ベクトルを用いた行列の固有値分解**に基づいている。

これら二つの概念を確実に習得することが、データサイエンスを学ぶ上での第一歩です。この講義では、連立方程式から線形回帰モデルへの応用、固有値・固有ベクトルを用いた主成分分析、さらに特異値分解、さらに時間が許せば因子分析の基礎までを幅広くカバーする。

### 2.3 成績の評価
前期の線形代数学Iと線形代数学（基礎）は、2つの授業を合わせて評価を行います。評価は、次の3つを通して実施します。

- **中間試験:** 持ち込み不可の60分の筆記試験です。基本的な行列の計算や、性質が理解できているかを確認します（30％）。
- **期末課題:** 自由記述形式の60分の授業内レポート試験です（30％）。
- **期末試験:** 持ち込み不可の60分の筆記試験です。基本的な行列の計算や、性質が理解できているかを確認します（40％）。

中間試験と期末試験は、線形代数で学ぶ基本計算の理屈がきちんと理解できているかを確かめるためのものです。一方で、期末課題は線形代数学とデータサイエンスの理論のつながりをきちんと説明できるかを確かめるための筆記試験です。これら3つの結果を総合して評定の判断を行います。評定の基準は以下のとおりです。

- **S** : 90%以上
- **A** : 80%以上〜89.9%以下
- **B** : 70%以上〜79.9%以下
- **C** : 60%以上〜69.9%以下
- **D** : 59.9%以下

### 2.4 生成AIの活用
この授業では、生成AIを活用します。この授業には、必ずPCを持ち込みましょう。その上で、わからないことは**ChatGPT**（そのほかの生成AIでもok）を用いて解決するというのを必ず実践してください。また、計算結果や図の表示は、**Google Colaboratory**を利用します。こちらは、ChatGPTを用いて生成したコードを実行して、計算結果や図を表示した視覚的理解をサポートしてくれます。

## 3. ChatGPT (LLM) の活用方法

### 3.1 概要
**ChatGPT** は、OpenAIが提供する大規模言語モデル（LLM）です。このほかLLMには、Googleの**Gemini**や、Anthropic が提供する **claude** もあります。自分が好きなものを利用すれば良いです。ただし、この授業では**ChatGPT**を基本として利用します。授業の理解を深めるための補助ツールとして活用できるので、積極的に利用しましょう。

従来型の授業では、教科書と演習問題＋友達や先生に聞くがメインだったと思いますが、これからの時代はここに**LLM**を加えることで、さらに学習する速度が加速するはずです。疑問点の解消や、補足説明、さらには理論背景の再確認など、様々な用途に利用してください。

### Step by Step 利用方法

1. **質問の準備:**  

   - 講義中に生じた疑問点や、より深い理解が必要な箇所を整理し、具体的な質問としてまとめる。  
   - 例: 「行列とベクトルの違いについて、もう少し詳しく説明してください。」

2. **質問の入力:**  

   - ChatGPTのチャットウィンドウに整理した質問を入力する。  
   - 例: 「内積の計算ルールをステップごとに教えてください。」

3. **回答の確認:**  

   - ChatGPTからの返答を読み、講義資料と照らし合わせながら理解を深める。  
   - 必要に応じて追加質問を行い、詳細な説明を求める。

4. **ディスカッションへの応用:**  

   - 得られた回答をグループディスカッションで共有し、他の学生の意見も参考にしながら理解を広げる。

5. **復習と予習:** 
  
   - 講義後の復習や、次回の予習の際にも、ChatGPTを利用して不明点を解消する。

## 4. Google Colaboratory の使い方

### 4.1 概要
Google Colaboratory (**Colab**) は、ブラウザ上でPython, Rのコードを実行できるオンライン環境です。講義で紹介するコード例や演習問題を、実際に動かして確認するために使用します。

一般的には、プログラムの書き方を学んでから、Colabで実際に自分で書いて動かしましょうということをするのですが、プログラムの書き方を学ばなくても、実際にコードを動かすことはできます。この授業では、プログラムの書き方は教えませんが、ChatGPTを利用してコードを生成し、それをColab上で動かして、動作を確認していきます。



### 4.2 Step by Step 利用方法

1. **Google Colabへのアクセス:**  

   - ウェブブラウザで [Google Colab](https://colab.research.google.com/) にアクセスします。  
   - Googleアカウントでログインします。

2. **新しいノートブックの作成:**  

   - 「新しいノートブック」をクリックして、空のノートブックを作成します。  
   - ノートブックの名前を「線形代数学_第1回」などに変更して、管理しやすくします。

3. **セルの使い方の理解:**  

   - Colabには「コードセル」と「テキストセル」があり、コードの実行や解説の記入に利用します。  
   - コードセルには講義のコード例を貼り付け、テキストセルにはメモや解説、質問などを記入してください。

4. **コードの実行:**  

   - コードセルを選択し、左側の再生ボタンをクリックするか、Shift+Enterキーを押してコードを実行します。  
   - 実行結果はセルの下に表示され、グラフや数値出力も確認できます。

5. **演習問題への応用:**  

   - 講義で出された演習問題のコードをColabに入力し、実際に実行して動作を確認します。  
   - 分からない点はセル内にコメントを追加するなどして、後で見返しやすくします。

6. **ファイルの保存と共有:**  

   - ノートブックは自動的にGoogleドライブに保存されます。  
   - 「共有」ボタンを使って、他の学生や講師とノートブックを共有することも可能です。


### 4.3 AIでコードを生成する
この授業では、授業中に生成AIでコードを生成して、それをColabに貼り付けることで結果を確認するという使い方がメインですが、コードセルには"AIで生成"というボタンがあります。このボタンを使用すると、生成AIを用いて自分がやりたい操作に対応するコードを書いてくれます。


## 5. 扱う内容の例（実例を提示、GPT, Colabなどは利用しない）

### 5.1 統計学・機械学習への応用例: 主成分分析（PCA）による次元削減

- **概要:**  
  線形代数学の基礎概念（固有値・固有ベクトルや行列分解）を用いて、多次元データから重要な情報を抽出し、次元削減を行う手法です。  
- **具体例:**  
  実際のIrisデータセットを用いて、4次元のデータを2次元に縮約し、データのクラスタリング傾向を視覚化します。  
- **コード例:**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

# Irisデータセットの読み込み
iris = load_iris()
X = iris.data
y = iris.target

# PCAで4次元から2次元に次元削減
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# 結果の散布図を作成
plt.figure(figsize=(8,6))
for label in np.unique(y):
    plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], label=iris.target_names[label])
plt.xlabel('第1主成分')
plt.ylabel('第2主成分')
plt.title('IrisデータセットのPCA結果')
plt.legend()
plt.show()
```

### 5.2 統計学・機械学習への応用例: 最小二乗法による線形回帰

- **概要:**  
  線形代数学の応用として、正規方程式を用いて与えられたデータに対して最適な直線をフィッティングする手法です。  
- **具体例:**  
  ランダムに生成したサンプルデータに対して、独立変数と従属変数の関係を線形モデルで近似し、最適なパラメータ（切片と傾き）を求めます。  
- **コード例:**

```python
import numpy as np
import matplotlib.pyplot as plt

# サンプルデータの生成
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# バイアス項を含む行列X_bの作成（Xに1の列を追加）
X_b = np.c_[np.ones((100, 1)), X]

# 正規方程式を用いて最小二乗解を計算
theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
print("最適なパラメータ:", theta_best)

# 回帰直線をプロット
plt.figure(figsize=(8,6))
plt.scatter(X, y, label="データ")
X_new = np.array([[0], [2]])
X_new_b = np.c_[np.ones((2, 1)), X_new]
y_predict = X_new_b.dot(theta_best)
plt.plot(X_new, y_predict, color="red", label="回帰直線")
plt.xlabel("X")
plt.ylabel("y")
plt.title("単回帰モデルの最小二乗解")
plt.legend()
plt.show()
```

### 5.3 医療データへの応用例: 乳がんデータセットのPCA

- **概要:**  
  医療分野では、多数の測定値から病気の状態を評価する際に、データの次元削減が有効です。ここでは、乳がんデータセットを用いてPCAによりデータの低次元表現を取得し、良性と悪性のサンプルを視覚化します。  
- **具体例:**  
  scikit-learnの乳がんデータセットを利用し、PCAで2次元に縮約して、各クラス（良性、悪性）の分布を散布図で示します。  
- **コード例:**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.decomposition import PCA

# 乳がんデータセットの読み込み
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

# PCAで特徴量を2次元に縮約
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# 結果の散布図を作成（0: 悪性, 1: 良性）
plt.figure(figsize=(8,6))
plt.scatter(X_pca[y == 0, 0], X_pca[y == 0, 1], alpha=0.7, label='悪性')
plt.scatter(X_pca[y == 1, 0], X_pca[y == 1, 1], alpha=0.7, label='良性')
plt.xlabel('第1主成分')
plt.ylabel('第2主成分')
plt.title('乳がんデータセットのPCA結果')
plt.legend()
plt.show()
```

### 5.4 画像処理への応用例: SVDによる画像の低ランク近似

- **概要:**  
  画像処理では、特に画像圧縮やノイズ除去の分野で線形代数学が活用されます。ここでは、特異値分解（SVD）を用いて画像の低ランク近似を行い、元の画像と近似画像の比較を行います。  
- **具体例:**  
  skimageのサンプル画像を用いて、SVDで画像を分解し、上位の特異値のみを用いた再構成画像を表示します。  
- **コード例:**

```python
import numpy as np
import matplotlib.pyplot as plt
from skimage import data
from skimage.color import rgb2gray

# サンプル画像（カメラ画像）の読み込み
image = data.camera()

# SVD分解
U, s, Vt = np.linalg.svd(image, full_matrices=False)

# 低ランク近似: 特異値の上位 k 個を利用
k = 50
S = np.diag(s[:k])
image_approx = U[:, :k] @ S @ Vt[:k, :]

# 画像の表示
plt.figure(figsize=(12, 6))
plt.subplot(1,2,1)
plt.imshow(image, cmap='gray')
plt.title('元の画像')
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(image_approx, cmap='gray')
plt.title(f'低ランク近似 (k={k})')
plt.axis('off')
plt.show()
```

## 6. 次回の内容
次回から、線形代数学の授業を始めます。特に、ベクトルの基礎から勉強していきます。高校までの内容を忘れてしまったという方も、最初から丁寧に勉強しますので、ついてきてくださいね。